{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1892483000194792, "mean_inference_ms": 2.6012680509111856, "mean_action_processing_ms": 0.1340301442535329, "mean_env_wait_ms": 0.11281251827955167, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 6000, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 3219.002, "sample_throughput": 1863.932, "learn_time_ms": 18863.601, "learn_throughput": 318.073, "update_time_ms": 6.035}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 980098.5744680851, "policy_loss": -0.028334343092555694, "vf_loss": 980098.6010638297, "vf_explained_var": -1.0, "kl": 0.0032459948202000653, "entropy": 2.8389832821298153, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 980109.7114361703, "policy_loss": 0.018480457920343318, "vf_loss": 980109.6954787234, "vf_explained_var": -1.0, "kl": 0.004138098440152851, "entropy": 2.8405147816272494, "entropy_coeff": 0.0}}}, "num_steps_sampled": 6000, "num_agent_steps_sampled": 12000, "num_steps_trained": 6000, "num_agent_steps_trained": 12000}, "done": false, "episodes_total": 6, "training_iteration": 1, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-15-41", "timestamp": 1624918541, "time_this_iter_s": 22.09586501121521, "time_total_s": 22.09586501121521, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc980dd6048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980dd60d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.09586501121521, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 26.270000000000003, "ram_util_percent": 59.116666666666674, "gpu_util_percent0": 0.2773333333333333, "vram_util_percent0": 0.23579934838782163}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20018058014008763, "mean_inference_ms": 2.721312560639321, "mean_action_processing_ms": 0.13981411800787866, "mean_env_wait_ms": 0.11713492260701276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 12000, "agent_timesteps_total": 24000, "timers": {"sample_time_ms": 3488.929, "sample_throughput": 1719.726, "learn_time_ms": 18135.437, "learn_throughput": 330.844, "update_time_ms": 6.152}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 960236.5465425532, "policy_loss": -0.0005400673823153719, "vf_loss": 960236.5478723404, "vf_explained_var": -1.0, "kl": 0.01683812120810468, "entropy": 2.7450533319026866, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 970853.9082446808, "policy_loss": -0.003128896625910668, "vf_loss": 970853.9175531915, "vf_explained_var": -1.0, "kl": 0.006080166288116511, "entropy": 2.8846323642324894, "entropy_coeff": 0.0}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 24000, "num_steps_trained": 12000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 12, "training_iteration": 2, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-16-02", "timestamp": 1624918562, "time_this_iter_s": 21.179829835891724, "time_total_s": 43.275694847106934, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fca9887e6a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980db9ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 43.275694847106934, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 26.225, "ram_util_percent": 58.93214285714286, "gpu_util_percent0": 0.25285714285714284, "vram_util_percent0": 0.23521835427801058}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20396716462830988, "mean_inference_ms": 2.7790869112803356, "mean_action_processing_ms": 0.1427280169483417, "mean_env_wait_ms": 0.11944100670957424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 18000, "agent_timesteps_total": 36000, "timers": {"sample_time_ms": 3556.439, "sample_throughput": 1687.081, "learn_time_ms": 18148.206, "learn_throughput": 330.611, "update_time_ms": 6.08}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 940439.9215425532, "policy_loss": 0.003652825416561137, "vf_loss": 940439.9015957447, "vf_explained_var": -1.0, "kl": 0.017394874561974343, "entropy": 2.6322980332881847, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 963106.4069148937, "policy_loss": -0.0015115007124048598, "vf_loss": 963106.4135638297, "vf_explained_var": -1.0, "kl": 0.004104363167301771, "entropy": 2.8738861388348518, "entropy_coeff": 0.0}}}, "num_steps_sampled": 18000, "num_agent_steps_sampled": 36000, "num_steps_trained": 18000, "num_agent_steps_trained": 36000}, "done": false, "episodes_total": 18, "training_iteration": 3, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-16-24", "timestamp": 1624918584, "time_this_iter_s": 21.879757165908813, "time_total_s": 65.15545201301575, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc9805b1730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc9805b1158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 65.15545201301575, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 24.720689655172414, "ram_util_percent": 59.27931034482759, "gpu_util_percent0": 0.25689655172413794, "vram_util_percent0": 0.2366142510140279}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20738685866778275, "mean_inference_ms": 2.822692646510134, "mean_action_processing_ms": 0.14488147251457556, "mean_env_wait_ms": 0.12122604181359532, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 24000, "agent_timesteps_total": 48000, "timers": {"sample_time_ms": 3622.845, "sample_throughput": 1656.157, "learn_time_ms": 18324.722, "learn_throughput": 327.427, "update_time_ms": 5.856}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 920850.7087765958, "policy_loss": -0.0034870594700283195, "vf_loss": 920850.722074468, "vf_explained_var": -1.0, "kl": 0.0125516081585529, "entropy": 2.644461971648196, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 956120.6263297872, "policy_loss": -0.0037249610462087267, "vf_loss": 956120.6236702128, "vf_explained_var": -1.0, "kl": 0.01197962855246473, "entropy": 2.7300955589781415, "entropy_coeff": 0.0}}}, "num_steps_sampled": 24000, "num_agent_steps_sampled": 48000, "num_steps_trained": 24000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 24, "training_iteration": 4, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-16-47", "timestamp": 1624918607, "time_this_iter_s": 22.689498901367188, "time_total_s": 87.84495091438293, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc9805a3488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc9805a3400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 87.84495091438293, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 26.993333333333336, "ram_util_percent": 59.18, "gpu_util_percent0": 0.2586666666666667, "vram_util_percent0": 0.23762498595663403}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20976347064137071, "mean_inference_ms": 2.8608803613193317, "mean_action_processing_ms": 0.14678120241208636, "mean_env_wait_ms": 0.1227506050463822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 30000, "agent_timesteps_total": 60000, "timers": {"sample_time_ms": 3688.795, "sample_throughput": 1626.547, "learn_time_ms": 18256.433, "learn_throughput": 328.651, "update_time_ms": 5.713}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 901448.2579787234, "policy_loss": -0.026503047628447095, "vf_loss": 901448.2739361703, "vf_explained_var": -1.0, "kl": 0.051848660124109144, "entropy": 2.936044271956099, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 948839.8723404255, "policy_loss": -0.002637082116400942, "vf_loss": 948839.8829787234, "vf_explained_var": -1.0, "kl": 0.009646417057894647, "entropy": 2.732432121926166, "entropy_coeff": 0.0}}}, "num_steps_sampled": 30000, "num_agent_steps_sampled": 60000, "num_steps_trained": 30000, "num_agent_steps_trained": 60000}, "done": false, "episodes_total": 30, "training_iteration": 5, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-17-09", "timestamp": 1624918629, "time_this_iter_s": 21.948562145233154, "time_total_s": 109.79351305961609, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc980dd6510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980dd6598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 109.79351305961609, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 27.727586206896554, "ram_util_percent": 59.15172413793105, "gpu_util_percent0": 0.24862068965517242, "vram_util_percent0": 0.23729414362586151}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21112811740719753, "mean_inference_ms": 2.8832879021250912, "mean_action_processing_ms": 0.1479083830822835, "mean_env_wait_ms": 0.12364907385061594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 36000, "agent_timesteps_total": 72000, "timers": {"sample_time_ms": 3666.597, "sample_throughput": 1636.395, "learn_time_ms": 17717.528, "learn_throughput": 338.648, "update_time_ms": 5.678}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.15000000000000008, "cur_lr": 5.000000000000002e-05, "total_loss": 882246.0784574468, "policy_loss": 0.06438480111512732, "vf_loss": 882246.0013297872, "vf_explained_var": "null", "kl": 0.030678572846536942, "entropy": 2.972508151480492, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 942214.3537234042, "policy_loss": -0.0026419312554471037, "vf_loss": 942214.3563829787, "vf_explained_var": -1.0, "kl": 0.00964525756128925, "entropy": 2.8574487452811383, "entropy_coeff": 0.0}}}, "num_steps_sampled": 36000, "num_agent_steps_sampled": 72000, "num_steps_trained": 36000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 36, "training_iteration": 6, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-17-27", "timestamp": 1624918647, "time_this_iter_s": 18.59135341644287, "time_total_s": 128.38486647605896, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc980dd6158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980dd6bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 128.38486647605896, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 23.344, "ram_util_percent": 59.37200000000001, "gpu_util_percent0": 0.24600000000000002, "vram_util_percent0": 0.23562521065048872}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21185518167443235, "mean_inference_ms": 2.895289392465757, "mean_action_processing_ms": 0.14851114111354166, "mean_env_wait_ms": 0.12413885792948727, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 42000, "agent_timesteps_total": 84000, "timers": {"sample_time_ms": 3625.635, "sample_throughput": 1654.883, "learn_time_ms": 17364.621, "learn_throughput": 345.53, "update_time_ms": 5.609}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 863240.4122340425, "policy_loss": -0.09299065442161357, "vf_loss": 863240.4973404255, "vf_explained_var": "null", "kl": 0.058880319145131615, "entropy": 2.96071775923384, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 933034.5079787234, "policy_loss": -0.0003779524580595341, "vf_loss": 933034.5066489362, "vf_explained_var": -1.0, "kl": 0.015536805614829063, "entropy": 2.9180250472210822, "entropy_coeff": 0.0}}}, "num_steps_sampled": 42000, "num_agent_steps_sampled": 84000, "num_steps_trained": 42000, "num_agent_steps_trained": 84000}, "done": false, "episodes_total": 42, "training_iteration": 7, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-17-46", "timestamp": 1624918666, "time_this_iter_s": 18.63923406600952, "time_total_s": 147.02410054206848, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc98059b2f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc98059b268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 147.02410054206848, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 22.979166666666668, "ram_util_percent": 59.45416666666667, "gpu_util_percent0": 0.2141666666666667, "vram_util_percent0": 0.23481209976407144}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2125025715811557, "mean_inference_ms": 2.904422405865308, "mean_action_processing_ms": 0.1489670215887584, "mean_env_wait_ms": 0.12449666070450556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 48000, "agent_timesteps_total": 96000, "timers": {"sample_time_ms": 3634.861, "sample_throughput": 1650.682, "learn_time_ms": 17487.177, "learn_throughput": 343.109, "update_time_ms": 5.721}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 844436.2406914893, "policy_loss": 0.11270927354455629, "vf_loss": 844436.1210106383, "vf_explained_var": "null", "kl": 0.021888855408797873, "entropy": 2.8776356717373464, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 926956.6343085107, "policy_loss": -0.005387443236689618, "vf_loss": 926956.6329787234, "vf_explained_var": -1.0, "kl": 0.016029712625164935, "entropy": 3.0585488664343004, "entropy_coeff": 0.0}}}, "num_steps_sampled": 48000, "num_agent_steps_sampled": 96000, "num_steps_trained": 48000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 48, "training_iteration": 8, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-18-08", "timestamp": 1624918688, "time_this_iter_s": 22.059041023254395, "time_total_s": 169.08314156532288, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc98059b950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc98059b840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 169.08314156532288, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 26.496666666666666, "ram_util_percent": 59.343333333333334, "gpu_util_percent0": 0.25533333333333336, "vram_util_percent0": 0.23611391978429389}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21324840397566647, "mean_inference_ms": 2.915178737964647, "mean_action_processing_ms": 0.14949666627314115, "mean_env_wait_ms": 0.12489915213607328, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 54000, "agent_timesteps_total": 108000, "timers": {"sample_time_ms": 3681.401, "sample_throughput": 1629.814, "learn_time_ms": 17340.242, "learn_throughput": 346.016, "update_time_ms": 5.679}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 825855.6010638297, "policy_loss": -0.0056827838750595746, "vf_loss": 825855.5890957447, "vf_explained_var": "null", "kl": 0.024252176522574526, "entropy": 3.0654506480440182, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 916137.2739361703, "policy_loss": 0.0011262775180821724, "vf_loss": 916137.2819148937, "vf_explained_var": -1.0, "kl": 0.03136910676480608, "entropy": 2.886698732984827, "entropy_coeff": 0.0}}}, "num_steps_sampled": 54000, "num_agent_steps_sampled": 108000, "num_steps_trained": 54000, "num_agent_steps_trained": 108000}, "done": false, "episodes_total": 54, "training_iteration": 9, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-18-28", "timestamp": 1624918708, "time_this_iter_s": 20.231253385543823, "time_total_s": 189.3143949508667, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc9805a38c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc9805a3840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 189.3143949508667, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 28.126923076923074, "ram_util_percent": 59.169230769230765, "gpu_util_percent0": 0.2461538461538461, "vram_util_percent0": 0.23439890072852657}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2137447050316628, "mean_inference_ms": 2.9244741651171666, "mean_action_processing_ms": 0.14989775861760338, "mean_env_wait_ms": 0.1252009121998235, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 60000, "agent_timesteps_total": 120000, "timers": {"sample_time_ms": 3686.912, "sample_throughput": 1627.378, "learn_time_ms": 17101.34, "learn_throughput": 350.85, "update_time_ms": 5.615}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 807480.4906914893, "policy_loss": 0.039028017880751734, "vf_loss": 807480.4055851063, "vf_explained_var": "null", "kl": 0.045502878249959744, "entropy": 3.1084412310985807, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 905152.8843085107, "policy_loss": -0.0030753079484751884, "vf_loss": 905152.8869680851, "vf_explained_var": -1.0, "kl": 0.0107959366027028, "entropy": 2.918363829876514, "entropy_coeff": 0.0}}}, "num_steps_sampled": 60000, "num_agent_steps_sampled": 120000, "num_steps_trained": 60000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 60, "training_iteration": 10, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-18-47", "timestamp": 1624918727, "time_this_iter_s": 18.700011253356934, "time_total_s": 208.01440620422363, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc980dd6ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980dd6b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 208.01440620422363, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 24.247999999999998, "ram_util_percent": 59.336000000000006, "gpu_util_percent0": 0.2208, "vram_util_percent0": 0.23245028648466465}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21398026844102597, "mean_inference_ms": 2.930073196158512, "mean_action_processing_ms": 0.1501316561846935, "mean_env_wait_ms": 0.1253773193053208, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 66000, "agent_timesteps_total": 132000, "timers": {"sample_time_ms": 3702.019, "sample_throughput": 1620.737, "learn_time_ms": 16704.962, "learn_throughput": 359.175, "update_time_ms": 5.525}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 789297.1675531915, "policy_loss": 0.20447591501981655, "vf_loss": 789296.9361702128, "vf_explained_var": "null", "kl": 0.008290008750763979, "entropy": 3.051836272503467, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 890414.6077127659, "policy_loss": -0.0047621430254521525, "vf_loss": 890414.6183510638, "vf_explained_var": -1.0, "kl": 0.011399229195840816, "entropy": 2.8463736848628267, "entropy_coeff": 0.0}}}, "num_steps_sampled": 66000, "num_agent_steps_sampled": 132000, "num_steps_trained": 66000, "num_agent_steps_trained": 132000}, "done": false, "episodes_total": 66, "training_iteration": 11, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-19-05", "timestamp": 1624918745, "time_this_iter_s": 18.28271460533142, "time_total_s": 226.29712080955505, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc980e13488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980e13d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 226.29712080955505, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 22.156, "ram_util_percent": 59.596000000000004, "gpu_util_percent0": 0.22880000000000003, "vram_util_percent0": 0.23245702730030332}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21419735660146363, "mean_inference_ms": 2.9351562347136753, "mean_action_processing_ms": 0.15033780671903324, "mean_env_wait_ms": 0.12553154510593836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 72000, "agent_timesteps_total": 144000, "timers": {"sample_time_ms": 3702.912, "sample_throughput": 1620.346, "learn_time_ms": 16473.487, "learn_throughput": 364.222, "update_time_ms": 5.396}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 771317.1742021276, "policy_loss": -0.5376605905116872, "vf_loss": 771317.6755319149, "vf_explained_var": "null", "kl": 0.013950760079983702, "entropy": 2.9636677884040994, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 880778.2566489362, "policy_loss": -0.0032069501566125993, "vf_loss": 880778.2553191489, "vf_explained_var": -1.0, "kl": 0.007867774183049481, "entropy": 2.732597868493263, "entropy_coeff": 0.0}}}, "num_steps_sampled": 72000, "num_agent_steps_sampled": 144000, "num_steps_trained": 72000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 72, "training_iteration": 12, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-19-24", "timestamp": 1624918764, "time_this_iter_s": 18.873669624328613, "time_total_s": 245.17079043388367, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fca94016e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980dd6488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 245.17079043388367, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 24.236, "ram_util_percent": 59.071999999999996, "gpu_util_percent0": 0.21799999999999997, "vram_util_percent0": 0.23107516009437146}, "trial_id": "4cf87_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_max": {"pol0": -10990.0, "pol1": 10990.0}, "policy_reward_mean": {"pol0": -10990.0, "pol1": 10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0], "policy_pol1_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21426843674751508, "mean_inference_ms": 2.9380503761528, "mean_action_processing_ms": 0.15044115261853294, "mean_env_wait_ms": 0.1256088297800264, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 78000, "agent_timesteps_total": 156000, "timers": {"sample_time_ms": 3676.85, "sample_throughput": 1631.832, "learn_time_ms": 16291.743, "learn_throughput": 368.285, "update_time_ms": 5.352}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 753547.0531914893, "policy_loss": 0.13388440393387002, "vf_loss": 753546.9308510638, "vf_explained_var": "null", "kl": 0.009022858984609868, "entropy": 2.9488454169415412, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 865272.0053191489, "policy_loss": -0.00026150239988210355, "vf_loss": 865271.9973404255, "vf_explained_var": -1.0, "kl": 0.012753841288863345, "entropy": 2.7501833337418575, "entropy_coeff": 0.0}}}, "num_steps_sampled": 78000, "num_agent_steps_sampled": 156000, "num_steps_trained": 78000, "num_agent_steps_trained": 156000}, "done": false, "episodes_total": 78, "training_iteration": 13, "experiment_id": "ab1fb181a03846b09844fcaa1323ce0d", "date": "2021-06-29_01-19-44", "timestamp": 1624918784, "time_this_iter_s": 19.799433708190918, "time_total_s": 264.9702241420746, "pid": 8614, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fc980dd62f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fc980dd6ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 264.9702241420746, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 24.323076923076922, "ram_util_percent": 59.23076923076923, "gpu_util_percent0": 0.22846153846153847, "vram_util_percent0": 0.2317997977755308}, "trial_id": "4cf87_00000"}
