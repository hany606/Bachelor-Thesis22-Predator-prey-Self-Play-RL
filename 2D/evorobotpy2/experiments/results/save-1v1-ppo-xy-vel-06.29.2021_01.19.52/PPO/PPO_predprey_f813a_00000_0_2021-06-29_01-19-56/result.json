{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17015519970191453, "mean_inference_ms": 2.3303886928799464, "mean_action_processing_ms": 0.11976599613984107, "mean_env_wait_ms": 0.10134288650786805, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 6006, "agent_timesteps_total": 12012, "timers": {"sample_time_ms": 2841.769, "sample_throughput": 2113.472, "learn_time_ms": 14746.864, "learn_throughput": 407.273, "update_time_ms": 5.896}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 980094.6555851063, "policy_loss": -0.00953188716889696, "vf_loss": 980094.659574468, "vf_explained_var": -1.0, "kl": 0.005305458157462009, "entropy": 2.8181456200619963, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 980106.9507978724, "policy_loss": -0.019886232991801932, "vf_loss": 980106.9481382979, "vf_explained_var": -1.0, "kl": 0.004356511576259707, "entropy": 2.830570865184703, "entropy_coeff": 0.0}}}, "num_steps_sampled": 6006, "num_agent_steps_sampled": 12012, "num_steps_trained": 6006, "num_agent_steps_trained": 12012}, "done": false, "episodes_total": 6, "training_iteration": 1, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-20-23", "timestamp": 1624918823, "time_this_iter_s": 17.601428270339966, "time_total_s": 17.601428270339966, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17.601428270339966, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 19.462500000000002, "ram_util_percent": 58.895833333333336, "gpu_util_percent0": 0.21750000000000003, "vram_util_percent0": 0.230058420402202}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17787620917904076, "mean_inference_ms": 2.470262742676414, "mean_action_processing_ms": 0.12662029232651842, "mean_env_wait_ms": 0.10663801254850087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 12012, "agent_timesteps_total": 24024, "timers": {"sample_time_ms": 3191.38, "sample_throughput": 1881.945, "learn_time_ms": 14817.026, "learn_throughput": 405.344, "update_time_ms": 5.871}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 960175.4574468085, "policy_loss": -0.0021225126024256363, "vf_loss": 960175.4640957447, "vf_explained_var": -1.0, "kl": 0.010314477171669615, "entropy": 2.8712184175531914, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 978851.1795212766, "policy_loss": -0.00342785073642401, "vf_loss": 978851.1848404255, "vf_explained_var": -1.0, "kl": 0.008174942122732705, "entropy": 2.8368123693669096, "entropy_coeff": 0.0}}}, "num_steps_sampled": 12012, "num_agent_steps_sampled": 24024, "num_steps_trained": 12012, "num_agent_steps_trained": 24024}, "done": false, "episodes_total": 12, "training_iteration": 2, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-20-41", "timestamp": 1624918841, "time_this_iter_s": 18.44131112098694, "time_total_s": 36.042739391326904, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c0d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 36.042739391326904, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 22.945833333333336, "ram_util_percent": 59.0875, "gpu_util_percent0": 0.22624999999999998, "vram_util_percent0": 0.23069037186832939}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18218470730410397, "mean_inference_ms": 2.539777186389219, "mean_action_processing_ms": 0.13003283244826636, "mean_env_wait_ms": 0.10921234897172911, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 18018, "agent_timesteps_total": 36036, "timers": {"sample_time_ms": 3337.657, "sample_throughput": 1799.466, "learn_time_ms": 14852.229, "learn_throughput": 404.384, "update_time_ms": 5.586}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 940390.3843085107, "policy_loss": 0.006955183725407783, "vf_loss": 940390.3537234042, "vf_explained_var": -1.0, "kl": 0.019141219556331635, "entropy": 2.9506066352763076, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 978071.2393617021, "policy_loss": -0.004434315289588685, "vf_loss": 978071.2446808511, "vf_explained_var": -1.0, "kl": 0.007620307725874033, "entropy": 2.9018383837760764, "entropy_coeff": 0.0}}}, "num_steps_sampled": 18018, "num_agent_steps_sampled": 36036, "num_steps_trained": 18018, "num_agent_steps_trained": 36036}, "done": false, "episodes_total": 18, "training_iteration": 3, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-21-00", "timestamp": 1624918860, "time_this_iter_s": 18.56571650505066, "time_total_s": 54.60845589637756, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b026f950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b026f378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 54.60845589637756, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 22.532000000000004, "ram_util_percent": 59.156000000000006, "gpu_util_percent0": 0.226, "vram_util_percent0": 0.23069093360296594}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1852664900338797, "mean_inference_ms": 2.5819045968709404, "mean_action_processing_ms": 0.13213967328960816, "mean_env_wait_ms": 0.1107950715474028, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 24024, "agent_timesteps_total": 48048, "timers": {"sample_time_ms": 3384.61, "sample_throughput": 1774.503, "learn_time_ms": 14898.23, "learn_throughput": 403.135, "update_time_ms": 5.565}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 920799.7739361703, "policy_loss": 0.003779453284879948, "vf_loss": 920799.7699468085, "vf_explained_var": -1.0, "kl": 0.016594116001370104, "entropy": 3.0078660985256764, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 972814.0571808511, "policy_loss": -0.0023716190988396077, "vf_loss": 972814.0585106383, "vf_explained_var": -1.0, "kl": 0.006321538913440197, "entropy": 2.7354107562531818, "entropy_coeff": 0.0}}}, "num_steps_sampled": 24024, "num_agent_steps_sampled": 48048, "num_steps_trained": 24024, "num_agent_steps_trained": 48048}, "done": false, "episodes_total": 24, "training_iteration": 4, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-21-18", "timestamp": 1624918878, "time_this_iter_s": 18.57460045814514, "time_total_s": 73.1830563545227, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b025e6a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 73.1830563545227, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 22.484, "ram_util_percent": 59.20000000000001, "gpu_util_percent0": 0.2224, "vram_util_percent0": 0.23071789686552077}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18777159378134306, "mean_inference_ms": 2.617003275930861, "mean_action_processing_ms": 0.13391993324700066, "mean_env_wait_ms": 0.1121235258857743, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 30030, "agent_timesteps_total": 60060, "timers": {"sample_time_ms": 3416.055, "sample_throughput": 1758.168, "learn_time_ms": 14904.649, "learn_throughput": 402.962, "update_time_ms": 5.489}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 901387.1622340425, "policy_loss": 0.015489909758276127, "vf_loss": 901387.1409574468, "vf_explained_var": -1.0, "kl": 0.04084814316097726, "entropy": 3.0426686418817397, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 977055.4827127659, "policy_loss": -6.493924066741416e-05, "vf_loss": 977055.4853723404, "vf_explained_var": -1.0, "kl": 0.009529094330649426, "entropy": 2.7688436812542854, "entropy_coeff": 0.0}}}, "num_steps_sampled": 30030, "num_agent_steps_sampled": 60060, "num_steps_trained": 30030, "num_agent_steps_trained": 60060}, "done": false, "episodes_total": 30, "training_iteration": 5, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-21-37", "timestamp": 1624918897, "time_this_iter_s": 18.500974655151367, "time_total_s": 91.68403100967407, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02ded90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02de510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 91.68403100967407, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 23.324, "ram_util_percent": 59.19200000000001, "gpu_util_percent0": 0.22560000000000002, "vram_util_percent0": 0.23073811931243682}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1896490300884112, "mean_inference_ms": 2.640998854351153, "mean_action_processing_ms": 0.13513233397031982, "mean_env_wait_ms": 0.11304179079122946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 36036, "agent_timesteps_total": 72072, "timers": {"sample_time_ms": 3405.333, "sample_throughput": 1763.704, "learn_time_ms": 14922.329, "learn_throughput": 402.484, "update_time_ms": 5.42}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 882182.597074468, "policy_loss": 0.02345181351646464, "vf_loss": 882182.5718085107, "vf_explained_var": -1.0, "kl": 0.028316943212709528, "entropy": 2.8168453358589334, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 966464.2593085107, "policy_loss": -0.000559674932601604, "vf_loss": 966464.2619680851, "vf_explained_var": -1.0, "kl": 0.00947732195020356, "entropy": 2.8157175906161043, "entropy_coeff": 0.0}}}, "num_steps_sampled": 36036, "num_agent_steps_sampled": 72072, "num_steps_trained": 36036, "num_agent_steps_trained": 72072}, "done": false, "episodes_total": 36, "training_iteration": 6, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-21-55", "timestamp": 1624918915, "time_this_iter_s": 18.37462568283081, "time_total_s": 110.05865669250488, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02ded08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02def28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 110.05865669250488, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 23.237499999999997, "ram_util_percent": 59.19166666666667, "gpu_util_percent0": 0.22166666666666668, "vram_util_percent0": 0.23074654533198516}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19102042602258962, "mean_inference_ms": 2.659915549805456, "mean_action_processing_ms": 0.13608090558179245, "mean_env_wait_ms": 0.11376259112751386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 42042, "agent_timesteps_total": 84084, "timers": {"sample_time_ms": 3432.917, "sample_throughput": 1749.533, "learn_time_ms": 14941.406, "learn_throughput": 401.97, "update_time_ms": 5.407}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 863181.8257978724, "policy_loss": 0.026676872824417785, "vf_loss": 863181.7925531915, "vf_explained_var": "null", "kl": 0.01369985662638507, "entropy": 2.730762035288709, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 971481.2034574468, "policy_loss": -0.006066452830712846, "vf_loss": 971481.2061170213, "vf_explained_var": -1.0, "kl": 0.007938762294485214, "entropy": 2.826384645827273, "entropy_coeff": 0.0}}}, "num_steps_sampled": 42042, "num_agent_steps_sampled": 84084, "num_steps_trained": 42042, "num_agent_steps_trained": 84084}, "done": false, "episodes_total": 42, "training_iteration": 7, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-22-14", "timestamp": 1624918934, "time_this_iter_s": 18.667545795440674, "time_total_s": 128.72620248794556, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0269510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0269488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 128.72620248794556, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 22.543999999999997, "ram_util_percent": 59.268, "gpu_util_percent0": 0.21960000000000002, "vram_util_percent0": 0.23071789686552077}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19220131960343323, "mean_inference_ms": 2.6747288288479454, "mean_action_processing_ms": 0.13682938132043232, "mean_env_wait_ms": 0.11434265038944685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 48048, "agent_timesteps_total": 96096, "timers": {"sample_time_ms": 3422.533, "sample_throughput": 1754.841, "learn_time_ms": 14943.081, "learn_throughput": 401.925, "update_time_ms": 5.361}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 844392.8962765958, "policy_loss": 0.009176158564204865, "vf_loss": 844392.8710106383, "vf_explained_var": -1.0, "kl": 0.03065949004698307, "entropy": 2.7824871489342224, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 968750.7819148937, "policy_loss": -2.352065069878355e-05, "vf_loss": 968750.7819148937, "vf_explained_var": -1.0, "kl": 0.01258455811345831, "entropy": 2.8119157273718653, "entropy_coeff": 0.0}}}, "num_steps_sampled": 48048, "num_agent_steps_sampled": 96096, "num_steps_trained": 48048, "num_agent_steps_trained": 96096}, "done": false, "episodes_total": 48, "training_iteration": 8, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-22-33", "timestamp": 1624918953, "time_this_iter_s": 18.317615270614624, "time_total_s": 147.04381775856018, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0269a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0269f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 147.04381775856018, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 23.162499999999998, "ram_util_percent": 59.20000000000001, "gpu_util_percent0": 0.22333333333333336, "vram_util_percent0": 0.23069739355128638}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19319319838208493, "mean_inference_ms": 2.686669509322425, "mean_action_processing_ms": 0.13744538252398214, "mean_env_wait_ms": 0.1148147541598546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 54054, "agent_timesteps_total": 108108, "timers": {"sample_time_ms": 3425.575, "sample_throughput": 1753.282, "learn_time_ms": 14954.268, "learn_throughput": 401.624, "update_time_ms": 5.351}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 825804.0478723404, "policy_loss": -0.8605119357717798, "vf_loss": 825804.875, "vf_explained_var": "null", "kl": 0.031305843250865634, "entropy": 2.6436485584746015, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 970459.1928191489, "policy_loss": -0.001737947833347828, "vf_loss": 970459.1954787234, "vf_explained_var": -1.0, "kl": 0.00993727379419068, "entropy": 2.7807453135226634, "entropy_coeff": 0.0}}}, "num_steps_sampled": 54054, "num_agent_steps_sampled": 108108, "num_steps_trained": 54054, "num_agent_steps_trained": 108108}, "done": false, "episodes_total": 54, "training_iteration": 9, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-22-51", "timestamp": 1624918971, "time_this_iter_s": 18.50633478164673, "time_total_s": 165.5501525402069, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02dee18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02de510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 165.5501525402069, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 22.476, "ram_util_percent": 59.19600000000001, "gpu_util_percent0": 0.22640000000000002, "vram_util_percent0": 0.23069767441860467}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1940331454520739, "mean_inference_ms": 2.6979238538319525, "mean_action_processing_ms": 0.13796759436988276, "mean_env_wait_ms": 0.11521676114487174, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 60060, "agent_timesteps_total": 120120, "timers": {"sample_time_ms": 3437.2, "sample_throughput": 1747.353, "learn_time_ms": 14972.691, "learn_throughput": 401.13, "update_time_ms": 5.309}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 807427.2952127659, "policy_loss": -0.06029507402885467, "vf_loss": 807427.3497340425, "vf_explained_var": -1.0, "kl": 0.007402609023166464, "entropy": 2.6749635503647173, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 961968.2234042553, "policy_loss": 0.001925649161034442, "vf_loss": 961968.227393617, "vf_explained_var": -1.0, "kl": 0.0207658523812573, "entropy": 2.8549205698865525, "entropy_coeff": 0.0}}}, "num_steps_sampled": 60060, "num_agent_steps_sampled": 120120, "num_steps_trained": 60060, "num_agent_steps_trained": 120120}, "done": false, "episodes_total": 60, "training_iteration": 10, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-23-10", "timestamp": 1624918990, "time_this_iter_s": 18.692390203475952, "time_total_s": 184.24254274368286, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02e5ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02e5950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 184.24254274368286, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 22.868, "ram_util_percent": 59.20000000000001, "gpu_util_percent0": 0.2228, "vram_util_percent0": 0.23070441523424334}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19471820196109568, "mean_inference_ms": 2.707155051989038, "mean_action_processing_ms": 0.13840016614768239, "mean_env_wait_ms": 0.11555371566520793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 66066, "agent_timesteps_total": 132132, "timers": {"sample_time_ms": 3503.839, "sample_throughput": 1714.12, "learn_time_ms": 14999.808, "learn_throughput": 400.405, "update_time_ms": 5.227}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 789244.6914893617, "policy_loss": 0.7757280494304414, "vf_loss": 789243.8776595745, "vf_explained_var": "null", "kl": 0.008694407629205826, "entropy": 2.6659974088060094, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.15000000000000008, "cur_lr": 5.000000000000002e-05, "total_loss": 974269.1449468085, "policy_loss": -0.0038212658242976413, "vf_loss": 974269.1449468085, "vf_explained_var": -1.0, "kl": 0.006313195273755712, "entropy": 3.0748035146835004, "entropy_coeff": 0.0}}}, "num_steps_sampled": 66066, "num_agent_steps_sampled": 132132, "num_steps_trained": 66066, "num_agent_steps_trained": 132132}, "done": false, "episodes_total": 66, "training_iteration": 11, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-23-28", "timestamp": 1624919008, "time_this_iter_s": 18.53864097595215, "time_total_s": 202.781183719635, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0250c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02506a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 202.781183719635, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 23.01666666666667, "ram_util_percent": 59.287499999999994, "gpu_util_percent0": 0.22208333333333333, "vram_util_percent0": 0.22944051230198856}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19529186374803198, "mean_inference_ms": 2.714905894026538, "mean_action_processing_ms": 0.13877103285559908, "mean_env_wait_ms": 0.11584141592113295, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 72072, "agent_timesteps_total": 144144, "timers": {"sample_time_ms": 3503.195, "sample_throughput": 1714.435, "learn_time_ms": 15004.421, "learn_throughput": 400.282, "update_time_ms": 5.179}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 771265.4454787234, "policy_loss": -0.027801510124923066, "vf_loss": 771265.4614361703, "vf_explained_var": "null", "kl": 0.008398516083809924, "entropy": 2.681027331250779, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.15000000000000008, "cur_lr": 5.000000000000002e-05, "total_loss": 967185.0159574468, "policy_loss": -0.00019313761607763616, "vf_loss": 967185.0186170213, "vf_explained_var": -1.0, "kl": 0.021011574114573762, "entropy": 2.924890411661026, "entropy_coeff": 0.0}}}, "num_steps_sampled": 72072, "num_agent_steps_sampled": 144144, "num_steps_trained": 72072, "num_agent_steps_trained": 144144}, "done": false, "episodes_total": 72, "training_iteration": 12, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-23-47", "timestamp": 1624919027, "time_this_iter_s": 18.481027126312256, "time_total_s": 221.26221084594727, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c6a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 221.26221084594727, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 22.272000000000002, "ram_util_percent": 59.29599999999999, "gpu_util_percent0": 0.2232, "vram_util_percent0": 0.22923491742500843}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19578690051577302, "mean_inference_ms": 2.7216626803472783, "mean_action_processing_ms": 0.13909840871652407, "mean_env_wait_ms": 0.11609353531967913, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 78078, "agent_timesteps_total": 156156, "timers": {"sample_time_ms": 3494.883, "sample_throughput": 1718.513, "learn_time_ms": 15011.497, "learn_throughput": 400.093, "update_time_ms": 5.189}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 753495.2433510638, "policy_loss": 0.011135545380889102, "vf_loss": 753495.2406914893, "vf_explained_var": "null", "kl": 0.005630995790929871, "entropy": 2.752327340714475, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 964322.0518617021, "policy_loss": -0.0027339780267248764, "vf_loss": 964322.0625, "vf_explained_var": -1.0, "kl": 0.006750771181380495, "entropy": 3.02474437368677, "entropy_coeff": 0.0}}}, "num_steps_sampled": 78078, "num_agent_steps_sampled": 156156, "num_steps_trained": 78078, "num_agent_steps_trained": 156156}, "done": false, "episodes_total": 78, "training_iteration": 13, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-24-05", "timestamp": 1624919045, "time_this_iter_s": 18.55327820777893, "time_total_s": 239.8154890537262, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028ca60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028cd90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 239.8154890537262, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 23.035999999999998, "ram_util_percent": 59.30399999999999, "gpu_util_percent0": 0.22, "vram_util_percent0": 0.22920795416245365}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19626497636698553, "mean_inference_ms": 2.727599642739843, "mean_action_processing_ms": 0.13938800814429214, "mean_env_wait_ms": 0.11631350017891003, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 84084, "agent_timesteps_total": 168168, "timers": {"sample_time_ms": 3489.511, "sample_throughput": 1721.158, "learn_time_ms": 15006.597, "learn_throughput": 400.224, "update_time_ms": 5.158}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 735933.7446808511, "policy_loss": 0.1999439571766143, "vf_loss": 735933.5, "vf_explained_var": "null", "kl": 0.0011326253855046123, "entropy": 2.780157337797449, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 968165.2593085107, "policy_loss": -0.0029935721862823406, "vf_loss": 968165.2619680851, "vf_explained_var": -1.0, "kl": 0.009260845965051905, "entropy": 2.7723599849863256, "entropy_coeff": 0.0}}}, "num_steps_sampled": 84084, "num_agent_steps_sampled": 168168, "num_steps_trained": 84084, "num_agent_steps_trained": 168168}, "done": false, "episodes_total": 84, "training_iteration": 14, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-24-24", "timestamp": 1624919064, "time_this_iter_s": 18.472339630126953, "time_total_s": 258.28782868385315, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b025e378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b025e2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 258.28782868385315, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 23.266666666666666, "ram_util_percent": 59.29999999999999, "gpu_util_percent0": 0.22, "vram_util_percent0": 0.22920177508145154}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1966661445047659, "mean_inference_ms": 2.732845666539875, "mean_action_processing_ms": 0.13965110140999254, "mean_env_wait_ms": 0.11651050051321471, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 90090, "agent_timesteps_total": 180180, "timers": {"sample_time_ms": 3484.815, "sample_throughput": 1723.478, "learn_time_ms": 15016.796, "learn_throughput": 399.952, "update_time_ms": 5.146}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 718579.8816489362, "policy_loss": -0.5663598052998806, "vf_loss": 718580.5, "vf_explained_var": "null", "kl": 0.0021469428382338363, "entropy": 2.7646864525815276, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 968548.5757978724, "policy_loss": -0.0026140383028603613, "vf_loss": 968548.5797872341, "vf_explained_var": -1.0, "kl": 0.007179746087244216, "entropy": 2.825493782124621, "entropy_coeff": 0.0}}}, "num_steps_sampled": 90090, "num_agent_steps_sampled": 180180, "num_steps_trained": 90090, "num_agent_steps_trained": 180180}, "done": false, "episodes_total": 90, "training_iteration": 15, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-24-43", "timestamp": 1624919083, "time_this_iter_s": 18.542336225509644, "time_total_s": 276.8301649093628, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b025ea60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b025e950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 276.8301649093628, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 22.328000000000003, "ram_util_percent": 59.29599999999999, "gpu_util_percent0": 0.22759999999999997, "vram_util_percent0": 0.2292281766093697}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19704549214163133, "mean_inference_ms": 2.7377504216370188, "mean_action_processing_ms": 0.1398984679381505, "mean_env_wait_ms": 0.11669569384024703, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 96096, "agent_timesteps_total": 192192, "timers": {"sample_time_ms": 3501.882, "sample_throughput": 1715.078, "learn_time_ms": 15016.749, "learn_throughput": 399.953, "update_time_ms": 5.394}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 701437.1236702128, "policy_loss": 0.9800005935608073, "vf_loss": 701436.125, "vf_explained_var": "null", "kl": 0.023779643223957814, "entropy": 2.9142538588097753, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 970345.2699468085, "policy_loss": -0.0035304897563888673, "vf_loss": 970345.2699468085, "vf_explained_var": -1.0, "kl": 0.007929792934830518, "entropy": 2.8933841928522637, "entropy_coeff": 0.0}}}, "num_steps_sampled": 96096, "num_agent_steps_sampled": 192192, "num_steps_trained": 96096, "num_agent_steps_trained": 192192}, "done": false, "episodes_total": 96, "training_iteration": 16, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-25-01", "timestamp": 1624919101, "time_this_iter_s": 18.55057716369629, "time_total_s": 295.3807420730591, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028cd08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c6a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 295.3807420730591, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 23.052000000000003, "ram_util_percent": 59.368, "gpu_util_percent0": 0.2256, "vram_util_percent0": 0.22924165824064713}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19797981146563415, "mean_inference_ms": 2.749816293702568, "mean_action_processing_ms": 0.14047718026212783, "mean_env_wait_ms": 0.1171520878011542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 102102, "agent_timesteps_total": 204204, "timers": {"sample_time_ms": 3506.096, "sample_throughput": 1713.017, "learn_time_ms": 15000.34, "learn_throughput": 400.391, "update_time_ms": 5.34}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 684501.2393617021, "policy_loss": 0.3052482113559195, "vf_loss": 684500.9015957447, "vf_explained_var": "null", "kl": 0.06366309626622403, "entropy": 3.006646303420371, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 945587.8058510638, "policy_loss": -0.004057701419484108, "vf_loss": 945587.8005319149, "vf_explained_var": -1.0, "kl": 0.009711048684697202, "entropy": 2.8581822172124336, "entropy_coeff": 0.0}}}, "num_steps_sampled": 102102, "num_agent_steps_sampled": 204204, "num_steps_trained": 102102, "num_agent_steps_trained": 204204}, "done": false, "episodes_total": 102, "training_iteration": 17, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-25-20", "timestamp": 1624919120, "time_this_iter_s": 18.54450011253357, "time_total_s": 313.92524218559265, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 313.92524218559265, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 23.09166666666667, "ram_util_percent": 59.324999999999996, "gpu_util_percent0": 0.22541666666666668, "vram_util_percent0": 0.22925092686215032}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1996928937549544, "mean_inference_ms": 2.774621427317296, "mean_action_processing_ms": 0.1417112330383019, "mean_env_wait_ms": 0.11806888881418454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 108108, "agent_timesteps_total": 216216, "timers": {"sample_time_ms": 3532.265, "sample_throughput": 1700.326, "learn_time_ms": 15006.334, "learn_throughput": 400.231, "update_time_ms": 5.389}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 667773.0465425532, "policy_loss": -0.9255788351627107, "vf_loss": 667773.9986702128, "vf_explained_var": "null", "kl": 0.016820058048247023, "entropy": 2.8343011014004973, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 963051.0558510638, "policy_loss": -0.001838590533650936, "vf_loss": 963051.0625, "vf_explained_var": -1.0, "kl": 0.007314876762238589, "entropy": 2.959575795112772, "entropy_coeff": 0.0}}}, "num_steps_sampled": 108108, "num_agent_steps_sampled": 216216, "num_steps_trained": 108108, "num_agent_steps_trained": 216216}, "done": false, "episodes_total": 108, "training_iteration": 18, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-25-38", "timestamp": 1624919138, "time_this_iter_s": 18.639467477798462, "time_total_s": 332.5647096633911, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0254950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0254378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 332.5647096633911, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 22.555999999999997, "ram_util_percent": 59.4, "gpu_util_percent0": 0.22560000000000002, "vram_util_percent0": 0.22924165824064713}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2006910588303625, "mean_inference_ms": 2.783954765513678, "mean_action_processing_ms": 0.14220615971312953, "mean_env_wait_ms": 0.11844791873575239, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 114114, "agent_timesteps_total": 228228, "timers": {"sample_time_ms": 3527.199, "sample_throughput": 1702.767, "learn_time_ms": 14999.488, "learn_throughput": 400.414, "update_time_ms": 5.353}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 651256.2832446808, "policy_loss": 0.7262377815043672, "vf_loss": 651255.5026595745, "vf_explained_var": "null", "kl": 0.015046186507382292, "entropy": 2.9416809183485966, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 961621.5997340425, "policy_loss": 0.0003635880557146478, "vf_loss": 961621.6010638297, "vf_explained_var": "null", "kl": 0.012221485495250275, "entropy": 3.00577586255175, "entropy_coeff": 0.0}}}, "num_steps_sampled": 114114, "num_agent_steps_sampled": 228228, "num_steps_trained": 114114, "num_agent_steps_trained": 228228}, "done": false, "episodes_total": 114, "training_iteration": 19, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-25-57", "timestamp": 1624919157, "time_this_iter_s": 18.386993408203125, "time_total_s": 350.95170307159424, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0254f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02541e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 350.95170307159424, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 23.129166666666666, "ram_util_percent": 59.375, "gpu_util_percent0": 0.22291666666666668, "vram_util_percent0": 0.22921581844736547}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20143428852610004, "mean_inference_ms": 2.791067958456836, "mean_action_processing_ms": 0.14257114259632295, "mean_env_wait_ms": 0.11872975919257518, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 120120, "agent_timesteps_total": 240240, "timers": {"sample_time_ms": 3530.96, "sample_throughput": 1700.954, "learn_time_ms": 14967.07, "learn_throughput": 401.281, "update_time_ms": 5.376}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 634944.8816489362, "policy_loss": -0.8692376004888657, "vf_loss": 634945.7513297872, "vf_explained_var": "null", "kl": 0.015953775019721783, "entropy": 3.0458250451595226, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 917835.8031914893, "policy_loss": 9.075112323811714e-05, "vf_loss": 917835.8018617021, "vf_explained_var": "null", "kl": 0.009320020814366798, "entropy": 2.8842122301142266, "entropy_coeff": 0.0}}}, "num_steps_sampled": 120120, "num_agent_steps_sampled": 240240, "num_steps_trained": 120120, "num_agent_steps_trained": 240240}, "done": false, "episodes_total": 120, "training_iteration": 20, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-26-15", "timestamp": 1624919175, "time_this_iter_s": 18.406663179397583, "time_total_s": 369.3583662509918, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02547b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0254620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 369.3583662509918, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 23.016, "ram_util_percent": 59.29999999999999, "gpu_util_percent0": 0.2224, "vram_util_percent0": 0.22922143579373103}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2019250355711416, "mean_inference_ms": 2.7971877258908666, "mean_action_processing_ms": 0.1428780172419516, "mean_env_wait_ms": 0.1189624572355791, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 126126, "agent_timesteps_total": 252252, "timers": {"sample_time_ms": 3530.978, "sample_throughput": 1700.945, "learn_time_ms": 14963.349, "learn_throughput": 401.381, "update_time_ms": 5.381}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 618844.3683510638, "policy_loss": -0.07895478503184115, "vf_loss": 618844.4507978724, "vf_explained_var": "null", "kl": 0.010151292217221665, "entropy": 2.9507301513184894, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 923659.460106383, "policy_loss": 0.0015559839679205672, "vf_loss": 923659.4534574468, "vf_explained_var": "null", "kl": 0.010505957449687289, "entropy": 2.8584999429418687, "entropy_coeff": 0.0}}}, "num_steps_sampled": 126126, "num_agent_steps_sampled": 252252, "num_steps_trained": 126126, "num_agent_steps_trained": 252252}, "done": false, "episodes_total": 126, "training_iteration": 21, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-26-34", "timestamp": 1624919194, "time_this_iter_s": 18.502061367034912, "time_total_s": 387.86042761802673, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028cb70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 387.86042761802673, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 22.796000000000003, "ram_util_percent": 59.38, "gpu_util_percent0": 0.22640000000000002, "vram_util_percent0": 0.22921469497809233}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2022953341344099, "mean_inference_ms": 2.800631774896577, "mean_action_processing_ms": 0.1430411813547139, "mean_env_wait_ms": 0.11909410369374893, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 132132, "agent_timesteps_total": 264264, "timers": {"sample_time_ms": 3517.377, "sample_throughput": 1707.522, "learn_time_ms": 14960.963, "learn_throughput": 401.445, "update_time_ms": 5.379}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 602951.2034574468, "policy_loss": -0.5122564333550473, "vf_loss": 602951.75, "vf_explained_var": "null", "kl": 0.027597621439936312, "entropy": 2.8897493545045245, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 933550.3125, "policy_loss": -0.004769842140376568, "vf_loss": 933550.3098404255, "vf_explained_var": -1.0, "kl": 0.006427985298982326, "entropy": 2.898152823143817, "entropy_coeff": 0.0}}}, "num_steps_sampled": 132132, "num_agent_steps_sampled": 264264, "num_steps_trained": 132132, "num_agent_steps_trained": 264264}, "done": false, "episodes_total": 132, "training_iteration": 22, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-26-52", "timestamp": 1624919212, "time_this_iter_s": 18.321024417877197, "time_total_s": 406.18145203590393, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02501e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0250a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 406.18145203590393, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 23.245833333333337, "ram_util_percent": 59.387499999999996, "gpu_util_percent0": 0.22999999999999998, "vram_util_percent0": 0.22924390517919338}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20264924018486208, "mean_inference_ms": 2.8046410915760878, "mean_action_processing_ms": 0.1432383657494509, "mean_env_wait_ms": 0.11924727777694269, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 138138, "agent_timesteps_total": 276276, "timers": {"sample_time_ms": 3554.96, "sample_throughput": 1689.47, "learn_time_ms": 15093.791, "learn_throughput": 397.912, "update_time_ms": 5.409}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 587267.2167553192, "policy_loss": -0.40181940730581894, "vf_loss": 587267.597074468, "vf_explained_var": "null", "kl": 0.006097927897613734, "entropy": 2.915803072300363, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 916611.1090425532, "policy_loss": 0.003694017913113249, "vf_loss": 916611.1090425532, "vf_explained_var": -1.0, "kl": 0.01865142165742656, "entropy": 2.7602996826171875, "entropy_coeff": 0.0}}}, "num_steps_sampled": 138138, "num_agent_steps_sampled": 276276, "num_steps_trained": 138138, "num_agent_steps_trained": 276276}, "done": false, "episodes_total": 138, "training_iteration": 23, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-27-12", "timestamp": 1624919232, "time_this_iter_s": 20.257781267166138, "time_total_s": 426.43923330307007, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 426.43923330307007, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 24.596296296296302, "ram_util_percent": 59.396296296296306, "gpu_util_percent0": 0.23925925925925923, "vram_util_percent0": 0.23046723838769675}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20296403157433612, "mean_inference_ms": 2.807725816855288, "mean_action_processing_ms": 0.14339113516683766, "mean_env_wait_ms": 0.11936313070448737, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 144144, "agent_timesteps_total": 288288, "timers": {"sample_time_ms": 3561.914, "sample_throughput": 1686.172, "learn_time_ms": 15086.174, "learn_throughput": 398.113, "update_time_ms": 5.431}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 571792.0, "policy_loss": 0.0014194071768446172, "vf_loss": 571792.0, "vf_explained_var": "null", "kl": 0.008962723426520824, "entropy": 2.8558759537148983, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 923720.5571808511, "policy_loss": -0.0007191244810027011, "vf_loss": 923720.5691489362, "vf_explained_var": -1.0, "kl": 0.011263897642493248, "entropy": 2.7059090949119406, "entropy_coeff": 0.0}}}, "num_steps_sampled": 144144, "num_agent_steps_sampled": 288288, "num_steps_trained": 144144, "num_agent_steps_trained": 288288}, "done": false, "episodes_total": 144, "training_iteration": 24, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-27-31", "timestamp": 1624919251, "time_this_iter_s": 18.46511197090149, "time_total_s": 444.90434527397156, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0250510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02500d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 444.90434527397156, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 22.679166666666664, "ram_util_percent": 59.49166666666667, "gpu_util_percent0": 0.20958333333333334, "vram_util_percent0": 0.22928603527693517}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20323502626731343, "mean_inference_ms": 2.810538948785036, "mean_action_processing_ms": 0.1435272032844433, "mean_env_wait_ms": 0.11946494778112518, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 150150, "agent_timesteps_total": 300300, "timers": {"sample_time_ms": 3560.375, "sample_throughput": 1686.901, "learn_time_ms": 15076.887, "learn_throughput": 398.358, "update_time_ms": 5.449}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 556497.5026595745, "policy_loss": -0.5725029351863455, "vf_loss": 556498.125, "vf_explained_var": "null", "kl": 0.0031662320549738533, "entropy": 2.889198288004449, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 923656.7805851063, "policy_loss": 0.0003445448472778848, "vf_loss": 923656.7805851063, "vf_explained_var": "null", "kl": 0.017470583319664, "entropy": 2.7895023011146707, "entropy_coeff": 0.0}}}, "num_steps_sampled": 150150, "num_agent_steps_sampled": 300300, "num_steps_trained": 150150, "num_agent_steps_trained": 300300}, "done": false, "episodes_total": 150, "training_iteration": 25, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-27-49", "timestamp": 1624919269, "time_this_iter_s": 18.432294845581055, "time_total_s": 463.3366401195526, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0250d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0254d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 463.3366401195526, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 22.72, "ram_util_percent": 59.53199999999999, "gpu_util_percent0": 0.21159999999999995, "vram_util_percent0": 0.22925513987192453}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2034326390031314, "mean_inference_ms": 2.812932526874908, "mean_action_processing_ms": 0.1436504118912442, "mean_env_wait_ms": 0.11955598952550449, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 156156, "agent_timesteps_total": 312312, "timers": {"sample_time_ms": 3551.648, "sample_throughput": 1691.046, "learn_time_ms": 14979.884, "learn_throughput": 400.938, "update_time_ms": 5.124}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 541419.8763297872, "policy_loss": -0.5972045571246045, "vf_loss": 541420.5, "vf_explained_var": "null", "kl": 0.010456492985658188, "entropy": 2.8226778913051525, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 895981.4348404255, "policy_loss": -0.00165934515918823, "vf_loss": 895981.4348404255, "vf_explained_var": "null", "kl": 0.006370982333542185, "entropy": 2.8968986196720854, "entropy_coeff": 0.0}}}, "num_steps_sampled": 156156, "num_agent_steps_sampled": 312312, "num_steps_trained": 156156, "num_agent_steps_trained": 312312}, "done": false, "episodes_total": 156, "training_iteration": 26, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-28-07", "timestamp": 1624919287, "time_this_iter_s": 17.486828804016113, "time_total_s": 480.8234689235687, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0254ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0254c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 480.8234689235687, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 23.52173913043478, "ram_util_percent": 59.43043478260872, "gpu_util_percent0": 0.2160869565217392, "vram_util_percent0": 0.22926832842426106}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.203615692878785, "mean_inference_ms": 2.8143954383209233, "mean_action_processing_ms": 0.143752502025898, "mean_env_wait_ms": 0.11962824231116449, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 162162, "agent_timesteps_total": 324324, "timers": {"sample_time_ms": 3538.996, "sample_throughput": 1697.092, "learn_time_ms": 14908.458, "learn_throughput": 402.859, "update_time_ms": 5.09}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 526554.8736702128, "policy_loss": 0.9819149134006906, "vf_loss": 526553.875, "vf_explained_var": "null", "kl": 0.01030428446036704, "entropy": 2.8750763852545558, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 902126.9893617021, "policy_loss": 0.00022333180730013137, "vf_loss": 902126.9933510638, "vf_explained_var": -1.0, "kl": 0.014027813627840356, "entropy": 2.864012013090418, "entropy_coeff": 0.0}}}, "num_steps_sampled": 162162, "num_agent_steps_sampled": 324324, "num_steps_trained": 162162, "num_agent_steps_trained": 324324}, "done": false, "episodes_total": 162, "training_iteration": 27, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-28-25", "timestamp": 1624919305, "time_this_iter_s": 17.703397512435913, "time_total_s": 498.52686643600464, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0208158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02087b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 498.52686643600464, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 22.483333333333334, "ram_util_percent": 59.5875, "gpu_util_percent0": 0.2204166666666667, "vram_util_percent0": 0.22927199191102124}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20379500354710023, "mean_inference_ms": 2.8158329508828683, "mean_action_processing_ms": 0.14384389657397417, "mean_env_wait_ms": 0.11969029513532557, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 168168, "agent_timesteps_total": 336336, "timers": {"sample_time_ms": 3535.455, "sample_throughput": 1698.791, "learn_time_ms": 14816.969, "learn_throughput": 405.346, "update_time_ms": 4.969}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 511896.298537234, "policy_loss": -0.3845302212111493, "vf_loss": 511896.69015957444, "vf_explained_var": "null", "kl": 0.015451658259522407, "entropy": 2.8561539294871876, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 843450.527925532, "policy_loss": -0.004519943980143425, "vf_loss": 843450.5332446808, "vf_explained_var": "null", "kl": 0.007181849241494499, "entropy": 2.9293735940405665, "entropy_coeff": 0.0}}}, "num_steps_sampled": 168168, "num_agent_steps_sampled": 336336, "num_steps_trained": 168168, "num_agent_steps_trained": 336336}, "done": false, "episodes_total": 168, "training_iteration": 28, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-28-42", "timestamp": 1624919322, "time_this_iter_s": 17.687498092651367, "time_total_s": 516.214364528656, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02086a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0254598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 516.214364528656, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 22.729166666666668, "ram_util_percent": 59.604166666666664, "gpu_util_percent0": 0.22125000000000003, "vram_util_percent0": 0.22829597798000226}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2039739045748269, "mean_inference_ms": 2.8173450658887167, "mean_action_processing_ms": 0.1439354873743086, "mean_env_wait_ms": 0.11975168254962261, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 174174, "agent_timesteps_total": 348348, "timers": {"sample_time_ms": 3544.199, "sample_throughput": 1694.6, "learn_time_ms": 14737.232, "learn_throughput": 407.539, "update_time_ms": 4.943}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 497447.9168882979, "policy_loss": -0.5952981849934192, "vf_loss": 497448.5, "vf_explained_var": "null", "kl": 0.017752469913598072, "entropy": 2.7494079610134694, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 892654.0492021276, "policy_loss": -0.0032180227497790722, "vf_loss": 892654.0518617021, "vf_explained_var": -1.0, "kl": 0.006389085649255108, "entropy": 2.890724704620686, "entropy_coeff": 0.0}}}, "num_steps_sampled": 174174, "num_agent_steps_sampled": 348348, "num_steps_trained": 174174, "num_agent_steps_trained": 348348}, "done": false, "episodes_total": 174, "training_iteration": 29, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-29-00", "timestamp": 1624919340, "time_this_iter_s": 17.677751541137695, "time_total_s": 533.8921160697937, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028cd90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 533.8921160697937, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 23.29565217391305, "ram_util_percent": 59.60434782608694, "gpu_util_percent0": 0.20608695652173914, "vram_util_percent0": 0.22817660936973375}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20413222361106506, "mean_inference_ms": 2.8189110831723956, "mean_action_processing_ms": 0.14402224068099045, "mean_env_wait_ms": 0.11980842903689902, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 180180, "agent_timesteps_total": 360360, "timers": {"sample_time_ms": 3539.614, "sample_throughput": 1696.795, "learn_time_ms": 14670.1, "learn_throughput": 409.404, "update_time_ms": 4.892}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 483210.19281914894, "policy_loss": 0.9962754997801273, "vf_loss": 483209.1875, "vf_explained_var": "null", "kl": 0.013787216447452282, "entropy": 2.8523566621415157, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 881926.1090425532, "policy_loss": -0.006327480553312504, "vf_loss": 881926.1156914893, "vf_explained_var": -1.0, "kl": 0.008643583701725336, "entropy": 3.002844069866424, "entropy_coeff": 0.0}}}, "num_steps_sampled": 180180, "num_agent_steps_sampled": 360360, "num_steps_trained": 180180, "num_agent_steps_trained": 360360}, "done": false, "episodes_total": 180, "training_iteration": 30, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-29-18", "timestamp": 1624919358, "time_this_iter_s": 17.688643217086792, "time_total_s": 551.5807592868805, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02506a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02500d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 551.5807592868805, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 23.03333333333333, "ram_util_percent": 59.69166666666667, "gpu_util_percent0": 0.22833333333333336, "vram_util_percent0": 0.22809234917425006}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20424324543322003, "mean_inference_ms": 2.8201690838682585, "mean_action_processing_ms": 0.14409227938025596, "mean_env_wait_ms": 0.11985528120544002, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 186186, "agent_timesteps_total": 372372, "timers": {"sample_time_ms": 3544.14, "sample_throughput": 1694.628, "learn_time_ms": 14593.569, "learn_throughput": 411.551, "update_time_ms": 5.007}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 469178.6289893617, "policy_loss": 0.1122833233564458, "vf_loss": 469178.50531914894, "vf_explained_var": "null", "kl": 0.013018216145165424, "entropy": 2.9469392502561527, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 875418.8989361703, "policy_loss": -0.001984162038152522, "vf_loss": 875418.897606383, "vf_explained_var": -1.0, "kl": 0.007957495877796665, "entropy": 3.1197415767832006, "entropy_coeff": 0.0}}}, "num_steps_sampled": 186186, "num_agent_steps_sampled": 372372, "num_steps_trained": 186186, "num_agent_steps_trained": 372372}, "done": false, "episodes_total": 186, "training_iteration": 31, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-29-36", "timestamp": 1624919376, "time_this_iter_s": 17.785018920898438, "time_total_s": 569.3657782077789, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0208b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0208f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 569.3657782077789, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 22.95416666666667, "ram_util_percent": 59.6, "gpu_util_percent0": 0.22958333333333336, "vram_util_percent0": 0.22812745758903494}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2043613523271382, "mean_inference_ms": 2.8213855788370155, "mean_action_processing_ms": 0.14415524137598462, "mean_env_wait_ms": 0.11989948034520034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 192192, "agent_timesteps_total": 384384, "timers": {"sample_time_ms": 3558.051, "sample_throughput": 1688.003, "learn_time_ms": 14502.822, "learn_throughput": 414.126, "update_time_ms": 4.919}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 455355.99734042556, "policy_loss": -0.6105752105408526, "vf_loss": 455356.5944148936, "vf_explained_var": "null", "kl": 0.010867248229840969, "entropy": 2.8680552573914224, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 895415.4308510638, "policy_loss": -0.0036690705059532155, "vf_loss": 895415.4441489362, "vf_explained_var": "null", "kl": 0.008464193288633164, "entropy": 3.2994868400249073, "entropy_coeff": 0.0}}}, "num_steps_sampled": 192192, "num_agent_steps_sampled": 384384, "num_steps_trained": 192192, "num_agent_steps_trained": 384384}, "done": false, "episodes_total": 192, "training_iteration": 32, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-29-53", "timestamp": 1624919393, "time_this_iter_s": 17.551567792892456, "time_total_s": 586.9173460006714, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0208730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0208488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 586.9173460006714, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 23.486956521739128, "ram_util_percent": 59.67391304347827, "gpu_util_percent0": 0.23304347826086963, "vram_util_percent0": 0.22811799358157123}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20444689528537896, "mean_inference_ms": 2.8225062665377907, "mean_action_processing_ms": 0.14419887117401747, "mean_env_wait_ms": 0.11992829348198443, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 198198, "agent_timesteps_total": 396396, "timers": {"sample_time_ms": 3530.155, "sample_throughput": 1701.342, "learn_time_ms": 14279.182, "learn_throughput": 420.612, "update_time_ms": 4.837}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 441742.68151595746, "policy_loss": -0.5248351591698667, "vf_loss": 441743.1875, "vf_explained_var": "null", "kl": 0.01132796187587875, "entropy": 2.8152918206884507, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 845007.3497340425, "policy_loss": -0.006389741627301307, "vf_loss": 845007.3497340425, "vf_explained_var": "null", "kl": 0.00981032604629055, "entropy": 3.297225957221173, "entropy_coeff": 0.0}}}, "num_steps_sampled": 198198, "num_agent_steps_sampled": 396396, "num_steps_trained": 198198, "num_agent_steps_trained": 396396}, "done": false, "episodes_total": 198, "training_iteration": 33, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-30-11", "timestamp": 1624919411, "time_this_iter_s": 17.740978002548218, "time_total_s": 604.6583240032196, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028ca60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 604.6583240032196, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 23.545833333333334, "ram_util_percent": 59.70000000000001, "gpu_util_percent0": 0.2329166666666667, "vram_util_percent0": 0.22809234917425006}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20447610301126748, "mean_inference_ms": 2.8235726544113997, "mean_action_processing_ms": 0.14423958595189323, "mean_env_wait_ms": 0.1199529616750174, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 204204, "agent_timesteps_total": 408408, "timers": {"sample_time_ms": 3529.141, "sample_throughput": 1701.831, "learn_time_ms": 14207.15, "learn_throughput": 422.745, "update_time_ms": 4.797}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 428315.25, "policy_loss": 0.0, "vf_loss": 428315.2180851064, "vf_explained_var": "null", "kl": 0.012799187820959599, "entropy": 2.878268739010425, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 922455.284574468, "policy_loss": -0.003415829601122978, "vf_loss": 922455.2819148937, "vf_explained_var": -1.0, "kl": 0.01071690985972577, "entropy": 3.478357360718098, "entropy_coeff": 0.0}}}, "num_steps_sampled": 204204, "num_agent_steps_sampled": 408408, "num_steps_trained": 204204, "num_agent_steps_trained": 408408}, "done": false, "episodes_total": 204, "training_iteration": 34, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-30-29", "timestamp": 1624919429, "time_this_iter_s": 17.73435401916504, "time_total_s": 622.3926780223846, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02e5ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0272510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 622.3926780223846, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 23.565217391304348, "ram_util_percent": 59.713043478260886, "gpu_util_percent0": 0.22826086956521746, "vram_util_percent0": 0.22808135871396965}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20450943537881816, "mean_inference_ms": 2.8245090669300845, "mean_action_processing_ms": 0.14427481094194472, "mean_env_wait_ms": 0.11997184107875784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 210210, "agent_timesteps_total": 420420, "timers": {"sample_time_ms": 3539.789, "sample_throughput": 1696.711, "learn_time_ms": 14134.978, "learn_throughput": 424.903, "update_time_ms": 4.792}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 415103.5033244681, "policy_loss": 0.6094394262800825, "vf_loss": 415102.90625, "vf_explained_var": "null", "kl": 0.00453729778924521, "entropy": 2.8661424200585546, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 844164.9015957447, "policy_loss": 0.0010593227566556727, "vf_loss": 844164.902925532, "vf_explained_var": "null", "kl": 0.01179418645482114, "entropy": 3.3549098055413427, "entropy_coeff": 0.0}}}, "num_steps_sampled": 210210, "num_agent_steps_sampled": 420420, "num_steps_trained": 210210, "num_agent_steps_trained": 420420}, "done": false, "episodes_total": 210, "training_iteration": 35, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-30-47", "timestamp": 1624919447, "time_this_iter_s": 17.817144632339478, "time_total_s": 640.2098226547241, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b025c488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b025c400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 640.2098226547241, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 22.8, "ram_util_percent": 59.70000000000001, "gpu_util_percent0": 0.22958333333333336, "vram_util_percent0": 0.228106392540164}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2045543504342162, "mean_inference_ms": 2.825596460321714, "mean_action_processing_ms": 0.14431652506841583, "mean_env_wait_ms": 0.11999462910437776, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 216216, "agent_timesteps_total": 432432, "timers": {"sample_time_ms": 3541.63, "sample_throughput": 1695.829, "learn_time_ms": 14147.393, "learn_throughput": 424.531, "update_time_ms": 4.822}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2135742187500001, "cur_lr": 5.000000000000002e-05, "total_loss": 402101.39760638296, "policy_loss": -0.5825715851276478, "vf_loss": 402101.99468085106, "vf_explained_var": "null", "kl": 0.008927247467193198, "entropy": 2.831008662568762, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 879069.7433510638, "policy_loss": -0.0040454679426360635, "vf_loss": 879069.75, "vf_explained_var": "null", "kl": 0.010861956415341255, "entropy": 3.550038636998927, "entropy_coeff": 0.0}}}, "num_steps_sampled": 216216, "num_agent_steps_sampled": 432432, "num_steps_trained": 216216, "num_agent_steps_trained": 432432}, "done": false, "episodes_total": 216, "training_iteration": 36, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-31-04", "timestamp": 1624919464, "time_this_iter_s": 17.629820585250854, "time_total_s": 657.839643239975, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02e56a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02e58c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 657.839643239975, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 23.412500000000005, "ram_util_percent": 59.79583333333333, "gpu_util_percent0": 0.23416666666666672, "vram_util_percent0": 0.228113414223121}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20458023169122078, "mean_inference_ms": 2.8264839072753456, "mean_action_processing_ms": 0.14434982101113403, "mean_env_wait_ms": 0.12001105716757893, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 222222, "agent_timesteps_total": 444444, "timers": {"sample_time_ms": 3530.023, "sample_throughput": 1701.405, "learn_time_ms": 14161.598, "learn_throughput": 424.105, "update_time_ms": 4.829}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2135742187500001, "cur_lr": 5.000000000000002e-05, "total_loss": 389309.25199468085, "policy_loss": -0.6112785364719148, "vf_loss": 389309.875, "vf_explained_var": "null", "kl": 0.008314329377831296, "entropy": 2.720906470684295, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 917084.3656914893, "policy_loss": -0.0015870549101778802, "vf_loss": 917084.3630319149, "vf_explained_var": -1.0, "kl": 0.01243882909654937, "entropy": 3.5523203180191363, "entropy_coeff": 0.0}}}, "num_steps_sampled": 222222, "num_agent_steps_sampled": 444444, "num_steps_trained": 222222, "num_agent_steps_trained": 444444}, "done": false, "episodes_total": 222, "training_iteration": 37, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-31-22", "timestamp": 1624919482, "time_this_iter_s": 17.729655265808105, "time_total_s": 675.5692985057831, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02d9bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028ca60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 675.5692985057831, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 24.004347826086963, "ram_util_percent": 59.79999999999998, "gpu_util_percent0": 0.23304347826086957, "vram_util_percent0": 0.2281253205550915}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20461365575277546, "mean_inference_ms": 2.8273961828312024, "mean_action_processing_ms": 0.14438507421177252, "mean_env_wait_ms": 0.12002776018303755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 228228, "agent_timesteps_total": 456456, "timers": {"sample_time_ms": 3526.018, "sample_throughput": 1703.338, "learn_time_ms": 14171.62, "learn_throughput": 423.805, "update_time_ms": 4.888}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2135742187500001, "cur_lr": 5.000000000000002e-05, "total_loss": 376727.31382978725, "policy_loss": 0.7555450226398225, "vf_loss": 376726.5625, "vf_explained_var": "null", "kl": 0.03699194505176646, "entropy": 2.925431175434843, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 816841.0558510638, "policy_loss": -0.00299677312215592, "vf_loss": 816841.0585106383, "vf_explained_var": -1.0, "kl": 0.014869916886883848, "entropy": 3.5701019205945603, "entropy_coeff": 0.0}}}, "num_steps_sampled": 228228, "num_agent_steps_sampled": 456456, "num_steps_trained": 228228, "num_agent_steps_trained": 456456}, "done": false, "episodes_total": 228, "training_iteration": 38, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-31-40", "timestamp": 1624919500, "time_this_iter_s": 17.748269081115723, "time_total_s": 693.3175675868988, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02de510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02de488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 693.3175675868988, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 23.558333333333337, "ram_util_percent": 59.79999999999999, "gpu_util_percent0": 0.23291666666666666, "vram_util_percent0": 0.22814852263790586}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2046516669666252, "mean_inference_ms": 2.8281693475028162, "mean_action_processing_ms": 0.14441177697367566, "mean_env_wait_ms": 0.1200356647241283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 234234, "agent_timesteps_total": 468468, "timers": {"sample_time_ms": 3529.997, "sample_throughput": 1701.418, "learn_time_ms": 14176.313, "learn_throughput": 423.664, "update_time_ms": 4.886}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3203613281249999, "cur_lr": 5.000000000000002e-05, "total_loss": 364351.6668882979, "policy_loss": -0.6004214400940753, "vf_loss": 364352.2506648936, "vf_explained_var": "null", "kl": 0.04228028020960219, "entropy": 2.9771018434078136, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 844377.3763297872, "policy_loss": -0.005776348107672752, "vf_loss": 844377.3882978724, "vf_explained_var": "null", "kl": 0.009821989206953886, "entropy": 3.264579635985354, "entropy_coeff": 0.0}}}, "num_steps_sampled": 234234, "num_agent_steps_sampled": 468468, "num_steps_trained": 234234, "num_agent_steps_trained": 468468}, "done": false, "episodes_total": 234, "training_iteration": 39, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-31-57", "timestamp": 1624919517, "time_this_iter_s": 17.763418912887573, "time_total_s": 711.0809864997864, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0258488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0258400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 711.0809864997864, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 23.025000000000002, "ram_util_percent": 59.80416666666665, "gpu_util_percent0": 0.23291666666666666, "vram_util_percent0": 0.22813447927199193}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20463474215582003, "mean_inference_ms": 2.8286766799988583, "mean_action_processing_ms": 0.14442447564600341, "mean_env_wait_ms": 0.12003260309283247, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 240240, "agent_timesteps_total": 480480, "timers": {"sample_time_ms": 3527.287, "sample_throughput": 1702.725, "learn_time_ms": 14174.035, "learn_throughput": 423.733, "update_time_ms": 4.852}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4805419921875001, "cur_lr": 5.000000000000002e-05, "total_loss": 352166.70013297873, "policy_loss": 0.6517035529968587, "vf_loss": 352166.0625, "vf_explained_var": "null", "kl": 0.023180126311614157, "entropy": 2.9379079849162, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 824786.7752659575, "policy_loss": -0.0003600296306800335, "vf_loss": 824786.7765957447, "vf_explained_var": "null", "kl": 0.014007052446299411, "entropy": 3.148736334861593, "entropy_coeff": 0.0}}}, "num_steps_sampled": 240240, "num_agent_steps_sampled": 480480, "num_steps_trained": 240240, "num_agent_steps_trained": 480480}, "done": false, "episodes_total": 240, "training_iteration": 40, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-32-15", "timestamp": 1624919535, "time_this_iter_s": 17.6382794380188, "time_total_s": 728.7192659378052, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02589d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0258f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 728.7192659378052, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 23.069565217391304, "ram_util_percent": 59.804347826086946, "gpu_util_percent0": 0.23304347826086946, "vram_util_percent0": 0.22813997450213216}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20463646489439863, "mean_inference_ms": 2.82926093008785, "mean_action_processing_ms": 0.1444417301162183, "mean_env_wait_ms": 0.12003315299000629, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 246246, "agent_timesteps_total": 492492, "timers": {"sample_time_ms": 3523.387, "sample_throughput": 1704.61, "learn_time_ms": 14191.254, "learn_throughput": 423.218, "update_time_ms": 4.69}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7208129882812501, "cur_lr": 5.000000000000002e-05, "total_loss": 340194.2460106383, "policy_loss": -0.5916960087228329, "vf_loss": 340194.8125, "vf_explained_var": "null", "kl": 0.025984836464866677, "entropy": 2.919861702208823, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 743542.3563829787, "policy_loss": 0.0006032582927257456, "vf_loss": 743542.3577127659, "vf_explained_var": -1.0, "kl": 0.006547059229713805, "entropy": 3.1932794794123223, "entropy_coeff": 0.0}}}, "num_steps_sampled": 246246, "num_agent_steps_sampled": 492492, "num_steps_trained": 246246, "num_agent_steps_trained": 492492}, "done": false, "episodes_total": 246, "training_iteration": 41, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-32-33", "timestamp": 1624919553, "time_this_iter_s": 17.914032459259033, "time_total_s": 746.6332983970642, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 746.6332983970642, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 22.933333333333337, "ram_util_percent": 59.887499999999996, "gpu_util_percent0": 0.2304166666666667, "vram_util_percent0": 0.228113414223121}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20462729023527917, "mean_inference_ms": 2.829708728098861, "mean_action_processing_ms": 0.1444536409514145, "mean_env_wait_ms": 0.12003036480534192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 252252, "agent_timesteps_total": 504504, "timers": {"sample_time_ms": 3521.652, "sample_throughput": 1705.45, "learn_time_ms": 14214.729, "learn_throughput": 422.519, "update_time_ms": 4.691}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 328434.19747340423, "policy_loss": -0.5950050810550122, "vf_loss": 328434.80784574465, "vf_explained_var": "null", "kl": 0.009944018987106515, "entropy": 2.82551461077751, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 814776.3882978724, "policy_loss": -0.006595336217829522, "vf_loss": 814776.3816489362, "vf_explained_var": -1.0, "kl": 0.008408352613766143, "entropy": 3.101657248557882, "entropy_coeff": 0.0}}}, "num_steps_sampled": 252252, "num_agent_steps_sampled": 504504, "num_steps_trained": 252252, "num_agent_steps_trained": 504504}, "done": false, "episodes_total": 252, "training_iteration": 42, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-32-51", "timestamp": 1624919571, "time_this_iter_s": 17.76909899711609, "time_total_s": 764.4023973941803, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02e58c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02e5488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 764.4023973941803, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 22.695833333333336, "ram_util_percent": 59.93333333333334, "gpu_util_percent0": 0.23125000000000004, "vram_util_percent0": 0.22809234917425006}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20462756854485767, "mean_inference_ms": 2.830304332156863, "mean_action_processing_ms": 0.1444730647853537, "mean_env_wait_ms": 0.12003373325891528, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 258258, "agent_timesteps_total": 516516, "timers": {"sample_time_ms": 3501.595, "sample_throughput": 1715.218, "learn_time_ms": 14237.084, "learn_throughput": 421.856, "update_time_ms": 4.668}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 316884.3743351064, "policy_loss": 0.0, "vf_loss": 316884.34375, "vf_explained_var": "null", "kl": 0.0038723807405442634, "entropy": 2.8094611878090716, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 877162.4401595745, "policy_loss": -0.0037797757999060004, "vf_loss": 877162.4494680851, "vf_explained_var": -1.0, "kl": 0.010552642133800274, "entropy": 3.207117937980814, "entropy_coeff": 0.0}}}, "num_steps_sampled": 258258, "num_agent_steps_sampled": 516516, "num_steps_trained": 258258, "num_agent_steps_trained": 516516}, "done": false, "episodes_total": 258, "training_iteration": 43, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-33-09", "timestamp": 1624919589, "time_this_iter_s": 17.764031648635864, "time_total_s": 782.1664290428162, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f38b9d0d2f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b026fb70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 782.1664290428162, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 23.45416666666667, "ram_util_percent": 59.9125, "gpu_util_percent0": 0.23083333333333336, "vram_util_percent0": 0.22809234917425006}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20464006597922293, "mean_inference_ms": 2.830921624289525, "mean_action_processing_ms": 0.14449323581084444, "mean_env_wait_ms": 0.12003973499268698, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 264264, "agent_timesteps_total": 528528, "timers": {"sample_time_ms": 3507.18, "sample_throughput": 1712.487, "learn_time_ms": 14243.789, "learn_throughput": 421.657, "update_time_ms": 4.612}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 305542.0631648936, "policy_loss": -0.6125582507316102, "vf_loss": 305542.6875, "vf_explained_var": "null", "kl": 0.0031186017514939638, "entropy": 2.8185738553392126, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 878073.8257978724, "policy_loss": -0.005064254170878136, "vf_loss": 878073.835106383, "vf_explained_var": -1.0, "kl": 0.007561047947866485, "entropy": 3.2576849511329162, "entropy_coeff": 0.0}}}, "num_steps_sampled": 264264, "num_agent_steps_sampled": 528528, "num_steps_trained": 264264, "num_agent_steps_trained": 528528}, "done": false, "episodes_total": 264, "training_iteration": 44, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-33-27", "timestamp": 1624919607, "time_this_iter_s": 17.857177019119263, "time_total_s": 800.0236060619354, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c6a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 800.0236060619354, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 22.979166666666668, "ram_util_percent": 60.1, "gpu_util_percent0": 0.22958333333333336, "vram_util_percent0": 0.22809937085720702}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20465207214207112, "mean_inference_ms": 2.8315305884210646, "mean_action_processing_ms": 0.14451409256942718, "mean_env_wait_ms": 0.12004734476409061, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 270270, "agent_timesteps_total": 540540, "timers": {"sample_time_ms": 3492.093, "sample_throughput": 1719.886, "learn_time_ms": 14242.864, "learn_throughput": 421.685, "update_time_ms": 4.531}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546865, "cur_lr": 5.000000000000002e-05, "total_loss": 294411.3716755319, "policy_loss": 0.6050040404847328, "vf_loss": 294410.75, "vf_explained_var": "null", "kl": 0.012423212639987469, "entropy": 2.8847907350418414, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 841139.8417553192, "policy_loss": 0.0007903097752243914, "vf_loss": 841139.8417553192, "vf_explained_var": -1.0, "kl": 0.014319509148914764, "entropy": 3.403183713872382, "entropy_coeff": 0.0}}}, "num_steps_sampled": 270270, "num_agent_steps_sampled": 540540, "num_steps_trained": 270270, "num_agent_steps_trained": 540540}, "done": false, "episodes_total": 270, "training_iteration": 45, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-33-44", "timestamp": 1624919624, "time_this_iter_s": 17.655823469161987, "time_total_s": 817.6794295310974, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b026f620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02dec80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 817.6794295310974, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 23.291304347826085, "ram_util_percent": 60.195652173913054, "gpu_util_percent0": 0.2339130434782609, "vram_util_percent0": 0.22790551134948206}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20466170200311043, "mean_inference_ms": 2.8321733969954397, "mean_action_processing_ms": 0.14453940360086112, "mean_env_wait_ms": 0.12005892065257806, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 276276, "agent_timesteps_total": 552552, "timers": {"sample_time_ms": 3498.239, "sample_throughput": 1716.864, "learn_time_ms": 14249.865, "learn_throughput": 421.478, "update_time_ms": 4.486}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546865, "cur_lr": 5.000000000000002e-05, "total_loss": 283468.14428191487, "policy_loss": -0.6066263520971258, "vf_loss": 283468.75, "vf_explained_var": "null", "kl": 0.025869798509681477, "entropy": 2.70694071181277, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 686479.210106383, "policy_loss": -0.001145882175323811, "vf_loss": 686479.2061170213, "vf_explained_var": "null", "kl": 0.012025141355363613, "entropy": 3.371681360488242, "entropy_coeff": 0.0}}}, "num_steps_sampled": 276276, "num_agent_steps_sampled": 552552, "num_steps_trained": 276276, "num_agent_steps_trained": 552552}, "done": false, "episodes_total": 276, "training_iteration": 46, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-34-02", "timestamp": 1624919642, "time_this_iter_s": 17.761013746261597, "time_total_s": 835.440443277359, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b026f730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02566a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 835.440443277359, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 23.36666666666667, "ram_util_percent": 60.25416666666666, "gpu_util_percent0": 0.23208333333333334, "vram_util_percent0": 0.22786765531962702}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2046690404594311, "mean_inference_ms": 2.8326769061862107, "mean_action_processing_ms": 0.14456129776033808, "mean_env_wait_ms": 0.12006804690220604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 282282, "agent_timesteps_total": 564564, "timers": {"sample_time_ms": 3491.229, "sample_throughput": 1720.311, "learn_time_ms": 14239.946, "learn_throughput": 421.771, "update_time_ms": 4.488}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4054573059082032, "cur_lr": 5.000000000000002e-05, "total_loss": 272740.75, "policy_loss": -1.004955216925195, "vf_loss": 272741.75, "vf_explained_var": "null", "kl": 0.007845073849200569, "entropy": 2.7185777349674956, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 851424.7473404255, "policy_loss": -0.00126396553551263, "vf_loss": 851424.7353723404, "vf_explained_var": -1.0, "kl": 0.006440250311997977, "entropy": 3.242662434882306, "entropy_coeff": 0.0}}}, "num_steps_sampled": 282282, "num_agent_steps_sampled": 564564, "num_steps_trained": 282282, "num_agent_steps_trained": 564564}, "done": false, "episodes_total": 282, "training_iteration": 47, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-34-20", "timestamp": 1624919660, "time_this_iter_s": 17.560291528701782, "time_total_s": 853.0007348060608, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0256bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0256f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 853.0007348060608, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 23.01739130434783, "ram_util_percent": 60.304347826086946, "gpu_util_percent0": 0.23173913043478261, "vram_util_percent0": 0.2278908574024414}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20468931450727976, "mean_inference_ms": 2.8332612031477424, "mean_action_processing_ms": 0.14458735455468064, "mean_env_wait_ms": 0.1200805921523386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 288288, "agent_timesteps_total": 576576, "timers": {"sample_time_ms": 3484.309, "sample_throughput": 1723.728, "learn_time_ms": 14240.518, "learn_throughput": 421.754, "update_time_ms": 4.42}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4054573059082032, "cur_lr": 5.000000000000002e-05, "total_loss": 262225.5, "policy_loss": 0.0008578914950819725, "vf_loss": 262225.5, "vf_explained_var": "null", "kl": 0.007576228852601762, "entropy": 2.770529924555028, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 833193.9481382979, "policy_loss": -0.002650281037897506, "vf_loss": 833193.9547872341, "vf_explained_var": "null", "kl": 0.008664265492970639, "entropy": 3.144038048196346, "entropy_coeff": 0.0}}}, "num_steps_sampled": 288288, "num_agent_steps_sampled": 576576, "num_steps_trained": 288288, "num_agent_steps_trained": 576576}, "done": false, "episodes_total": 288, "training_iteration": 48, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-34-37", "timestamp": 1624919677, "time_this_iter_s": 17.68444323539734, "time_total_s": 870.6851780414581, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0256488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0256598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 870.6851780414581, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 23.49166666666667, "ram_util_percent": 60.20416666666667, "gpu_util_percent0": 0.22833333333333336, "vram_util_percent0": 0.227874677002584}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20471267220557013, "mean_inference_ms": 2.8336375848524638, "mean_action_processing_ms": 0.1446071296140417, "mean_env_wait_ms": 0.12009003722319195, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 294294, "agent_timesteps_total": 588588, "timers": {"sample_time_ms": 3469.226, "sample_throughput": 1731.222, "learn_time_ms": 14257.067, "learn_throughput": 421.265, "update_time_ms": 4.412}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4054573059082032, "cur_lr": 5.000000000000002e-05, "total_loss": 251919.09574468085, "policy_loss": 0.3051107811166885, "vf_loss": 251918.80252659574, "vf_explained_var": "null", "kl": 0.004377880648888172, "entropy": 2.8172467414368976, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 853891.847074468, "policy_loss": -0.001704650415860592, "vf_loss": 853891.835106383, "vf_explained_var": -1.0, "kl": 0.010165877977108701, "entropy": 3.1044050784821207, "entropy_coeff": 0.0}}}, "num_steps_sampled": 294294, "num_agent_steps_sampled": 588588, "num_steps_trained": 294294, "num_agent_steps_trained": 588588}, "done": false, "episodes_total": 294, "training_iteration": 49, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-34-55", "timestamp": 1624919695, "time_this_iter_s": 17.77808380126953, "time_total_s": 888.4632618427277, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028ce18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 888.4632618427277, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 23.5625, "ram_util_percent": 60.15833333333333, "gpu_util_percent0": 0.23583333333333334, "vram_util_percent0": 0.227874677002584}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20473166088230296, "mean_inference_ms": 2.8339596761635653, "mean_action_processing_ms": 0.14463368332178253, "mean_env_wait_ms": 0.12010446105137801, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 300300, "agent_timesteps_total": 600600, "timers": {"sample_time_ms": 3476.028, "sample_throughput": 1727.834, "learn_time_ms": 14250.747, "learn_throughput": 421.452, "update_time_ms": 4.444}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2027286529541016, "cur_lr": 5.000000000000002e-05, "total_loss": 241804.140625, "policy_loss": 0.0, "vf_loss": 241804.140625, "vf_explained_var": "null", "kl": 0.009745344024230825, "entropy": 2.840369797767477, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 772846.7140957447, "policy_loss": 0.003253902427535108, "vf_loss": 772846.7087765958, "vf_explained_var": -1.0, "kl": 0.009075485922871752, "entropy": 2.9763149504965924, "entropy_coeff": 0.0}}}, "num_steps_sampled": 300300, "num_agent_steps_sampled": 600600, "num_steps_trained": 300300, "num_agent_steps_trained": 600600}, "done": false, "episodes_total": 300, "training_iteration": 50, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-35-13", "timestamp": 1624919713, "time_this_iter_s": 17.643390417099, "time_total_s": 906.1066522598267, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b026ff28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b026f048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 906.1066522598267, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 23.5695652173913, "ram_util_percent": 60.20000000000002, "gpu_util_percent0": 0.22913043478260875, "vram_util_percent0": 0.2278835304289211}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20476019722940186, "mean_inference_ms": 2.8343516774813406, "mean_action_processing_ms": 0.14466301440281476, "mean_env_wait_ms": 0.12012066905076564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 306306, "agent_timesteps_total": 612612, "timers": {"sample_time_ms": 3483.703, "sample_throughput": 1724.028, "learn_time_ms": 14241.264, "learn_throughput": 421.732, "update_time_ms": 4.411}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2027286529541016, "cur_lr": 5.000000000000002e-05, "total_loss": 231903.62998670212, "policy_loss": -0.5743531369148417, "vf_loss": 231904.203125, "vf_explained_var": "null", "kl": 0.0065859239647521614, "entropy": 2.7865562743328987, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 753069.1728723404, "policy_loss": -0.005194225863731922, "vf_loss": 753069.1755319149, "vf_explained_var": "null", "kl": 0.005468560035954764, "entropy": 3.0210660822848054, "entropy_coeff": 0.0}}}, "num_steps_sampled": 306306, "num_agent_steps_sampled": 612612, "num_steps_trained": 306306, "num_agent_steps_trained": 612612}, "done": false, "episodes_total": 306, "training_iteration": 51, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-35-31", "timestamp": 1624919731, "time_this_iter_s": 17.895718812942505, "time_total_s": 924.0023710727692, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0256510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02560d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 924.0023710727692, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 23.495833333333334, "ram_util_percent": 60.49583333333334, "gpu_util_percent0": 0.225, "vram_util_percent0": 0.22788872036849792}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20475798663038444, "mean_inference_ms": 2.8345824545108043, "mean_action_processing_ms": 0.14468298942083677, "mean_env_wait_ms": 0.12013182403476474, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 312312, "agent_timesteps_total": 624624, "timers": {"sample_time_ms": 3462.595, "sample_throughput": 1734.537, "learn_time_ms": 14271.511, "learn_throughput": 420.838, "update_time_ms": 4.399}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2027286529541016, "cur_lr": 5.000000000000002e-05, "total_loss": 222215.625, "policy_loss": 0.0, "vf_loss": 222215.625, "vf_explained_var": "null", "kl": 0.015928319774251035, "entropy": 2.9469874615364886, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 839252.8683510638, "policy_loss": -0.007275845617689985, "vf_loss": 839252.8763297872, "vf_explained_var": -1.0, "kl": 0.009216299240893506, "entropy": 3.0069853752217393, "entropy_coeff": 0.0}}}, "num_steps_sampled": 312312, "num_agent_steps_sampled": 624624, "num_steps_trained": 312312, "num_agent_steps_trained": 624624}, "done": false, "episodes_total": 312, "training_iteration": 52, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-35-49", "timestamp": 1624919749, "time_this_iter_s": 17.861056089401245, "time_total_s": 941.8634271621704, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0256598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0256730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 941.8634271621704, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 23.208333333333332, "ram_util_percent": 60.54999999999999, "gpu_util_percent0": 0.22666666666666668, "vram_util_percent0": 0.22790276373441187}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2047629258620817, "mean_inference_ms": 2.8350243028224638, "mean_action_processing_ms": 0.14470948266662423, "mean_env_wait_ms": 0.12014757700207179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 318318, "agent_timesteps_total": 636636, "timers": {"sample_time_ms": 3480.898, "sample_throughput": 1725.417, "learn_time_ms": 14264.509, "learn_throughput": 421.045, "update_time_ms": 4.399}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2027286529541016, "cur_lr": 5.000000000000002e-05, "total_loss": 212736.40392287233, "policy_loss": -0.24602658063807387, "vf_loss": 212736.65558510637, "vf_explained_var": "null", "kl": 0.005297370918808465, "entropy": 2.874662455092085, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 785463.7074468085, "policy_loss": 0.005352060469065575, "vf_loss": 785463.7034574468, "vf_explained_var": -1.0, "kl": 0.013334885001816649, "entropy": 3.162955852265054, "entropy_coeff": 0.0}}}, "num_steps_sampled": 318318, "num_agent_steps_sampled": 636636, "num_steps_trained": 318318, "num_agent_steps_trained": 636636}, "done": false, "episodes_total": 318, "training_iteration": 53, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-36-07", "timestamp": 1624919767, "time_this_iter_s": 17.87715435028076, "time_total_s": 959.7405815124512, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0267c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0267620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 959.7405815124512, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 23.95, "ram_util_percent": 60.67083333333333, "gpu_util_percent0": 0.22291666666666674, "vram_util_percent0": 0.2279168071003258}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20477338416515306, "mean_inference_ms": 2.8353899846639705, "mean_action_processing_ms": 0.1447327271674609, "mean_env_wait_ms": 0.12016130585443868, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 324324, "agent_timesteps_total": 648648, "timers": {"sample_time_ms": 3467.408, "sample_throughput": 1732.13, "learn_time_ms": 14268.111, "learn_throughput": 420.939, "update_time_ms": 4.409}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2027286529541016, "cur_lr": 5.000000000000002e-05, "total_loss": 203450.50664893616, "policy_loss": -0.6072460856843502, "vf_loss": 203451.1097074468, "vf_explained_var": "null", "kl": 0.029223879997400528, "entropy": 2.771743723686705, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 823257.539893617, "policy_loss": -0.002732683607238404, "vf_loss": 823257.5412234042, "vf_explained_var": -1.0, "kl": 0.015754410164787413, "entropy": 3.1747869177067534, "entropy_coeff": 0.0}}}, "num_steps_sampled": 324324, "num_agent_steps_sampled": 648648, "num_steps_trained": 324324, "num_agent_steps_trained": 648648}, "done": false, "episodes_total": 324, "training_iteration": 54, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-36-24", "timestamp": 1624919784, "time_this_iter_s": 17.758363246917725, "time_total_s": 977.4989447593689, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0214950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b0214378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 977.4989447593689, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 23.3, "ram_util_percent": 60.604166666666664, "gpu_util_percent0": 0.22708333333333333, "vram_util_percent0": 0.2279168071003258}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2047792530330244, "mean_inference_ms": 2.835797380501774, "mean_action_processing_ms": 0.14475766061745637, "mean_env_wait_ms": 0.12017626386726211, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 330330, "agent_timesteps_total": 660660, "timers": {"sample_time_ms": 3484.209, "sample_throughput": 1723.777, "learn_time_ms": 14276.163, "learn_throughput": 420.701, "update_time_ms": 4.469}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3040929794311523, "cur_lr": 5.000000000000002e-05, "total_loss": 194379.64261968085, "policy_loss": -0.5162922695596167, "vf_loss": 194380.14627659574, "vf_explained_var": "null", "kl": 0.02337319237437654, "entropy": 2.7103295833506484, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 746961.2194148937, "policy_loss": 0.004100029277516172, "vf_loss": 746961.2114361703, "vf_explained_var": -1.0, "kl": 0.01613038578169777, "entropy": 3.3651751761740827, "entropy_coeff": 0.0}}}, "num_steps_sampled": 330330, "num_agent_steps_sampled": 660660, "num_steps_trained": 330330, "num_agent_steps_trained": 660660}, "done": false, "episodes_total": 330, "training_iteration": 55, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-36-42", "timestamp": 1624919802, "time_this_iter_s": 17.920239448547363, "time_total_s": 995.4191842079163, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b0214f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02141e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 995.4191842079163, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 23.883333333333336, "ram_util_percent": 60.50416666666666, "gpu_util_percent0": 0.23208333333333334, "vram_util_percent0": 0.22790978541736884}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2047833367559514, "mean_inference_ms": 2.83608082639724, "mean_action_processing_ms": 0.14477724088887095, "mean_env_wait_ms": 0.12018807468272859, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 336336, "agent_timesteps_total": 672672, "timers": {"sample_time_ms": 3487.168, "sample_throughput": 1722.314, "learn_time_ms": 14278.169, "learn_throughput": 420.642, "update_time_ms": 4.492}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4561394691467283, "cur_lr": 5.000000000000002e-05, "total_loss": 185519.7380319149, "policy_loss": -0.9094476015009778, "vf_loss": 185520.65093085106, "vf_explained_var": "null", "kl": 0.008244061485884037, "entropy": 2.761332674229399, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 825194.5425531915, "policy_loss": -0.0006438645316248244, "vf_loss": 825194.5332446808, "vf_explained_var": -1.0, "kl": 0.007903838143783046, "entropy": 3.393919067179903, "entropy_coeff": 0.0}}}, "num_steps_sampled": 336336, "num_agent_steps_sampled": 672672, "num_steps_trained": 336336, "num_agent_steps_trained": 672672}, "done": false, "episodes_total": 336, "training_iteration": 56, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-37-00", "timestamp": 1624919820, "time_this_iter_s": 17.810914278030396, "time_total_s": 1013.2300984859467, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02147b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02146a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1013.2300984859467, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 23.847826086956523, "ram_util_percent": 60.49130434782609, "gpu_util_percent0": 0.22086956521739123, "vram_util_percent0": 0.2278908574024414}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20478650882195315, "mean_inference_ms": 2.8364271528650264, "mean_action_processing_ms": 0.14479951479200387, "mean_env_wait_ms": 0.12020177944923528, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 342342, "agent_timesteps_total": 684684, "timers": {"sample_time_ms": 3515.098, "sample_throughput": 1708.629, "learn_time_ms": 14277.679, "learn_throughput": 420.657, "update_time_ms": 4.501}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4561394691467283, "cur_lr": 5.000000000000002e-05, "total_loss": 176856.43916223405, "policy_loss": 0.00262965903954303, "vf_loss": 176856.4375, "vf_explained_var": "null", "kl": 0.015207539570141346, "entropy": 2.825575382151502, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 872471.5305851063, "policy_loss": 0.0015444188041889922, "vf_loss": 872471.527925532, "vf_explained_var": "null", "kl": 0.021947664426679305, "entropy": 3.3749060123524766, "entropy_coeff": 0.0}}}, "num_steps_sampled": 342342, "num_agent_steps_sampled": 684684, "num_steps_trained": 342342, "num_agent_steps_trained": 684684}, "done": false, "episodes_total": 342, "training_iteration": 57, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-37-18", "timestamp": 1624919838, "time_this_iter_s": 17.835576057434082, "time_total_s": 1031.0656745433807, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b02ded08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b02debf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1031.0656745433807, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 23.45, "ram_util_percent": 60.216666666666676, "gpu_util_percent0": 0.22625000000000003, "vram_util_percent0": 0.22786765531962702}, "trial_id": "f813a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_max": {"pol0": -11000.0, "pol1": 11000.0}, "policy_reward_mean": {"pol0": -11000.0, "pol1": 11000.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0, -11000.0], "policy_pol1_reward": [11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20479294604396522, "mean_inference_ms": 2.836778622126224, "mean_action_processing_ms": 0.14482211211295443, "mean_env_wait_ms": 0.12021568179049585, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 348348, "agent_timesteps_total": 696696, "timers": {"sample_time_ms": 3513.685, "sample_throughput": 1709.317, "learn_time_ms": 14548.76, "learn_throughput": 412.819, "update_time_ms": 4.764}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4561394691467283, "cur_lr": 5.000000000000002e-05, "total_loss": 168406.28324468085, "policy_loss": -0.3044102027061138, "vf_loss": 168406.59375, "vf_explained_var": "null", "kl": 0.005187757660020539, "entropy": 2.8394689306299736, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 749634.5053191489, "policy_loss": -0.0028171614605061552, "vf_loss": 749634.5106382979, "vf_explained_var": "null", "kl": 0.006332047580880054, "entropy": 3.464355839059708, "entropy_coeff": 0.0}}}, "num_steps_sampled": 348348, "num_agent_steps_sampled": 696696, "num_steps_trained": 348348, "num_agent_steps_trained": 696696}, "done": false, "episodes_total": 348, "training_iteration": 58, "experiment_id": "32781e4b19ba47aabe1304056828d7cd", "date": "2021-06-29_01-37-38", "timestamp": 1624919858, "time_this_iter_s": 20.38552451133728, "time_total_s": 1051.451199054718, "pid": 9726, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f37b028c158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f37b028c268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1051.451199054718, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 22.799999999999997, "ram_util_percent": 60.28518518518518, "gpu_util_percent0": 0.2151851851851852, "vram_util_percent0": 0.22788950055549317}, "trial_id": "f813a_00000"}
