{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1917410.485208946, "pol1": 1639767.7874626834}, "policy_reward_max": {"pol0": -1639767.7874626834, "pol1": 1917410.485208946}, "policy_reward_mean": {"pol0": -1792680.3726028122, "pol1": 1792680.3726028122}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2102867730522029, "mean_inference_ms": 2.943040843971237, "mean_action_processing_ms": 0.14988454436748247, "mean_env_wait_ms": 0.12535066978977427, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 6006, "agent_timesteps_total": 12012, "timers": {"sample_time_ms": 3586.857, "sample_throughput": 1674.447, "learn_time_ms": 17470.135, "learn_throughput": 343.787, "update_time_ms": 7.398}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27112832631.82979, "policy_loss": -0.004187914205992476, "vf_loss": 27112832631.82979, "vf_explained_var": -9.89183490673895e-08, "kl": 0.005494881867173504, "entropy": 2.8400896356460894, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27112514058.893616, "policy_loss": -0.0037750693711828677, "vf_loss": 27112514058.893616, "vf_explained_var": 1.0145471662781347e-07, "kl": 0.005858454080496697, "entropy": 2.845917265465919, "entropy_coeff": 0.0}}}, "num_steps_sampled": 6006, "num_agent_steps_sampled": 12012, "num_steps_trained": 6006, "num_agent_steps_trained": 12012}, "done": false, "episodes_total": 6, "training_iteration": 1, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-39-26", "timestamp": 1624919966, "time_this_iter_s": 21.073989391326904, "time_total_s": 21.073989391326904, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e06f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e10048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.073989391326904, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 20.603571428571428, "ram_util_percent": 59.17142857142858, "gpu_util_percent0": 0.22571428571428573, "vram_util_percent0": 0.22887476527516964}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1483765.574457984}, "policy_reward_max": {"pol0": -1483765.574457984, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1796979.2914304817, "pol1": 1796979.2914304817}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22129102680960322, "mean_inference_ms": 3.0693351612617956, "mean_action_processing_ms": 0.15569083395780478, "mean_env_wait_ms": 0.1297318200092363, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 12012, "agent_timesteps_total": 24024, "timers": {"sample_time_ms": 3918.0, "sample_throughput": 1532.925, "learn_time_ms": 17598.936, "learn_throughput": 341.271, "update_time_ms": 7.697}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27751322994.38298, "policy_loss": 3.93938550606687e-05, "vf_loss": 27751322994.38298, "vf_explained_var": 8.87728734966231e-09, "kl": 0.008275205229825161, "entropy": 2.8558965794583586, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27751803664.340427, "policy_loss": -0.0038677455183673414, "vf_loss": 27751803664.340427, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.007188894587786908, "entropy": 2.8654388163952116, "entropy_coeff": 0.0}}}, "num_steps_sampled": 12012, "num_agent_steps_sampled": 24024, "num_steps_trained": 12012, "num_agent_steps_trained": 24024}, "done": false, "episodes_total": 12, "training_iteration": 2, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-39-48", "timestamp": 1624919988, "time_this_iter_s": 21.993757963180542, "time_total_s": 43.067747354507446, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f17a7e18730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f16a41a4d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 43.067747354507446, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 23.448275862068964, "ram_util_percent": 59.32758620689656, "gpu_util_percent0": 0.23068965517241377, "vram_util_percent0": 0.2295015283056146}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1483765.574457984}, "policy_reward_max": {"pol0": -1483765.574457984, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1792279.9127051176, "pol1": 1792279.9127051176}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22663890569889034, "mean_inference_ms": 3.145446911648995, "mean_action_processing_ms": 0.15924712216056192, "mean_env_wait_ms": 0.13240782657284242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 18018, "agent_timesteps_total": 36036, "timers": {"sample_time_ms": 4044.805, "sample_throughput": 1484.868, "learn_time_ms": 17619.597, "learn_throughput": 340.87, "update_time_ms": 7.647}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26667950167.148937, "policy_loss": -0.0027171636119167853, "vf_loss": 26667950167.148937, "vf_explained_var": -2.5363679156953367e-08, "kl": 0.013085745691143453, "entropy": 2.840100293463849, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26673824310.468086, "policy_loss": -0.0032689750115288065, "vf_loss": 26673824310.468086, "vf_explained_var": 5.199554209411872e-08, "kl": 0.0076389824674326055, "entropy": 2.914680841121268, "entropy_coeff": 0.0}}}, "num_steps_sampled": 18018, "num_agent_steps_sampled": 36036, "num_steps_trained": 18018, "num_agent_steps_trained": 36036}, "done": false, "episodes_total": 18, "training_iteration": 3, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-40-10", "timestamp": 1624920010, "time_this_iter_s": 21.97562575340271, "time_total_s": 65.04337310791016, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e060d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682de96a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 65.04337310791016, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 23.644827586206898, "ram_util_percent": 59.40000000000001, "gpu_util_percent0": 0.23310344827586202, "vram_util_percent0": 0.22944922887393507}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1483765.574457984}, "policy_reward_max": {"pol0": -1483765.574457984, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1792932.4496078573, "pol1": 1792932.4496078573}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2296740619595429, "mean_inference_ms": 3.19232648233926, "mean_action_processing_ms": 0.1614863813030645, "mean_env_wait_ms": 0.1340734750242081, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 24024, "agent_timesteps_total": 48048, "timers": {"sample_time_ms": 4112.411, "sample_throughput": 1460.457, "learn_time_ms": 17877.302, "learn_throughput": 335.957, "update_time_ms": 7.493}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27050954229.106384, "policy_loss": -0.0003691218951915173, "vf_loss": 27050954229.106384, "vf_explained_var": -6.848193123687452e-08, "kl": 0.022413977758681522, "entropy": 2.949151926852287, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27059688426.212765, "policy_loss": 0.0009128164420736597, "vf_loss": 27059688426.212765, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.010944452196201111, "entropy": 2.9568031442926284, "entropy_coeff": 0.0}}}, "num_steps_sampled": 24024, "num_agent_steps_sampled": 48048, "num_steps_trained": 24024, "num_agent_steps_trained": 48048}, "done": false, "episodes_total": 24, "training_iteration": 4, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-40-33", "timestamp": 1624920033, "time_this_iter_s": 22.98150086402893, "time_total_s": 88.02487397193909, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dd5400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dd5378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 88.02487397193909, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 23.83333333333333, "ram_util_percent": 59.483333333333334, "gpu_util_percent0": 0.25133333333333335, "vram_util_percent0": 0.22947421638018192}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1768435.7217100107, "pol1": 1768435.7217100107}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23174065044497183, "mean_inference_ms": 3.2290535274390497, "mean_action_processing_ms": 0.1632434000548593, "mean_env_wait_ms": 0.1353840853627932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 30030, "agent_timesteps_total": 60060, "timers": {"sample_time_ms": 4151.665, "sample_throughput": 1446.649, "learn_time_ms": 18135.172, "learn_throughput": 331.18, "update_time_ms": 7.429}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 23588977206.468086, "policy_loss": 0.0008063591580758703, "vf_loss": 23588977206.468086, "vf_explained_var": -1.318911273529011e-07, "kl": 0.01927925800865001, "entropy": 3.0475903318283404, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 23598455568.340427, "policy_loss": 0.0010318836950241252, "vf_loss": 23598455568.340427, "vf_explained_var": -7.609103569450326e-09, "kl": 0.01916903388151463, "entropy": 3.0506302448029214, "entropy_coeff": 0.0}}}, "num_steps_sampled": 30030, "num_agent_steps_sampled": 60060, "num_steps_trained": 30030, "num_agent_steps_trained": 60060}, "done": false, "episodes_total": 30, "training_iteration": 5, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-40-57", "timestamp": 1624920057, "time_this_iter_s": 23.490630388259888, "time_total_s": 111.51550436019897, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e100d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dd5ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 111.51550436019897, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 24.067741935483873, "ram_util_percent": 59.44193548387099, "gpu_util_percent0": 0.22096774193548388, "vram_util_percent0": 0.22946497493938697}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1764463.1715868106, "pol1": 1764463.1715868106}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23404449113351442, "mean_inference_ms": 3.2673566277078354, "mean_action_processing_ms": 0.16508538993137079, "mean_env_wait_ms": 0.13677574599092554, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 36036, "agent_timesteps_total": 72072, "timers": {"sample_time_ms": 4253.01, "sample_throughput": 1412.176, "learn_time_ms": 18533.7, "learn_throughput": 324.058, "update_time_ms": 7.519}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25664135473.02128, "policy_loss": -0.00039682291606639295, "vf_loss": 25664135473.02128, "vf_explained_var": -9.384561394654156e-08, "kl": 0.012503712418231559, "entropy": 3.0524899604472706, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25669644767.31915, "policy_loss": -0.0005240597504567592, "vf_loss": 25669644767.31915, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.009329495733564204, "entropy": 2.9436238572952593, "entropy_coeff": 0.0}}}, "num_steps_sampled": 36036, "num_agent_steps_sampled": 72072, "num_steps_trained": 36036, "num_agent_steps_trained": 72072}, "done": false, "episodes_total": 36, "training_iteration": 6, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-41-22", "timestamp": 1624920082, "time_this_iter_s": 25.303635597229004, "time_total_s": 136.81913995742798, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e101e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e10bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 136.81913995742798, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 24.86875, "ram_util_percent": 59.496875, "gpu_util_percent0": 0.2403125, "vram_util_percent0": 0.22998820357263228}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1765828.6784853276, "pol1": 1765828.6784853276}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23608141840099792, "mean_inference_ms": 3.301951558630409, "mean_action_processing_ms": 0.16675876849943683, "mean_env_wait_ms": 0.13805242213132635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 42042, "agent_timesteps_total": 84084, "timers": {"sample_time_ms": 4298.098, "sample_throughput": 1397.362, "learn_time_ms": 18490.014, "learn_throughput": 324.824, "update_time_ms": 7.439}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26540641868.255318, "policy_loss": 0.002628168982869767, "vf_loss": 26540641868.255318, "vf_explained_var": 1.1667292199035728e-07, "kl": 0.014508105140734227, "entropy": 3.05674217609649, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26552717181.276596, "policy_loss": -0.0025756711219536497, "vf_loss": 26552717181.276596, "vf_explained_var": -2.4095495376741383e-08, "kl": 0.010589517771880677, "entropy": 3.044092924036878, "entropy_coeff": 0.0}}}, "num_steps_sampled": 42042, "num_agent_steps_sampled": 84084, "num_steps_trained": 42042, "num_agent_steps_trained": 84084}, "done": false, "episodes_total": 42, "training_iteration": 7, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-41-45", "timestamp": 1624920105, "time_this_iter_s": 22.812354803085327, "time_total_s": 159.6314947605133, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ddb488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ddb400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 159.6314947605133, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 24.34333333333333, "ram_util_percent": 59.52333333333331, "gpu_util_percent0": 0.22733333333333328, "vram_util_percent0": 0.2354679249522526}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1762873.1631135382, "pol1": 1762873.1631135382}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2373878378450852, "mean_inference_ms": 3.3250114487045033, "mean_action_processing_ms": 0.16789163745354982, "mean_env_wait_ms": 0.13890884880939774, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 48048, "agent_timesteps_total": 96096, "timers": {"sample_time_ms": 4264.041, "sample_throughput": 1408.523, "learn_time_ms": 17886.295, "learn_throughput": 335.788, "update_time_ms": 7.107}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25795030778.553192, "policy_loss": -0.001002196658481943, "vf_loss": 25795030778.553192, "vf_explained_var": 0.0, "kl": 0.016141428453649614, "entropy": 3.002215380364276, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25812865329.02128, "policy_loss": 0.009407609423741381, "vf_loss": 25812865329.02128, "vf_explained_var": 0.0, "kl": 0.03844459695701904, "entropy": 2.957110475986562, "entropy_coeff": 0.0}}}, "num_steps_sampled": 48048, "num_agent_steps_sampled": 96096, "num_steps_trained": 48048, "num_agent_steps_trained": 96096}, "done": false, "episodes_total": 48, "training_iteration": 8, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-42-03", "timestamp": 1624920123, "time_this_iter_s": 17.6973557472229, "time_total_s": 177.3288505077362, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ddb9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ddbf28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 177.3288505077362, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 24.620833333333334, "ram_util_percent": 59.525, "gpu_util_percent0": 0.2325, "vram_util_percent0": 0.23549320301089763}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1765992.00030022, "pol1": 1765992.00030022}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23775924310281235, "mean_inference_ms": 3.3338969722166514, "mean_action_processing_ms": 0.16833698737112315, "mean_env_wait_ms": 0.13921556400266227, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 54054, "agent_timesteps_total": 108108, "timers": {"sample_time_ms": 4186.585, "sample_throughput": 1434.582, "learn_time_ms": 17414.311, "learn_throughput": 344.889, "update_time_ms": 6.833}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 27046488674.042553, "policy_loss": 0.002454775702604588, "vf_loss": 27046488674.042553, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.017121646691985588, "entropy": 2.8941747178422643, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 27055242915.404255, "policy_loss": 0.003122103202374692, "vf_loss": 27055242915.404255, "vf_explained_var": 3.9313700739285196e-08, "kl": 0.01750067248940468, "entropy": 2.9903071231030403, "entropy_coeff": 0.0}}}, "num_steps_sampled": 54054, "num_agent_steps_sampled": 108108, "num_steps_trained": 54054, "num_agent_steps_trained": 108108}, "done": false, "episodes_total": 54, "training_iteration": 9, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-42-20", "timestamp": 1624920140, "time_this_iter_s": 17.216384172439575, "time_total_s": 194.54523468017578, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dd56a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dd5ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 194.54523468017578, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 22.40434782608696, "ram_util_percent": 59.5, "gpu_util_percent0": 0.2295652173913044, "vram_util_percent0": 0.23549625591653112}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1765926.3926044193, "pol1": 1765926.3926044193}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23760907696999525, "mean_inference_ms": 3.335178609901273, "mean_action_processing_ms": 0.16836505702572954, "mean_env_wait_ms": 0.1391925687773125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 60060, "agent_timesteps_total": 120120, "timers": {"sample_time_ms": 4115.677, "sample_throughput": 1459.298, "learn_time_ms": 17042.488, "learn_throughput": 352.413, "update_time_ms": 6.613}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26789403669.787235, "policy_loss": -0.00223695621528524, "vf_loss": 26789403669.787235, "vf_explained_var": 1.242820246716292e-07, "kl": 0.017771614675826216, "entropy": 2.7593982929879046, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26799727681.361702, "policy_loss": -0.002232603362186792, "vf_loss": 26799727681.361702, "vf_explained_var": 1.1033200308929736e-07, "kl": 0.011287051213390015, "entropy": 3.0279037648058953, "entropy_coeff": 0.0}}}, "num_steps_sampled": 60060, "num_agent_steps_sampled": 120120, "num_steps_trained": 60060, "num_agent_steps_trained": 120120}, "done": false, "episodes_total": 60, "training_iteration": 10, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-42-37", "timestamp": 1624920157, "time_this_iter_s": 17.184919118881226, "time_total_s": 211.730153799057, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e10a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 211.730153799057, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 22.96521739130435, "ram_util_percent": 59.3086956521739, "gpu_util_percent0": 0.2304347826086957, "vram_util_percent0": 0.23548892894301088}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1768597.8692904857, "pol1": 1768597.8692904857}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23716239974346, "mean_inference_ms": 3.331365822441448, "mean_action_processing_ms": 0.16815485932059313, "mean_env_wait_ms": 0.13897999032111275, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 66066, "agent_timesteps_total": 132132, "timers": {"sample_time_ms": 4100.904, "sample_throughput": 1464.555, "learn_time_ms": 16670.52, "learn_throughput": 360.277, "update_time_ms": 6.301}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 27247591946.893616, "policy_loss": -0.0025936303303596823, "vf_loss": 27247591946.893616, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.014136382992914382, "entropy": 2.7961991695647543, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 27264934933.787235, "policy_loss": 0.0013716188754807127, "vf_loss": 27264934933.787235, "vf_explained_var": -1.2174565711120522e-07, "kl": 0.013280273395332885, "entropy": 3.1308338134846787, "entropy_coeff": 0.0}}}, "num_steps_sampled": 66066, "num_agent_steps_sampled": 132132, "num_steps_trained": 66066, "num_agent_steps_trained": 132132}, "done": false, "episodes_total": 66, "training_iteration": 11, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-42-54", "timestamp": 1624920174, "time_this_iter_s": 17.200687170028687, "time_total_s": 228.9308409690857, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e06d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e06a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 228.9308409690857, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 23.217391304347824, "ram_util_percent": 59.33043478260871, "gpu_util_percent0": 0.22478260869565225, "vram_util_percent0": 0.23548160196949058}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1766993.0532908444, "pol1": 1766993.0532908444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23654200590612412, "mean_inference_ms": 3.3247726270799367, "mean_action_processing_ms": 0.1678150003377655, "mean_env_wait_ms": 0.13866746664423585, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 72072, "agent_timesteps_total": 144144, "timers": {"sample_time_ms": 4025.707, "sample_throughput": 1491.912, "learn_time_ms": 16271.293, "learn_throughput": 369.116, "update_time_ms": 5.955}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26422047112.17021, "policy_loss": 0.00046787565534419203, "vf_loss": 26422047112.17021, "vf_explained_var": 1.356956857989644e-07, "kl": 0.017291109870247384, "entropy": 2.799533301211418, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26433212677.446808, "policy_loss": 0.011829648345233278, "vf_loss": 26433212677.446808, "vf_explained_var": 3.2972781838225274e-08, "kl": 0.04648031088265967, "entropy": 2.9725850440086203, "entropy_coeff": 0.0}}}, "num_steps_sampled": 72072, "num_agent_steps_sampled": 144144, "num_steps_trained": 72072, "num_agent_steps_trained": 144144}, "done": false, "episodes_total": 72, "training_iteration": 12, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-43-12", "timestamp": 1624920192, "time_this_iter_s": 17.244308710098267, "time_total_s": 246.17514967918396, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e108c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 246.17514967918396, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 23.23913043478261, "ram_util_percent": 59.40000000000002, "gpu_util_percent0": 0.22391304347826088, "vram_util_percent0": 0.2354962559165312}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1772832.2787042558, "pol1": 1772832.2787042558}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23587035327939873, "mean_inference_ms": 3.3158241983044934, "mean_action_processing_ms": 0.16736920839372518, "mean_env_wait_ms": 0.13827610799616694, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 78078, "agent_timesteps_total": 156156, "timers": {"sample_time_ms": 3932.22, "sample_throughput": 1527.381, "learn_time_ms": 15877.778, "learn_throughput": 378.265, "update_time_ms": 5.666}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 28658105322.212765, "policy_loss": 0.0013917004689574242, "vf_loss": 28658105322.212765, "vf_explained_var": -4.311825207992115e-08, "kl": 0.01622307522499815, "entropy": 2.762661451989032, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 28678704236.93617, "policy_loss": -0.0017930359995745597, "vf_loss": 28678704236.93617, "vf_explained_var": -7.609103569450326e-09, "kl": 0.010493173620643769, "entropy": 3.091951588366894, "entropy_coeff": 0.0}}}, "num_steps_sampled": 78078, "num_agent_steps_sampled": 156156, "num_steps_trained": 78078, "num_agent_steps_trained": 156156}, "done": false, "episodes_total": 78, "training_iteration": 13, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-43-29", "timestamp": 1624920209, "time_this_iter_s": 17.101375579833984, "time_total_s": 263.27652525901794, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e10378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 263.27652525901794, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 23.39090909090909, "ram_util_percent": 59.44545454545455, "gpu_util_percent0": 0.2277272727272728, "vram_util_percent0": 0.23549958635904036}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1770681.9963935716, "pol1": 1770681.9963935716}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2351154795375338, "mean_inference_ms": 3.3057769459347885, "mean_action_processing_ms": 0.1668765146682635, "mean_env_wait_ms": 0.13784872918621044, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 84084, "agent_timesteps_total": 168168, "timers": {"sample_time_ms": 3837.188, "sample_throughput": 1565.209, "learn_time_ms": 15382.73, "learn_throughput": 390.438, "update_time_ms": 5.431}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25435087893.787235, "policy_loss": 0.001879516711577456, "vf_loss": 25435087893.787235, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.012188670720825804, "entropy": 2.818978106721919, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25453402852.765957, "policy_loss": -0.0022962028358845, "vf_loss": 25453402852.765957, "vf_explained_var": 1.3950023358688668e-08, "kl": 0.012378011552735846, "entropy": 3.1835501752001174, "entropy_coeff": 0.0}}}, "num_steps_sampled": 84084, "num_agent_steps_sampled": 168168, "num_steps_trained": 84084, "num_agent_steps_trained": 168168}, "done": false, "episodes_total": 84, "training_iteration": 14, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-43-46", "timestamp": 1624920226, "time_this_iter_s": 17.076974868774414, "time_total_s": 280.35350012779236, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ded7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ded840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 280.35350012779236, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 22.591304347826092, "ram_util_percent": 59.46521739130436, "gpu_util_percent0": 0.23043478260869577, "vram_util_percent0": 0.23528377368444184}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1770748.4450484104, "pol1": 1770748.4450484104}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2343604429725925, "mean_inference_ms": 3.2957402730585885, "mean_action_processing_ms": 0.16638690248283663, "mean_env_wait_ms": 0.1374232110009494, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 90090, "agent_timesteps_total": 180180, "timers": {"sample_time_ms": 3749.803, "sample_throughput": 1601.684, "learn_time_ms": 14843.16, "learn_throughput": 404.631, "update_time_ms": 5.173}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26343097409.361702, "policy_loss": -0.0012262104515065539, "vf_loss": 26343097409.361702, "vf_explained_var": -2.1559126039960574e-08, "kl": 0.011492726848797595, "entropy": 2.9430608039206647, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26367003364.765957, "policy_loss": 0.0009117824758620972, "vf_loss": 26367003364.765957, "vf_explained_var": 1.0145471129874295e-08, "kl": 0.020518468375852767, "entropy": 3.1488412085999835, "entropy_coeff": 0.0}}}, "num_steps_sampled": 90090, "num_agent_steps_sampled": 180180, "num_steps_trained": 90090, "num_agent_steps_trained": 180180}, "done": false, "episodes_total": 90, "training_iteration": 15, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-44-03", "timestamp": 1624920243, "time_this_iter_s": 17.219411611557007, "time_total_s": 297.57291173934937, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ded9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ded158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 297.57291173934937, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 23.208695652173915, "ram_util_percent": 59.49565217391305, "gpu_util_percent0": 0.22260869565217395, "vram_util_percent0": 0.23524713881684028}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1767010.1923726324, "pol1": 1767010.1923726324}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1689027.4091189557, -1779751.5312052718, -1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745], "policy_pol1_reward": [1689027.4091189557, 1779751.5312052718, 1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23358965769902226, "mean_inference_ms": 3.2854476230665655, "mean_action_processing_ms": 0.16588741377645122, "mean_env_wait_ms": 0.1369956894999566, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 96096, "agent_timesteps_total": 192192, "timers": {"sample_time_ms": 3619.469, "sample_throughput": 1659.359, "learn_time_ms": 14160.89, "learn_throughput": 424.126, "update_time_ms": 4.834}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 24660333328.340427, "policy_loss": -0.00035745979465068653, "vf_loss": 24660333328.340427, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.007200125931821605, "entropy": 2.8823517028321612, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 24676538760.17021, "policy_loss": 0.003959576500223038, "vf_loss": 24676538760.17021, "vf_explained_var": 9.257743016632958e-08, "kl": 0.01223030448593992, "entropy": 3.1137797122306012, "entropy_coeff": 0.0}}}, "num_steps_sampled": 96096, "num_agent_steps_sampled": 192192, "num_steps_trained": 96096, "num_agent_steps_trained": 192192}, "done": false, "episodes_total": 96, "training_iteration": 16, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-44-20", "timestamp": 1624920260, "time_this_iter_s": 17.171780824661255, "time_total_s": 314.7446925640106, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e108c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e107b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 314.7446925640106, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 22.395652173913046, "ram_util_percent": 59.40000000000002, "gpu_util_percent0": 0.2234782608695653, "vram_util_percent0": 0.23523981184331996}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1765215.3196888978, "pol1": 1765215.3196888978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1639767.7874626834, -1831222.0355616254, -1917410.485208946, -1898902.987059391, -1889285.9872589593, -1855591.8868472937, -1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244], "policy_pol1_reward": [1639767.7874626834, 1831222.0355616254, 1917410.485208946, 1898902.987059391, 1889285.9872589593, 1855591.8868472937, 1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2333192929826946, "mean_inference_ms": 3.2804282051511815, "mean_action_processing_ms": 0.16561898316554746, "mean_env_wait_ms": 0.13676383288488367, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 102102, "agent_timesteps_total": 204204, "timers": {"sample_time_ms": 3491.824, "sample_throughput": 1720.018, "learn_time_ms": 13722.088, "learn_throughput": 437.688, "update_time_ms": 4.625}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25118368310.468086, "policy_loss": 0.0016002977623584423, "vf_loss": 25118368310.468086, "vf_explained_var": -1.775457469932462e-08, "kl": 0.027379965488897994, "entropy": 2.771437771776889, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25138672705.361702, "policy_loss": 0.00044644622013289875, "vf_loss": 25138672705.361702, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.011821366311546335, "entropy": 3.0264189040407223, "entropy_coeff": 0.0}}}, "num_steps_sampled": 102102, "num_agent_steps_sampled": 204204, "num_steps_trained": 102102, "num_agent_steps_trained": 204204}, "done": false, "episodes_total": 102, "training_iteration": 17, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-44-38", "timestamp": 1624920278, "time_this_iter_s": 17.144266366958618, "time_total_s": 331.88895893096924, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e10a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 331.88895893096924, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 23.321739130434786, "ram_util_percent": 59.48260869565217, "gpu_util_percent0": 0.22695652173913053, "vram_util_percent0": 0.23525446579036058}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1939170.5611096788, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1939170.5611096788}, "policy_reward_mean": {"pol0": -1758106.1571127283, "pol1": 1758106.1571127283}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1483765.574457984, -1776320.9473310914, -1939170.5611096788, -1863534.3045439, -1802524.498062629, -1916112.019453656, -1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723], "policy_pol1_reward": [1483765.574457984, 1776320.9473310914, 1939170.5611096788, 1863534.3045439, 1802524.498062629, 1916112.019453656, 1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2333680004742417, "mean_inference_ms": 3.285563903259351, "mean_action_processing_ms": 0.16585051758640618, "mean_env_wait_ms": 0.13685396844556014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 108108, "agent_timesteps_total": 216216, "timers": {"sample_time_ms": 3443.625, "sample_throughput": 1744.093, "learn_time_ms": 13734.797, "learn_throughput": 437.283, "update_time_ms": 4.618}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24750068844.93617, "policy_loss": 0.0017964834585151774, "vf_loss": 24750068844.93617, "vf_explained_var": -1.065274517486614e-07, "kl": 0.015733359956202356, "entropy": 2.8571329776276935, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 24769897668.085106, "policy_loss": -7.089950699121394e-05, "vf_loss": 24769897668.085106, "vf_explained_var": 0.0, "kl": 0.01621715248899257, "entropy": 2.9473434001841445, "entropy_coeff": 0.0}}}, "num_steps_sampled": 108108, "num_agent_steps_sampled": 216216, "num_steps_trained": 108108, "num_agent_steps_trained": 216216}, "done": false, "episodes_total": 108, "training_iteration": 18, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-44-55", "timestamp": 1624920295, "time_this_iter_s": 17.3428635597229, "time_total_s": 349.23182249069214, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ded400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dedea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 349.23182249069214, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 23.391304347826086, "ram_util_percent": 59.40000000000002, "gpu_util_percent0": 0.22565217391304357, "vram_util_percent0": 0.23524713881684023}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930835.5966091985, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1930835.5966091985}, "policy_reward_mean": {"pol0": -1754868.3708900798, "pol1": 1754868.3708900798}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1740810.3004015686, -1860648.9248379278, -1672395.198667304, -1704795.9901032506, -1811400.8451902645, -1704199.4105247958, -1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553], "policy_pol1_reward": [1740810.3004015686, 1860648.9248379278, 1672395.198667304, 1704795.9901032506, 1811400.8451902645, 1704199.4105247958, 1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23242987502597046, "mean_inference_ms": 3.2754032053608655, "mean_action_processing_ms": 0.16538255987301434, "mean_env_wait_ms": 0.1364211681589118, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 114114, "agent_timesteps_total": 228228, "timers": {"sample_time_ms": 3428.778, "sample_throughput": 1751.645, "learn_time_ms": 13749.495, "learn_throughput": 436.816, "update_time_ms": 4.638}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25633440092.595745, "policy_loss": -0.0005160837255893869, "vf_loss": 25633440092.595745, "vf_explained_var": 9.638198150696553e-08, "kl": 0.00951893762388128, "entropy": 2.8385144649667944, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25657372933.446808, "policy_loss": 0.0018811844527087313, "vf_loss": 25657372933.446808, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.01334613414996482, "entropy": 2.8966432885920748, "entropy_coeff": 0.0}}}, "num_steps_sampled": 114114, "num_agent_steps_sampled": 228228, "num_steps_trained": 114114, "num_agent_steps_trained": 228228}, "done": false, "episodes_total": 114, "training_iteration": 19, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-45-12", "timestamp": 1624920312, "time_this_iter_s": 17.21675133705139, "time_total_s": 366.44857382774353, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dedae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682deda60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 366.44857382774353, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 23.013043478260872, "ram_util_percent": 59.40000000000002, "gpu_util_percent0": 0.22739130434782603, "vram_util_percent0": 0.23524713881684028}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1938027.611557932, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1938027.611557932}, "policy_reward_mean": {"pol0": -1757198.0679669776, "pol1": 1757198.0679669776}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1820577.304868135, -1860987.6773123879, -1803305.4738621642, -1768869.650138709, -1782158.0359626655, -1818529.1883653854, -1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142], "policy_pol1_reward": [1820577.304868135, 1860987.6773123879, 1803305.4738621642, 1768869.650138709, 1782158.0359626655, 1818529.1883653854, 1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23116300605297457, "mean_inference_ms": 3.2593885184339126, "mean_action_processing_ms": 0.16462414920779048, "mean_env_wait_ms": 0.13577037818672535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 120120, "agent_timesteps_total": 240240, "timers": {"sample_time_ms": 3423.101, "sample_throughput": 1754.549, "learn_time_ms": 13760.59, "learn_throughput": 436.464, "update_time_ms": 4.598}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 27122696192.0, "policy_loss": 0.0011855147263788162, "vf_loss": 27122696192.0, "vf_explained_var": 1.775457469932462e-08, "kl": 0.011505126358663782, "entropy": 2.8956623331029365, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 27144666351.659573, "policy_loss": 2.97531802603539e-06, "vf_loss": 27144666351.659573, "vf_explained_var": 2.5363679156953367e-08, "kl": 0.011950474589111958, "entropy": 2.852769430647505, "entropy_coeff": 0.0}}}, "num_steps_sampled": 120120, "num_agent_steps_sampled": 240240, "num_steps_trained": 120120, "num_agent_steps_trained": 240240}, "done": false, "episodes_total": 120, "training_iteration": 20, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-45-29", "timestamp": 1624920329, "time_this_iter_s": 17.239519596099854, "time_total_s": 383.6880934238434, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ded8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ded048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 383.6880934238434, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 22.87391304347826, "ram_util_percent": 59.417391304347845, "gpu_util_percent0": 0.2221739130434783, "vram_util_percent0": 0.23523981184331996}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1938027.611557932, "pol1": 1297831.80755207}, "policy_reward_max": {"pol0": -1297831.80755207, "pol1": 1938027.611557932}, "policy_reward_mean": {"pol0": -1747494.251250781, "pol1": 1747494.251250781}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1621117.233965037, -1297831.80755207, -1770493.7755053877, -1732562.819361204, -1919503.3132565552, -1560876.1705293881, -1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682], "policy_pol1_reward": [1621117.233965037, 1297831.80755207, 1770493.7755053877, 1732562.819361204, 1919503.3132565552, 1560876.1705293881, 1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2297753715127001, "mean_inference_ms": 3.2418241621049346, "mean_action_processing_ms": 0.16377811216898994, "mean_env_wait_ms": 0.13504573097289, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 126126, "agent_timesteps_total": 252252, "timers": {"sample_time_ms": 3427.629, "sample_throughput": 1752.232, "learn_time_ms": 13766.938, "learn_throughput": 436.263, "update_time_ms": 4.618}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 23019133668.765957, "policy_loss": -0.001082858665192381, "vf_loss": 23019133668.765957, "vf_explained_var": -1.39500230034173e-07, "kl": 0.017750131283351716, "entropy": 2.948890949817414, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 23036857496.51064, "policy_loss": 0.0010710107360748535, "vf_loss": 23036857496.51064, "vf_explained_var": -5.0727358313906734e-08, "kl": 0.014792659399198724, "entropy": 2.8483855825789433, "entropy_coeff": 0.0}}}, "num_steps_sampled": 126126, "num_agent_steps_sampled": 252252, "num_steps_trained": 126126, "num_agent_steps_trained": 252252}, "done": false, "episodes_total": 126, "training_iteration": 21, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-45-47", "timestamp": 1624920347, "time_this_iter_s": 17.310553312301636, "time_total_s": 400.998646736145, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e101e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 400.998646736145, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 23.139130434782615, "ram_util_percent": 59.40000000000002, "gpu_util_percent0": 0.22521739130434792, "vram_util_percent0": 0.23524713881684028}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1938027.611557932, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 1938027.611557932}, "policy_reward_mean": {"pol0": -1758624.2106076828, "pol1": 1758624.2106076828}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1836976.7076821143, -1792819.504878985, -1763794.810534404, -1593632.018943424, -1831646.7775340425, -1547603.359329446, -1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922], "policy_pol1_reward": [1836976.7076821143, 1792819.504878985, 1763794.810534404, 1593632.018943424, 1831646.7775340425, 1547603.359329446, 1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2281905259478864, "mean_inference_ms": 3.219899632131618, "mean_action_processing_ms": 0.16272204937957555, "mean_env_wait_ms": 0.13416029224016282, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 132132, "agent_timesteps_total": 264264, "timers": {"sample_time_ms": 3420.645, "sample_throughput": 1755.809, "learn_time_ms": 13774.327, "learn_throughput": 436.029, "update_time_ms": 4.61}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 28384398139.914894, "policy_loss": -0.0018449269552180108, "vf_loss": 28384398139.914894, "vf_explained_var": -1.0145471662781347e-07, "kl": 0.01600674345613794, "entropy": 2.863798461061843, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 28412135336.851063, "policy_loss": 0.0021900788464761793, "vf_loss": 28412135336.851063, "vf_explained_var": -1.6486390919112637e-08, "kl": 0.015591089494843433, "entropy": 3.0322921174637814, "entropy_coeff": 0.0}}}, "num_steps_sampled": 132132, "num_agent_steps_sampled": 264264, "num_steps_trained": 132132, "num_agent_steps_trained": 264264}, "done": false, "episodes_total": 132, "training_iteration": 22, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-46-04", "timestamp": 1624920364, "time_this_iter_s": 17.24819850921631, "time_total_s": 418.2468452453613, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ddb950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ddbae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 418.2468452453613, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 22.791304347826088, "ram_util_percent": 59.49565217391305, "gpu_util_percent0": 0.22695652173913047, "vram_util_percent0": 0.23524713881684023}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1994870.3143729162, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 1994870.3143729162}, "policy_reward_mean": {"pol0": -1767948.2194333277, "pol1": 1767948.2194333277}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1758101.2000021506, -1809712.080087352, -1907679.478865822, -1789387.4234397549, -1842507.9671740825, -1643249.2342687245, -1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622], "policy_pol1_reward": [1758101.2000021506, 1809712.080087352, 1907679.478865822, 1789387.4234397549, 1842507.9671740825, 1643249.2342687245, 1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22626873599730796, "mean_inference_ms": 3.1930996173997683, "mean_action_processing_ms": 0.161429073471607, "mean_env_wait_ms": 0.13309076579131507, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 138138, "agent_timesteps_total": 276276, "timers": {"sample_time_ms": 3437.396, "sample_throughput": 1747.253, "learn_time_ms": 13793.279, "learn_throughput": 435.429, "update_time_ms": 4.734}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 30477976205.61702, "policy_loss": 0.006780504595805356, "vf_loss": 30477976205.61702, "vf_explained_var": 8.750468794005428e-08, "kl": 0.02120450642356213, "entropy": 2.8499030863985104, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 30507725105.02128, "policy_loss": 0.008691042166282522, "vf_loss": 30507725105.02128, "vf_explained_var": 0.0, "kl": 0.04283630546737224, "entropy": 2.9467486980113575, "entropy_coeff": 0.0}}}, "num_steps_sampled": 138138, "num_agent_steps_sampled": 276276, "num_steps_trained": 138138, "num_agent_steps_trained": 276276}, "done": false, "episodes_total": 138, "training_iteration": 23, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-46-22", "timestamp": 1624920382, "time_this_iter_s": 17.46121311187744, "time_total_s": 435.70805835723877, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e10bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 435.70805835723877, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 22.708333333333332, "ram_util_percent": 59.40416666666666, "gpu_util_percent0": 0.22541666666666668, "vram_util_percent0": 0.23524744410740364}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1994870.3143729162, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 1994870.3143729162}, "policy_reward_mean": {"pol0": -1765176.404692442, "pol1": 1765176.404692442}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1741334.9679834773, -1696927.2427009796, -1690345.6158841979, -1838742.3050546169, -1805818.9908052378, -1779773.6576166449, -1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086], "policy_pol1_reward": [1741334.9679834773, 1696927.2427009796, 1690345.6158841979, 1838742.3050546169, 1805818.9908052378, 1779773.6576166449, 1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22427340249008942, "mean_inference_ms": 3.1639193068830065, "mean_action_processing_ms": 0.16002072718146226, "mean_env_wait_ms": 0.13193036014612747, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 144144, "agent_timesteps_total": 288288, "timers": {"sample_time_ms": 3446.581, "sample_throughput": 1742.596, "learn_time_ms": 13811.409, "learn_throughput": 434.858, "update_time_ms": 4.734}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25556774606.97872, "policy_loss": 0.0044215465400447235, "vf_loss": 25556774606.97872, "vf_explained_var": -4.438643586013313e-08, "kl": 0.0122956560647234, "entropy": 2.865313240822325, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 25581881954.042553, "policy_loss": 0.003457653395673062, "vf_loss": 25581881954.042553, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.017903174709607946, "entropy": 2.8572817356028457, "entropy_coeff": 0.0}}}, "num_steps_sampled": 144144, "num_agent_steps_sampled": 288288, "num_steps_trained": 144144, "num_agent_steps_trained": 288288}, "done": false, "episodes_total": 144, "training_iteration": 24, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-46-39", "timestamp": 1624920399, "time_this_iter_s": 17.35038447380066, "time_total_s": 453.05844283103943, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ddb598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 453.05844283103943, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 23.047826086956523, "ram_util_percent": 59.5, "gpu_util_percent0": 0.22869565217391308, "vram_util_percent0": 0.23524713881684028}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1773941.211127742, "pol1": 1773941.211127742}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1827459.2985100877, -1839747.111452246, -1818368.7830557318, -1674488.3453220865, -1680173.32584974, -1865936.9508901334, -1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583], "policy_pol1_reward": [1827459.2985100877, 1839747.111452246, 1818368.7830557318, 1674488.3453220865, 1680173.32584974, 1865936.9508901334, 1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2223901236662315, "mean_inference_ms": 3.1371710864367235, "mean_action_processing_ms": 0.15872340271447286, "mean_env_wait_ms": 0.13085433261199428, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 150150, "agent_timesteps_total": 300300, "timers": {"sample_time_ms": 3461.246, "sample_throughput": 1735.213, "learn_time_ms": 13818.966, "learn_throughput": 434.62, "update_time_ms": 4.735}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 31584807173.446808, "policy_loss": -0.00025242713696145, "vf_loss": 31584807173.446808, "vf_explained_var": 0.0, "kl": 0.00867533035814128, "entropy": 2.851018099074668, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 31618812949.787235, "policy_loss": 0.027146076426861135, "vf_loss": 31618812949.787235, "vf_explained_var": -1.0906381930908537e-07, "kl": 0.05404416764987276, "entropy": 2.926114244663969, "entropy_coeff": 0.0}}}, "num_steps_sampled": 150150, "num_agent_steps_sampled": 300300, "num_steps_trained": 150150, "num_agent_steps_trained": 300300}, "done": false, "episodes_total": 150, "training_iteration": 25, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-46-56", "timestamp": 1624920416, "time_this_iter_s": 17.439450979232788, "time_total_s": 470.4978938102722, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ded0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ded048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 470.4978938102722, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 23.295652173913048, "ram_util_percent": 59.40000000000002, "gpu_util_percent0": 0.22391304347826088, "vram_util_percent0": 0.23524713881684028}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1769269.8431706866, "pol1": 1769269.8431706866}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1666750.445947326, -1761266.4971553248, -1727024.9240075403, -1890863.396203244, -1721049.9153621707, -1520186.2445728339, -1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261], "policy_pol1_reward": [1666750.445947326, 1761266.4971553248, 1727024.9240075403, 1890863.396203244, 1721049.9153621707, 1520186.2445728339, 1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2208035838367439, "mean_inference_ms": 3.1139803888597872, "mean_action_processing_ms": 0.15760766788839878, "mean_env_wait_ms": 0.12993378014194848, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 156156, "agent_timesteps_total": 312312, "timers": {"sample_time_ms": 3450.346, "sample_throughput": 1740.695, "learn_time_ms": 13844.959, "learn_throughput": 433.804, "update_time_ms": 4.727}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 24524135140.765957, "policy_loss": -0.0010849411619153428, "vf_loss": 24524135140.765957, "vf_explained_var": -2.1559126039960574e-08, "kl": 0.005876372181909516, "entropy": 2.8673558285895813, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5187499999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 24549321749.787235, "policy_loss": 0.0031500278595597187, "vf_loss": 24549321749.787235, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.014680860009282194, "entropy": 2.940580784006322, "entropy_coeff": 0.0}}}, "num_steps_sampled": 156156, "num_agent_steps_sampled": 312312, "num_steps_trained": 156156, "num_agent_steps_trained": 312312}, "done": false, "episodes_total": 156, "training_iteration": 26, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-47-14", "timestamp": 1624920434, "time_this_iter_s": 17.323139905929565, "time_total_s": 487.8210337162018, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d841e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 487.8210337162018, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 23.378260869565214, "ram_util_percent": 59.317391304347815, "gpu_util_percent0": 0.22043478260869567, "vram_util_percent0": 0.23525446579036058}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1780446.1037023868, "pol1": 1780446.1037023868}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1846420.9933062117, -1860862.6489773756, -1930835.5966091985, -1892520.4180790933, -1832240.2956981522, -1895295.662814588, -1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023], "policy_pol1_reward": [1846420.9933062117, 1860862.6489773756, 1930835.5966091985, 1892520.4180790933, 1832240.2956981522, 1895295.662814588, 1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21943835396943737, "mean_inference_ms": 3.0937132760810098, "mean_action_processing_ms": 0.15665263413236943, "mean_env_wait_ms": 0.12914478406163785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 162162, "agent_timesteps_total": 324324, "timers": {"sample_time_ms": 3478.872, "sample_throughput": 1726.422, "learn_time_ms": 13838.907, "learn_throughput": 433.994, "update_time_ms": 4.702}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 31449289793.361702, "policy_loss": 0.001420106699175023, "vf_loss": 31449289793.361702, "vf_explained_var": -1.1160018686950934e-07, "kl": 0.014746873956569966, "entropy": 2.892775682692832, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5187499999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 31479787825.02128, "policy_loss": 0.017475954930674522, "vf_loss": 31479787825.02128, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.04271748606511887, "entropy": 2.9235232332919505, "entropy_coeff": 0.0}}}, "num_steps_sampled": 162162, "num_agent_steps_sampled": 324324, "num_steps_trained": 162162, "num_agent_steps_trained": 324324}, "done": false, "episodes_total": 162, "training_iteration": 27, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-47-31", "timestamp": 1624920451, "time_this_iter_s": 17.369013786315918, "time_total_s": 505.1900475025177, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 505.1900475025177, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 23.221739130434784, "ram_util_percent": 59.3086956521739, "gpu_util_percent0": 0.22391304347826088, "vram_util_percent0": 0.23524713881684023}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1775308.9918378314, "pol1": 1775308.9918378314}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1711830.4816242314, -1513803.2718679155, -1736510.756060301, -1806359.9957035438, -1745346.4161192453, -1812676.9828315033, -1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294], "policy_pol1_reward": [1711830.4816242314, 1513803.2718679155, 1736510.756060301, 1806359.9957035438, 1745346.4161192453, 1812676.9828315033, 1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21823518050585305, "mean_inference_ms": 3.0756621326814826, "mean_action_processing_ms": 0.15580656361303696, "mean_env_wait_ms": 0.12844834532709754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 168168, "agent_timesteps_total": 336336, "timers": {"sample_time_ms": 3466.6, "sample_throughput": 1732.533, "learn_time_ms": 13856.929, "learn_throughput": 433.429, "update_time_ms": 4.712}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 27050435692.93617, "policy_loss": -0.003598270561308303, "vf_loss": 27050435692.93617, "vf_explained_var": -1.2681839578476684e-08, "kl": 0.005685363321545276, "entropy": 2.903726060339745, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2781250000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 27079029302.468086, "policy_loss": 0.003874853808195033, "vf_loss": 27079029302.468086, "vf_explained_var": -3.424096561843726e-08, "kl": 0.016165959351557367, "entropy": 2.972087763725443, "entropy_coeff": 0.0}}}, "num_steps_sampled": 168168, "num_agent_steps_sampled": 336336, "num_steps_trained": 168168, "num_agent_steps_trained": 336336}, "done": false, "episodes_total": 168, "training_iteration": 28, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-47-49", "timestamp": 1624920469, "time_this_iter_s": 17.401010274887085, "time_total_s": 522.5910577774048, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e10d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e10d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 522.5910577774048, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 22.53333333333333, "ram_util_percent": 59.40416666666666, "gpu_util_percent0": 0.22708333333333333, "vram_util_percent0": 0.23524744410740364}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1776760.2788462876, "pol1": 1776760.2788462876}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1875309.4080837246, -1909689.2919485392, -1865327.680926779, -1849068.1220813543, -1704757.74166173, -1728902.9642894312, -1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024], "policy_pol1_reward": [1875309.4080837246, 1909689.2919485392, 1865327.680926779, 1849068.1220813543, 1704757.74166173, 1728902.9642894312, 1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21715010119655395, "mean_inference_ms": 3.059942435258256, "mean_action_processing_ms": 0.15507165322038718, "mean_env_wait_ms": 0.12784150195452407, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 174174, "agent_timesteps_total": 348348, "timers": {"sample_time_ms": 3462.81, "sample_throughput": 1734.429, "learn_time_ms": 13878.644, "learn_throughput": 432.751, "update_time_ms": 4.715}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25445989528.51064, "policy_loss": 0.0012107654375598787, "vf_loss": 25445989528.51064, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.012271288861619664, "entropy": 2.8760560167596694, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2781250000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 25471058660.765957, "policy_loss": 0.0012937988293297746, "vf_loss": 25471058660.765957, "vf_explained_var": -2.663186293716535e-08, "kl": 0.01469127364218869, "entropy": 2.985768439921927, "entropy_coeff": 0.0}}}, "num_steps_sampled": 174174, "num_agent_steps_sampled": 348348, "num_steps_trained": 174174, "num_agent_steps_trained": 348348}, "done": false, "episodes_total": 174, "training_iteration": 29, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-48-06", "timestamp": 1624920486, "time_this_iter_s": 17.396843910217285, "time_total_s": 539.9879016876221, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682ddb378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682ddb620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 539.9879016876221, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 23.33043478260869, "ram_util_percent": 59.39565217391306, "gpu_util_percent0": 0.22608695652173919, "vram_util_percent0": 0.23524713881684028}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1776890.2440892363, "pol1": 1776890.2440892363}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1788787.0085195035, -1668055.1069993866, -1758677.2463347032, -1807189.890323312, -1835903.510611015, -1891990.0303575876, -1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608], "policy_pol1_reward": [1788787.0085195035, 1668055.1069993866, 1758677.2463347032, 1807189.890323312, 1835903.510611015, 1891990.0303575876, 1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2161916044615556, "mean_inference_ms": 3.046461602545012, "mean_action_processing_ms": 0.15443355208721601, "mean_env_wait_ms": 0.12731325423476178, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 180180, "agent_timesteps_total": 360360, "timers": {"sample_time_ms": 3487.42, "sample_throughput": 1722.19, "learn_time_ms": 13884.433, "learn_throughput": 432.571, "update_time_ms": 4.755}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 28052537605.446808, "policy_loss": -0.00410401101838401, "vf_loss": 28052537605.446808, "vf_explained_var": 8.62365041598423e-08, "kl": 0.00417394269792799, "entropy": 2.859285466214444, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2781250000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 28088580749.61702, "policy_loss": 0.006269368600655109, "vf_loss": 28088580749.61702, "vf_explained_var": -6.340919789238342e-09, "kl": 0.01702308478428328, "entropy": 3.030524233554272, "entropy_coeff": 0.0}}}, "num_steps_sampled": 180180, "num_agent_steps_sampled": 360360, "num_steps_trained": 180180, "num_agent_steps_trained": 360360}, "done": false, "episodes_total": 180, "training_iteration": 30, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-48-24", "timestamp": 1624920504, "time_this_iter_s": 17.54383683204651, "time_total_s": 557.5317385196686, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d841e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 557.5317385196686, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 23.39565217391305, "ram_util_percent": 59.5, "gpu_util_percent0": 0.22217391304347836, "vram_util_percent0": 0.23524713881684028}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1776691.5417830325, "pol1": 1776691.5417830325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1815073.8501644894, -1653369.4273104426, -1777787.8323271412, -1655947.706526294, -1715414.884244174, -1506437.5683402505, -1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846], "policy_pol1_reward": [1815073.8501644894, 1653369.4273104426, 1777787.8323271412, 1655947.706526294, 1715414.884244174, 1506437.5683402505, 1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21532707674848445, "mean_inference_ms": 3.0341891306874107, "mean_action_processing_ms": 0.1538517240497167, "mean_env_wait_ms": 0.12683449404484148, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 186186, "agent_timesteps_total": 372372, "timers": {"sample_time_ms": 3480.771, "sample_throughput": 1725.48, "learn_time_ms": 13888.717, "learn_throughput": 432.437, "update_time_ms": 4.75}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 26798711786.212765, "policy_loss": 2.9874291825801767e-05, "vf_loss": 26798711786.212765, "vf_explained_var": -5.0727358313906734e-08, "kl": 0.014672877049033946, "entropy": 2.8051099878676395, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2781250000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 26830254515.744682, "policy_loss": 0.009955093205133651, "vf_loss": 26830254515.744682, "vf_explained_var": 1.0145471129874295e-08, "kl": 0.021184938266239267, "entropy": 3.0907847018952066, "entropy_coeff": 0.0}}}, "num_steps_sampled": 186186, "num_agent_steps_sampled": 372372, "num_steps_trained": 186186, "num_agent_steps_trained": 372372}, "done": false, "episodes_total": 186, "training_iteration": 31, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-48-41", "timestamp": 1624920521, "time_this_iter_s": 17.286266565322876, "time_total_s": 574.8180050849915, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 574.8180050849915, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 23.286956521739125, "ram_util_percent": 59.595652173913024, "gpu_util_percent0": 0.2304347826086957, "vram_util_percent0": 0.23523981184331996}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1781874.798596026, "pol1": 1781874.798596026}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1876965.7926859313, -1573696.9713642339, -1784594.0888810924, -1808509.1079000745, -1835195.9571658976, -1623332.029664395, -1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183], "policy_pol1_reward": [1876965.7926859313, 1573696.9713642339, 1784594.0888810924, 1808509.1079000745, 1835195.9571658976, 1623332.029664395, 1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2145398990203441, "mean_inference_ms": 3.022917299771546, "mean_action_processing_ms": 0.15331711917807772, "mean_env_wait_ms": 0.12639608076167577, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 192192, "agent_timesteps_total": 384384, "timers": {"sample_time_ms": 3492.065, "sample_throughput": 1719.899, "learn_time_ms": 13912.607, "learn_throughput": 431.695, "update_time_ms": 4.793}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 26472697986.723404, "policy_loss": -0.004093844899313247, "vf_loss": 26472697986.723404, "vf_explained_var": 0.0, "kl": 0.00998331929378687, "entropy": 2.715539404686461, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4171875000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26504583952.340427, "policy_loss": 0.007751857049446156, "vf_loss": 26504583952.340427, "vf_explained_var": -2.4095495376741383e-08, "kl": 0.020489584179000653, "entropy": 3.085963208624657, "entropy_coeff": 0.0}}}, "num_steps_sampled": 192192, "num_agent_steps_sampled": 384384, "num_steps_trained": 192192, "num_agent_steps_trained": 384384}, "done": false, "episodes_total": 192, "training_iteration": 32, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-48-59", "timestamp": 1624920539, "time_this_iter_s": 17.60038185119629, "time_total_s": 592.4183869361877, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 592.4183869361877, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 23.616666666666664, "ram_util_percent": 59.6, "gpu_util_percent0": 0.2204166666666667, "vram_util_percent0": 0.23442590720143808}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1782667.761709158, "pol1": 1782667.761709158}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1762395.538609491, -1843965.5211749899, -1654992.883560261, -1637450.511266244, -1651627.4648391975, -1751183.417784704, -1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625], "policy_pol1_reward": [1762395.538609491, 1843965.5211749899, 1654992.883560261, 1637450.511266244, 1651627.4648391975, 1751183.417784704, 1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21385078314189399, "mean_inference_ms": 3.012873929629177, "mean_action_processing_ms": 0.1528381652817956, "mean_env_wait_ms": 0.12599884629111313, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 198198, "agent_timesteps_total": 396396, "timers": {"sample_time_ms": 3491.32, "sample_throughput": 1720.266, "learn_time_ms": 13930.559, "learn_throughput": 431.138, "update_time_ms": 4.652}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 26026088448.0, "policy_loss": 0.018207677739097716, "vf_loss": 26026088448.0, "vf_explained_var": -1.6486390919112637e-08, "kl": 0.05373588458020637, "entropy": 2.7284156160151705, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.125781249999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26059101118.638298, "policy_loss": 0.008755419621283704, "vf_loss": 26059101118.638298, "vf_explained_var": 1.0145471129874295e-08, "kl": 0.019459021733479298, "entropy": 3.132746544290096, "entropy_coeff": 0.0}}}, "num_steps_sampled": 198198, "num_agent_steps_sampled": 396396, "num_steps_trained": 198198, "num_agent_steps_trained": 396396}, "done": false, "episodes_total": 198, "training_iteration": 33, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-49-16", "timestamp": 1624920556, "time_this_iter_s": 17.630451679229736, "time_total_s": 610.0488386154175, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f16a41a4d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f16a41a4400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 610.0488386154175, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 23.16086956521739, "ram_util_percent": 59.630434782608674, "gpu_util_percent0": 0.21782608695652173, "vram_util_percent0": 0.2333934145161999}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1786245.7167405316, "pol1": 1786245.7167405316}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1629492.002474449, -1834733.9675309483, -1767134.6209613963, -1687093.4381912723, -1848197.2114778438, -1644736.6326604937, -1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845], "policy_pol1_reward": [1629492.002474449, 1834733.9675309483, 1767134.6209613963, 1687093.4381912723, 1848197.2114778438, 1644736.6326604937, 1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2132277535327249, "mean_inference_ms": 3.003868619562748, "mean_action_processing_ms": 0.15240824101846262, "mean_env_wait_ms": 0.1256406723943075, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 204204, "agent_timesteps_total": 408408, "timers": {"sample_time_ms": 3488.108, "sample_throughput": 1721.85, "learn_time_ms": 13943.853, "learn_throughput": 430.727, "update_time_ms": 4.723}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26653459129.19149, "policy_loss": -0.003675810081210542, "vf_loss": 26653459129.19149, "vf_explained_var": 1.0779563552887339e-07, "kl": 0.008581003550677858, "entropy": 2.8920932729193507, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.125781249999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26689747989.787235, "policy_loss": 0.00702650119808126, "vf_loss": 26689747989.787235, "vf_explained_var": 1.775457469932462e-08, "kl": 0.025859215158097287, "entropy": 3.161507784052098, "entropy_coeff": 0.0}}}, "num_steps_sampled": 204204, "num_agent_steps_sampled": 408408, "num_steps_trained": 204204, "num_agent_steps_trained": 408408}, "done": false, "episodes_total": 204, "training_iteration": 34, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-49-34", "timestamp": 1624920574, "time_this_iter_s": 17.45266890525818, "time_total_s": 627.5015075206757, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682de6620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682de6048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 627.5015075206757, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 22.5625, "ram_util_percent": 59.69166666666667, "gpu_util_percent0": 0.22375000000000003, "vram_util_percent0": 0.2313433883833277}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1788585.0842630437, "pol1": 1788585.0842630437}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1915328.5056758388, -1530280.5540268908, -1877047.94840329, -1642058.4304496553, -1840328.060604403, -1887204.5044152036, -1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477], "policy_pol1_reward": [1915328.5056758388, 1530280.5540268908, 1877047.94840329, 1642058.4304496553, 1840328.060604403, 1887204.5044152036, 1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21267031701612576, "mean_inference_ms": 2.995583524682263, "mean_action_processing_ms": 0.15201241619917052, "mean_env_wait_ms": 0.1253103282169537, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 210210, "agent_timesteps_total": 420420, "timers": {"sample_time_ms": 3474.24, "sample_throughput": 1728.723, "learn_time_ms": 13962.363, "learn_throughput": 430.156, "update_time_ms": 4.706}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26336573178.553192, "policy_loss": -0.0018248706857891793, "vf_loss": 26336573178.553192, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.006933978689398537, "entropy": 2.874872567805838, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.688671875000002, "cur_lr": 5.000000000000002e-05, "total_loss": 26370503440.340427, "policy_loss": 0.00819229948869411, "vf_loss": 26370503440.340427, "vf_explained_var": -2.4095495376741383e-08, "kl": 0.027208744766230277, "entropy": 3.177543462590968, "entropy_coeff": 0.0}}}, "num_steps_sampled": 210210, "num_agent_steps_sampled": 420420, "num_steps_trained": 210210, "num_agent_steps_trained": 420420}, "done": false, "episodes_total": 210, "training_iteration": 35, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-49-51", "timestamp": 1624920591, "time_this_iter_s": 17.4865140914917, "time_total_s": 644.9880216121674, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682de6bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682de6f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 644.9880216121674, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 23.87391304347826, "ram_util_percent": 59.79130434782607, "gpu_util_percent0": 0.22217391304347825, "vram_util_percent0": 0.2313272079834703}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1784149.9710722982, "pol1": 1784149.9710722982}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1904874.5629725535, -1938027.611557932, -1582521.840265754, -1574263.7975991142, -1781874.3044085528, -1741758.9435462712, -1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195], "policy_pol1_reward": [1904874.5629725535, 1938027.611557932, 1582521.840265754, 1574263.7975991142, 1781874.3044085528, 1741758.9435462712, 1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21216338455223707, "mean_inference_ms": 2.9880827228903017, "mean_action_processing_ms": 0.15165224999422303, "mean_env_wait_ms": 0.12501031034925808, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 216216, "agent_timesteps_total": 432432, "timers": {"sample_time_ms": 3465.252, "sample_throughput": 1733.207, "learn_time_ms": 13963.888, "learn_throughput": 430.109, "update_time_ms": 4.726}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24569886807.148937, "policy_loss": 0.004985003890667824, "vf_loss": 24569886807.148937, "vf_explained_var": -3.0436414277801305e-08, "kl": 0.01232344064703013, "entropy": 2.8636626081263765, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 11.533007812500001, "cur_lr": 5.000000000000002e-05, "total_loss": 24602061845.787235, "policy_loss": 0.004468695478553468, "vf_loss": 24602061845.787235, "vf_explained_var": -5.0727358313906734e-08, "kl": 0.023227097149542037, "entropy": 3.237310232000148, "entropy_coeff": 0.0}}}, "num_steps_sampled": 216216, "num_agent_steps_sampled": 432432, "num_steps_trained": 216216, "num_agent_steps_trained": 432432}, "done": false, "episodes_total": 216, "training_iteration": 36, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-50-09", "timestamp": 1624920609, "time_this_iter_s": 17.24862289428711, "time_total_s": 662.2366445064545, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e06d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e06d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 662.2366445064545, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 23.191304347826087, "ram_util_percent": 59.79999999999998, "gpu_util_percent0": 0.22782608695652176, "vram_util_percent0": 0.23132720798347034}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1338430.0350204802}, "policy_reward_max": {"pol0": -1338430.0350204802, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1784964.263457776, "pol1": 1784964.263457776}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1338430.0350204802, -1450477.9856981956, -1823435.8688225744, -1748068.521393682, -1902965.7467241886, -1809582.243350356, -1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614], "policy_pol1_reward": [1338430.0350204802, 1450477.9856981956, 1823435.8688225744, 1748068.521393682, 1902965.7467241886, 1809582.243350356, 1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2116949241824958, "mean_inference_ms": 2.9809918403472415, "mean_action_processing_ms": 0.15131271268159638, "mean_env_wait_ms": 0.12472890242721547, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 222222, "agent_timesteps_total": 444444, "timers": {"sample_time_ms": 3439.744, "sample_throughput": 1746.06, "learn_time_ms": 13991.457, "learn_throughput": 429.262, "update_time_ms": 4.734}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26191631861.106384, "policy_loss": -0.0017560035327172025, "vf_loss": 26191631861.106384, "vf_explained_var": -1.0145471662781347e-07, "kl": 0.00847393427876399, "entropy": 2.8853597133717637, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 17.299511718749994, "cur_lr": 5.000000000000002e-05, "total_loss": 26230102146.723404, "policy_loss": 0.01123217384311113, "vf_loss": 26230102146.723404, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.0362286924364719, "entropy": 3.326891858527001, "entropy_coeff": 0.0}}}, "num_steps_sampled": 222222, "num_agent_steps_sampled": 444444, "num_steps_trained": 222222, "num_agent_steps_trained": 444444}, "done": false, "episodes_total": 222, "training_iteration": 37, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-50-26", "timestamp": 1624920626, "time_this_iter_s": 17.389559984207153, "time_total_s": 679.6262044906616, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 679.6262044906616, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 23.382608695652177, "ram_util_percent": 59.804347826086946, "gpu_util_percent0": 0.22347826086956524, "vram_util_percent0": 0.2313272079834703}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1431801.4551496261}, "policy_reward_max": {"pol0": -1431801.4551496261, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1793860.4011426629, "pol1": 1793860.4011426629}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1812053.9115968368, -1882414.1333991806, -1862015.3920537482, -1746349.6287354922, -1764737.2280801262, -1884897.08061852, -1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585], "policy_pol1_reward": [1812053.9115968368, 1882414.1333991806, 1862015.3920537482, 1746349.6287354922, 1764737.2280801262, 1884897.08061852, 1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2112545822932492, "mean_inference_ms": 2.9744534009951447, "mean_action_processing_ms": 0.15100111685574988, "mean_env_wait_ms": 0.12446969711568374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 228228, "agent_timesteps_total": 456456, "timers": {"sample_time_ms": 3436.353, "sample_throughput": 1747.783, "learn_time_ms": 13997.309, "learn_throughput": 429.082, "update_time_ms": 4.711}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 28723387195.914894, "policy_loss": 0.0020747167712196393, "vf_loss": 28723387195.914894, "vf_explained_var": 2.5363679156953367e-08, "kl": 0.00938383085613555, "entropy": 2.8988349944987197, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 25.949267578125006, "cur_lr": 5.000000000000002e-05, "total_loss": 28773255037.276596, "policy_loss": 0.05453979812483204, "vf_loss": 28773255037.276596, "vf_explained_var": 7.735921769835841e-08, "kl": 0.12629643653301484, "entropy": 3.3946617359810687, "entropy_coeff": 0.0}}}, "num_steps_sampled": 228228, "num_agent_steps_sampled": 456456, "num_steps_trained": 228228, "num_agent_steps_trained": 456456}, "done": false, "episodes_total": 228, "training_iteration": 38, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-50-43", "timestamp": 1624920643, "time_this_iter_s": 17.424962043762207, "time_total_s": 697.0511665344238, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dec488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dec378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 697.0511665344238, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 23.495652173913044, "ram_util_percent": 59.804347826086946, "gpu_util_percent0": 0.21913043478260874, "vram_util_percent0": 0.2313345349569906}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2092985.0432850483, "pol1": 1431801.4551496261}, "policy_reward_max": {"pol0": -1431801.4551496261, "pol1": 2092985.0432850483}, "policy_reward_mean": {"pol0": -1792426.3446080463, "pol1": 1792426.3446080463}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1795577.1402495347, -1994870.3143729162, -1981988.250391049, -1876804.0477547622, -1887020.0495419034, -1720727.7564303156, -1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312], "policy_pol1_reward": [1795577.1402495347, 1994870.3143729162, 1981988.250391049, 1876804.0477547622, 1887020.0495419034, 1720727.7564303156, 1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21085746789163262, "mean_inference_ms": 2.9683165868167567, "mean_action_processing_ms": 0.15071178117877074, "mean_env_wait_ms": 0.12422950311200781, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 234234, "agent_timesteps_total": 468468, "timers": {"sample_time_ms": 3443.538, "sample_throughput": 1744.136, "learn_time_ms": 14007.126, "learn_throughput": 428.782, "update_time_ms": 4.657}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 27159841683.06383, "policy_loss": -0.0040441336546172485, "vf_loss": 27159841683.06383, "vf_explained_var": -1.2681839578476684e-08, "kl": 0.008762388767555673, "entropy": 2.90116611440131, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 38.9239013671875, "cur_lr": 5.000000000000002e-05, "total_loss": 27204548608.0, "policy_loss": 0.010682845488190651, "vf_loss": 27204548608.0, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.028878490777408825, "entropy": 3.45681853497282, "entropy_coeff": 0.0}}}, "num_steps_sampled": 234234, "num_agent_steps_sampled": 468468, "num_steps_trained": 234234, "num_agent_steps_trained": 468468}, "done": false, "episodes_total": 234, "training_iteration": 39, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-51-01", "timestamp": 1624920661, "time_this_iter_s": 17.566288471221924, "time_total_s": 714.6174550056458, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f16a41a4400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 714.6174550056458, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 22.8875, "ram_util_percent": 59.79583333333333, "gpu_util_percent0": 0.22250000000000003, "vram_util_percent0": 0.23133636670037072}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1431801.4551496261}, "policy_reward_max": {"pol0": -1431801.4551496261, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1804774.2612199595, "pol1": 1804774.2612199595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1842333.7652512658, -1653388.3401066244, -1813621.2718226924, -1556364.7265965086, -1932308.3138069727, -2092985.0432850483, -1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207], "policy_pol1_reward": [1842333.7652512658, 1653388.3401066244, 1813621.2718226924, 1556364.7265965086, 1932308.3138069727, 2092985.0432850483, 1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21047957628437086, "mean_inference_ms": 2.962590713244889, "mean_action_processing_ms": 0.15044193756157687, "mean_env_wait_ms": 0.12400672115662913, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 240240, "agent_timesteps_total": 480480, "timers": {"sample_time_ms": 3417.866, "sample_throughput": 1757.237, "learn_time_ms": 14016.103, "learn_throughput": 428.507, "update_time_ms": 4.639}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 37517027720.17021, "policy_loss": 0.0028444371047489187, "vf_loss": 37517027720.17021, "vf_explained_var": 5.32637258743307e-08, "kl": 0.0122479933928302, "entropy": 2.838245635337018, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 58.385852050781224, "cur_lr": 5.000000000000002e-05, "total_loss": 37595175565.61702, "policy_loss": 0.04374172808007991, "vf_loss": 37595175565.61702, "vf_explained_var": 1.1413655798264699e-08, "kl": 0.11054418711586202, "entropy": 3.458983375671062, "entropy_coeff": 0.0}}}, "num_steps_sampled": 240240, "num_agent_steps_sampled": 480480, "num_steps_trained": 240240, "num_agent_steps_trained": 480480}, "done": false, "episodes_total": 240, "training_iteration": 40, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-51-18", "timestamp": 1624920678, "time_this_iter_s": 17.377195835113525, "time_total_s": 731.9946508407593, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 731.9946508407593, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 22.95652173913043, "ram_util_percent": 59.79999999999998, "gpu_util_percent0": 0.22304347826086957, "vram_util_percent0": 0.2313272079834703}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1431801.4551496261}, "policy_reward_max": {"pol0": -1431801.4551496261, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1798996.3560375813, "pol1": 1798996.3560375813}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1595187.7730327616, -1925744.7725614852, -2036859.5598320258, -1846337.9610568583, -1697355.4243941002, -1793160.2953117164, -1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125], "policy_pol1_reward": [1595187.7730327616, 1925744.7725614852, 2036859.5598320258, 1846337.9610568583, 1697355.4243941002, 1793160.2953117164, 1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21013808702131534, "mean_inference_ms": 2.95726370336683, "mean_action_processing_ms": 0.15018885289033618, "mean_env_wait_ms": 0.12380184661116057, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 246246, "agent_timesteps_total": 492492, "timers": {"sample_time_ms": 3421.992, "sample_throughput": 1755.118, "learn_time_ms": 14035.685, "learn_throughput": 427.909, "update_time_ms": 4.619}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24764409638.12766, "policy_loss": -0.00042302044544448243, "vf_loss": 24764409638.12766, "vf_explained_var": -1.204774804364206e-07, "kl": 0.008174300728801718, "entropy": 2.788417714707395, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 87.5787780761719, "cur_lr": 5.000000000000002e-05, "total_loss": 24801646809.87234, "policy_loss": 0.00893704597144685, "vf_loss": 24801646809.87234, "vf_explained_var": -7.609103569450326e-09, "kl": 0.03183144826362742, "entropy": 3.5697086466119643, "entropy_coeff": 0.0}}}, "num_steps_sampled": 246246, "num_agent_steps_sampled": 492492, "num_steps_trained": 246246, "num_agent_steps_trained": 492492}, "done": false, "episodes_total": 246, "training_iteration": 41, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-51-36", "timestamp": 1624920696, "time_this_iter_s": 17.52345871925354, "time_total_s": 749.5181095600128, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcd620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 749.5181095600128, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 23.617391304347823, "ram_util_percent": 59.70869565217393, "gpu_util_percent0": 0.2204347826086957, "vram_util_percent0": 0.23131988100995}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1431801.4551496261}, "policy_reward_max": {"pol0": -1431801.4551496261, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1815442.1263046118, "pol1": 1815442.1263046118}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1770171.3510298915, -1810147.3069572076, -1736401.1865319603, -1431801.4551496261, -1786731.293952077, -1991133.4997544826, -1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504], "policy_pol1_reward": [1770171.3510298915, 1810147.3069572076, 1736401.1865319603, 1431801.4551496261, 1786731.293952077, 1991133.4997544826, 1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2098122623083113, "mean_inference_ms": 2.9524808166431007, "mean_action_processing_ms": 0.14996350581121898, "mean_env_wait_ms": 0.12361922731550198, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 252252, "agent_timesteps_total": 504504, "timers": {"sample_time_ms": 3410.726, "sample_throughput": 1760.915, "learn_time_ms": 14029.981, "learn_throughput": 428.083, "update_time_ms": 4.569}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 37811812221.276596, "policy_loss": -0.00425436152541574, "vf_loss": 37811812221.276596, "vf_explained_var": 3.804551784725163e-09, "kl": 0.00790799181274277, "entropy": 2.8340471348863967, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 131.3681671142578, "cur_lr": 5.000000000000002e-05, "total_loss": 37899668545.3617, "policy_loss": 0.07365964380826087, "vf_loss": 37899668545.3617, "vf_explained_var": 8.87728734966231e-09, "kl": 0.13771545157787649, "entropy": 3.538035920325746, "entropy_coeff": 0.0}}}, "num_steps_sampled": 252252, "num_agent_steps_sampled": 504504, "num_steps_trained": 252252, "num_agent_steps_trained": 504504}, "done": false, "episodes_total": 252, "training_iteration": 42, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-51-53", "timestamp": 1624920713, "time_this_iter_s": 17.43029022216797, "time_total_s": 766.9483997821808, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdb70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcdf28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 766.9483997821808, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 22.774999999999995, "ram_util_percent": 59.69583333333333, "gpu_util_percent0": 0.22791666666666668, "vram_util_percent0": 0.2313223233344568}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1460184.198787845}, "policy_reward_max": {"pol0": -1460184.198787845, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1814099.0943530381, "pol1": 1814099.0943530381}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1642019.8925781108, -2000556.3000128674, -1909457.5901629578, -2074868.899958023, -1929476.8387063588, -1575808.0159539827, -1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696], "policy_pol1_reward": [1642019.8925781108, 2000556.3000128674, 1909457.5901629578, 2074868.899958023, 1929476.8387063588, 1575808.0159539827, 1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20951881890264673, "mean_inference_ms": 2.9480646358597973, "mean_action_processing_ms": 0.14975581655386727, "mean_env_wait_ms": 0.12344984014637138, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 258258, "agent_timesteps_total": 516516, "timers": {"sample_time_ms": 3419.209, "sample_throughput": 1756.547, "learn_time_ms": 14023.731, "learn_throughput": 428.274, "update_time_ms": 4.578}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 25165148639.31915, "policy_loss": 0.0009652015535121268, "vf_loss": 25165148639.31915, "vf_explained_var": -7.609103569450326e-09, "kl": 0.005649204474893656, "entropy": 2.8882774393609227, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 197.05225067138664, "cur_lr": 5.000000000000002e-05, "total_loss": 25208578353.02128, "policy_loss": 0.013355168058200086, "vf_loss": 25208578353.02128, "vf_explained_var": -1.39500230034173e-07, "kl": 0.028678742257204463, "entropy": 3.6150296393861163, "entropy_coeff": 0.0}}}, "num_steps_sampled": 258258, "num_agent_steps_sampled": 516516, "num_steps_trained": 258258, "num_agent_steps_trained": 516516}, "done": false, "episodes_total": 258, "training_iteration": 43, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-52-11", "timestamp": 1624920731, "time_this_iter_s": 17.652652740478516, "time_total_s": 784.6010525226593, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e06048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e06a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 784.6010525226593, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 23.38695652173913, "ram_util_percent": 59.6913043478261, "gpu_util_percent0": 0.222608695652174, "vram_util_percent0": 0.23133453495699066}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1460184.198787845}, "policy_reward_max": {"pol0": -1460184.198787845, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1808812.8326167467, "pol1": 1808812.8326167467}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1641446.2295968588, -1878684.170428723, -1915471.736117182, -1803577.4382259294, -1699897.830234282, -1756256.7513527966, -1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491], "policy_pol1_reward": [1641446.2295968588, 1878684.170428723, 1915471.736117182, 1803577.4382259294, 1699897.830234282, 1756256.7513527966, 1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20925707811839406, "mean_inference_ms": 2.944179471579811, "mean_action_processing_ms": 0.14957253359096637, "mean_env_wait_ms": 0.12329878576388582, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 264264, "agent_timesteps_total": 528528, "timers": {"sample_time_ms": 3427.812, "sample_throughput": 1752.138, "learn_time_ms": 14032.368, "learn_throughput": 428.01, "update_time_ms": 4.518}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26291522538.212765, "policy_loss": -0.0035185738605387666, "vf_loss": 26291522538.212765, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.008485371732410598, "entropy": 2.831816460223908, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 295.57837600708024, "cur_lr": 5.000000000000002e-05, "total_loss": 26339453015.148937, "policy_loss": 0.010481592713597608, "vf_loss": 26339453015.148937, "vf_explained_var": 1.204774804364206e-07, "kl": 0.03686262532434565, "entropy": 3.733084922141217, "entropy_coeff": 0.0}}}, "num_steps_sampled": 264264, "num_agent_steps_sampled": 528528, "num_steps_trained": 264264, "num_agent_steps_trained": 528528}, "done": false, "episodes_total": 264, "training_iteration": 44, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-52-29", "timestamp": 1624920749, "time_this_iter_s": 17.62391495704651, "time_total_s": 802.2249674797058, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 802.2249674797058, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 23.270833333333332, "ram_util_percent": 59.791666666666664, "gpu_util_percent0": 0.22458333333333336, "vram_util_percent0": 0.23132934501741376}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1460184.198787845}, "policy_reward_max": {"pol0": -1460184.198787845, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1808717.6094905585, "pol1": 1808717.6094905585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1749346.4946473164, -1698011.338359866, -1913504.480612785, -1654639.7098453024, -1764438.6004070512, -1679821.061876916, -1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903], "policy_pol1_reward": [1749346.4946473164, 1698011.338359866, 1913504.480612785, 1654639.7098453024, 1764438.6004070512, 1679821.061876916, 1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20901537582677887, "mean_inference_ms": 2.940525754625263, "mean_action_processing_ms": 0.14939898048574524, "mean_env_wait_ms": 0.1231556601133947, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 270270, "agent_timesteps_total": 540540, "timers": {"sample_time_ms": 3415.582, "sample_throughput": 1758.412, "learn_time_ms": 14059.91, "learn_throughput": 427.172, "update_time_ms": 4.565}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26465050972.595745, "policy_loss": 1.5612652010106027e-05, "vf_loss": 26465050972.595745, "vf_explained_var": -1.2174565711120522e-07, "kl": 0.01480216966902322, "entropy": 2.8307501305925085, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 443.3675640106201, "cur_lr": 5.000000000000002e-05, "total_loss": 26509779161.87234, "policy_loss": 0.013900181991939849, "vf_loss": 26509779161.87234, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.031507693191475054, "entropy": 3.8364991482267987, "entropy_coeff": 0.0}}}, "num_steps_sampled": 270270, "num_agent_steps_sampled": 540540, "num_steps_trained": 270270, "num_agent_steps_trained": 540540}, "done": false, "episodes_total": 270, "training_iteration": 45, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-52-46", "timestamp": 1624920766, "time_this_iter_s": 17.63957905769348, "time_total_s": 819.8645465373993, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dd0ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dd0510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 819.8645465373993, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 22.69130434782609, "ram_util_percent": 59.59999999999998, "gpu_util_percent0": 0.2204347826086956, "vram_util_percent0": 0.23134186193051093}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1460184.198787845}, "policy_reward_max": {"pol0": -1460184.198787845, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1811283.3643232393, "pol1": 1811283.3643232393}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1895718.721745709, -1843782.3739432567, -1855786.7702743465, -1906504.2050391608, -1855309.2676979706, -1873099.719390251, -1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233], "policy_pol1_reward": [1895718.721745709, 1843782.3739432567, 1855786.7702743465, 1906504.2050391608, 1855309.2676979706, 1873099.719390251, 1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20878825881003682, "mean_inference_ms": 2.936939880647572, "mean_action_processing_ms": 0.14923192988144982, "mean_env_wait_ms": 0.12301849473567246, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 276276, "agent_timesteps_total": 552552, "timers": {"sample_time_ms": 3433.127, "sample_throughput": 1749.425, "learn_time_ms": 14072.755, "learn_throughput": 426.782, "update_time_ms": 4.543}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26850945895.48936, "policy_loss": 0.0021889852359890938, "vf_loss": 26850945895.48936, "vf_explained_var": 8.87728734966231e-09, "kl": 0.011451172543332932, "entropy": 2.8214641327553607, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 665.0513460159303, "cur_lr": 5.000000000000002e-05, "total_loss": 26899596396.93617, "policy_loss": 0.01225295098141787, "vf_loss": 26899596396.93617, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.05081450899547719, "entropy": 3.953100853777946, "entropy_coeff": 0.0}}}, "num_steps_sampled": 276276, "num_agent_steps_sampled": 552552, "num_steps_trained": 276276, "num_agent_steps_trained": 552552}, "done": false, "episodes_total": 276, "training_iteration": 46, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-53-04", "timestamp": 1624920784, "time_this_iter_s": 17.55271863937378, "time_total_s": 837.4172651767731, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1683e06ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1683e069d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 837.4172651767731, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 22.725000000000005, "ram_util_percent": 59.69583333333335, "gpu_util_percent0": 0.21875, "vram_util_percent0": 0.23133636670037072}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1423191.8398244805}, "policy_reward_max": {"pol0": -1423191.8398244805, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1799473.3309341182, "pol1": 1799473.3309341182}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1693478.0726559458, -1827880.602595974, -1769135.2368600692, -1711829.6633248846, -1783832.2977319385, -1848693.4457470109, -1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883], "policy_pol1_reward": [1693478.0726559458, 1827880.602595974, 1769135.2368600692, 1711829.6633248846, 1783832.2977319385, 1848693.4457470109, 1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2085799744083741, "mean_inference_ms": 2.933471696654686, "mean_action_processing_ms": 0.14907478910030972, "mean_env_wait_ms": 0.12288893490657088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 282282, "agent_timesteps_total": 564564, "timers": {"sample_time_ms": 3453.108, "sample_throughput": 1739.303, "learn_time_ms": 14050.574, "learn_throughput": 427.456, "update_time_ms": 4.517}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 23477125642.893616, "policy_loss": -0.003556679201094394, "vf_loss": 23477125642.893616, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.008277224079567068, "entropy": 2.9070249770550016, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 997.5770190238957, "cur_lr": 5.000000000000002e-05, "total_loss": 23518688321.361702, "policy_loss": 0.021606793369543045, "vf_loss": 23518688321.361702, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.057374155267756036, "entropy": 4.1296306772434965, "entropy_coeff": 0.0}}}, "num_steps_sampled": 282282, "num_agent_steps_sampled": 564564, "num_steps_trained": 282282, "num_agent_steps_trained": 564564}, "done": false, "episodes_total": 282, "training_iteration": 47, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-53-21", "timestamp": 1624920801, "time_this_iter_s": 17.368058443069458, "time_total_s": 854.7853236198425, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d847b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 854.7853236198425, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 23.59130434782609, "ram_util_percent": 59.617391304347805, "gpu_util_percent0": 0.22173913043478266, "vram_util_percent0": 0.2313272079834703}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1423191.8398244805}, "policy_reward_max": {"pol0": -1423191.8398244805, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1795985.5232369073, "pol1": 1795985.5232369073}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1839420.8743081547, -1733405.7946271363, -1595766.0305744347, -1841238.5072235183, -1829692.9785013562, -1647248.710322893, -1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692], "policy_pol1_reward": [1839420.8743081547, 1733405.7946271363, 1595766.0305744347, 1841238.5072235183, 1829692.9785013562, 1647248.710322893, 1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2083830425178042, "mean_inference_ms": 2.9302322747661544, "mean_action_processing_ms": 0.1489285633345033, "mean_env_wait_ms": 0.12276846733790361, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 288288, "agent_timesteps_total": 576576, "timers": {"sample_time_ms": 3475.539, "sample_throughput": 1728.077, "learn_time_ms": 14043.408, "learn_throughput": 427.674, "update_time_ms": 4.527}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24588185425.70213, "policy_loss": -0.0004910877608555428, "vf_loss": 24588185425.70213, "vf_explained_var": 1.3062295067811647e-07, "kl": 0.01422750414844523, "entropy": 2.8729689882156695, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1496.3655285358425, "cur_lr": 5.000000000000002e-05, "total_loss": 24634482600.851063, "policy_loss": 0.02243989757559401, "vf_loss": 24634482600.851063, "vf_explained_var": 4.058188451949718e-08, "kl": 0.05845491175955914, "entropy": 4.262767456947489, "entropy_coeff": 0.0}}}, "num_steps_sampled": 288288, "num_agent_steps_sampled": 576576, "num_steps_trained": 288288, "num_agent_steps_trained": 576576}, "done": false, "episodes_total": 288, "training_iteration": 48, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-53-39", "timestamp": 1624920819, "time_this_iter_s": 17.577794551849365, "time_total_s": 872.3631181716919, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdd08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 872.3631181716919, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 23.373913043478268, "ram_util_percent": 59.6086956521739, "gpu_util_percent0": 0.2221739130434783, "vram_util_percent0": 0.23134186193051096}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1423191.8398244805}, "policy_reward_max": {"pol0": -1423191.8398244805, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1797440.2075669635, "pol1": 1797440.2075669635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1759519.085005965, -1831719.4082949483, -1732979.809925056, -1780430.266924625, -1853265.0039995373, -1899649.728372994, -1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168], "policy_pol1_reward": [1759519.085005965, 1831719.4082949483, 1732979.809925056, 1780430.266924625, 1853265.0039995373, 1899649.728372994, 1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20820205117231363, "mean_inference_ms": 2.927071207970644, "mean_action_processing_ms": 0.14878651843714175, "mean_env_wait_ms": 0.12265263081303523, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 294294, "agent_timesteps_total": 588588, "timers": {"sample_time_ms": 3489.2, "sample_throughput": 1721.311, "learn_time_ms": 14030.522, "learn_throughput": 428.067, "update_time_ms": 4.534}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26631737823.31915, "policy_loss": 0.005681747471557018, "vf_loss": 26631737823.31915, "vf_explained_var": 7.609103569450326e-09, "kl": 0.023742087106121346, "entropy": 2.775215270671439, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2244.548292803765, "cur_lr": 5.000000000000002e-05, "total_loss": 26686174142.638298, "policy_loss": 0.016991397722604426, "vf_loss": 26686174142.638298, "vf_explained_var": 6.21410123358146e-08, "kl": 0.07947405118574487, "entropy": 4.380726946161149, "entropy_coeff": 0.0}}}, "num_steps_sampled": 294294, "num_agent_steps_sampled": 588588, "num_steps_trained": 294294, "num_agent_steps_trained": 588588}, "done": false, "episodes_total": 294, "training_iteration": 49, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-53-57", "timestamp": 1624920837, "time_this_iter_s": 17.573811769485474, "time_total_s": 889.9369299411774, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcd9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 889.9369299411774, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 23.237499999999997, "ram_util_percent": 59.791666666666664, "gpu_util_percent0": 0.22125000000000003, "vram_util_percent0": 0.2313433883833277}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1423191.8398244805}, "policy_reward_max": {"pol0": -1423191.8398244805, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1795048.4865028942, "pol1": 1795048.4865028942}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1824293.0012401233, -1851404.9609692297, -1770613.9470024845, -1460184.198787845, -1793014.6801730623, -1743110.9135985856, -1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353], "policy_pol1_reward": [1824293.0012401233, 1851404.9609692297, 1770613.9470024845, 1460184.198787845, 1793014.6801730623, 1743110.9135985856, 1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20802639746879092, "mean_inference_ms": 2.9242227497918534, "mean_action_processing_ms": 0.14865907786516305, "mean_env_wait_ms": 0.12254837208113525, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 300300, "agent_timesteps_total": 600600, "timers": {"sample_time_ms": 3492.147, "sample_throughput": 1719.859, "learn_time_ms": 14063.55, "learn_throughput": 427.061, "update_time_ms": 4.542}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26115268477.276596, "policy_loss": 0.007853015048548262, "vf_loss": 26115268477.276596, "vf_explained_var": -7.609103569450326e-09, "kl": 0.03814483790638599, "entropy": 2.8947748529150132, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3366.822439205648, "cur_lr": 5.000000000000002e-05, "total_loss": 26164823628.255318, "policy_loss": 0.01833392574669833, "vf_loss": 26164823584.68085, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.07955554841046637, "entropy": 4.482563323162972, "entropy_coeff": 0.0}}}, "num_steps_sampled": 300300, "num_agent_steps_sampled": 600600, "num_steps_trained": 300300, "num_agent_steps_trained": 600600}, "done": false, "episodes_total": 300, "training_iteration": 50, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-54-14", "timestamp": 1624920854, "time_this_iter_s": 17.752161264419556, "time_total_s": 907.6890912055969, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d848c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 907.6890912055969, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 23.166666666666668, "ram_util_percent": 59.69166666666667, "gpu_util_percent0": 0.22083333333333335, "vram_util_percent0": 0.23133636670037075}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1423191.8398244805}, "policy_reward_max": {"pol0": -1423191.8398244805, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1792620.1967953125, "pol1": 1792620.1967953125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1773957.7277020244, -1766179.4639286257, -1803732.9442608305, -1765328.895884477, -1561181.268932979, -1742135.5864035925, -1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712], "policy_pol1_reward": [1773957.7277020244, 1766179.4639286257, 1803732.9442608305, 1765328.895884477, 1561181.268932979, 1742135.5864035925, 1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20785365879678344, "mean_inference_ms": 2.921476500067597, "mean_action_processing_ms": 0.14853719698463477, "mean_env_wait_ms": 0.12244914451843478, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 306306, "agent_timesteps_total": 612612, "timers": {"sample_time_ms": 3489.039, "sample_throughput": 1721.391, "learn_time_ms": 14068.947, "learn_throughput": 426.898, "update_time_ms": 4.584}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24150707744.68085, "policy_loss": 0.00915449499053524, "vf_loss": 24150707744.68085, "vf_explained_var": -1.3823205335938837e-07, "kl": 0.02920556425097141, "entropy": 2.9112465229440243, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5050.233658808468, "cur_lr": 5.000000000000002e-05, "total_loss": 24193682410.212765, "policy_loss": 0.02700253974329284, "vf_loss": 24193682192.340427, "vf_explained_var": 6.340919789238342e-09, "kl": 0.09248005487817398, "entropy": 4.586270464227555, "entropy_coeff": 0.0}}}, "num_steps_sampled": 306306, "num_agent_steps_sampled": 612612, "num_steps_trained": 306306, "num_agent_steps_trained": 612612}, "done": false, "episodes_total": 306, "training_iteration": 51, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-54-32", "timestamp": 1624920872, "time_this_iter_s": 17.546741008758545, "time_total_s": 925.2358322143555, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d847b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 925.2358322143555, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 24.030434782608697, "ram_util_percent": 59.695652173913054, "gpu_util_percent0": 0.2217391304347826, "vram_util_percent0": 0.2313565158775516}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1793512.2540039874, "pol1": 1793512.2540039874}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1834706.825661851, -1901159.530562767, -1483704.1373428593, -1725849.3355967195, -1779842.5867885088, -1754149.994198612, -1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883], "policy_pol1_reward": [1834706.825661851, 1901159.530562767, 1483704.1373428593, 1725849.3355967195, 1779842.5867885088, 1754149.994198612, 1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2077011521996361, "mean_inference_ms": 2.918885738835478, "mean_action_processing_ms": 0.14842179836218417, "mean_env_wait_ms": 0.12235548721510651, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 312312, "agent_timesteps_total": 624624, "timers": {"sample_time_ms": 3483.208, "sample_throughput": 1724.273, "learn_time_ms": 14076.926, "learn_throughput": 426.656, "update_time_ms": 4.585}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7085937500000008, "cur_lr": 5.000000000000002e-05, "total_loss": 25819236831.31915, "policy_loss": -0.0009508306120938443, "vf_loss": 25819236831.31915, "vf_explained_var": -2.916823049758932e-08, "kl": 0.006102097636841713, "entropy": 2.904597840410598, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7575.350488212706, "cur_lr": 5.000000000000002e-05, "total_loss": 25870461799.48936, "policy_loss": 0.03296756484803367, "vf_loss": 25870460884.425533, "vf_explained_var": -1.2301384799684456e-07, "kl": 0.11236311923316185, "entropy": 4.72300568032772, "entropy_coeff": 0.0}}}, "num_steps_sampled": 312312, "num_agent_steps_sampled": 624624, "num_steps_trained": 312312, "num_agent_steps_trained": 624624}, "done": false, "episodes_total": 312, "training_iteration": 52, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-54-50", "timestamp": 1624920890, "time_this_iter_s": 17.45216202735901, "time_total_s": 942.6879942417145, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 942.6879942417145, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 23.691304347826087, "ram_util_percent": 59.769565217391296, "gpu_util_percent0": 0.2243478260869565, "vram_util_percent0": 0.2313638428510719}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1786470.5748410488, "pol1": 1786470.5748410488}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1873281.0371627004, -1687959.548612602, -1768764.9154499169, -1740752.216685614, -1702788.418898799, -1987663.6995053852, -1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347], "policy_pol1_reward": [1873281.0371627004, 1687959.548612602, 1768764.9154499169, 1740752.216685614, 1702788.418898799, 1987663.6995053852, 1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20757308995942922, "mean_inference_ms": 2.916668746337273, "mean_action_processing_ms": 0.1483192568374299, "mean_env_wait_ms": 0.12227131651274192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 318318, "agent_timesteps_total": 636636, "timers": {"sample_time_ms": 3479.502, "sample_throughput": 1726.109, "learn_time_ms": 14079.845, "learn_throughput": 426.567, "update_time_ms": 4.633}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7085937500000008, "cur_lr": 5.000000000000002e-05, "total_loss": 22639632471.148937, "policy_loss": -0.0008728525977819524, "vf_loss": 22639632471.148937, "vf_explained_var": 1.2935475979247713e-07, "kl": 0.0043933087504132, "entropy": 2.929114762772905, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 11363.025732319056, "cur_lr": 5.000000000000002e-05, "total_loss": 22684546374.80851, "policy_loss": 0.11185420413521376, "vf_loss": 22684541581.61702, "vf_explained_var": -7.609103569450326e-09, "kl": 0.3932457889648194, "entropy": 4.8086838722229, "entropy_coeff": 0.0}}}, "num_steps_sampled": 318318, "num_agent_steps_sampled": 636636, "num_steps_trained": 318318, "num_agent_steps_trained": 636636}, "done": false, "episodes_total": 318, "training_iteration": 53, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-55-07", "timestamp": 1624920907, "time_this_iter_s": 17.64537215232849, "time_total_s": 960.333366394043, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d7a7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d7a840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 960.333366394043, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 23.666666666666668, "ram_util_percent": 59.729166666666664, "gpu_util_percent0": 0.225, "vram_util_percent0": 0.2313644534321986}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1785539.9751087169, "pol1": 1785539.9751087169}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1742747.4071116145, -1916056.273039428, -1869154.8579398254, -1744163.5130030585, -1791172.99293284, -1817141.4388697036, -1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323], "policy_pol1_reward": [1742747.4071116145, 1916056.273039428, 1869154.8579398254, 1744163.5130030585, 1791172.99293284, 1817141.4388697036, 1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2074644187638253, "mean_inference_ms": 2.9146306986520045, "mean_action_processing_ms": 0.14822564506098837, "mean_env_wait_ms": 0.12219344646895229, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 324324, "agent_timesteps_total": 648648, "timers": {"sample_time_ms": 3470.231, "sample_throughput": 1730.721, "learn_time_ms": 14092.291, "learn_throughput": 426.19, "update_time_ms": 4.595}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26652779018.893616, "policy_loss": 0.0030783361735496114, "vf_loss": 26652779018.893616, "vf_explained_var": -3.550914939864924e-08, "kl": 0.012766973888303371, "entropy": 2.933380791481505, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 17044.53859847858, "cur_lr": 5.000000000000002e-05, "total_loss": 26706483287.148937, "policy_loss": 0.03069083087463328, "vf_loss": 26706481326.29787, "vf_explained_var": -5.453190965454269e-08, "kl": 0.11681098395839651, "entropy": 5.126548564180415, "entropy_coeff": 0.0}}}, "num_steps_sampled": 324324, "num_agent_steps_sampled": 648648, "num_steps_trained": 324324, "num_agent_steps_trained": 648648}, "done": false, "episodes_total": 324, "training_iteration": 54, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-55-25", "timestamp": 1624920925, "time_this_iter_s": 17.65496325492859, "time_total_s": 977.9883296489716, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682da3378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682da32f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 977.9883296489716, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 23.852173913043476, "ram_util_percent": 59.904347826086976, "gpu_util_percent0": 0.21956521739130438, "vram_util_percent0": 0.23136384285107187}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2201707.7138886773, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 2201707.7138886773}, "policy_reward_mean": {"pol0": -1778009.462377941, "pol1": 1778009.462377941}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1824030.7433751193, -1702598.7531737667, -1871765.0097064048, -1802352.7829644312, -2201707.7138886773, -1985578.2640194355, -2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237], "policy_pol1_reward": [1824030.7433751193, 1702598.7531737667, 1871765.0097064048, 1802352.7829644312, 2201707.7138886773, 1985578.2640194355, 2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20738584276740446, "mean_inference_ms": 2.912811684208359, "mean_action_processing_ms": 0.14814109676025938, "mean_env_wait_ms": 0.12212258319959599, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 330330, "agent_timesteps_total": 660660, "timers": {"sample_time_ms": 3500.346, "sample_throughput": 1715.83, "learn_time_ms": 14061.577, "learn_throughput": 427.121, "update_time_ms": 4.544}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24032144057.19149, "policy_loss": -0.0012110612711849365, "vf_loss": 24032144057.19149, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.011444803703814111, "entropy": 2.8150072909416037, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 25566.807897717885, "cur_lr": 5.000000000000002e-05, "total_loss": 24078621020.595745, "policy_loss": 0.13769399786883213, "vf_loss": 24078607948.255318, "vf_explained_var": 0.0, "kl": 0.509795051939944, "entropy": 5.183334604222724, "entropy_coeff": 0.0}}}, "num_steps_sampled": 330330, "num_agent_steps_sampled": 660660, "num_steps_trained": 330330, "num_agent_steps_trained": 660660}, "done": false, "episodes_total": 330, "training_iteration": 55, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-55-43", "timestamp": 1624920943, "time_this_iter_s": 17.633330583572388, "time_total_s": 995.621660232544, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682da38c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682da3f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 995.621660232544, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 23.32916666666667, "ram_util_percent": 59.80833333333333, "gpu_util_percent0": 0.21791666666666668, "vram_util_percent0": 0.23135743174924164}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2151086.089943162, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 2151086.089943162}, "policy_reward_mean": {"pol0": -1768837.8793857158, "pol1": 1768837.8793857158}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-2102809.9197254037, -2039730.1420474523, -2036275.3631877103, -2125677.8170631207, -1737101.8960872835, -1835234.3876060185, -1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803], "policy_pol1_reward": [2102809.9197254037, 2039730.1420474523, 2036275.3631877103, 2125677.8170631207, 1737101.8960872835, 1835234.3876060185, 1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20731257532036282, "mean_inference_ms": 2.9111947190117435, "mean_action_processing_ms": 0.14806301208767006, "mean_env_wait_ms": 0.12205744543637936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 336336, "agent_timesteps_total": 672672, "timers": {"sample_time_ms": 3501.192, "sample_throughput": 1715.416, "learn_time_ms": 14056.3, "learn_throughput": 427.282, "update_time_ms": 4.557}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25523251374.29787, "policy_loss": -0.002232161964824859, "vf_loss": 25523251374.29787, "vf_explained_var": -1.065274517486614e-07, "kl": 0.007666669815699471, "entropy": 2.7764096006434014, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 38350.211846576814, "cur_lr": 5.000000000000002e-05, "total_loss": 25570367880.17021, "policy_loss": 0.03962896201521792, "vf_loss": 25570363522.723404, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.11208299341353964, "entropy": 5.427639788769661, "entropy_coeff": 0.0}}}, "num_steps_sampled": 336336, "num_agent_steps_sampled": 672672, "num_steps_trained": 336336, "num_agent_steps_trained": 672672}, "done": false, "episodes_total": 336, "training_iteration": 56, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-56-00", "timestamp": 1624920960, "time_this_iter_s": 17.507426738739014, "time_total_s": 1013.129086971283, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d7ad90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d7a1e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1013.129086971283, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 23.86521739130435, "ram_util_percent": 59.804347826086946, "gpu_util_percent0": 0.2178260869565218, "vram_util_percent0": 0.2313565158775516}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2151086.089943162, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 2151086.089943162}, "policy_reward_mean": {"pol0": -1756854.6307311645, "pol1": 1756854.6307311645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1542108.5805612528, -1801696.0891889173, -1757026.5837786642, -1640043.4054092125, -2124627.772624405, -2057662.3778665755, -2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656], "policy_pol1_reward": [1542108.5805612528, 1801696.0891889173, 1757026.5837786642, 1640043.4054092125, 2124627.772624405, 2057662.3778665755, 2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20725816192929655, "mean_inference_ms": 2.909722892843729, "mean_action_processing_ms": 0.14799172398674773, "mean_env_wait_ms": 0.12199714727874111, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 342342, "agent_timesteps_total": 684684, "timers": {"sample_time_ms": 3504.438, "sample_throughput": 1713.827, "learn_time_ms": 14093.214, "learn_throughput": 426.163, "update_time_ms": 4.599}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26721837099.574467, "policy_loss": 0.007431742953176194, "vf_loss": 26721837099.574467, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.02200273404571604, "entropy": 2.7865752463645124, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 57525.3177698652, "cur_lr": 5.000000000000002e-05, "total_loss": 26774993898.212765, "policy_loss": 0.10869157560011174, "vf_loss": 26774971370.212765, "vf_explained_var": -1.2174565711120522e-07, "kl": 0.38763095153138993, "entropy": 5.375256416645456, "entropy_coeff": 0.0}}}, "num_steps_sampled": 342342, "num_agent_steps_sampled": 684684, "num_steps_trained": 342342, "num_agent_steps_trained": 684684}, "done": false, "episodes_total": 342, "training_iteration": 57, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-56-18", "timestamp": 1624920978, "time_this_iter_s": 17.76936960220337, "time_total_s": 1030.8984565734863, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d7a8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d7a598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1030.8984565734863, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 23.275000000000002, "ram_util_percent": 59.60833333333334, "gpu_util_percent0": 0.22166666666666668, "vram_util_percent0": 0.23135743174924164}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2151086.089943162, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 2151086.089943162}, "policy_reward_mean": {"pol0": -1759688.6523548, "pol1": 1759688.6523548}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-2068494.090676824, -2151086.089943162, -2057598.1775213336, -2079754.3042596504, -1920088.43413462, -1553849.1677079443, -1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981], "policy_pol1_reward": [2068494.090676824, 2151086.089943162, 2057598.1775213336, 2079754.3042596504, 1920088.43413462, 1553849.1677079443, 1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20721471425440569, "mean_inference_ms": 2.908342699502662, "mean_action_processing_ms": 0.14792347883770793, "mean_env_wait_ms": 0.12193785266577534, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 348348, "agent_timesteps_total": 696696, "timers": {"sample_time_ms": 3493.539, "sample_throughput": 1719.174, "learn_time_ms": 14094.224, "learn_throughput": 426.132, "update_time_ms": 4.592}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 29339380191.31915, "policy_loss": -0.0010870206863322156, "vf_loss": 29339380191.31915, "vf_explained_var": -1.0779563552887339e-07, "kl": 0.005235434133321681, "entropy": 2.8159518394064396, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 86287.97665479784, "cur_lr": 5.000000000000002e-05, "total_loss": 29405727678.638298, "policy_loss": 0.02807095168316935, "vf_loss": 29405716828.595745, "vf_explained_var": -2.029094225974859e-08, "kl": 0.1255546692521014, "entropy": 5.727462961318645, "entropy_coeff": 0.0}}}, "num_steps_sampled": 348348, "num_agent_steps_sampled": 696696, "num_steps_trained": 348348, "num_agent_steps_trained": 696696}, "done": false, "episodes_total": 348, "training_iteration": 58, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-56-35", "timestamp": 1624920995, "time_this_iter_s": 17.479071140289307, "time_total_s": 1048.3775277137756, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcd9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcdb70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1048.3775277137756, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 23.83478260869565, "ram_util_percent": 59.717391304347835, "gpu_util_percent0": 0.22304347826086957, "vram_util_percent0": 0.23137116982459222}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1745052.8320221081, "pol1": 1745052.8320221081}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1747904.7397098246, -1707385.027086007, -1773497.5868082661, -1689357.9427711696, -1856661.4170991527, -1745896.441665187, -1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363], "policy_pol1_reward": [1747904.7397098246, 1707385.027086007, 1773497.5868082661, 1689357.9427711696, 1856661.4170991527, 1745896.441665187, 1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20718793524132414, "mean_inference_ms": 2.907029228059204, "mean_action_processing_ms": 0.14785832713087857, "mean_env_wait_ms": 0.12188115514660534, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 354354, "agent_timesteps_total": 708708, "timers": {"sample_time_ms": 3491.55, "sample_throughput": 1720.153, "learn_time_ms": 14115.185, "learn_throughput": 425.499, "update_time_ms": 4.597}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24929304096.68085, "policy_loss": 0.0014955767212395973, "vf_loss": 24929304096.68085, "vf_explained_var": 1.1794110577056927e-07, "kl": 0.0143774641241799, "entropy": 2.8331929216993617, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 129431.96498219676, "cur_lr": 5.000000000000002e-05, "total_loss": 24986560206.97872, "policy_loss": 0.05921925525081918, "vf_loss": 24986541818.553192, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.14357041282222627, "entropy": 5.947698024993247, "entropy_coeff": 0.0}}}, "num_steps_sampled": 354354, "num_agent_steps_sampled": 708708, "num_steps_trained": 354354, "num_agent_steps_trained": 708708}, "done": false, "episodes_total": 354, "training_iteration": 59, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-56-53", "timestamp": 1624921013, "time_this_iter_s": 17.762510061264038, "time_total_s": 1066.1400377750397, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1066.1400377750397, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 23.662499999999998, "ram_util_percent": 59.79999999999999, "gpu_util_percent0": 0.2225, "vram_util_percent0": 0.23136445343219866}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1745424.8570876422, "pol1": 1745424.8570876422}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1842812.7247821004, -1762794.3058413074, -1934075.4536489502, -1461321.020706491, -1819570.85741853, -1764208.941208674, -1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677], "policy_pol1_reward": [1842812.7247821004, 1762794.3058413074, 1934075.4536489502, 1461321.020706491, 1819570.85741853, 1764208.941208674, 1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20714638930641147, "mean_inference_ms": 2.9057179774862947, "mean_action_processing_ms": 0.14779282461033005, "mean_env_wait_ms": 0.12182464546152294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 360360, "agent_timesteps_total": 720720, "timers": {"sample_time_ms": 3504.776, "sample_throughput": 1713.662, "learn_time_ms": 14100.309, "learn_throughput": 425.948, "update_time_ms": 4.586}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25830339518.638298, "policy_loss": -0.0037602690900576875, "vf_loss": 25830339518.638298, "vf_explained_var": 1.242820246716292e-07, "kl": 0.011951989890571604, "entropy": 2.8514122303496015, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 194147.94747329515, "cur_lr": 5.000000000000002e-05, "total_loss": 25891708928.0, "policy_loss": 0.05174296079797948, "vf_loss": 25891679994.553192, "vf_explained_var": 1.6486390919112637e-08, "kl": 0.14947217766274798, "entropy": 6.189081435507917, "entropy_coeff": 0.0}}}, "num_steps_sampled": 360360, "num_agent_steps_sampled": 720720, "num_steps_trained": 360360, "num_agent_steps_trained": 720720}, "done": false, "episodes_total": 360, "training_iteration": 60, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-57-11", "timestamp": 1624921031, "time_this_iter_s": 17.737800121307373, "time_total_s": 1083.877837896347, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d847b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1083.877837896347, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 23.308333333333334, "ram_util_percent": 59.712500000000006, "gpu_util_percent0": 0.22333333333333338, "vram_util_percent0": 0.23137147511515563}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1743563.4995709984, "pol1": 1743563.4995709984}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1888324.7190060015, -1737453.7507923893, -1625182.7506214739, -1851070.824289903, -1751987.0218875997, -1649960.4108678687, -1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885], "policy_pol1_reward": [1888324.7190060015, 1737453.7507923893, 1625182.7506214739, 1851070.824289903, 1751987.0218875997, 1649960.4108678687, 1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20710716006045118, "mean_inference_ms": 2.9043573126431848, "mean_action_processing_ms": 0.14772658048345175, "mean_env_wait_ms": 0.12176870949407163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 366366, "agent_timesteps_total": 732732, "timers": {"sample_time_ms": 3510.687, "sample_throughput": 1710.776, "learn_time_ms": 14100.061, "learn_throughput": 425.956, "update_time_ms": 4.581}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25262508337.02128, "policy_loss": 0.0002683953362259459, "vf_loss": 25262508337.02128, "vf_explained_var": -1.1160018686950934e-07, "kl": 0.008252246979069202, "entropy": 2.7853070370694426, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 291221.9212099427, "cur_lr": 5.000000000000002e-05, "total_loss": 25321340928.0, "policy_loss": 0.0734620917033642, "vf_loss": 25321281143.82979, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.2038614455055683, "entropy": 6.620208070633259, "entropy_coeff": 0.0}}}, "num_steps_sampled": 366366, "num_agent_steps_sampled": 732732, "num_steps_trained": 366366, "num_agent_steps_trained": 732732}, "done": false, "episodes_total": 366, "training_iteration": 61, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-57-29", "timestamp": 1624921049, "time_this_iter_s": 17.603861808776855, "time_total_s": 1101.481699705124, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682da3a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682da3510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1101.481699705124, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 23.80869565217391, "ram_util_percent": 59.782608695652165, "gpu_util_percent0": 0.22260869565217395, "vram_util_percent0": 0.2313784967981125}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1745523.2965170944, "pol1": 1745523.2965170944}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1919838.7514704466, -1752480.7422834837, -1806280.6327197705, -1835789.6097881233, -1708118.8483120943, -1423191.8398244805, -1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843], "policy_pol1_reward": [1919838.7514704466, 1752480.7422834837, 1806280.6327197705, 1835789.6097881233, 1708118.8483120943, 1423191.8398244805, 1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2070671458375658, "mean_inference_ms": 2.903242407486571, "mean_action_processing_ms": 0.14767173762585178, "mean_env_wait_ms": 0.12172052386946836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 372372, "agent_timesteps_total": 744744, "timers": {"sample_time_ms": 3527.119, "sample_throughput": 1702.806, "learn_time_ms": 14108.998, "learn_throughput": 425.686, "update_time_ms": 4.608}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26633277962.893616, "policy_loss": -0.0026346452217152778, "vf_loss": 26633277962.893616, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.006165319617758406, "entropy": 2.829641174762807, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 436832.88181491423, "cur_lr": 5.000000000000002e-05, "total_loss": 26695772203.574467, "policy_loss": 0.05753070657002799, "vf_loss": 26695671197.957447, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.23122461710838563, "entropy": 6.926232540861089, "entropy_coeff": 0.0}}}, "num_steps_sampled": 372372, "num_agent_steps_sampled": 744744, "num_steps_trained": 372372, "num_agent_steps_trained": 744744}, "done": false, "episodes_total": 372, "training_iteration": 62, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-57-46", "timestamp": 1624921066, "time_this_iter_s": 17.70641779899597, "time_total_s": 1119.1881175041199, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1119.1881175041199, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 23.412499999999998, "ram_util_percent": 59.90833333333333, "gpu_util_percent0": 0.22291666666666665, "vram_util_percent0": 0.2313784967981126}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1745881.4856893397, "pol1": 1745881.4856893397}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1768005.9705431133, -1637835.3466433543, -1743152.534090058, -1768893.1797654883, -1633639.9584051685, -1861071.6308836485, -1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496], "policy_pol1_reward": [1768005.9705431133, 1637835.3466433543, 1743152.534090058, 1768893.1797654883, 1633639.9584051685, 1861071.6308836485, 1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20702785046276811, "mean_inference_ms": 2.902102793138206, "mean_action_processing_ms": 0.14761665597677717, "mean_env_wait_ms": 0.12167355287940614, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 378378, "agent_timesteps_total": 756756, "timers": {"sample_time_ms": 3501.509, "sample_throughput": 1715.26, "learn_time_ms": 14130.892, "learn_throughput": 425.026, "update_time_ms": 4.561}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25424837523.06383, "policy_loss": -0.0019241906702518463, "vf_loss": 25424837523.06383, "vf_explained_var": 1.4837752360108425e-07, "kl": 0.011950625007615444, "entropy": 2.8490240218791554, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 655249.3227223712, "cur_lr": 5.000000000000002e-05, "total_loss": 25482721018.553192, "policy_loss": 0.06621676053297013, "vf_loss": 25482514954.893616, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.31459053811874793, "entropy": 7.350944133515053, "entropy_coeff": 0.0}}}, "num_steps_sampled": 378378, "num_agent_steps_sampled": 756756, "num_steps_trained": 378378, "num_agent_steps_trained": 756756}, "done": false, "episodes_total": 378, "training_iteration": 63, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-58-04", "timestamp": 1624921084, "time_this_iter_s": 17.607744932174683, "time_total_s": 1136.7958624362946, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1136.7958624362946, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 23.49130434782609, "ram_util_percent": 59.804347826086946, "gpu_util_percent0": 0.22260869565217395, "vram_util_percent0": 0.2313784967981125}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1743872.7603541499, "pol1": 1743872.7603541499}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1864258.9969363385, -1630905.9183541292, -1768204.3770630928, -1527987.6675523692, -1667020.3684874198, -1785932.0448599171, -1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701], "policy_pol1_reward": [1864258.9969363385, 1630905.9183541292, 1768204.3770630928, 1527987.6675523692, 1667020.3684874198, 1785932.0448599171, 1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2070021383236167, "mean_inference_ms": 2.9011244891417247, "mean_action_processing_ms": 0.1475700618750234, "mean_env_wait_ms": 0.121632345376851, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 384384, "agent_timesteps_total": 768768, "timers": {"sample_time_ms": 3511.083, "sample_throughput": 1710.583, "learn_time_ms": 14134.206, "learn_throughput": 424.927, "update_time_ms": 4.573}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24152771213.61702, "policy_loss": -0.0011288402205769051, "vf_loss": 24152771213.61702, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.007774580616821, "entropy": 2.815674178143765, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 982873.9840835565, "cur_lr": 5.000000000000002e-05, "total_loss": 24206531562.212765, "policy_loss": 0.117558077730714, "vf_loss": 24206174730.893616, "vf_explained_var": -6.721374745666253e-08, "kl": 0.36310775229271425, "entropy": 7.736487824866113, "entropy_coeff": 0.0}}}, "num_steps_sampled": 384384, "num_agent_steps_sampled": 768768, "num_steps_trained": 384384, "num_agent_steps_trained": 768768}, "done": false, "episodes_total": 384, "training_iteration": 64, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-58-22", "timestamp": 1624921102, "time_this_iter_s": 17.783783435821533, "time_total_s": 1154.579645872116, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1154.579645872116, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 23.258333333333336, "ram_util_percent": 59.60833333333333, "gpu_util_percent0": 0.22208333333333333, "vram_util_percent0": 0.23137147511515557}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1747782.9169380001, "pol1": 1747782.9169380001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1496868.893390238, -1871987.6385881195, -1917546.011831312, -1892886.3714061168, -1684737.1298036582, -1875914.16673657, -1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618], "policy_pol1_reward": [1496868.893390238, 1871987.6385881195, 1917546.011831312, 1892886.3714061168, 1684737.1298036582, 1875914.16673657, 1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20698112019349468, "mean_inference_ms": 2.900206932938693, "mean_action_processing_ms": 0.14752555866028338, "mean_env_wait_ms": 0.12159312987085076, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 390390, "agent_timesteps_total": 780780, "timers": {"sample_time_ms": 3494.124, "sample_throughput": 1718.886, "learn_time_ms": 14158.877, "learn_throughput": 424.186, "update_time_ms": 4.577}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26356457559.148937, "policy_loss": 0.003554653713202223, "vf_loss": 26356457559.148937, "vf_explained_var": 9.765016528717751e-08, "kl": 0.02533087336478081, "entropy": 2.810300588607788, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1474310.976125335, "cur_lr": 5.000000000000002e-05, "total_loss": 26423335827.06383, "policy_loss": 0.08533008995049811, "vf_loss": 26422809534.638298, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.3570216285421493, "entropy": 8.250529350118434, "entropy_coeff": 0.0}}}, "num_steps_sampled": 390390, "num_agent_steps_sampled": 780780, "num_steps_trained": 390390, "num_agent_steps_trained": 780780}, "done": false, "episodes_total": 390, "training_iteration": 65, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-58-40", "timestamp": 1624921120, "time_this_iter_s": 17.72699284553528, "time_total_s": 1172.3066387176514, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1172.3066387176514, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 23.337500000000002, "ram_util_percent": 59.775, "gpu_util_percent0": 0.21791666666666668, "vram_util_percent0": 0.23137147511515557}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1748789.047711601, "pol1": 1748789.047711601}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1802038.5952947, -1705974.8998466458, -1705111.266999152, -1844615.1374354353, -1727297.8577433545, -1785769.2726194446, -1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513], "policy_pol1_reward": [1802038.5952947, 1705974.8998466458, 1705111.266999152, 1844615.1374354353, 1727297.8577433545, 1785769.2726194446, 1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20695636412273063, "mean_inference_ms": 2.8992901000412883, "mean_action_processing_ms": 0.14748132743935177, "mean_env_wait_ms": 0.12155436748774921, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 396396, "agent_timesteps_total": 792792, "timers": {"sample_time_ms": 3500.144, "sample_throughput": 1715.93, "learn_time_ms": 14169.207, "learn_throughput": 423.877, "update_time_ms": 4.586}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9221679687500004, "cur_lr": 5.000000000000002e-05, "total_loss": 27510113171.06383, "policy_loss": 0.0038206304443326403, "vf_loss": 27510113171.06383, "vf_explained_var": 8.496832037963031e-08, "kl": 0.016030496660065143, "entropy": 2.9404251474015255, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2211466.464188003, "cur_lr": 5.000000000000002e-05, "total_loss": 27585932440.51064, "policy_loss": 0.14594828256187922, "vf_loss": 27584860290.723404, "vf_explained_var": -1.6486390919112637e-08, "kl": 0.4847912591822604, "entropy": 8.745257519661113, "entropy_coeff": 0.0}}}, "num_steps_sampled": 396396, "num_agent_steps_sampled": 792792, "num_steps_trained": 396396, "num_agent_steps_trained": 792792}, "done": false, "episodes_total": 396, "training_iteration": 66, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-58-57", "timestamp": 1624921137, "time_this_iter_s": 17.671297073364258, "time_total_s": 1189.9779357910156, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d811e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1189.9779357910156, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 24.3, "ram_util_percent": 59.98260869565217, "gpu_util_percent0": 0.21391304347826087, "vram_util_percent0": 0.23137116982459222}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1397761.532211216}, "policy_reward_max": {"pol0": -1397761.532211216, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1748603.2831793132, "pol1": 1748603.2831793132}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1754543.881748026, -1814713.760955327, -1499844.5268336826, -1617623.4311133712, -1905450.736846284, -1397761.532211216, -1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235], "policy_pol1_reward": [1754543.881748026, 1814713.760955327, 1499844.5268336826, 1617623.4311133712, 1905450.736846284, 1397761.532211216, 1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2069464340434562, "mean_inference_ms": 2.8984049612458413, "mean_action_processing_ms": 0.1474387527306068, "mean_env_wait_ms": 0.12151628189451939, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 402402, "agent_timesteps_total": 804804, "timers": {"sample_time_ms": 3489.296, "sample_throughput": 1721.264, "learn_time_ms": 14164.764, "learn_throughput": 424.01, "update_time_ms": 4.666}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9221679687500004, "cur_lr": 5.000000000000002e-05, "total_loss": 25998511387.234043, "policy_loss": 0.005566088641260533, "vf_loss": 25998511387.234043, "vf_explained_var": -1.2301384799684456e-07, "kl": 0.011063282001525798, "entropy": 2.9279023079161948, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3317199.6962820026, "cur_lr": 5.000000000000002e-05, "total_loss": 26067746423.82979, "policy_loss": 0.11189789649970988, "vf_loss": 26065666222.29787, "vf_explained_var": -1.7500937588010856e-07, "kl": 0.6271524492730486, "entropy": 9.378839330470308, "entropy_coeff": 0.0}}}, "num_steps_sampled": 402402, "num_agent_steps_sampled": 804804, "num_steps_trained": 402402, "num_agent_steps_trained": 804804}, "done": false, "episodes_total": 402, "training_iteration": 67, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-59-15", "timestamp": 1624921155, "time_this_iter_s": 17.617408514022827, "time_total_s": 1207.5953443050385, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f16a41a4400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f16a41a42f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1207.5953443050385, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 23.52916666666667, "ram_util_percent": 59.729166666666664, "gpu_util_percent0": 0.2191666666666667, "vram_util_percent0": 0.2313223233344568}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1487962.1892468885}, "policy_reward_max": {"pol0": -1487962.1892468885, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1761271.3952372188, "pol1": 1761271.3952372188}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1762262.2939633594, -1815738.7466592144, -1875542.7574766173, -1744965.5408232883, -1535683.0024652837, -1518679.49529918, -1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398], "policy_pol1_reward": [1762262.2939633594, 1815738.7466592144, 1875542.7574766173, 1744965.5408232883, 1535683.0024652837, 1518679.49529918, 1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20692849195206775, "mean_inference_ms": 2.8976487644539706, "mean_action_processing_ms": 0.14740289414668836, "mean_env_wait_ms": 0.12148259307067898, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 408408, "agent_timesteps_total": 816816, "timers": {"sample_time_ms": 3499.298, "sample_throughput": 1716.344, "learn_time_ms": 14188.071, "learn_throughput": 423.313, "update_time_ms": 4.635}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9221679687500004, "cur_lr": 5.000000000000002e-05, "total_loss": 30093674713.87234, "policy_loss": 0.0010678545036848556, "vf_loss": 30093674713.87234, "vf_explained_var": -1.9022758479536606e-08, "kl": 0.010009193535339325, "entropy": 2.905215344530471, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4975799.5444230065, "cur_lr": 5.000000000000002e-05, "total_loss": 30163222789.446808, "policy_loss": 0.10917127078914261, "vf_loss": 30157801994.893616, "vf_explained_var": -7.101829879729848e-08, "kl": 1.0893780855422324, "entropy": 9.417258384379934, "entropy_coeff": 0.0}}}, "num_steps_sampled": 408408, "num_agent_steps_sampled": 816816, "num_steps_trained": 408408, "num_agent_steps_trained": 816816}, "done": false, "episodes_total": 408, "training_iteration": 68, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-59-33", "timestamp": 1624921173, "time_this_iter_s": 17.811266899108887, "time_total_s": 1225.4066112041473, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1225.4066112041473, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 23.730434782608693, "ram_util_percent": 59.90000000000002, "gpu_util_percent0": 0.21478260869565216, "vram_util_percent0": 0.23132720798347034}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1955100.8102099628, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 1955100.8102099628}, "policy_reward_mean": {"pol0": -1764982.7666747633, "pol1": 1764982.7666747633}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1697699.639472717, -1695509.4419825405, -1781727.6751642271, -1545945.2394735347, -1857813.8066327535, -1955100.8102099628, -1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005], "policy_pol1_reward": [1697699.639472717, 1695509.4419825405, 1781727.6751642271, 1545945.2394735347, 1857813.8066327535, 1955100.8102099628, 1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20691272362781635, "mean_inference_ms": 2.896889771353825, "mean_action_processing_ms": 0.14736754767533827, "mean_env_wait_ms": 0.12145002321787088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 414414, "agent_timesteps_total": 828828, "timers": {"sample_time_ms": 3498.848, "sample_throughput": 1716.565, "learn_time_ms": 14201.448, "learn_throughput": 422.915, "update_time_ms": 4.644}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9221679687500004, "cur_lr": 5.000000000000002e-05, "total_loss": 26731780575.31915, "policy_loss": -0.00018951718873800116, "vf_loss": 26731780575.31915, "vf_explained_var": -4.058188451949718e-08, "kl": 0.003614111877779694, "entropy": 2.924160622535868, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7463699.316634512, "cur_lr": 5.000000000000002e-05, "total_loss": 26806344246.468086, "policy_loss": 0.10002700118546157, "vf_loss": 26801527916.93617, "vf_explained_var": -1.154047382101453e-07, "kl": 0.645346130462403, "entropy": 10.064184148260887, "entropy_coeff": 0.0}}}, "num_steps_sampled": 414414, "num_agent_steps_sampled": 828828, "num_steps_trained": 414414, "num_agent_steps_trained": 828828}, "done": false, "episodes_total": 414, "training_iteration": 69, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_01-59-51", "timestamp": 1624921191, "time_this_iter_s": 17.892932653427124, "time_total_s": 1243.2995438575745, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1243.2995438575745, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 23.5125, "ram_util_percent": 59.80833333333333, "gpu_util_percent0": 0.21750000000000003, "vram_util_percent0": 0.23132934501741376}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1773356.2250260012, "pol1": 1773356.2250260012}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1559013.5374292308, -1868925.4807669292, -1782086.6338028298, -1645209.5942401323, -1742680.7967291768, -1770351.0446818268, -1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542], "policy_pol1_reward": [1559013.5374292308, 1868925.4807669292, 1782086.6338028298, 1645209.5942401323, 1742680.7967291768, 1770351.0446818268, 1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20689417993593104, "mean_inference_ms": 2.8961101332918924, "mean_action_processing_ms": 0.14733386814108912, "mean_env_wait_ms": 0.12141825639761221, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 420420, "agent_timesteps_total": 840840, "timers": {"sample_time_ms": 3495.797, "sample_throughput": 1718.063, "learn_time_ms": 14196.849, "learn_throughput": 423.052, "update_time_ms": 4.655}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9610839843750002, "cur_lr": 5.000000000000002e-05, "total_loss": 30733182627.404255, "policy_loss": -0.0010157669002705432, "vf_loss": 30733182627.404255, "vf_explained_var": 7.862740147857039e-08, "kl": 0.0035262457590470924, "entropy": 2.809004560429999, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 11195548.974951757, "cur_lr": 5.000000000000002e-05, "total_loss": 30823245998.29787, "policy_loss": 0.6693903724762037, "vf_loss": 30812235253.106384, "vf_explained_var": 1.0145471129874295e-08, "kl": 0.9835064018026312, "entropy": 10.014435768127441, "entropy_coeff": 0.0}}}, "num_steps_sampled": 420420, "num_agent_steps_sampled": 840840, "num_steps_trained": 420420, "num_agent_steps_trained": 840840}, "done": false, "episodes_total": 420, "training_iteration": 70, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-00-08", "timestamp": 1624921208, "time_this_iter_s": 17.64358687400818, "time_total_s": 1260.9431307315826, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1260.9431307315826, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 23.325, "ram_util_percent": 59.73333333333333, "gpu_util_percent0": 0.22208333333333333, "vram_util_percent0": 0.2313223233344568}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1776337.5636472043, "pol1": 1776337.5636472043}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1709270.7426255625, -1575736.2153262512, -1653981.800662225, -1675364.6097938237, -1755769.8241125934, -1791242.9229578397, -1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208], "policy_pol1_reward": [1709270.7426255625, 1575736.2153262512, 1653981.800662225, 1675364.6097938237, 1755769.8241125934, 1791242.9229578397, 1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20686990169865674, "mean_inference_ms": 2.895445052759483, "mean_action_processing_ms": 0.14730529955186633, "mean_env_wait_ms": 0.12139043290251662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 426426, "agent_timesteps_total": 852852, "timers": {"sample_time_ms": 3504.688, "sample_throughput": 1713.704, "learn_time_ms": 14221.721, "learn_throughput": 422.312, "update_time_ms": 4.666}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4805419921875001, "cur_lr": 5.000000000000002e-05, "total_loss": 26536473534.638298, "policy_loss": -0.0048688681043208915, "vf_loss": 26536473534.638298, "vf_explained_var": 1.065274517486614e-07, "kl": 0.006415422411358103, "entropy": 2.843245988196515, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 16793323.46242764, "cur_lr": 5.000000000000002e-05, "total_loss": 26622194230.468086, "policy_loss": 0.1167061847654429, "vf_loss": 26610292038.80851, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.7087444346001808, "entropy": 10.30435393718963, "entropy_coeff": 0.0}}}, "num_steps_sampled": 426426, "num_agent_steps_sampled": 852852, "num_steps_trained": 426426, "num_agent_steps_trained": 852852}, "done": false, "episodes_total": 426, "training_iteration": 71, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-00-26", "timestamp": 1624921226, "time_this_iter_s": 17.940643310546875, "time_total_s": 1278.8837740421295, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1278.8837740421295, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 23.55, "ram_util_percent": 59.79999999999999, "gpu_util_percent0": 0.21750000000000003, "vram_util_percent0": 0.23132934501741376}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1779648.4161010766, "pol1": 1779648.4161010766}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1639880.9592800536, -1835826.9441573196, -1856256.296648901, -1591898.0207485803, -1792300.487779433, -1844346.2244350472, -1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448], "policy_pol1_reward": [1639880.9592800536, 1835826.9441573196, 1856256.296648901, 1591898.0207485803, 1792300.487779433, 1844346.2244350472, 1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20684754365680277, "mean_inference_ms": 2.894676103728113, "mean_action_processing_ms": 0.1472727491239344, "mean_env_wait_ms": 0.12136014038073627, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 432432, "agent_timesteps_total": 864864, "timers": {"sample_time_ms": 3497.78, "sample_throughput": 1717.089, "learn_time_ms": 14222.11, "learn_throughput": 422.3, "update_time_ms": 4.637}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4805419921875001, "cur_lr": 5.000000000000002e-05, "total_loss": 26276413962.893616, "policy_loss": 0.00025128143185630756, "vf_loss": 26276413962.893616, "vf_explained_var": -1.1286837064972133e-07, "kl": 0.013976099227178605, "entropy": 2.9620521677301284, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 25189985.193641454, "cur_lr": 5.000000000000002e-05, "total_loss": 26370399340.93617, "policy_loss": 0.28691524243418204, "vf_loss": 26341054028.255318, "vf_explained_var": -1.775457469932462e-08, "kl": 1.1649590679939756, "entropy": 10.510898711833548, "entropy_coeff": 0.0}}}, "num_steps_sampled": 432432, "num_agent_steps_sampled": 864864, "num_steps_trained": 432432, "num_agent_steps_trained": 864864}, "done": false, "episodes_total": 432, "training_iteration": 72, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-00-44", "timestamp": 1624921244, "time_this_iter_s": 17.641069412231445, "time_total_s": 1296.524843454361, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dec378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dec2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1296.524843454361, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 23.96521739130435, "ram_util_percent": 59.79999999999998, "gpu_util_percent0": 0.2217391304347826, "vram_util_percent0": 0.23133453495699066}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1785756.9982744006, "pol1": 1785756.9982744006}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1795691.8399194065, -1785546.8371012209, -1741934.655507327, -1718684.6155194656, -1899913.488427048, -1872684.387646553, -1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458], "policy_pol1_reward": [1795691.8399194065, 1785546.8371012209, 1741934.655507327, 1718684.6155194656, 1899913.488427048, 1872684.387646553, 1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20681120203797576, "mean_inference_ms": 2.893854615812674, "mean_action_processing_ms": 0.1472379253448689, "mean_env_wait_ms": 0.12132876451048262, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 438438, "agent_timesteps_total": 876876, "timers": {"sample_time_ms": 3520.573, "sample_throughput": 1705.972, "learn_time_ms": 14208.219, "learn_throughput": 422.713, "update_time_ms": 4.622}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4805419921875001, "cur_lr": 5.000000000000002e-05, "total_loss": 29065990361.87234, "policy_loss": -0.0005480891608811439, "vf_loss": 29065990361.87234, "vf_explained_var": -1.2935475979247713e-07, "kl": 0.02343820035457611, "entropy": 2.762133222945193, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 37784977.7904622, "cur_lr": 5.000000000000002e-05, "total_loss": 29178786619.914894, "policy_loss": 0.1096615354193652, "vf_loss": 29149039202.042553, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.7872746193662603, "entropy": 11.355692944628126, "entropy_coeff": 0.0}}}, "num_steps_sampled": 438438, "num_agent_steps_sampled": 876876, "num_steps_trained": 438438, "num_agent_steps_trained": 876876}, "done": false, "episodes_total": 438, "training_iteration": 73, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-01-02", "timestamp": 1624921262, "time_this_iter_s": 17.69740605354309, "time_total_s": 1314.222249507904, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682decae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dec9d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1314.222249507904, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 23.041666666666668, "ram_util_percent": 59.80833333333333, "gpu_util_percent0": 0.22208333333333333, "vram_util_percent0": 0.23132934501741376}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1781082.4550271675, "pol1": 1781082.4550271675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1902445.6007578266, -1883128.262529599, -1812367.2912470242, -1836027.9411844981, -1695753.010951185, -1865783.2948202693, -1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556], "policy_pol1_reward": [1902445.6007578266, 1883128.262529599, 1812367.2912470242, 1836027.9411844981, 1695753.010951185, 1865783.2948202693, 1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20678026535216776, "mean_inference_ms": 2.8930147863614395, "mean_action_processing_ms": 0.1472027651848319, "mean_env_wait_ms": 0.12129748784177799, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 444444, "agent_timesteps_total": 888888, "timers": {"sample_time_ms": 3508.741, "sample_throughput": 1711.725, "learn_time_ms": 14202.724, "learn_throughput": 422.877, "update_time_ms": 4.611}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7208129882812501, "cur_lr": 5.000000000000002e-05, "total_loss": 24950370216.851063, "policy_loss": 0.01286394634541679, "vf_loss": 24950370216.851063, "vf_explained_var": -1.2681839223205316e-07, "kl": 0.03930830804908529, "entropy": 2.6715100775373744, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 56677466.68569329, "cur_lr": 5.000000000000002e-05, "total_loss": 25069862389.106384, "policy_loss": 0.15419502166951907, "vf_loss": 25018724744.17021, "vf_explained_var": 1.5218207138900652e-08, "kl": 0.9022564228544844, "entropy": 11.709475578145778, "entropy_coeff": 0.0}}}, "num_steps_sampled": 444444, "num_agent_steps_sampled": 888888, "num_steps_trained": 444444, "num_agent_steps_trained": 888888}, "done": false, "episodes_total": 444, "training_iteration": 74, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-01-19", "timestamp": 1624921279, "time_this_iter_s": 17.610167264938354, "time_total_s": 1331.8324167728424, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdc80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1331.8324167728424, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 24.426086956521743, "ram_util_percent": 59.8086956521739, "gpu_util_percent0": 0.22391304347826088, "vram_util_percent0": 0.2313565158775516}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1778356.3958512538, "pol1": 1778356.3958512538}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1636111.6687594969, -1635948.9120945933, -1762597.4989639123, -1771093.8453849363, -1901680.1561949828, -1626527.173408855, -1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818], "policy_pol1_reward": [1636111.6687594969, 1635948.9120945933, 1762597.4989639123, 1771093.8453849363, 1901680.1561949828, 1626527.173408855, 1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2067478090916615, "mean_inference_ms": 2.892132970622069, "mean_action_processing_ms": 0.1471662442614658, "mean_env_wait_ms": 0.12126545676682897, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 450450, "agent_timesteps_total": 900900, "timers": {"sample_time_ms": 3513.716, "sample_throughput": 1709.301, "learn_time_ms": 14192.765, "learn_throughput": 423.173, "update_time_ms": 4.606}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 26632897557.787235, "policy_loss": 0.0028526761192590633, "vf_loss": 26632897557.787235, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.011249168676898834, "entropy": 2.7076521629982806, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 85016200.02853997, "cur_lr": 5.000000000000002e-05, "total_loss": 26807904691.744682, "policy_loss": 0.17684948433468, "vf_loss": 26708634732.93617, "vf_explained_var": -1.2681838912342869e-09, "kl": 1.1676595680257107, "entropy": 12.600740473321144, "entropy_coeff": 0.0}}}, "num_steps_sampled": 450450, "num_agent_steps_sampled": 900900, "num_steps_trained": 450450, "num_agent_steps_trained": 900900}, "done": false, "episodes_total": 450, "training_iteration": 75, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-01-37", "timestamp": 1624921297, "time_this_iter_s": 17.660106658935547, "time_total_s": 1349.492523431778, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f17ad02ba60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd7b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1349.492523431778, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 23.1375, "ram_util_percent": 59.508333333333326, "gpu_util_percent0": 0.22125000000000003, "vram_util_percent0": 0.2313644534321986}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1777699.4779800186, "pol1": 1777699.4779800186}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1669010.7464745739, -1866138.2442396504, -1753780.9689042498, -1740768.372470677, -1845532.8781469092, -1874813.522392092, -1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915], "policy_pol1_reward": [1669010.7464745739, 1866138.2442396504, 1753780.9689042498, 1740768.372470677, 1845532.8781469092, 1874813.522392092, 1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20671406665156916, "mean_inference_ms": 2.891253114380163, "mean_action_processing_ms": 0.14712944116235302, "mean_env_wait_ms": 0.12123360129632278, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 456456, "agent_timesteps_total": 912912, "timers": {"sample_time_ms": 3516.097, "sample_throughput": 1708.144, "learn_time_ms": 14210.748, "learn_throughput": 422.638, "update_time_ms": 4.594}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 24532973611.574467, "policy_loss": 0.00025133303109001605, "vf_loss": 24532973611.574467, "vf_explained_var": 1.3696386247374903e-07, "kl": 0.006353554652726396, "entropy": 2.7492847899173167, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 127524300.04280986, "cur_lr": 5.000000000000002e-05, "total_loss": 24767014694.12766, "policy_loss": 0.17072657210395692, "vf_loss": 24608328420.765957, "vf_explained_var": 1.204774804364206e-07, "kl": 1.2443593182462327, "entropy": 13.163086627392058, "entropy_coeff": 0.0}}}, "num_steps_sampled": 456456, "num_agent_steps_sampled": 912912, "num_steps_trained": 456456, "num_agent_steps_trained": 912912}, "done": false, "episodes_total": 456, "training_iteration": 76, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-01-55", "timestamp": 1624921315, "time_this_iter_s": 17.87529492378235, "time_total_s": 1367.3678183555603, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d819d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d811e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1367.3678183555603, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 23.53333333333333, "ram_util_percent": 59.53333333333333, "gpu_util_percent0": 0.21583333333333332, "vram_util_percent0": 0.23141360521289744}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1774903.928484341, "pol1": 1774903.928484341}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1657085.0264670926, -1876111.5054506492, -1657142.430238039, -1487962.1892468885, -1749480.034792947, -1812796.1785322402, -1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476], "policy_pol1_reward": [1657085.0264670926, 1876111.5054506492, 1657142.430238039, 1487962.1892468885, 1749480.034792947, 1812796.1785322402, 1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2066923968966383, "mean_inference_ms": 2.8905500696020483, "mean_action_processing_ms": 0.14710096140725903, "mean_env_wait_ms": 0.12120705112774342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 462462, "agent_timesteps_total": 924924, "timers": {"sample_time_ms": 3537.576, "sample_throughput": 1697.773, "learn_time_ms": 14194.615, "learn_throughput": 423.118, "update_time_ms": 4.475}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 25579782144.0, "policy_loss": -0.001518655409838291, "vf_loss": 25579782144.0, "vf_explained_var": -7.609103569450326e-09, "kl": 0.0058490844701040295, "entropy": 2.841279567556178, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 191286450.06421483, "cur_lr": 5.000000000000002e-05, "total_loss": 25946263813.446808, "policy_loss": 0.1765806495826295, "vf_loss": 25658199976.851063, "vf_explained_var": -1.5218207138900652e-08, "kl": 1.5059279913597918, "entropy": 13.93756789349495, "entropy_coeff": 0.0}}}, "num_steps_sampled": 462462, "num_agent_steps_sampled": 924924, "num_steps_trained": 462462, "num_agent_steps_trained": 924924}, "done": false, "episodes_total": 462, "training_iteration": 77, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-02-13", "timestamp": 1624921333, "time_this_iter_s": 17.669763803482056, "time_total_s": 1385.0375821590424, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd0d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1385.0375821590424, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 24.14782608695652, "ram_util_percent": 59.51739130434783, "gpu_util_percent0": 0.2147826086956522, "vram_util_percent0": 0.2315323632420392}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1778825.775112585, "pol1": 1778825.775112585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1774637.2669761644, -1705165.891796162, -1846005.2700966243, -1811874.5298806843, -1781597.7355956675, -1764673.0167705682, -1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116], "policy_pol1_reward": [1774637.2669761644, 1705165.891796162, 1846005.2700966243, 1811874.5298806843, 1781597.7355956675, 1764673.0167705682, 1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20667795311707216, "mean_inference_ms": 2.889924722989943, "mean_action_processing_ms": 0.14707578838735255, "mean_env_wait_ms": 0.12118258027973816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 468468, "agent_timesteps_total": 936936, "timers": {"sample_time_ms": 3533.17, "sample_throughput": 1699.89, "learn_time_ms": 14182.754, "learn_throughput": 423.472, "update_time_ms": 4.495}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 26327779589.446808, "policy_loss": 0.005702180649213334, "vf_loss": 26327779589.446808, "vf_explained_var": -1.2935475979247713e-07, "kl": 0.009987698451794208, "entropy": 2.903453309485253, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 286929675.0963224, "cur_lr": 5.000000000000002e-05, "total_loss": 26968040208.340427, "policy_loss": 0.19940645350737773, "vf_loss": 26410690952.17021, "vf_explained_var": 3.804551695907321e-08, "kl": 1.9424583810441038, "entropy": 15.034925765179572, "entropy_coeff": 0.0}}}, "num_steps_sampled": 468468, "num_agent_steps_sampled": 936936, "num_steps_trained": 468468, "num_agent_steps_trained": 936936}, "done": false, "episodes_total": 468, "training_iteration": 78, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-02-30", "timestamp": 1624921350, "time_this_iter_s": 17.649651527404785, "time_total_s": 1402.6872336864471, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d841e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1402.6872336864471, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 23.350000000000005, "ram_util_percent": 59.53333333333333, "gpu_util_percent0": 0.21791666666666668, "vram_util_percent0": 0.23152595214020896}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1773959.5715951293, "pol1": 1773959.5715951293}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1778264.2591836823, -1675577.1884702097, -1754563.8756119558, -1726843.2659908496, -1769098.2600855478, -1810524.264794792, -1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888], "policy_pol1_reward": [1778264.2591836823, 1675577.1884702097, 1754563.8756119558, 1726843.2659908496, 1769098.2600855478, 1810524.264794792, 1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20666567395676538, "mean_inference_ms": 2.8893182813041083, "mean_action_processing_ms": 0.14705173758997536, "mean_env_wait_ms": 0.12115901760515989, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 474474, "agent_timesteps_total": 948948, "timers": {"sample_time_ms": 3540.51, "sample_throughput": 1696.366, "learn_time_ms": 14162.115, "learn_throughput": 424.089, "update_time_ms": 4.522}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 24040699686.12766, "policy_loss": -2.8351480339435822e-05, "vf_loss": 24040699686.12766, "vf_explained_var": -7.609103569450326e-09, "kl": 0.008984161085112298, "entropy": 2.8223908251904426, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 430394512.6444832, "cur_lr": 5.000000000000002e-05, "total_loss": 25029387808.68085, "policy_loss": 0.21647643424729082, "vf_loss": 24107735911.48936, "vf_explained_var": 1.1286837064972133e-07, "kl": 2.141411880229382, "entropy": 16.542812103920795, "entropy_coeff": 0.0}}}, "num_steps_sampled": 474474, "num_agent_steps_sampled": 948948, "num_steps_trained": 474474, "num_agent_steps_trained": 948948}, "done": false, "episodes_total": 474, "training_iteration": 79, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-02-48", "timestamp": 1624921368, "time_this_iter_s": 17.76028537750244, "time_total_s": 1420.4475190639496, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d9a488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1420.4475190639496, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 24.356521739130432, "ram_util_percent": 59.417391304347845, "gpu_util_percent0": 0.2152173913043478, "vram_util_percent0": 0.23152503626851892}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1779175.9607507146, "pol1": 1779175.9607507146}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1640472.6360378903, -1763116.4545933828, -1681766.7654145565, -1546747.7058856701, -1870301.6111548743, -1765142.5090591863, -1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132], "policy_pol1_reward": [1640472.6360378903, 1763116.4545933828, 1681766.7654145565, 1546747.7058856701, 1870301.6111548743, 1765142.5090591863, 1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2066524397371855, "mean_inference_ms": 2.888802809503137, "mean_action_processing_ms": 0.1470311593249506, "mean_env_wait_ms": 0.12113721214407366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 480480, "agent_timesteps_total": 960960, "timers": {"sample_time_ms": 3547.368, "sample_throughput": 1693.086, "learn_time_ms": 14172.612, "learn_throughput": 423.775, "update_time_ms": 4.512}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 28357615441.70213, "policy_loss": -0.0011163614442611628, "vf_loss": 28357615441.70213, "vf_explained_var": 9.004106260590561e-08, "kl": 0.017563756456241964, "entropy": 2.8239188143547547, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 645591768.966725, "cur_lr": 5.000000000000002e-05, "total_loss": 29998865211.914894, "policy_loss": 0.20409188292762068, "vf_loss": 28449515607.148937, "vf_explained_var": -1.2174565711120522e-07, "kl": 2.399890646021417, "entropy": 17.50521546221794, "entropy_coeff": 0.0}}}, "num_steps_sampled": 480480, "num_agent_steps_sampled": 960960, "num_steps_trained": 480480, "num_agent_steps_trained": 960960}, "done": false, "episodes_total": 480, "training_iteration": 80, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-03-06", "timestamp": 1624921386, "time_this_iter_s": 17.817460775375366, "time_total_s": 1438.264979839325, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d9a9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d9af28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1438.264979839325, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 23.274999999999995, "ram_util_percent": 59.487500000000004, "gpu_util_percent0": 0.21791666666666668, "vram_util_percent0": 0.231518930457252}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1780761.9105627267, "pol1": 1780761.9105627267}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1761666.2010720102, -1805678.1785321191, -1806264.6773379354, -1626271.8544821618, -1939324.7289710434, -1799244.1685078603, -1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886], "policy_pol1_reward": [1761666.2010720102, 1805678.1785321191, 1806264.6773379354, 1626271.8544821618, 1939324.7289710434, 1799244.1685078603, 1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20663978193684096, "mean_inference_ms": 2.8882810658885205, "mean_action_processing_ms": 0.14700914186559755, "mean_env_wait_ms": 0.12111545407284156, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 486486, "agent_timesteps_total": 972972, "timers": {"sample_time_ms": 3541.088, "sample_throughput": 1696.089, "learn_time_ms": 14165.574, "learn_throughput": 423.986, "update_time_ms": 4.482}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218746, "cur_lr": 5.000000000000002e-05, "total_loss": 25102385457.02128, "policy_loss": -0.0037228458144880354, "vf_loss": 25102385457.02128, "vf_explained_var": -3.804551695907321e-08, "kl": 0.004142102567439384, "entropy": 2.788934352550101, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 968387653.4500879, "cur_lr": 5.000000000000002e-05, "total_loss": 28194759919.659573, "policy_loss": 0.22263423400990506, "vf_loss": 25176808339.06383, "vf_explained_var": -6.340919611602658e-08, "kl": 3.1164703064776482, "entropy": 19.48223410261438, "entropy_coeff": 0.0}}}, "num_steps_sampled": 486486, "num_agent_steps_sampled": 972972, "num_steps_trained": 486486, "num_agent_steps_trained": 972972}, "done": false, "episodes_total": 486, "training_iteration": 81, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-03-24", "timestamp": 1624921404, "time_this_iter_s": 17.80851674079895, "time_total_s": 1456.073496580124, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1456.073496580124, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 23.462500000000002, "ram_util_percent": 59.429166666666674, "gpu_util_percent0": 0.21833333333333335, "vram_util_percent0": 0.23153297382316596}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2021889.5092335644, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2021889.5092335644}, "policy_reward_mean": {"pol0": -1778496.1797438136, "pol1": 1778496.1797438136}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1775006.3760400307, -1816592.1108026593, -1788778.0315103473, -1721607.8732841513, -1670711.3376174176, -1623793.11051328, -1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266], "policy_pol1_reward": [1775006.3760400307, 1816592.1108026593, 1788778.0315103473, 1721607.8732841513, 1670711.3376174176, 1623793.11051328, 1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.206643660682457, "mean_inference_ms": 2.887911397494426, "mean_action_processing_ms": 0.14699388559751791, "mean_env_wait_ms": 0.1210987871983835, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 492492, "agent_timesteps_total": 984984, "timers": {"sample_time_ms": 3549.659, "sample_throughput": 1691.993, "learn_time_ms": 14166.719, "learn_throughput": 423.951, "update_time_ms": 4.488}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 25552336198.80851, "policy_loss": -1.0667230062028194e-05, "vf_loss": 25552336198.80851, "vf_explained_var": -1.3696386247374903e-07, "kl": 0.008185407265703729, "entropy": 2.7439595587710115, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1452581480.1751318, "cur_lr": 5.000000000000002e-05, "total_loss": 30794906863.659573, "policy_loss": 0.23343643799741218, "vf_loss": 25633577570.042553, "vf_explained_var": -2.5363677824685738e-09, "kl": 3.5532115418860255, "entropy": 21.69806565629675, "entropy_coeff": 0.0}}}, "num_steps_sampled": 492492, "num_agent_steps_sampled": 984984, "num_steps_trained": 492492, "num_agent_steps_trained": 984984}, "done": false, "episodes_total": 492, "training_iteration": 82, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-03-42", "timestamp": 1624921422, "time_this_iter_s": 17.73822546005249, "time_total_s": 1473.8117220401764, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcd400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd0d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1473.8117220401764, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 24.039130434782606, "ram_util_percent": 59.3086956521739, "gpu_util_percent0": 0.2204347826086957, "vram_util_percent0": 0.2315396902155595}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2169876.011005258, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2169876.011005258}, "policy_reward_mean": {"pol0": -1796126.1559725169, "pol1": 1796126.1559725169}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1691909.4134221736, -1875829.7539675357, -1838504.2634463706, -1851482.697743235, -1934649.326789019, -1917090.430453424, -1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914], "policy_pol1_reward": [1691909.4134221736, 1875829.7539675357, 1838504.2634463706, 1851482.697743235, 1934649.326789019, 1917090.430453424, 1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2066374687957767, "mean_inference_ms": 2.8874845272770737, "mean_action_processing_ms": 0.14697625671519182, "mean_env_wait_ms": 0.12108081375898505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 498498, "agent_timesteps_total": 996996, "timers": {"sample_time_ms": 3543.413, "sample_throughput": 1694.976, "learn_time_ms": 14168.348, "learn_throughput": 423.903, "update_time_ms": 4.531}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 35557318133.106384, "policy_loss": 0.0030955142004692807, "vf_loss": 35557318133.106384, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.015927866358864815, "entropy": 2.6594844523896564, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2178872220.2626967, "cur_lr": 5.000000000000002e-05, "total_loss": 49978754505.53191, "policy_loss": 0.28742530085939044, "vf_loss": 35694075598.97872, "vf_explained_var": -2.5363679156953367e-08, "kl": 6.555996357126439, "entropy": 23.092043125883063, "entropy_coeff": 0.0}}}, "num_steps_sampled": 498498, "num_agent_steps_sampled": 996996, "num_steps_trained": 498498, "num_agent_steps_trained": 996996}, "done": false, "episodes_total": 498, "training_iteration": 83, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-03-59", "timestamp": 1624921439, "time_this_iter_s": 17.650943279266357, "time_total_s": 1491.4626653194427, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d817b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1491.4626653194427, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 23.641666666666666, "ram_util_percent": 59.4125, "gpu_util_percent0": 0.22458333333333336, "vram_util_percent0": 0.23153297382316596}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2169876.011005258, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2169876.011005258}, "policy_reward_mean": {"pol0": -1792422.0311953982, "pol1": 1792422.0311953982}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1850185.55183794, -1795621.9758978495, -1863090.9153516742, -1896110.8751685398, -1917803.466766106, -1881313.454186697, -1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289], "policy_pol1_reward": [1850185.55183794, 1795621.9758978495, 1863090.9153516742, 1896110.8751685398, 1917803.466766106, 1881313.454186697, 1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20664260941536974, "mean_inference_ms": 2.8871273549630554, "mean_action_processing_ms": 0.14696362773909477, "mean_env_wait_ms": 0.12106466515956288, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 504504, "agent_timesteps_total": 1009008, "timers": {"sample_time_ms": 3565.287, "sample_throughput": 1684.577, "learn_time_ms": 14167.722, "learn_throughput": 423.921, "update_time_ms": 4.579}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 26691244859.914894, "policy_loss": 0.0005909782992874054, "vf_loss": 26691244859.914894, "vf_explained_var": 7.862740147857039e-08, "kl": 0.01892198424072976, "entropy": 2.6231449766361967, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3268308330.3940454, "cur_lr": 5.000000000000002e-05, "total_loss": 44209704960.0, "policy_loss": 0.2296948718263748, "vf_loss": 26779380104.17021, "vf_explained_var": -5.0727358313906734e-08, "kl": 5.33313386998278, "entropy": 24.871757547906103, "entropy_coeff": 0.0}}}, "num_steps_sampled": 504504, "num_agent_steps_sampled": 1009008, "num_steps_trained": 504504, "num_agent_steps_trained": 1009008}, "done": false, "episodes_total": 504, "training_iteration": 84, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-04-17", "timestamp": 1624921457, "time_this_iter_s": 17.823503732681274, "time_total_s": 1509.286169052124, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d810d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1509.286169052124, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 23.90416666666667, "ram_util_percent": 59.59166666666667, "gpu_util_percent0": 0.2204166666666667, "vram_util_percent0": 0.23152595214020896}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1267643.965364964}, "policy_reward_max": {"pol0": -1267643.965364964, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1801289.1389075734, "pol1": 1801289.1389075734}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1845188.3253785279, -1267643.965364964, -1837120.5402608747, -1874939.2284842005, -1736562.4450106663, -2021889.5092335644, -1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793], "policy_pol1_reward": [1845188.3253785279, 1267643.965364964, 1837120.5402608747, 1874939.2284842005, 1736562.4450106663, 2021889.5092335644, 1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20664332140698646, "mean_inference_ms": 2.8867548673487193, "mean_action_processing_ms": 0.14694922924799783, "mean_env_wait_ms": 0.12104791355250452, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 510510, "agent_timesteps_total": 1021020, "timers": {"sample_time_ms": 3563.566, "sample_throughput": 1685.39, "learn_time_ms": 14168.872, "learn_throughput": 423.887, "update_time_ms": 4.578}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 35095183229.276596, "policy_loss": 0.0011513117066723234, "vf_loss": 35095183229.276596, "vf_explained_var": 1.5218207138900652e-08, "kl": 0.013771417649819496, "entropy": 2.707009071999408, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4902462495.591067, "cur_lr": 5.000000000000002e-05, "total_loss": 80740995682.04256, "policy_loss": 0.2744790943379098, "vf_loss": 35240392006.80851, "vf_explained_var": -9.638198150696553e-08, "kl": 9.281173421981487, "entropy": 26.36419941516633, "entropy_coeff": 0.0}}}, "num_steps_sampled": 510510, "num_agent_steps_sampled": 1021020, "num_steps_trained": 510510, "num_agent_steps_trained": 1021020}, "done": false, "episodes_total": 510, "training_iteration": 85, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-04-35", "timestamp": 1624921475, "time_this_iter_s": 17.655604124069214, "time_total_s": 1526.9417731761932, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcde18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1526.9417731761932, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 23.530434782608694, "ram_util_percent": 59.49565217391305, "gpu_util_percent0": 0.2221739130434782, "vram_util_percent0": 0.23154701718907983}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1418534.6158129915}, "policy_reward_max": {"pol0": -1418534.6158129915, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1800480.0800669063, "pol1": 1800480.0800669063}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1871442.5878605621, -1984532.3522126758, -1810469.5613865482, -1946245.992355542, -1878524.1971506234, -1725246.1477050625, -1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683], "policy_pol1_reward": [1871442.5878605621, 1984532.3522126758, 1810469.5613865482, 1946245.992355542, 1878524.1971506234, 1725246.1477050625, 1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20664415887099644, "mean_inference_ms": 2.886317556332065, "mean_action_processing_ms": 0.1469318774627598, "mean_env_wait_ms": 0.12102955215347834, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 516516, "agent_timesteps_total": 1033032, "timers": {"sample_time_ms": 3568.793, "sample_throughput": 1682.922, "learn_time_ms": 14148.27, "learn_throughput": 424.504, "update_time_ms": 4.575}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 25576911850.212765, "policy_loss": 0.005572362703845856, "vf_loss": 25576911850.212765, "vf_explained_var": -1.775457469932462e-08, "kl": 0.022487889380848156, "entropy": 2.8007321256272335, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7353693743.386601, "cur_lr": 5.000000000000002e-05, "total_loss": 66423866999.82979, "policy_loss": 0.2575773652246658, "vf_loss": 25667276494.97872, "vf_explained_var": -1.1413655442993331e-07, "kl": 5.542329199770664, "entropy": 27.668194953431474, "entropy_coeff": 0.0}}}, "num_steps_sampled": 516516, "num_agent_steps_sampled": 1033032, "num_steps_trained": 516516, "num_agent_steps_trained": 1033032}, "done": false, "episodes_total": 516, "training_iteration": 86, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-04-53", "timestamp": 1624921493, "time_this_iter_s": 17.721564054489136, "time_total_s": 1544.6633372306824, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682da0378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682da02f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1544.6633372306824, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 22.941666666666663, "ram_util_percent": 59.30833333333333, "gpu_util_percent0": 0.22375000000000003, "vram_util_percent0": 0.2315399955061229}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1418534.6158129915}, "policy_reward_max": {"pol0": -1418534.6158129915, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1804613.5595104834, "pol1": 1804613.5595104834}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1833962.284942843, -1692698.7693568007, -1840083.587158197, -1695885.9634569208, -1626501.10300625, -1682762.810918492, -1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416], "policy_pol1_reward": [1833962.284942843, 1692698.7693568007, 1840083.587158197, 1695885.9634569208, 1626501.10300625, 1682762.810918492, 1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2066410452130746, "mean_inference_ms": 2.8859342905942724, "mean_action_processing_ms": 0.1469150577862982, "mean_env_wait_ms": 0.1210117730777574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 522522, "agent_timesteps_total": 1045044, "timers": {"sample_time_ms": 3568.216, "sample_throughput": 1683.194, "learn_time_ms": 14156.483, "learn_throughput": 424.258, "update_time_ms": 4.572}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 32398883338.893616, "policy_loss": -0.0001002275880346907, "vf_loss": 32398883338.893616, "vf_explained_var": -1.2681839578476684e-08, "kl": 0.011901988429909057, "entropy": 2.7955269813537598, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 11030540615.0799, "cur_lr": 5.000000000000002e-05, "total_loss": 159920295674.5532, "policy_loss": 0.287590947239957, "vf_loss": 32524271136.68085, "vf_explained_var": -5.0727355649371475e-09, "kl": 11.54939099575611, "entropy": 28.385448374646774, "entropy_coeff": 0.0}}}, "num_steps_sampled": 522522, "num_agent_steps_sampled": 1045044, "num_steps_trained": 522522, "num_agent_steps_trained": 1045044}, "done": false, "episodes_total": 522, "training_iteration": 87, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-05-10", "timestamp": 1624921510, "time_this_iter_s": 17.746077060699463, "time_total_s": 1562.4094142913818, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682da08c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682da0f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1562.4094142913818, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 23.304166666666664, "ram_util_percent": 59.479166666666664, "gpu_util_percent0": 0.22333333333333336, "vram_util_percent0": 0.23153297382316593}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1418534.6158129915}, "policy_reward_max": {"pol0": -1418534.6158129915, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1810850.4888234525, "pol1": 1810850.4888234525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1461378.3208828312, -1934740.0274609483, -1850004.950260091, -1937064.1483368448, -1827153.1744064502, -1862279.3550985798, -1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562], "policy_pol1_reward": [1461378.3208828312, 1934740.0274609483, 1850004.950260091, 1937064.1483368448, 1827153.1744064502, 1862279.3550985798, 1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2066402837536013, "mean_inference_ms": 2.8855394915356545, "mean_action_processing_ms": 0.14689843729511387, "mean_env_wait_ms": 0.12099414982100677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 528528, "agent_timesteps_total": 1057056, "timers": {"sample_time_ms": 3568.142, "sample_throughput": 1683.229, "learn_time_ms": 14156.314, "learn_throughput": 424.263, "update_time_ms": 4.582}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 28090854247.48936, "policy_loss": -0.002412468393115287, "vf_loss": 28090854247.48936, "vf_explained_var": 1.2681839578476684e-08, "kl": 0.006443762289796104, "entropy": 2.7847718380867166, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 16545810922.619858, "cur_lr": 5.000000000000002e-05, "total_loss": 137750126243.40427, "policy_loss": 0.2363395833588661, "vf_loss": 28194233540.085106, "vf_explained_var": -2.7900046717377336e-08, "kl": 6.621367677729181, "entropy": 29.424472118945832, "entropy_coeff": 0.0}}}, "num_steps_sampled": 528528, "num_agent_steps_sampled": 1057056, "num_steps_trained": 528528, "num_agent_steps_trained": 1057056}, "done": false, "episodes_total": 528, "training_iteration": 88, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-05-28", "timestamp": 1624921528, "time_this_iter_s": 17.646695375442505, "time_total_s": 1580.0561096668243, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1580.0561096668243, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 23.72608695652173, "ram_util_percent": 59.48260869565218, "gpu_util_percent0": 0.22260869565217392, "vram_util_percent0": 0.23152503626851892}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1418534.6158129915}, "policy_reward_max": {"pol0": -1418534.6158129915, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1810858.882988639, "pol1": 1810858.882988639}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1921373.0915109615, -1908094.4982006343, -1756392.8773254042, -1896074.1538397458, -1650321.8009640682, -1717273.24087514, -1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363], "policy_pol1_reward": [1921373.0915109615, 1908094.4982006343, 1756392.8773254042, 1896074.1538397458, 1650321.8009640682, 1717273.24087514, 1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20663157537543878, "mean_inference_ms": 2.885074076400165, "mean_action_processing_ms": 0.14687845925430654, "mean_env_wait_ms": 0.12097468828895704, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 534534, "agent_timesteps_total": 1069068, "timers": {"sample_time_ms": 3550.451, "sample_throughput": 1691.616, "learn_time_ms": 14187.555, "learn_throughput": 423.329, "update_time_ms": 4.584}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 27411729037.61702, "policy_loss": 0.0012384357842359138, "vf_loss": 27411729037.61702, "vf_explained_var": 1.0399108418823744e-07, "kl": 0.01655027488286191, "entropy": 2.8643822365618767, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 24818716383.929775, "cur_lr": 5.000000000000002e-05, "total_loss": 187023716264.85107, "policy_loss": 0.21894916796937902, "vf_loss": 27510021838.97872, "vf_explained_var": 3.2972781838225274e-08, "kl": 6.4271531206496215, "entropy": 29.875706165394885, "entropy_coeff": 0.0}}}, "num_steps_sampled": 534534, "num_agent_steps_sampled": 1069068, "num_steps_trained": 534534, "num_agent_steps_trained": 1069068}, "done": false, "episodes_total": 534, "training_iteration": 89, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-05-46", "timestamp": 1624921546, "time_this_iter_s": 17.89458394050598, "time_total_s": 1597.9506936073303, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdd90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcde18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1597.9506936073303, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 23.295833333333334, "ram_util_percent": 59.50416666666666, "gpu_util_percent0": 0.22375, "vram_util_percent0": 0.23151190877429503}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1418534.6158129915}, "policy_reward_max": {"pol0": -1418534.6158129915, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1798471.0066909292, "pol1": 1798471.0066909292}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1905907.5226570705, -1756423.8645912728, -1633232.5230239935, -1683842.5472861556, -1827422.8027818203, -1770862.1147779608, -1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978], "policy_pol1_reward": [1905907.5226570705, 1756423.8645912728, 1633232.5230239935, 1683842.5472861556, 1827422.8027818203, 1770862.1147779608, 1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20662693842840166, "mean_inference_ms": 2.88474753492862, "mean_action_processing_ms": 0.1468643247075861, "mean_env_wait_ms": 0.12095879511846556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 540540, "agent_timesteps_total": 1081080, "timers": {"sample_time_ms": 3549.563, "sample_throughput": 1692.039, "learn_time_ms": 14175.047, "learn_throughput": 423.702, "update_time_ms": 6.318}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 21361657943.148937, "policy_loss": 0.0008707782055469269, "vf_loss": 21361657943.148937, "vf_explained_var": 2.916823049758932e-08, "kl": 0.007465131491660438, "entropy": 2.856672525405884, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 37228074575.894684, "cur_lr": 5.000000000000002e-05, "total_loss": 295683714984.8511, "policy_loss": 0.2759177370908413, "vf_loss": 21435560894.638298, "vf_explained_var": -4.1850068299709164e-08, "kl": 7.366702881265194, "entropy": 31.171914729666202, "entropy_coeff": 0.0}}}, "num_steps_sampled": 540540, "num_agent_steps_sampled": 1081080, "num_steps_trained": 540540, "num_agent_steps_trained": 1081080}, "done": false, "episodes_total": 540, "training_iteration": 90, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-06-04", "timestamp": 1624921564, "time_this_iter_s": 17.701737642288208, "time_total_s": 1615.6524312496185, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1615.6524312496185, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 23.108333333333334, "ram_util_percent": 59.320833333333326, "gpu_util_percent0": 0.22916666666666666, "vram_util_percent0": 0.23149786540838105}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1418534.6158129915}, "policy_reward_max": {"pol0": -1418534.6158129915, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1800722.205182201, "pol1": 1800722.205182201}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1832302.6746011388, -1761373.7445144143, -1806587.7622291094, -1724350.3849945818, -1685073.4894009705, -1862093.173382278, -1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555], "policy_pol1_reward": [1832302.6746011388, 1761373.7445144143, 1806587.7622291094, 1724350.3849945818, 1685073.4894009705, 1862093.173382278, 1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20661812442550656, "mean_inference_ms": 2.8843877471744457, "mean_action_processing_ms": 0.14684814255489667, "mean_env_wait_ms": 0.120942645859909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 546546, "agent_timesteps_total": 1093092, "timers": {"sample_time_ms": 3555.43, "sample_throughput": 1689.247, "learn_time_ms": 14179.167, "learn_throughput": 423.579, "update_time_ms": 6.314}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 27046631685.446808, "policy_loss": -0.0037344397303271802, "vf_loss": 27046631685.446808, "vf_explained_var": 1.3442749491332506e-07, "kl": 0.0068978643183536985, "entropy": 2.8164633740770055, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 55842111863.84197, "cur_lr": 5.000000000000002e-05, "total_loss": 435640473730.7234, "policy_loss": 0.24213131786660946, "vf_loss": 27146885294.29787, "vf_explained_var": 3.804551784725163e-09, "kl": 7.315153010348056, "entropy": 32.29765060100149, "entropy_coeff": 0.0}}}, "num_steps_sampled": 546546, "num_agent_steps_sampled": 1093092, "num_steps_trained": 546546, "num_agent_steps_trained": 1093092}, "done": false, "episodes_total": 546, "training_iteration": 91, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-06-22", "timestamp": 1624921582, "time_this_iter_s": 17.90790605545044, "time_total_s": 1633.560337305069, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d819d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1633.560337305069, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 23.38695652173913, "ram_util_percent": 59.417391304347845, "gpu_util_percent0": 0.2126086956521739, "vram_util_percent0": 0.2314957283744376}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1418534.6158129915}, "policy_reward_max": {"pol0": -1418534.6158129915, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1800211.3109216662, "pol1": 1800211.3109216662}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1799170.8588156372, -1717462.5034323884, -1785932.8268389984, -1418534.6158129915, -1905274.3259291316, -1575807.6621379894, -1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446], "policy_pol1_reward": [1799170.8588156372, 1717462.5034323884, 1785932.8268389984, 1418534.6158129915, 1905274.3259291316, 1575807.6621379894, 1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2066121790209477, "mean_inference_ms": 2.884052062679188, "mean_action_processing_ms": 0.14683311181571648, "mean_env_wait_ms": 0.12092714762245192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 552552, "agent_timesteps_total": 1105104, "timers": {"sample_time_ms": 3561.143, "sample_throughput": 1686.537, "learn_time_ms": 14187.43, "learn_throughput": 423.332, "update_time_ms": 6.358}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 26133699780.085106, "policy_loss": 0.0066138627998372345, "vf_loss": 26133699780.085106, "vf_explained_var": 3.804551784725163e-09, "kl": 0.014579374759279668, "entropy": 2.9524690546887986, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 83763167795.76303, "cur_lr": 5.000000000000002e-05, "total_loss": 631590986599.4894, "policy_loss": 0.25690622833815024, "vf_loss": 26231056253.276596, "vf_explained_var": 5.833646099517864e-08, "kl": 7.22704197498078, "entropy": 32.87082842563061, "entropy_coeff": 0.0}}}, "num_steps_sampled": 552552, "num_agent_steps_sampled": 1105104, "num_steps_trained": 552552, "num_agent_steps_trained": 1105104}, "done": false, "episodes_total": 552, "training_iteration": 92, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-06-40", "timestamp": 1624921600, "time_this_iter_s": 17.878496170043945, "time_total_s": 1651.438833475113, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcd158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcdd90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1651.438833475113, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 23.025000000000002, "ram_util_percent": 59.49166666666667, "gpu_util_percent0": 0.21708333333333338, "vram_util_percent0": 0.23149786540838105}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1805600.4129981676, "pol1": 1805600.4129981676}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1686255.3422661514, -1850508.0197837811, -1578994.48100087, -1873649.951942476, -1897998.3880532437, -1668909.4104929047, -1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628], "policy_pol1_reward": [1686255.3422661514, 1850508.0197837811, 1578994.48100087, 1873649.951942476, 1897998.3880532437, 1668909.4104929047, 1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2065979030799714, "mean_inference_ms": 2.8836460921909595, "mean_action_processing_ms": 0.14681555229648707, "mean_env_wait_ms": 0.12090992623727746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 558558, "agent_timesteps_total": 1117116, "timers": {"sample_time_ms": 3549.088, "sample_throughput": 1692.266, "learn_time_ms": 14191.648, "learn_throughput": 423.207, "update_time_ms": 6.315}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 26601202971.234043, "policy_loss": 0.005981883073740817, "vf_loss": 26601202971.234043, "vf_explained_var": -1.3442749491332506e-07, "kl": 0.022205729909399723, "entropy": 2.9227918716187173, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 125644751693.64452, "cur_lr": 5.000000000000002e-05, "total_loss": 1105443217233.7021, "policy_loss": 0.22605718101592773, "vf_loss": 26700481165.61702, "vf_explained_var": -1.0145471129874295e-08, "kl": 8.585656987859847, "entropy": 34.56742363787712, "entropy_coeff": 0.0}}}, "num_steps_sampled": 558558, "num_agent_steps_sampled": 1117116, "num_steps_trained": 558558, "num_agent_steps_trained": 1117116}, "done": false, "episodes_total": 558, "training_iteration": 93, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-06-57", "timestamp": 1624921617, "time_this_iter_s": 17.57232642173767, "time_total_s": 1669.0111598968506, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d810d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1669.0111598968506, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 22.666666666666668, "ram_util_percent": 59.30833333333333, "gpu_util_percent0": 0.2225, "vram_util_percent0": 0.23149786540838105}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1801504.3414532966, "pol1": 1801504.3414532966}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1913255.2201510961, -1847174.8728124828, -1561406.6437346158, -1744017.4923079116, -1679526.0072150936, -1699023.0975908744, -1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628, -1717889.9028287062, -1455210.2400659819, -1728768.3735779114, -1821071.8415966064, -1748875.439283877, -1674892.641699214], "policy_pol1_reward": [1913255.2201510961, 1847174.8728124828, 1561406.6437346158, 1744017.4923079116, 1679526.0072150936, 1699023.0975908744, 1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628, 1717889.9028287062, 1455210.2400659819, 1728768.3735779114, 1821071.8415966064, 1748875.439283877, 1674892.641699214]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20658259179741267, "mean_inference_ms": 2.883132979138048, "mean_action_processing_ms": 0.14679251930472773, "mean_env_wait_ms": 0.12088890672731978, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 564564, "agent_timesteps_total": 1129128, "timers": {"sample_time_ms": 3534.412, "sample_throughput": 1699.293, "learn_time_ms": 14192.408, "learn_throughput": 423.184, "update_time_ms": 6.28}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2163719177246093, "cur_lr": 5.000000000000002e-05, "total_loss": 23977375918.29787, "policy_loss": 0.010991925591642552, "vf_loss": 23977375918.29787, "vf_explained_var": -3.550914939864924e-08, "kl": 0.029123706980905634, "entropy": 2.9614314272048627, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 188467127540.46677, "cur_lr": 5.000000000000002e-05, "total_loss": 1603537327212.9363, "policy_loss": 0.2618176945029421, "vf_loss": 24069847040.0, "vf_explained_var": -2.663186293716535e-08, "kl": 8.380599021911621, "entropy": 35.832102674119014, "entropy_coeff": 0.0}}}, "num_steps_sampled": 564564, "num_agent_steps_sampled": 1129128, "num_steps_trained": 564564, "num_agent_steps_trained": 1129128}, "done": false, "episodes_total": 564, "training_iteration": 94, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-07-15", "timestamp": 1624921635, "time_this_iter_s": 17.68434190750122, "time_total_s": 1686.6955018043518, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682da08c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682da01e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1686.6955018043518, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 23.304347826086957, "ram_util_percent": 59.295652173913034, "gpu_util_percent0": 0.21478260869565216, "vram_util_percent0": 0.23148840140091725}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1801456.336658055, "pol1": 1801456.336658055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1624754.6267603275, -1581774.1713859187, -1897148.3424119889, -1715107.1140060888, -1831035.843170946, -1937353.3645471737, -1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628, -1717889.9028287062, -1455210.2400659819, -1728768.3735779114, -1821071.8415966064, -1748875.439283877, -1674892.641699214, -1603287.0145049654, -1756752.9286290372, -1725168.6268670724, -1651533.8829267453, -1772582.5298482778, -1930277.8715118368], "policy_pol1_reward": [1624754.6267603275, 1581774.1713859187, 1897148.3424119889, 1715107.1140060888, 1831035.843170946, 1937353.3645471737, 1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628, 1717889.9028287062, 1455210.2400659819, 1728768.3735779114, 1821071.8415966064, 1748875.439283877, 1674892.641699214, 1603287.0145049654, 1756752.9286290372, 1725168.6268670724, 1651533.8829267453, 1772582.5298482778, 1930277.8715118368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20657631010510832, "mean_inference_ms": 2.8825701710491636, "mean_action_processing_ms": 0.14676719642763247, "mean_env_wait_ms": 0.12086633362201095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 570570, "agent_timesteps_total": 1141140, "timers": {"sample_time_ms": 3536.156, "sample_throughput": 1698.455, "learn_time_ms": 14199.381, "learn_throughput": 422.976, "update_time_ms": 6.321}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8245578765869133, "cur_lr": 5.000000000000002e-05, "total_loss": 25315894119.48936, "policy_loss": 0.0022013047313753594, "vf_loss": 25315894119.48936, "vf_explained_var": 9.89183490673895e-08, "kl": 0.012524634520424174, "entropy": 2.926980454870995, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 282700691310.69995, "cur_lr": 5.000000000000002e-05, "total_loss": 2333214897435.234, "policy_loss": 0.24148261008110453, "vf_loss": 25411980745.531914, "vf_explained_var": -2.663186293716535e-08, "kl": 8.163414863829917, "entropy": 36.87623166023417, "entropy_coeff": 0.0}}}, "num_steps_sampled": 570570, "num_agent_steps_sampled": 1141140, "num_steps_trained": 570570, "num_agent_steps_trained": 1141140}, "done": false, "episodes_total": 570, "training_iteration": 95, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-07-33", "timestamp": 1624921653, "time_this_iter_s": 17.74241352081299, "time_total_s": 1704.4379153251648, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682da0730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682da07b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1704.4379153251648, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 23.045833333333334, "ram_util_percent": 59.40833333333333, "gpu_util_percent0": 0.22125000000000003, "vram_util_percent0": 0.23149786540838105}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1799941.2522364177, "pol1": 1799941.2522364177}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1854394.2389940426, -1884319.6134737183, -1857602.88614599, -1671804.0833637132, -1776794.254620252, -1724025.6830452273, -1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628, -1717889.9028287062, -1455210.2400659819, -1728768.3735779114, -1821071.8415966064, -1748875.439283877, -1674892.641699214, -1603287.0145049654, -1756752.9286290372, -1725168.6268670724, -1651533.8829267453, -1772582.5298482778, -1930277.8715118368, -1792316.2366229245, -1912283.162267295, -1712267.5815236224, -1695245.1230622584, -1741511.626579084, -1582041.290063559], "policy_pol1_reward": [1854394.2389940426, 1884319.6134737183, 1857602.88614599, 1671804.0833637132, 1776794.254620252, 1724025.6830452273, 1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628, 1717889.9028287062, 1455210.2400659819, 1728768.3735779114, 1821071.8415966064, 1748875.439283877, 1674892.641699214, 1603287.0145049654, 1756752.9286290372, 1725168.6268670724, 1651533.8829267453, 1772582.5298482778, 1930277.8715118368, 1792316.2366229245, 1912283.162267295, 1712267.5815236224, 1695245.1230622584, 1741511.626579084, 1582041.290063559]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2065694727447236, "mean_inference_ms": 2.881985287198392, "mean_action_processing_ms": 0.1467408259029481, "mean_env_wait_ms": 0.1208433799975929, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 576576, "agent_timesteps_total": 1153152, "timers": {"sample_time_ms": 3527.252, "sample_throughput": 1702.742, "learn_time_ms": 14191.857, "learn_throughput": 423.2, "update_time_ms": 6.349}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8245578765869133, "cur_lr": 5.000000000000002e-05, "total_loss": 25212162483.744682, "policy_loss": -0.0015208909010633509, "vf_loss": 25212162483.744682, "vf_explained_var": -1.1413655798264699e-08, "kl": 0.004964500338711003, "entropy": 2.920666456222534, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 424051036966.0502, "cur_lr": 5.000000000000002e-05, "total_loss": 3913927890377.5317, "policy_loss": 0.30023603046194036, "vf_loss": 25308078123.574467, "vf_explained_var": -1.1160018686950934e-07, "kl": 9.170169079557379, "entropy": 38.33730194416452, "entropy_coeff": 0.0}}}, "num_steps_sampled": 576576, "num_agent_steps_sampled": 1153152, "num_steps_trained": 576576, "num_agent_steps_trained": 1153152}, "done": false, "episodes_total": 576, "training_iteration": 96, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-07-50", "timestamp": 1624921670, "time_this_iter_s": 17.55812406539917, "time_total_s": 1721.996039390564, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d849d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1721.996039390564, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 23.152173913043477, "ram_util_percent": 59.47391304347826, "gpu_util_percent0": 0.22173913043478266, "vram_util_percent0": 0.2315103823214782}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1797050.7815932517, "pol1": 1797050.7815932517}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1639967.0841019338, -1713981.4601040138, -1762079.944750418, -1809294.236724886, -1841430.738768573, -1624550.0110587352, -1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628, -1717889.9028287062, -1455210.2400659819, -1728768.3735779114, -1821071.8415966064, -1748875.439283877, -1674892.641699214, -1603287.0145049654, -1756752.9286290372, -1725168.6268670724, -1651533.8829267453, -1772582.5298482778, -1930277.8715118368, -1792316.2366229245, -1912283.162267295, -1712267.5815236224, -1695245.1230622584, -1741511.626579084, -1582041.290063559, -1591006.8263298108, -1761605.0276732743, -1746068.236191362, -1775393.7605579076, -1798095.381606987, -1807724.4629669867], "policy_pol1_reward": [1639967.0841019338, 1713981.4601040138, 1762079.944750418, 1809294.236724886, 1841430.738768573, 1624550.0110587352, 1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628, 1717889.9028287062, 1455210.2400659819, 1728768.3735779114, 1821071.8415966064, 1748875.439283877, 1674892.641699214, 1603287.0145049654, 1756752.9286290372, 1725168.6268670724, 1651533.8829267453, 1772582.5298482778, 1930277.8715118368, 1792316.2366229245, 1912283.162267295, 1712267.5815236224, 1695245.1230622584, 1741511.626579084, 1582041.290063559, 1591006.8263298108, 1761605.0276732743, 1746068.236191362, 1775393.7605579076, 1798095.381606987, 1807724.4629669867]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2065556851488578, "mean_inference_ms": 2.8813614729729107, "mean_action_processing_ms": 0.14671286707892853, "mean_env_wait_ms": 0.12081957351957005, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 582582, "agent_timesteps_total": 1165164, "timers": {"sample_time_ms": 3518.192, "sample_throughput": 1707.127, "learn_time_ms": 14185.095, "learn_throughput": 423.402, "update_time_ms": 6.33}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 25367815538.38298, "policy_loss": -0.0001579537551770819, "vf_loss": 25367815538.38298, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.010436010745136028, "entropy": 2.898422530356874, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 636076555449.0751, "cur_lr": 5.000000000000002e-05, "total_loss": 5727021349169.021, "policy_loss": 0.24662321108452817, "vf_loss": 25462057570.042553, "vf_explained_var": 0.0, "kl": 8.963636865007116, "entropy": 39.2470194228152, "entropy_coeff": 0.0}}}, "num_steps_sampled": 582582, "num_agent_steps_sampled": 1165164, "num_steps_trained": 582582, "num_agent_steps_trained": 1165164}, "done": false, "episodes_total": 582, "training_iteration": 97, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-08-08", "timestamp": 1624921688, "time_this_iter_s": 17.58791732788086, "time_total_s": 1739.5839567184448, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcdae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1739.5839567184448, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 22.854166666666668, "ram_util_percent": 59.487500000000004, "gpu_util_percent0": 0.2241666666666667, "vram_util_percent0": 0.231518930457252}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1797537.3897083902, "pol1": 1797537.3897083902}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1797828.103455029, -1736820.669573542, -1783188.0581312443, -1728059.1460247266, -2116894.8836559956, -1797842.4440910758, -2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628, -1717889.9028287062, -1455210.2400659819, -1728768.3735779114, -1821071.8415966064, -1748875.439283877, -1674892.641699214, -1603287.0145049654, -1756752.9286290372, -1725168.6268670724, -1651533.8829267453, -1772582.5298482778, -1930277.8715118368, -1792316.2366229245, -1912283.162267295, -1712267.5815236224, -1695245.1230622584, -1741511.626579084, -1582041.290063559, -1591006.8263298108, -1761605.0276732743, -1746068.236191362, -1775393.7605579076, -1798095.381606987, -1807724.4629669867, -1722036.0536494327, -1830910.0662496747, -1860941.614020646, -1593700.0912625855, -1793395.1627983756, -1638981.299041708], "policy_pol1_reward": [1797828.103455029, 1736820.669573542, 1783188.0581312443, 1728059.1460247266, 2116894.8836559956, 1797842.4440910758, 2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628, 1717889.9028287062, 1455210.2400659819, 1728768.3735779114, 1821071.8415966064, 1748875.439283877, 1674892.641699214, 1603287.0145049654, 1756752.9286290372, 1725168.6268670724, 1651533.8829267453, 1772582.5298482778, 1930277.8715118368, 1792316.2366229245, 1912283.162267295, 1712267.5815236224, 1695245.1230622584, 1741511.626579084, 1582041.290063559, 1591006.8263298108, 1761605.0276732743, 1746068.236191362, 1775393.7605579076, 1798095.381606987, 1807724.4629669867, 1722036.0536494327, 1830910.0662496747, 1860941.614020646, 1593700.0912625855, 1793395.1627983756, 1638981.299041708]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20653928926991502, "mean_inference_ms": 2.8806494227681894, "mean_action_processing_ms": 0.14668151002804175, "mean_env_wait_ms": 0.12079320232485227, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 588588, "agent_timesteps_total": 1177176, "timers": {"sample_time_ms": 3511.172, "sample_throughput": 1710.54, "learn_time_ms": 14203.422, "learn_throughput": 422.856, "update_time_ms": 8.204}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 25665731736.51064, "policy_loss": -0.0011669045730315624, "vf_loss": 25665731736.51064, "vf_explained_var": 8.877287172026627e-08, "kl": 0.009746081849679034, "entropy": 2.8388672788092433, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 954114833173.6124, "cur_lr": 5.000000000000002e-05, "total_loss": 19295993984283.234, "policy_loss": 0.28922486653987395, "vf_loss": 25759405034.212765, "vf_explained_var": -1.2174565711120522e-07, "kl": 20.196975910917242, "entropy": 40.31026345110954, "entropy_coeff": 0.0}}}, "num_steps_sampled": 588588, "num_agent_steps_sampled": 1177176, "num_steps_trained": 588588, "num_agent_steps_trained": 1177176}, "done": false, "episodes_total": 588, "training_iteration": 98, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-08-26", "timestamp": 1624921706, "time_this_iter_s": 17.780084371566772, "time_total_s": 1757.3640410900116, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d81400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d81ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1757.3640410900116, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 22.775000000000002, "ram_util_percent": 59.25416666666666, "gpu_util_percent0": 0.22333333333333338, "vram_util_percent0": 0.23153297382316596}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1791523.6319801318, "pol1": 1791523.6319801318}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-2159645.3799298913, -1795637.826943411, -2169876.011005258, -2119589.9170125914, -1844768.7255620556, -1936140.7772226392, -1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628, -1717889.9028287062, -1455210.2400659819, -1728768.3735779114, -1821071.8415966064, -1748875.439283877, -1674892.641699214, -1603287.0145049654, -1756752.9286290372, -1725168.6268670724, -1651533.8829267453, -1772582.5298482778, -1930277.8715118368, -1792316.2366229245, -1912283.162267295, -1712267.5815236224, -1695245.1230622584, -1741511.626579084, -1582041.290063559, -1591006.8263298108, -1761605.0276732743, -1746068.236191362, -1775393.7605579076, -1798095.381606987, -1807724.4629669867, -1722036.0536494327, -1830910.0662496747, -1860941.614020646, -1593700.0912625855, -1793395.1627983756, -1638981.299041708, -1455747.5420588085, -1871729.9852192216, -1897838.306342985, -1550877.0962284503, -1802165.3465439773, -1780899.255712338], "policy_pol1_reward": [2159645.3799298913, 1795637.826943411, 2169876.011005258, 2119589.9170125914, 1844768.7255620556, 1936140.7772226392, 1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628, 1717889.9028287062, 1455210.2400659819, 1728768.3735779114, 1821071.8415966064, 1748875.439283877, 1674892.641699214, 1603287.0145049654, 1756752.9286290372, 1725168.6268670724, 1651533.8829267453, 1772582.5298482778, 1930277.8715118368, 1792316.2366229245, 1912283.162267295, 1712267.5815236224, 1695245.1230622584, 1741511.626579084, 1582041.290063559, 1591006.8263298108, 1761605.0276732743, 1746068.236191362, 1775393.7605579076, 1798095.381606987, 1807724.4629669867, 1722036.0536494327, 1830910.0662496747, 1860941.614020646, 1593700.0912625855, 1793395.1627983756, 1638981.299041708, 1455747.5420588085, 1871729.9852192216, 1897838.306342985, 1550877.0962284503, 1802165.3465439773, 1780899.255712338]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2065083639492528, "mean_inference_ms": 2.879935383187748, "mean_action_processing_ms": 0.14664919937651333, "mean_env_wait_ms": 0.12076569425200662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 594594, "agent_timesteps_total": 1189188, "timers": {"sample_time_ms": 3507.332, "sample_throughput": 1712.413, "learn_time_ms": 14190.044, "learn_throughput": 423.255, "update_time_ms": 8.162}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 24871950466.723404, "policy_loss": -0.002150296114702174, "vf_loss": 24871950466.723404, "vf_explained_var": 8.243195281920634e-08, "kl": 0.011133620852327093, "entropy": 2.8087703877307, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1431172249760.4194, "cur_lr": 5.000000000000002e-05, "total_loss": 13523269156166.809, "policy_loss": 0.26589361118509414, "vf_loss": 24972776644.085106, "vf_explained_var": -1.1413655442993331e-07, "kl": 9.431636221865391, "entropy": 41.229177190902384, "entropy_coeff": 0.0}}}, "num_steps_sampled": 594594, "num_agent_steps_sampled": 1189188, "num_steps_trained": 594594, "num_agent_steps_trained": 1189188}, "done": false, "episodes_total": 594, "training_iteration": 99, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-08-44", "timestamp": 1624921724, "time_this_iter_s": 17.722885608673096, "time_total_s": 1775.0869266986847, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682d84b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682d84c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1775.0869266986847, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 23.434782608695652, "ram_util_percent": 59.34782608695652, "gpu_util_percent0": 0.22173913043478263, "vram_util_percent0": 0.23153969021555956}, "trial_id": "9e4f5_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -2197105.570418706, "pol1": 1429980.5707829115}, "policy_reward_max": {"pol0": -1429980.5707829115, "pol1": 2197105.570418706}, "policy_reward_mean": {"pol0": -1778742.6703735164, "pol1": 1778742.6703735164}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1627486.883921974, -1674476.3651720262, -1763920.3052345458, -1892260.3509966289, -1899001.4909822505, -1787224.562209097, -2197105.570418706, -2058910.1621852836, -2160442.6682611434, -1988152.5563698793, -1837605.2995921238, -1715128.3363007347, -1604760.2553392786, -1844463.2986182875, -1848976.8066700187, -1651504.1331456683, -2048883.563533039, -2161067.4767671307, -1867150.0189602687, -1661330.0926342546, -1951081.3533247537, -1940296.2778092416, -1891463.1258366054, -1816856.3194108566, -1822013.9779336476, -1911790.3537877249, -1638208.6344720153, -1915255.038695562, -1746906.9600625262, -1783528.3806851949, -1775068.9687979629, -1868004.4052088077, -1905474.459657163, -1794476.2185527363, -1635544.8449566036, -1429980.5707829115, -1615924.1569874235, -1520178.5629556084, -1664379.8895861234, -1744734.0076762978, -1760221.0064719054, -1845207.81266764, -1596923.1446217424, -1909948.3554812518, -1797331.1724959987, -1893179.7325069555, -1823333.524755502, -1830598.0654220255, -1714765.3023364935, -1802952.2980112727, -1837588.0594492787, -1611454.5530944446, -1698380.111472401, -1819530.9964330231, -1912894.592392014, -1728494.751507272, -1785832.4856754644, -1795960.0631370628, -1717889.9028287062, -1455210.2400659819, -1728768.3735779114, -1821071.8415966064, -1748875.439283877, -1674892.641699214, -1603287.0145049654, -1756752.9286290372, -1725168.6268670724, -1651533.8829267453, -1772582.5298482778, -1930277.8715118368, -1792316.2366229245, -1912283.162267295, -1712267.5815236224, -1695245.1230622584, -1741511.626579084, -1582041.290063559, -1591006.8263298108, -1761605.0276732743, -1746068.236191362, -1775393.7605579076, -1798095.381606987, -1807724.4629669867, -1722036.0536494327, -1830910.0662496747, -1860941.614020646, -1593700.0912625855, -1793395.1627983756, -1638981.299041708, -1455747.5420588085, -1871729.9852192216, -1897838.306342985, -1550877.0962284503, -1802165.3465439773, -1780899.255712338, -1507339.007634965, -1950075.6248783427, -1804778.8135513647, -1784901.9768662262, -1905671.585857513, -1794795.4682259096], "policy_pol1_reward": [1627486.883921974, 1674476.3651720262, 1763920.3052345458, 1892260.3509966289, 1899001.4909822505, 1787224.562209097, 2197105.570418706, 2058910.1621852836, 2160442.6682611434, 1988152.5563698793, 1837605.2995921238, 1715128.3363007347, 1604760.2553392786, 1844463.2986182875, 1848976.8066700187, 1651504.1331456683, 2048883.563533039, 2161067.4767671307, 1867150.0189602687, 1661330.0926342546, 1951081.3533247537, 1940296.2778092416, 1891463.1258366054, 1816856.3194108566, 1822013.9779336476, 1911790.3537877249, 1638208.6344720153, 1915255.038695562, 1746906.9600625262, 1783528.3806851949, 1775068.9687979629, 1868004.4052088077, 1905474.459657163, 1794476.2185527363, 1635544.8449566036, 1429980.5707829115, 1615924.1569874235, 1520178.5629556084, 1664379.8895861234, 1744734.0076762978, 1760221.0064719054, 1845207.81266764, 1596923.1446217424, 1909948.3554812518, 1797331.1724959987, 1893179.7325069555, 1823333.524755502, 1830598.0654220255, 1714765.3023364935, 1802952.2980112727, 1837588.0594492787, 1611454.5530944446, 1698380.111472401, 1819530.9964330231, 1912894.592392014, 1728494.751507272, 1785832.4856754644, 1795960.0631370628, 1717889.9028287062, 1455210.2400659819, 1728768.3735779114, 1821071.8415966064, 1748875.439283877, 1674892.641699214, 1603287.0145049654, 1756752.9286290372, 1725168.6268670724, 1651533.8829267453, 1772582.5298482778, 1930277.8715118368, 1792316.2366229245, 1912283.162267295, 1712267.5815236224, 1695245.1230622584, 1741511.626579084, 1582041.290063559, 1591006.8263298108, 1761605.0276732743, 1746068.236191362, 1775393.7605579076, 1798095.381606987, 1807724.4629669867, 1722036.0536494327, 1830910.0662496747, 1860941.614020646, 1593700.0912625855, 1793395.1627983756, 1638981.299041708, 1455747.5420588085, 1871729.9852192216, 1897838.306342985, 1550877.0962284503, 1802165.3465439773, 1780899.255712338, 1507339.007634965, 1950075.6248783427, 1804778.8135513647, 1784901.9768662262, 1905671.585857513, 1794795.4682259096]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20647276243236187, "mean_inference_ms": 2.87925483175587, "mean_action_processing_ms": 0.1466177553649396, "mean_env_wait_ms": 0.12073923798318181, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 600600, "agent_timesteps_total": 1201200, "timers": {"sample_time_ms": 3496.49, "sample_throughput": 1717.723, "learn_time_ms": 14233.817, "learn_throughput": 421.953, "update_time_ms": 6.417}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 27451372827.234043, "policy_loss": -0.0031657662797481456, "vf_loss": 27451372827.234043, "vf_explained_var": 0.0, "kl": 0.004391561757693899, "entropy": 2.8664658881248313, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2146758374640.6284, "cur_lr": 5.000000000000002e-05, "total_loss": 40481539857909.11, "policy_loss": 0.28308423465870797, "vf_loss": 27574257533.276596, "vf_explained_var": -1.3950023358688668e-08, "kl": 18.844209589856735, "entropy": 42.12721252441406, "entropy_coeff": 0.0}}}, "num_steps_sampled": 600600, "num_agent_steps_sampled": 1201200, "num_steps_trained": 600600, "num_agent_steps_trained": 1201200}, "done": false, "episodes_total": 600, "training_iteration": 100, "experiment_id": "13dbdef7e2f9491fbf921f84181f5445", "date": "2021-06-29_02-09-02", "timestamp": 1624921742, "time_this_iter_s": 18.012634754180908, "time_total_s": 1793.0995614528656, "pid": 12199, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f1682dcd1e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f1682dcd950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1793.0995614528656, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 23.40833333333333, "ram_util_percent": 59.4, "gpu_util_percent0": 0.21666666666666667, "vram_util_percent0": 0.23153297382316593}, "trial_id": "9e4f5_00000"}
