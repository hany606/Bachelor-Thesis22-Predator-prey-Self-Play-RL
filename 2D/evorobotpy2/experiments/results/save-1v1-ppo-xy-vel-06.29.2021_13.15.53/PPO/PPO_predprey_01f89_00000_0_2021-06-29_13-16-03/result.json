{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1611373.3713136497}, "policy_reward_max": {"pol0": -1611373.3713136497, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1801138.4266320225, "pol1": 1801138.4266320225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20129852745426705, "mean_inference_ms": 2.829607018453632, "mean_action_processing_ms": 0.1452065910090626, "mean_env_wait_ms": 0.11119280191397396, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 6006, "agent_timesteps_total": 12012, "timers": {"sample_time_ms": 3405.125, "sample_throughput": 1763.812, "learn_time_ms": 18241.806, "learn_throughput": 329.244, "update_time_ms": 5.602}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27523947323.914894, "policy_loss": -0.006400262411842321, "vf_loss": 27523947323.914894, "vf_explained_var": -1.0906381930908537e-07, "kl": 0.008275070921220679, "entropy": 2.825511206971838, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27523168256.0, "policy_loss": -0.0058954685649022145, "vf_loss": 27523168256.0, "vf_explained_var": 1.280865831176925e-07, "kl": 0.0066813083583528695, "entropy": 2.833007995118486, "entropy_coeff": 0.0}}}, "num_steps_sampled": 6006, "num_agent_steps_sampled": 12012, "num_steps_trained": 6006, "num_agent_steps_trained": 12012}, "done": false, "episodes_total": 6, "training_iteration": 1, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-16-53", "timestamp": 1624961813, "time_this_iter_s": 21.66004967689514, "time_total_s": 21.66004967689514, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eaca60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.66004967689514, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 26.351724137931036, "ram_util_percent": 64.78620689655172, "gpu_util_percent0": 0.38482758620689655, "vram_util_percent0": 0.3088281440675012}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1611373.3713136497}, "policy_reward_max": {"pol0": -1611373.3713136497, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1770489.9454943005, "pol1": 1770489.9454943005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21473934849883566, "mean_inference_ms": 2.9810235810191013, "mean_action_processing_ms": 0.1519569756731872, "mean_env_wait_ms": 0.11640834480535932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 12012, "agent_timesteps_total": 24024, "timers": {"sample_time_ms": 3742.0, "sample_throughput": 1605.024, "learn_time_ms": 18907.45, "learn_throughput": 317.653, "update_time_ms": 6.577}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25579160074.893616, "policy_loss": -0.005860293918150536, "vf_loss": 25579160074.893616, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.009168368556160243, "entropy": 2.8438190297877535, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25580522648.51064, "policy_loss": -0.003477355088800826, "vf_loss": 25580522648.51064, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.004574744709509801, "entropy": 2.77987639447476, "entropy_coeff": 0.0}}}, "num_steps_sampled": 12012, "num_agent_steps_sampled": 24024, "num_steps_trained": 12012, "num_agent_steps_trained": 24024}, "done": false, "episodes_total": 12, "training_iteration": 2, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-17-16", "timestamp": 1624961836, "time_this_iter_s": 23.670971870422363, "time_total_s": 45.331021547317505, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 45.331021547317505, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 31.625, "ram_util_percent": 65.396875, "gpu_util_percent0": 0.4021875, "vram_util_percent0": 0.30990373272665994}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1611373.3713136497}, "policy_reward_max": {"pol0": -1611373.3713136497, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1766049.4138125472, "pol1": 1766049.4138125472}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22398246748407796, "mean_inference_ms": 3.112183487212914, "mean_action_processing_ms": 0.15788813605000757, "mean_env_wait_ms": 0.12069835449943225, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 18018, "agent_timesteps_total": 36036, "timers": {"sample_time_ms": 4015.844, "sample_throughput": 1495.576, "learn_time_ms": 20132.316, "learn_throughput": 298.326, "update_time_ms": 6.16}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26064716211.744682, "policy_loss": 0.0011326138603877515, "vf_loss": 26064716211.744682, "vf_explained_var": 7.101829879729848e-08, "kl": 0.0299349687597219, "entropy": 2.9170659704411284, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26069682001.70213, "policy_loss": -0.0031485009958293845, "vf_loss": 26069682001.70213, "vf_explained_var": 3.119732525647123e-07, "kl": 0.006674260951261571, "entropy": 2.70827187883093, "entropy_coeff": 0.0}}}, "num_steps_sampled": 18018, "num_agent_steps_sampled": 36036, "num_steps_trained": 18018, "num_agent_steps_trained": 36036}, "done": false, "episodes_total": 18, "training_iteration": 3, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-17-44", "timestamp": 1624961864, "time_this_iter_s": 27.16013193130493, "time_total_s": 72.49115347862244, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e8d400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f062f6a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 72.49115347862244, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 38.808571428571426, "ram_util_percent": 67.19714285714286, "gpu_util_percent0": 0.5011428571428571, "vram_util_percent0": 0.3241561943280852}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1581690.284614844}, "policy_reward_max": {"pol0": -1581690.284614844, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1748783.2793037724, "pol1": 1748783.2793037724}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2318505411881712, "mean_inference_ms": 3.2199182504107964, "mean_action_processing_ms": 0.1627991839887978, "mean_env_wait_ms": 0.12409297779075755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 24024, "agent_timesteps_total": 48048, "timers": {"sample_time_ms": 4210.171, "sample_throughput": 1426.545, "learn_time_ms": 20093.278, "learn_throughput": 298.906, "update_time_ms": 5.796}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 24164295483.914894, "policy_loss": -0.0036061096619418326, "vf_loss": 24164295483.914894, "vf_explained_var": -6.340919611602658e-08, "kl": 0.005546386145610124, "entropy": 2.7814605337508183, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 24170697706.212765, "policy_loss": -0.0032415057710827666, "vf_loss": 24170697706.212765, "vf_explained_var": -2.029094225974859e-08, "kl": 0.007679943470878804, "entropy": 2.7780774755680815, "entropy_coeff": 0.0}}}, "num_steps_sampled": 24024, "num_agent_steps_sampled": 48048, "num_steps_trained": 24024, "num_agent_steps_trained": 48048}, "done": false, "episodes_total": 24, "training_iteration": 4, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-18-08", "timestamp": 1624961888, "time_this_iter_s": 24.782092809677124, "time_total_s": 97.27324628829956, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f061c400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f061c378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 97.27324628829956, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 34.27272727272728, "ram_util_percent": 66.45151515151515, "gpu_util_percent0": 0.4484848484848485, "vram_util_percent0": 0.31470927679218885}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1568249.1713454414}, "policy_reward_max": {"pol0": -1568249.1713454414, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1745501.8720446457, "pol1": 1745501.8720446457}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2368336802695744, "mean_inference_ms": 3.2857158593769222, "mean_action_processing_ms": 0.1658611768900731, "mean_env_wait_ms": 0.1262494489049186, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 30030, "agent_timesteps_total": 60060, "timers": {"sample_time_ms": 4226.011, "sample_throughput": 1421.198, "learn_time_ms": 20382.121, "learn_throughput": 294.67, "update_time_ms": 5.547}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25482879455.31915, "policy_loss": 0.0020068534253601064, "vf_loss": 25482879455.31915, "vf_explained_var": 9.257743016632958e-08, "kl": 0.016715439987626483, "entropy": 2.779527669257306, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 25493223380.425533, "policy_loss": -0.0046253144305120125, "vf_loss": 25493223380.425533, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.00645617044907301, "entropy": 2.8711861042266196, "entropy_coeff": 0.0}}}, "num_steps_sampled": 30030, "num_agent_steps_sampled": 60060, "num_steps_trained": 30030, "num_agent_steps_trained": 60060}, "done": false, "episodes_total": 30, "training_iteration": 5, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-18-34", "timestamp": 1624961914, "time_this_iter_s": 25.83892011642456, "time_total_s": 123.11216640472412, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f061cae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f061c9d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 123.11216640472412, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 33.397058823529406, "ram_util_percent": 66.4529411764706, "gpu_util_percent0": 0.5676470588235294, "vram_util_percent0": 0.3128432363845437}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1568249.1713454414}, "policy_reward_max": {"pol0": -1568249.1713454414, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1746264.4242152758, "pol1": 1746264.4242152758}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2402165069811629, "mean_inference_ms": 3.3304576578029867, "mean_action_processing_ms": 0.16794592125343202, "mean_env_wait_ms": 0.12777922905571937, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 36036, "agent_timesteps_total": 72072, "timers": {"sample_time_ms": 4230.655, "sample_throughput": 1419.638, "learn_time_ms": 20514.672, "learn_throughput": 292.766, "update_time_ms": 5.331}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25762722184.17021, "policy_loss": 0.004469255996035769, "vf_loss": 25762722184.17021, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.015307160332164865, "entropy": 2.8549389027534646, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 25775871477.106384, "policy_loss": -0.0029376755726147207, "vf_loss": 25775871477.106384, "vf_explained_var": 1.5598662628235616e-07, "kl": 0.007111118700196768, "entropy": 3.0325119647573917, "entropy_coeff": 0.0}}}, "num_steps_sampled": 36036, "num_agent_steps_sampled": 72072, "num_steps_trained": 36036, "num_agent_steps_trained": 72072}, "done": false, "episodes_total": 36, "training_iteration": 6, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-19-00", "timestamp": 1624961940, "time_this_iter_s": 25.44329071044922, "time_total_s": 148.55545711517334, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e356a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 148.55545711517334, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 32.14848484848485, "ram_util_percent": 66.84848484848484, "gpu_util_percent0": 0.5318181818181819, "vram_util_percent0": 0.31424967572591433}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1728605.7896406914, "pol1": 1728605.7896406914}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24295107068095032, "mean_inference_ms": 3.3637634440078803, "mean_action_processing_ms": 0.16951628100841434, "mean_env_wait_ms": 0.12894493753075167, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 42042, "agent_timesteps_total": 84084, "timers": {"sample_time_ms": 4246.353, "sample_throughput": 1414.39, "learn_time_ms": 20519.287, "learn_throughput": 292.7, "update_time_ms": 5.202}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 22647374259.744682, "policy_loss": -0.002843618056082979, "vf_loss": 22647374259.744682, "vf_explained_var": -1.4964570027586888e-07, "kl": 0.013948190699707954, "entropy": 2.8797659315961472, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 22663722267.234043, "policy_loss": -0.0037791115093104384, "vf_loss": 22663722267.234043, "vf_explained_var": 9.89183490673895e-08, "kl": 0.005926194699837807, "entropy": 2.7050146295669233, "entropy_coeff": 0.0}}}, "num_steps_sampled": 42042, "num_agent_steps_sampled": 84084, "num_steps_trained": 42042, "num_agent_steps_trained": 84084}, "done": false, "episodes_total": 42, "training_iteration": 7, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-19-25", "timestamp": 1624961965, "time_this_iter_s": 24.90036702156067, "time_total_s": 173.455824136734, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e351e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e357b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 173.455824136734, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 32.16060606060606, "ram_util_percent": 66.60606060606061, "gpu_util_percent0": 0.40818181818181815, "vram_util_percent0": 0.3136470876612434}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1732359.0533680515, "pol1": 1732359.0533680515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24509656956534384, "mean_inference_ms": 3.390205514925551, "mean_action_processing_ms": 0.17075679954836895, "mean_env_wait_ms": 0.1298816232215368, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 48048, "agent_timesteps_total": 96096, "timers": {"sample_time_ms": 4260.237, "sample_throughput": 1409.781, "learn_time_ms": 20536.405, "learn_throughput": 292.456, "update_time_ms": 5.138}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26291403972.085106, "policy_loss": 0.007668784581758874, "vf_loss": 26291403972.085106, "vf_explained_var": 1.6486390919112637e-08, "kl": 0.023159784918769875, "entropy": 2.920104559431685, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26310554732.93617, "policy_loss": -0.004088646355778613, "vf_loss": 26310554732.93617, "vf_explained_var": 8.370013659941833e-08, "kl": 0.007547696903744277, "entropy": 2.62834913679894, "entropy_coeff": 0.0}}}, "num_steps_sampled": 48048, "num_agent_steps_sampled": 96096, "num_steps_trained": 48048, "num_agent_steps_trained": 96096}, "done": false, "episodes_total": 48, "training_iteration": 8, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-19-50", "timestamp": 1624961990, "time_this_iter_s": 25.0265793800354, "time_total_s": 198.4824035167694, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06178c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06177b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 198.4824035167694, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 31.260606060606065, "ram_util_percent": 66.64545454545454, "gpu_util_percent0": 0.4087878787878788, "vram_util_percent0": 0.3136879410893566}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1734034.6821859346, "pol1": 1734034.6821859346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24691001753742442, "mean_inference_ms": 3.412509924858216, "mean_action_processing_ms": 0.17181251870537742, "mean_env_wait_ms": 0.13067931775754638, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 54054, "agent_timesteps_total": 108108, "timers": {"sample_time_ms": 4275.396, "sample_throughput": 1404.782, "learn_time_ms": 20539.379, "learn_throughput": 292.414, "update_time_ms": 5.119}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25865427292.595745, "policy_loss": 0.004477512606597961, "vf_loss": 25865427292.595745, "vf_explained_var": -1.1413655442993331e-07, "kl": 0.014458970285635045, "entropy": 2.7631886512675186, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 25888852316.595745, "policy_loss": -0.0033928597781886444, "vf_loss": 25888852316.595745, "vf_explained_var": 2.0417760993041156e-07, "kl": 0.008427200383169854, "entropy": 2.4930080657309674, "entropy_coeff": 0.0}}}, "num_steps_sampled": 54054, "num_agent_steps_sampled": 108108, "num_steps_trained": 54054, "num_agent_steps_trained": 108108}, "done": false, "episodes_total": 54, "training_iteration": 9, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-20-15", "timestamp": 1624962015, "time_this_iter_s": 24.97209644317627, "time_total_s": 223.45449995994568, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 223.45449995994568, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 30.875757575757575, "ram_util_percent": 66.96969696969697, "gpu_util_percent0": 0.41393939393939394, "vram_util_percent0": 0.31353474073393184}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1736800.2847329997, "pol1": 1736800.2847329997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24837953426683254, "mean_inference_ms": 3.4327099314158116, "mean_action_processing_ms": 0.17271580507459253, "mean_env_wait_ms": 0.131354492019308, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 60060, "agent_timesteps_total": 120120, "timers": {"sample_time_ms": 4302.523, "sample_throughput": 1395.925, "learn_time_ms": 20583.313, "learn_throughput": 291.79, "update_time_ms": 5.083}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26363024144.340427, "policy_loss": -0.0035266815387505167, "vf_loss": 26363024144.340427, "vf_explained_var": -1.775457469932462e-08, "kl": 0.01290958741323111, "entropy": 2.830298236075868, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26393673902.29787, "policy_loss": -0.0054276434189461644, "vf_loss": 26393673902.29787, "vf_explained_var": -6.340919789238342e-09, "kl": 0.00984577667166261, "entropy": 2.6166757218381194, "entropy_coeff": 0.0}}}, "num_steps_sampled": 60060, "num_agent_steps_sampled": 120120, "num_steps_trained": 60060, "num_agent_steps_trained": 120120}, "done": false, "episodes_total": 60, "training_iteration": 10, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-20-40", "timestamp": 1624962040, "time_this_iter_s": 25.538970470428467, "time_total_s": 248.99347043037415, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 248.99347043037415, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 31.19117647058823, "ram_util_percent": 66.89117647058822, "gpu_util_percent0": 0.4164705882352941, "vram_util_percent0": 0.3136065346259838}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1724135.4828014495, "pol1": 1724135.4828014495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24987437281943087, "mean_inference_ms": 3.452695341307431, "mean_action_processing_ms": 0.17362274696383592, "mean_env_wait_ms": 0.13203339015222068, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 66066, "agent_timesteps_total": 132132, "timers": {"sample_time_ms": 4442.647, "sample_throughput": 1351.897, "learn_time_ms": 20859.119, "learn_throughput": 287.932, "update_time_ms": 5.01}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 21436548509.957447, "policy_loss": -0.0007377976670544198, "vf_loss": 21436548509.957447, "vf_explained_var": 0.0, "kl": 0.015094483152348945, "entropy": 2.831447312172423, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 21460333807.659573, "policy_loss": -0.002312780536235647, "vf_loss": 21460333807.659573, "vf_explained_var": 1.1413655798264699e-08, "kl": 0.006082080591945572, "entropy": 2.7812648276065257, "entropy_coeff": 0.0}}}, "num_steps_sampled": 66066, "num_agent_steps_sampled": 132132, "num_steps_trained": 66066, "num_agent_steps_trained": 132132}, "done": false, "episodes_total": 66, "training_iteration": 11, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-21-06", "timestamp": 1624962066, "time_this_iter_s": 25.819069147109985, "time_total_s": 274.81253957748413, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c09d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c0400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 274.81253957748413, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 32.95294117647058, "ram_util_percent": 66.58235294117645, "gpu_util_percent0": 0.4008823529411764, "vram_util_percent0": 0.3135470568409366}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1728767.5582951335, "pol1": 1728767.5582951335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25128239060960705, "mean_inference_ms": 3.471043806371466, "mean_action_processing_ms": 0.17446485419317195, "mean_env_wait_ms": 0.13265722884104644, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 72072, "agent_timesteps_total": 144144, "timers": {"sample_time_ms": 4499.238, "sample_throughput": 1334.893, "learn_time_ms": 21001.866, "learn_throughput": 285.975, "update_time_ms": 4.729}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26759995522.723404, "policy_loss": 0.00538115825583326, "vf_loss": 26759995522.723404, "vf_explained_var": 0.0, "kl": 0.027864596350712978, "entropy": 2.810337056504919, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26795403176.851063, "policy_loss": -0.004593952340965575, "vf_loss": 26795403176.851063, "vf_explained_var": -1.242820246716292e-07, "kl": 0.009447729680687189, "entropy": 2.642748386301893, "entropy_coeff": 0.0}}}, "num_steps_sampled": 72072, "num_agent_steps_sampled": 144144, "num_steps_trained": 72072, "num_agent_steps_trained": 144144}, "done": false, "episodes_total": 72, "training_iteration": 12, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-21-32", "timestamp": 1624962092, "time_this_iter_s": 25.658385038375854, "time_total_s": 300.47092461586, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac2f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 300.47092461586, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 31.567647058823535, "ram_util_percent": 66.62941176470588, "gpu_util_percent0": 0.40882352941176464, "vram_util_percent0": 0.31357679573346026}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1730875.6874883233, "pol1": 1730875.6874883233}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2526282611514578, "mean_inference_ms": 3.4876394417153826, "mean_action_processing_ms": 0.1752323805642089, "mean_env_wait_ms": 0.13322244054263246, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 78078, "agent_timesteps_total": 156156, "timers": {"sample_time_ms": 4496.797, "sample_throughput": 1335.617, "learn_time_ms": 20780.251, "learn_throughput": 289.024, "update_time_ms": 4.719}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 26060889066.212765, "policy_loss": 0.0025993672774193136, "vf_loss": 26060889066.212765, "vf_explained_var": -1.2174565711120522e-07, "kl": 0.015390971814222793, "entropy": 2.7160517256310643, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26092735858.38298, "policy_loss": -0.002511056140065193, "vf_loss": 26092735858.38298, "vf_explained_var": 8.87728734966231e-09, "kl": 0.009076087428455023, "entropy": 2.6452193361647587, "entropy_coeff": 0.0}}}, "num_steps_sampled": 78078, "num_agent_steps_sampled": 156156, "num_steps_trained": 78078, "num_agent_steps_trained": 156156}, "done": false, "episodes_total": 78, "training_iteration": 13, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-21-57", "timestamp": 1624962117, "time_this_iter_s": 24.918434858322144, "time_total_s": 325.38935947418213, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eaca60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 325.38935947418213, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 30.363636363636363, "ram_util_percent": 66.77575757575757, "gpu_util_percent0": 0.38636363636363635, "vram_util_percent0": 0.31360623423313005}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934343.5582317212, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1934343.5582317212}, "policy_reward_mean": {"pol0": -1732119.863536593, "pol1": 1732119.863536593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25383908045848314, "mean_inference_ms": 3.502695639807239, "mean_action_processing_ms": 0.17593378282922587, "mean_env_wait_ms": 0.1337358425335399, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 84084, "agent_timesteps_total": 168168, "timers": {"sample_time_ms": 4485.73, "sample_throughput": 1338.912, "learn_time_ms": 20899.943, "learn_throughput": 287.369, "update_time_ms": 4.679}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25801037039.659573, "policy_loss": -0.0001977287193245076, "vf_loss": 25801037039.659573, "vf_explained_var": 1.4203659759459697e-07, "kl": 0.009577837574513668, "entropy": 2.814086523461849, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 25841142675.06383, "policy_loss": -0.004137060169051302, "vf_loss": 25841142675.06383, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.005933926866805934, "entropy": 2.8269640283381685, "entropy_coeff": 0.0}}}, "num_steps_sampled": 84084, "num_agent_steps_sampled": 168168, "num_steps_trained": 84084, "num_agent_steps_trained": 168168}, "done": false, "episodes_total": 84, "training_iteration": 14, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-22-23", "timestamp": 1624962143, "time_this_iter_s": 25.868953943252563, "time_total_s": 351.2583134174347, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 351.2583134174347, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 31.13823529411765, "ram_util_percent": 66.77352941176471, "gpu_util_percent0": 0.4076470588235294, "vram_util_percent0": 0.3135321873946747}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1734924.9255519924, "pol1": 1734924.9255519924}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2548676237445408, "mean_inference_ms": 3.515881279699996, "mean_action_processing_ms": 0.17655293661554972, "mean_env_wait_ms": 0.13418448166364025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 90090, "agent_timesteps_total": 180180, "timers": {"sample_time_ms": 4509.052, "sample_throughput": 1331.987, "learn_time_ms": 20809.484, "learn_throughput": 288.618, "update_time_ms": 4.717}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 26544925543.48936, "policy_loss": 0.0008718838637813608, "vf_loss": 26544925543.48936, "vf_explained_var": 1.154047382101453e-07, "kl": 0.017151372804445154, "entropy": 2.767253140185742, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26588020779.574467, "policy_loss": -0.005221852101385593, "vf_loss": 26588020779.574467, "vf_explained_var": 8.116376903899436e-08, "kl": 0.007277426082006795, "entropy": 2.65125287847316, "entropy_coeff": 0.0}}}, "num_steps_sampled": 90090, "num_agent_steps_sampled": 180180, "num_steps_trained": 90090, "num_agent_steps_trained": 180180}, "done": false, "episodes_total": 90, "training_iteration": 15, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-22-48", "timestamp": 1624962168, "time_this_iter_s": 25.16867995262146, "time_total_s": 376.42699337005615, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06178c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 376.42699337005615, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 30.015151515151516, "ram_util_percent": 66.95454545454545, "gpu_util_percent0": 0.4063636363636363, "vram_util_percent0": 0.31324366005862464}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1733810.3917783014, "pol1": 1733810.3917783014}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684888.5841349072, -1611373.3713136497, -1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602], "policy_pol1_reward": [1684888.5841349072, 1611373.3713136497, 1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2557541971851327, "mean_inference_ms": 3.527126040489435, "mean_action_processing_ms": 0.17708243366445445, "mean_env_wait_ms": 0.13456699016138976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 96096, "agent_timesteps_total": 192192, "timers": {"sample_time_ms": 4517.475, "sample_throughput": 1329.504, "learn_time_ms": 20750.425, "learn_throughput": 289.44, "update_time_ms": 4.771}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 24737738359.82979, "policy_loss": -0.0008636061894766828, "vf_loss": 24737738359.82979, "vf_explained_var": -9.89183490673895e-08, "kl": 0.02216655673815849, "entropy": 2.759184198176607, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 24784920750.29787, "policy_loss": -0.0045855397834105695, "vf_loss": 24784920750.29787, "vf_explained_var": 1.1794110577056927e-07, "kl": 0.008030972393982589, "entropy": 2.4458516404983843, "entropy_coeff": 0.0}}}, "num_steps_sampled": 96096, "num_agent_steps_sampled": 192192, "num_steps_trained": 96096, "num_agent_steps_trained": 192192}, "done": false, "episodes_total": 96, "training_iteration": 16, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-23-13", "timestamp": 1624962193, "time_this_iter_s": 24.93807291984558, "time_total_s": 401.36506628990173, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 401.36506628990173, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 29.83030303030303, "ram_util_percent": 66.88484848484848, "gpu_util_percent0": 0.3951515151515152, "vram_util_percent0": 0.3128249124204635}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1735789.108923015, "pol1": 1735789.108923015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1934343.5582317212, -1908465.184343203, -1765750.2328408677, -1902009.6289277866, -1698049.1137155998, -1844002.6497445626, -1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647], "policy_pol1_reward": [1934343.5582317212, 1908465.184343203, 1765750.2328408677, 1902009.6289277866, 1698049.1137155998, 1844002.6497445626, 1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25758252545007887, "mean_inference_ms": 3.552411280378718, "mean_action_processing_ms": 0.17825321737449218, "mean_env_wait_ms": 0.13540658391666716, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 102102, "agent_timesteps_total": 204204, "timers": {"sample_time_ms": 4528.644, "sample_throughput": 1326.225, "learn_time_ms": 20749.534, "learn_throughput": 289.452, "update_time_ms": 4.79}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 25499839684.085106, "policy_loss": 0.004078736092816008, "vf_loss": 25499839684.085106, "vf_explained_var": -1.4076842091981234e-07, "kl": 0.019317144607292846, "entropy": 2.77827857403045, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 25547146436.085106, "policy_loss": -0.005108739744792593, "vf_loss": 25547146436.085106, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.008755911508218405, "entropy": 2.556018646727217, "entropy_coeff": 0.0}}}, "num_steps_sampled": 102102, "num_agent_steps_sampled": 204204, "num_steps_trained": 102102, "num_agent_steps_trained": 204204}, "done": false, "episodes_total": 102, "training_iteration": 17, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-23-38", "timestamp": 1624962218, "time_this_iter_s": 25.00254487991333, "time_total_s": 426.36761116981506, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 426.36761116981506, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 30.800000000000004, "ram_util_percent": 66.62121212121212, "gpu_util_percent0": 0.3842424242424242, "vram_util_percent0": 0.3129015125981759}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1729243.2046045226, "pol1": 1729243.2046045226}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1854562.1608285839, -1669547.0381953102, -1663918.4706078751, -1708969.3530475367, -1850523.0721335749, -1780715.5695730061, -1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256], "policy_pol1_reward": [1854562.1608285839, 1669547.0381953102, 1663918.4706078751, 1708969.3530475367, 1850523.0721335749, 1780715.5695730061, 1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2611810921808504, "mean_inference_ms": 3.5972838041887005, "mean_action_processing_ms": 0.18030531303207367, "mean_env_wait_ms": 0.13692029776823234, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 108108, "agent_timesteps_total": 216216, "timers": {"sample_time_ms": 4529.995, "sample_throughput": 1325.829, "learn_time_ms": 20716.77, "learn_throughput": 289.91, "update_time_ms": 5.051}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 25378265959.48936, "policy_loss": -0.004172334566395333, "vf_loss": 25378265959.48936, "vf_explained_var": 1.775457469932462e-08, "kl": 0.0038461564108729362, "entropy": 2.7716314640450985, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 25428956573.957447, "policy_loss": -0.004529802643872322, "vf_loss": 25428956573.957447, "vf_explained_var": 1.2555021555726853e-07, "kl": 0.005145511124283075, "entropy": 2.5517647012751152, "entropy_coeff": 0.0}}}, "num_steps_sampled": 108108, "num_agent_steps_sampled": 216216, "num_steps_trained": 108108, "num_agent_steps_trained": 216216}, "done": false, "episodes_total": 108, "training_iteration": 18, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-24-03", "timestamp": 1624962243, "time_this_iter_s": 24.71452569961548, "time_total_s": 451.08213686943054, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06178c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 451.08213686943054, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 29.64242424242424, "ram_util_percent": 66.76060606060605, "gpu_util_percent0": 0.37818181818181823, "vram_util_percent0": 0.31040434680475126}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1729653.633167134, "pol1": 1729653.633167134}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1819459.7744161729, -1667292.492975829, -1630435.9994743897, -1794583.1941212753, -1659018.037644544, -1628000.230855028, -1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327], "policy_pol1_reward": [1819459.7744161729, 1667292.492975829, 1630435.9994743897, 1794583.1941212753, 1659018.037644544, 1628000.230855028, 1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2633707939691769, "mean_inference_ms": 3.6261131138925884, "mean_action_processing_ms": 0.1816674899124721, "mean_env_wait_ms": 0.13789631094447072, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 114114, "agent_timesteps_total": 228228, "timers": {"sample_time_ms": 4537.454, "sample_throughput": 1323.65, "learn_time_ms": 20925.119, "learn_throughput": 287.023, "update_time_ms": 5.057}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26221621901.61702, "policy_loss": -0.003445093519985676, "vf_loss": 26221621901.61702, "vf_explained_var": -1.2555021555726853e-07, "kl": 0.011135907566293757, "entropy": 2.803608184165143, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26281444068.765957, "policy_loss": -0.005117724362285214, "vf_loss": 26281444068.765957, "vf_explained_var": 1.5471843539671681e-07, "kl": 0.008941101524582568, "entropy": 2.594164599763586, "entropy_coeff": 0.0}}}, "num_steps_sampled": 114114, "num_agent_steps_sampled": 228228, "num_steps_trained": 114114, "num_agent_steps_trained": 228228}, "done": false, "episodes_total": 114, "training_iteration": 19, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-24-30", "timestamp": 1624962270, "time_this_iter_s": 27.1306095123291, "time_total_s": 478.21274638175964, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0617598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 478.21274638175964, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 31.100000000000005, "ram_util_percent": 66.55999999999999, "gpu_util_percent0": 0.36571428571428566, "vram_util_percent0": 0.3074245269391882}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1726669.2266006724, "pol1": 1726669.2266006724}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1722576.4426417602, -1688209.7083724788, -1902414.5505360283, -1581690.284614844, -1655739.9985299981, -1799796.6867638617, -1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122], "policy_pol1_reward": [1722576.4426417602, 1688209.7083724788, 1902414.5505360283, 1581690.284614844, 1655739.9985299981, 1799796.6867638617, 1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26454770610565237, "mean_inference_ms": 3.6414898393882464, "mean_action_processing_ms": 0.18241490056575785, "mean_env_wait_ms": 0.1384523054064214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 120120, "agent_timesteps_total": 240240, "timers": {"sample_time_ms": 4517.752, "sample_throughput": 1329.422, "learn_time_ms": 20861.4, "learn_throughput": 287.9, "update_time_ms": 5.05}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 23052718341.446808, "policy_loss": -0.0013620792095489958, "vf_loss": 23052718341.446808, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.011894453376373078, "entropy": 2.805566630464919, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 23104546946.723404, "policy_loss": -0.004395292001835843, "vf_loss": 23104546946.723404, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.007690609868695127, "entropy": 2.671845182459405, "entropy_coeff": 0.0}}}, "num_steps_sampled": 120120, "num_agent_steps_sampled": 240240, "num_steps_trained": 120120, "num_agent_steps_trained": 240240}, "done": false, "episodes_total": 120, "training_iteration": 20, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-24-55", "timestamp": 1624962295, "time_this_iter_s": 24.703561067581177, "time_total_s": 502.9163074493408, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c0730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c0950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 502.9163074493408, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 29.65151515151515, "ram_util_percent": 66.6878787878788, "gpu_util_percent0": 0.3787878787878788, "vram_util_percent0": 0.3072535261615141}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1723358.0845189646, "pol1": 1723358.0845189646}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1703066.5758915779, -1757612.9410755, -1568249.1713454414, -1909792.0844424528, -1898185.0685084753, -1809039.7420443897, -1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266], "policy_pol1_reward": [1703066.5758915779, 1757612.9410755, 1568249.1713454414, 1909792.0844424528, 1898185.0685084753, 1809039.7420443897, 1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2653811775971895, "mean_inference_ms": 3.6496651789199, "mean_action_processing_ms": 0.18281365725357224, "mean_env_wait_ms": 0.13879129453476113, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 126126, "agent_timesteps_total": 252252, "timers": {"sample_time_ms": 4478.477, "sample_throughput": 1341.081, "learn_time_ms": 20827.821, "learn_throughput": 288.364, "update_time_ms": 5.049}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 23777381920.68085, "policy_loss": -0.002941366641762409, "vf_loss": 23777381920.68085, "vf_explained_var": -4.058188451949718e-08, "kl": 0.005681419844164494, "entropy": 2.7733226735541163, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 23836537659.914894, "policy_loss": -0.003845778690215121, "vf_loss": 23836537659.914894, "vf_explained_var": 1.2174565711120522e-07, "kl": 0.006019160191112376, "entropy": 2.956944506219093, "entropy_coeff": 0.0}}}, "num_steps_sampled": 126126, "num_agent_steps_sampled": 252252, "num_steps_trained": 126126, "num_agent_steps_trained": 252252}, "done": false, "episodes_total": 126, "training_iteration": 21, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-25-20", "timestamp": 1624962320, "time_this_iter_s": 25.090396881103516, "time_total_s": 528.0067043304443, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 528.0067043304443, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 31.196969696969695, "ram_util_percent": 66.45151515151514, "gpu_util_percent0": 0.3818181818181818, "vram_util_percent0": 0.30718713934083003}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946052.0461867326, "pol1": 1115223.488742501}, "policy_reward_max": {"pol0": -1115223.488742501, "pol1": 1946052.0461867326}, "policy_reward_mean": {"pol0": -1721581.633583431, "pol1": 1721581.633583431}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1769675.1667552576, -1571129.6172722664, -1657267.248652524, -1795166.2671776453, -1115223.488742501, -1883778.542597361, -1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825], "policy_pol1_reward": [1769675.1667552576, 1571129.6172722664, 1657267.248652524, 1795166.2671776453, 1115223.488742501, 1883778.542597361, 1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2660894425006492, "mean_inference_ms": 3.6580419486900255, "mean_action_processing_ms": 0.18320097228191265, "mean_env_wait_ms": 0.1391098427417976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 132132, "agent_timesteps_total": 264264, "timers": {"sample_time_ms": 4466.487, "sample_throughput": 1344.681, "learn_time_ms": 20788.262, "learn_throughput": 288.913, "update_time_ms": 5.019}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 25576380633.87234, "policy_loss": 0.005059964776514692, "vf_loss": 25576380633.87234, "vf_explained_var": -2.029094225974859e-08, "kl": 0.016470405768523825, "entropy": 2.691870664028411, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 25638766679.148937, "policy_loss": -0.00207574079011349, "vf_loss": 25638766679.148937, "vf_explained_var": -3.804551784725163e-09, "kl": 0.0046942009233889425, "entropy": 2.861740989887968, "entropy_coeff": 0.0}}}, "num_steps_sampled": 132132, "num_agent_steps_sampled": 264264, "num_steps_trained": 132132, "num_agent_steps_trained": 264264}, "done": false, "episodes_total": 132, "training_iteration": 22, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-25-45", "timestamp": 1624962345, "time_this_iter_s": 25.142046689987183, "time_total_s": 553.1487510204315, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e350d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 553.1487510204315, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 31.306060606060605, "ram_util_percent": 66.46969696969695, "gpu_util_percent0": 0.3809090909090909, "vram_util_percent0": 0.30737608644585385}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956733.045137202, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956733.045137202}, "policy_reward_mean": {"pol0": -1735178.7407170637, "pol1": 1735178.7407170637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1809957.5047556101, -1630118.3368870413, -1596590.2208788728, -1700255.7992977253, -1902426.3368831328, -1724065.4325641105, -1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762], "policy_pol1_reward": [1809957.5047556101, 1630118.3368870413, 1596590.2208788728, 1700255.7992977253, 1902426.3368831328, 1724065.4325641105, 1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26682841322585504, "mean_inference_ms": 3.6659742664654438, "mean_action_processing_ms": 0.1835649687884625, "mean_env_wait_ms": 0.13938999058201212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 138138, "agent_timesteps_total": 276276, "timers": {"sample_time_ms": 4456.839, "sample_throughput": 1347.592, "learn_time_ms": 20839.456, "learn_throughput": 288.203, "update_time_ms": 4.981}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 29176975316.425533, "policy_loss": -0.0020649717684755936, "vf_loss": 29176975316.425533, "vf_explained_var": -4.058188451949718e-08, "kl": 0.007228837814182043, "entropy": 2.6040779022460288, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 29248721462.468086, "policy_loss": -0.004316341151740957, "vf_loss": 29248721462.468086, "vf_explained_var": -6.340919789238342e-09, "kl": 0.010002701820686776, "entropy": 2.8102693659193974, "entropy_coeff": 0.0}}}, "num_steps_sampled": 138138, "num_agent_steps_sampled": 276276, "num_steps_trained": 138138, "num_agent_steps_trained": 276276}, "done": false, "episodes_total": 138, "training_iteration": 23, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-26-10", "timestamp": 1624962370, "time_this_iter_s": 25.33293914794922, "time_total_s": 578.4816901683807, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac9d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 578.4816901683807, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 31.77575757575758, "ram_util_percent": 66.45454545454544, "gpu_util_percent0": 0.37939393939393945, "vram_util_percent0": 0.3072688461970565}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956733.045137202, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956733.045137202}, "policy_reward_mean": {"pol0": -1738857.4335290522, "pol1": 1738857.4335290522}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1772645.2213944097, -1843285.4078788357, -1479662.964225377, -1829706.0338115757, -1780799.756659874, -1825835.3734745635, -1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193], "policy_pol1_reward": [1772645.2213944097, 1843285.4078788357, 1479662.964225377, 1829706.0338115757, 1780799.756659874, 1825835.3734745635, 1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26737188827559366, "mean_inference_ms": 3.6735794745642276, "mean_action_processing_ms": 0.18391367950040802, "mean_env_wait_ms": 0.13965445444169464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 144144, "agent_timesteps_total": 288288, "timers": {"sample_time_ms": 4435.893, "sample_throughput": 1353.955, "learn_time_ms": 20783.129, "learn_throughput": 288.984, "update_time_ms": 4.996}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26843486861.61702, "policy_loss": -0.0031687955748527607, "vf_loss": 26843486861.61702, "vf_explained_var": -1.0779563552887339e-07, "kl": 0.01372723249678916, "entropy": 2.691755589018477, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26917130457.87234, "policy_loss": -0.0020012703942174606, "vf_loss": 26917130457.87234, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.0066459268390973835, "entropy": 2.6583040673682032, "entropy_coeff": 0.0}}}, "num_steps_sampled": 144144, "num_agent_steps_sampled": 288288, "num_steps_trained": 144144, "num_agent_steps_trained": 288288}, "done": false, "episodes_total": 144, "training_iteration": 24, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-26-35", "timestamp": 1624962395, "time_this_iter_s": 25.09603238105774, "time_total_s": 603.5777225494385, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7aedcc3730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eaca60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 603.5777225494385, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 30.772727272727277, "ram_util_percent": 66.54848484848485, "gpu_util_percent0": 0.38303030303030305, "vram_util_percent0": 0.3073454463747689}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1741223.3140352226, "pol1": 1741223.3140352226}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1868731.500145267, -1783383.9201659828, -1714927.798637866, -1510959.9272904305, -1754729.4092537207, -1843412.7741907164, -1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597], "policy_pol1_reward": [1868731.500145267, 1783383.9201659828, 1714927.798637866, 1510959.9272904305, 1754729.4092537207, 1843412.7741907164, 1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2678665800066201, "mean_inference_ms": 3.6803416285667057, "mean_action_processing_ms": 0.18422390237449332, "mean_env_wait_ms": 0.13988292645270994, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 150150, "agent_timesteps_total": 300300, "timers": {"sample_time_ms": 4415.155, "sample_throughput": 1360.315, "learn_time_ms": 20783.981, "learn_throughput": 288.973, "update_time_ms": 5.061}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 27290318586.553192, "policy_loss": 0.011016935129907536, "vf_loss": 27290318586.553192, "vf_explained_var": 1.1160018686950934e-07, "kl": 0.031455319612584215, "entropy": 2.7729028843818826, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 27361386583.148937, "policy_loss": -0.0034144787870823068, "vf_loss": 27361386583.148937, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.008714084028008771, "entropy": 2.688378886973604, "entropy_coeff": 0.0}}}, "num_steps_sampled": 150150, "num_agent_steps_sampled": 300300, "num_steps_trained": 150150, "num_agent_steps_trained": 300300}, "done": false, "episodes_total": 150, "training_iteration": 25, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-27-00", "timestamp": 1624962420, "time_this_iter_s": 24.969507455825806, "time_total_s": 628.5472300052643, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 628.5472300052643, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 30.045454545454547, "ram_util_percent": 66.75757575757575, "gpu_util_percent0": 0.3784848484848485, "vram_util_percent0": 0.3073045929466557}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1740275.5341570072, "pol1": 1740275.5341570072}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1665714.4453321667, -1863434.585903526, -1866480.5001045424, -1576372.5311548195, -1626174.1677658467, -1424430.7793738898, -1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356], "policy_pol1_reward": [1665714.4453321667, 1863434.585903526, 1866480.5001045424, 1576372.5311548195, 1626174.1677658467, 1424430.7793738898, 1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26832963057326714, "mean_inference_ms": 3.686509205570415, "mean_action_processing_ms": 0.1845118641171847, "mean_env_wait_ms": 0.1400918637525888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 156156, "agent_timesteps_total": 312312, "timers": {"sample_time_ms": 4441.574, "sample_throughput": 1352.223, "learn_time_ms": 20806.267, "learn_throughput": 288.663, "update_time_ms": 5.034}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25283622301.957447, "policy_loss": -0.0018578514337856719, "vf_loss": 25283622301.957447, "vf_explained_var": 7.101829879729848e-08, "kl": 0.005286380658520663, "entropy": 2.880813410941591, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25356973905.70213, "policy_loss": -0.005139120913883473, "vf_loss": 25356973905.70213, "vf_explained_var": 1.3442749491332506e-07, "kl": 0.012406627726840211, "entropy": 2.6606565384154623, "entropy_coeff": 0.0}}}, "num_steps_sampled": 156156, "num_agent_steps_sampled": 312312, "num_steps_trained": 156156, "num_agent_steps_trained": 312312}, "done": false, "episodes_total": 156, "training_iteration": 26, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-27-26", "timestamp": 1624962446, "time_this_iter_s": 25.425289154052734, "time_total_s": 653.972519159317, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 653.972519159317, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 31.726470588235287, "ram_util_percent": 66.62058823529412, "gpu_util_percent0": 0.3764705882352941, "vram_util_percent0": 0.3072820634826226}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1745062.5313653734, "pol1": 1745062.5313653734}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1865610.2020196198, -1522617.3447664944, -1682644.3016582257, -1463447.9853316355, -1680386.0941259095, -1913366.0227404379, -1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873], "policy_pol1_reward": [1865610.2020196198, 1522617.3447664944, 1682644.3016582257, 1463447.9853316355, 1680386.0941259095, 1913366.0227404379, 1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2687468525834526, "mean_inference_ms": 3.6910456695882683, "mean_action_processing_ms": 0.18474055701125322, "mean_env_wait_ms": 0.14026133826722334, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 162162, "agent_timesteps_total": 324324, "timers": {"sample_time_ms": 4444.179, "sample_throughput": 1351.431, "learn_time_ms": 20823.509, "learn_throughput": 288.424, "update_time_ms": 5.067}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25978225903.659573, "policy_loss": -0.004171019618181472, "vf_loss": 25978225903.659573, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.008075483232498803, "entropy": 2.9021572711619923, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26054298427.914894, "policy_loss": -0.0050318230419082845, "vf_loss": 26054298427.914894, "vf_explained_var": 7.609103569450326e-09, "kl": 0.009402074801557242, "entropy": 2.5699834113425397, "entropy_coeff": 0.0}}}, "num_steps_sampled": 162162, "num_agent_steps_sampled": 324324, "num_steps_trained": 162162, "num_agent_steps_trained": 324324}, "done": false, "episodes_total": 162, "training_iteration": 27, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-27-51", "timestamp": 1624962471, "time_this_iter_s": 25.202841758728027, "time_total_s": 679.175360918045, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 679.175360918045, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 31.084848484848482, "ram_util_percent": 66.60606060606061, "gpu_util_percent0": 0.3827272727272727, "vram_util_percent0": 0.30737097976733974}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1748197.4762078961, "pol1": 1748197.4762078961}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1742155.6495837395, -1699803.3683401123, -1832884.1708184632, -1809727.026745276, -1770047.2077981692, -1924119.203358608, -1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062], "policy_pol1_reward": [1742155.6495837395, 1699803.3683401123, 1832884.1708184632, 1809727.026745276, 1770047.2077981692, 1924119.203358608, 1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26896696681624244, "mean_inference_ms": 3.693850046648978, "mean_action_processing_ms": 0.18488103343144072, "mean_env_wait_ms": 0.1403715063030054, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 168168, "agent_timesteps_total": 336336, "timers": {"sample_time_ms": 4447.871, "sample_throughput": 1350.309, "learn_time_ms": 20835.628, "learn_throughput": 288.256, "update_time_ms": 4.764}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25563955505.02128, "policy_loss": -0.0015656889436092781, "vf_loss": 25563955505.02128, "vf_explained_var": -1.2935475979247713e-07, "kl": 0.0043420604469769815, "entropy": 2.9317898445941033, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25644487788.93617, "policy_loss": -0.0018850761525174404, "vf_loss": 25644487788.93617, "vf_explained_var": 1.775457469932462e-08, "kl": 0.006105513232661054, "entropy": 2.6673909552553865, "entropy_coeff": 0.0}}}, "num_steps_sampled": 168168, "num_agent_steps_sampled": 336336, "num_steps_trained": 168168, "num_agent_steps_trained": 336336}, "done": false, "episodes_total": 168, "training_iteration": 28, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-28-16", "timestamp": 1624962496, "time_this_iter_s": 24.870279550552368, "time_total_s": 704.0456404685974, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06172f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0617950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 704.0456404685974, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 29.915151515151514, "ram_util_percent": 66.76969696969697, "gpu_util_percent0": 0.3763636363636364, "vram_util_percent0": 0.3072688461970565}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1743999.2345047914, "pol1": 1743999.2345047914}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1757406.0574312273, -1773171.0940689677, -1839145.036187427, -1473150.827995204, -1734596.5988197466, -1856014.1374942588, -1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664], "policy_pol1_reward": [1757406.0574312273, 1773171.0940689677, 1839145.036187427, 1473150.827995204, 1734596.5988197466, 1856014.1374942588, 1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26913973770810484, "mean_inference_ms": 3.695622430191544, "mean_action_processing_ms": 0.1849752356257177, "mean_env_wait_ms": 0.14044824387487684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 174174, "agent_timesteps_total": 348348, "timers": {"sample_time_ms": 4453.862, "sample_throughput": 1348.493, "learn_time_ms": 20639.239, "learn_throughput": 290.999, "update_time_ms": 4.74}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25092284808.17021, "policy_loss": 0.0005604420055417305, "vf_loss": 25092284808.17021, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.009353631394023591, "entropy": 2.8546707985248974, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25174223850.212765, "policy_loss": -0.004341859093054812, "vf_loss": 25174223850.212765, "vf_explained_var": 8.87728734966231e-09, "kl": 0.0075443368107873075, "entropy": 2.8210982160365328, "entropy_coeff": 0.0}}}, "num_steps_sampled": 174174, "num_agent_steps_sampled": 348348, "num_steps_trained": 174174, "num_agent_steps_trained": 348348}, "done": false, "episodes_total": 174, "training_iteration": 29, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-28-41", "timestamp": 1624962521, "time_this_iter_s": 25.22684645652771, "time_total_s": 729.2724869251251, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05e3488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05e3378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 729.2724869251251, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 31.59090909090909, "ram_util_percent": 66.53333333333332, "gpu_util_percent0": 0.38515151515151513, "vram_util_percent0": 0.3073862998028822}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1746346.109776503, "pol1": 1746346.109776503}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1808618.9838289511, -1722306.8036697758, -1814296.4786321814, -1553931.9105396536, -1679174.2694343547, -1754777.6794528402, -1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261], "policy_pol1_reward": [1808618.9838289511, 1722306.8036697758, 1814296.4786321814, 1553931.9105396536, 1679174.2694343547, 1754777.6794528402, 1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26921387801616203, "mean_inference_ms": 3.696895836900527, "mean_action_processing_ms": 0.18504523380308274, "mean_env_wait_ms": 0.1405064668225343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 180180, "agent_timesteps_total": 360360, "timers": {"sample_time_ms": 4471.0, "sample_throughput": 1343.324, "learn_time_ms": 20686.185, "learn_throughput": 290.339, "update_time_ms": 4.7}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26409804560.340427, "policy_loss": 0.001538046714948847, "vf_loss": 26409804560.340427, "vf_explained_var": -4.311825207992115e-08, "kl": 0.018071486198521676, "entropy": 2.8972297272783645, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26494416068.085106, "policy_loss": -0.0062224250683125025, "vf_loss": 26494416068.085106, "vf_explained_var": 7.862740147857039e-08, "kl": 0.010059058428444762, "entropy": 2.8918352380711982, "entropy_coeff": 0.0}}}, "num_steps_sampled": 180180, "num_agent_steps_sampled": 360360, "num_steps_trained": 180180, "num_agent_steps_trained": 360360}, "done": false, "episodes_total": 180, "training_iteration": 30, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-29-07", "timestamp": 1624962547, "time_this_iter_s": 25.344820261001587, "time_total_s": 754.6173071861267, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05e3ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05e3f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 754.6173071861267, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 31.11764705882353, "ram_util_percent": 66.75294117647059, "gpu_util_percent0": 0.38117647058823534, "vram_util_percent0": 0.30460060667340744}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1747399.343289043, "pol1": 1747399.343289043}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1827900.8878226127, -1744065.8346038787, -1946052.0461867326, -1693204.0451050724, -1640539.9146310946, -1742517.3094856916, -1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416], "policy_pol1_reward": [1827900.8878226127, 1744065.8346038787, 1946052.0461867326, 1693204.0451050724, 1640539.9146310946, 1742517.3094856916, 1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26928250452981684, "mean_inference_ms": 3.697617369301948, "mean_action_processing_ms": 0.1850890380637807, "mean_env_wait_ms": 0.14055009042183905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 186186, "agent_timesteps_total": 372372, "timers": {"sample_time_ms": 4478.156, "sample_throughput": 1341.177, "learn_time_ms": 20693.151, "learn_throughput": 290.241, "update_time_ms": 4.684}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25607031699.06383, "policy_loss": 0.0002849877593999213, "vf_loss": 25607031699.06383, "vf_explained_var": -3.9313700739285196e-08, "kl": 0.019225735455117327, "entropy": 2.8686771088458123, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25697814615.148937, "policy_loss": -0.006022088388179211, "vf_loss": 25697814615.148937, "vf_explained_var": -1.1033200308929736e-07, "kl": 0.011063779506119007, "entropy": 2.8555277459164885, "entropy_coeff": 0.0}}}, "num_steps_sampled": 186186, "num_agent_steps_sampled": 372372, "num_steps_trained": 186186, "num_agent_steps_trained": 372372}, "done": false, "episodes_total": 186, "training_iteration": 31, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-29-32", "timestamp": 1624962572, "time_this_iter_s": 25.233336448669434, "time_total_s": 779.8506436347961, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06172f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 779.8506436347961, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 31.069696969696967, "ram_util_percent": 66.86060606060606, "gpu_util_percent0": 0.38363636363636366, "vram_util_percent0": 0.30662029802575813}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1747970.702861695, "pol1": 1747970.702861695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1656440.4674942482, -1845803.4697881716, -1788674.6622718456, -1628578.487366602, -1708896.4218414763, -1827950.4511740657, -1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331], "policy_pol1_reward": [1656440.4674942482, 1845803.4697881716, 1788674.6622718456, 1628578.487366602, 1708896.4218414763, 1827950.4511740657, 1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26939206074316147, "mean_inference_ms": 3.698525481212729, "mean_action_processing_ms": 0.1851363755846198, "mean_env_wait_ms": 0.1405978365752183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 192192, "agent_timesteps_total": 384384, "timers": {"sample_time_ms": 4472.177, "sample_throughput": 1342.97, "learn_time_ms": 20708.98, "learn_throughput": 290.019, "update_time_ms": 4.761}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26492036989.276596, "policy_loss": -0.0018274244911810184, "vf_loss": 26492036989.276596, "vf_explained_var": -1.9022758479536606e-08, "kl": 0.009420285417519986, "entropy": 2.8227314543216786, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26581769063.48936, "policy_loss": -0.0044445461058553225, "vf_loss": 26581769063.48936, "vf_explained_var": -9.638198150696553e-08, "kl": 0.009468564416896155, "entropy": 2.8702367163719016, "entropy_coeff": 0.0}}}, "num_steps_sampled": 192192, "num_agent_steps_sampled": 384384, "num_steps_trained": 192192, "num_agent_steps_trained": 384384}, "done": false, "episodes_total": 192, "training_iteration": 32, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-29-57", "timestamp": 1624962597, "time_this_iter_s": 25.242900609970093, "time_total_s": 805.0935442447662, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 805.0935442447662, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 30.38484848484849, "ram_util_percent": 66.98484848484848, "gpu_util_percent0": 0.3790909090909091, "vram_util_percent0": 0.30671221823901296}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1749138.9625245845, "pol1": 1749138.9625245845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1526309.037062985, -1792140.2188059064, -1693706.1882251636, -1880372.9199235647, -1879770.4496140608, -1700027.1443047572, -1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058], "policy_pol1_reward": [1526309.037062985, 1792140.2188059064, 1693706.1882251636, 1880372.9199235647, 1879770.4496140608, 1700027.1443047572, 1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2695408366187996, "mean_inference_ms": 3.6997844553781363, "mean_action_processing_ms": 0.18520429442957959, "mean_env_wait_ms": 0.14065930669986743, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 198198, "agent_timesteps_total": 396396, "timers": {"sample_time_ms": 4485.431, "sample_throughput": 1339.002, "learn_time_ms": 20684.707, "learn_throughput": 290.359, "update_time_ms": 4.727}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26154566721.361702, "policy_loss": 0.008082566109109433, "vf_loss": 26154566721.361702, "vf_explained_var": 3.9313700739285196e-08, "kl": 0.030840002832577585, "entropy": 2.836431787369099, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26248199625.531914, "policy_loss": -0.005123270120709501, "vf_loss": 26248199625.531914, "vf_explained_var": -1.1286837064972133e-07, "kl": 0.010715537228958403, "entropy": 2.775082882414473, "entropy_coeff": 0.0}}}, "num_steps_sampled": 198198, "num_agent_steps_sampled": 396396, "num_steps_trained": 198198, "num_agent_steps_trained": 396396}, "done": false, "episodes_total": 198, "training_iteration": 33, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-30-22", "timestamp": 1624962622, "time_this_iter_s": 25.22258758544922, "time_total_s": 830.3161318302155, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e356a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 830.3161318302155, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 30.464705882352945, "ram_util_percent": 66.87058823529412, "gpu_util_percent0": 0.3752941176470589, "vram_util_percent0": 0.30658815599040423}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1397421.3776456625}, "policy_reward_max": {"pol0": -1397421.3776456625, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1747197.1744943822, "pol1": 1747197.1744943822}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1397421.3776456625, -1779304.6495580522, -1832906.913160219, -1808599.4016717256, -1791391.911785538, -1880865.4310359787, -1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532], "policy_pol1_reward": [1397421.3776456625, 1779304.6495580522, 1832906.913160219, 1808599.4016717256, 1791391.911785538, 1880865.4310359787, 1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2696924378494473, "mean_inference_ms": 3.7010643843216853, "mean_action_processing_ms": 0.18527098802158481, "mean_env_wait_ms": 0.1407134402999881, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 204204, "agent_timesteps_total": 408408, "timers": {"sample_time_ms": 4477.685, "sample_throughput": 1341.318, "learn_time_ms": 20682.411, "learn_throughput": 290.392, "update_time_ms": 4.775}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 24530410517.787235, "policy_loss": 0.0016712712599559034, "vf_loss": 24530410517.787235, "vf_explained_var": -2.1559126039960574e-08, "kl": 0.022607175276634542, "entropy": 2.7833977506515826, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24624315544.51064, "policy_loss": -0.0030485419754652265, "vf_loss": 24624315544.51064, "vf_explained_var": -4.8190990753482765e-08, "kl": 0.007631995249539614, "entropy": 2.9305682334494083, "entropy_coeff": 0.0}}}, "num_steps_sampled": 204204, "num_agent_steps_sampled": 408408, "num_steps_trained": 204204, "num_agent_steps_trained": 408408}, "done": false, "episodes_total": 204, "training_iteration": 34, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-30-47", "timestamp": 1624962647, "time_this_iter_s": 24.99520492553711, "time_total_s": 855.3113367557526, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacc80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 855.3113367557526, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 29.993939393939392, "ram_util_percent": 66.98181818181818, "gpu_util_percent0": 0.3772727272727273, "vram_util_percent0": 0.30670711156049885}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1401842.0341777513}, "policy_reward_max": {"pol0": -1401842.0341777513, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1747414.8708009792, "pol1": 1747414.8708009792}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1839931.2706913294, -1755974.2517054025, -1570545.8747654182, -1730569.7806633327, -1571220.6333588064, -1695185.322184642, -1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149], "policy_pol1_reward": [1839931.2706913294, 1755974.2517054025, 1570545.8747654182, 1730569.7806633327, 1571220.6333588064, 1695185.322184642, 1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2698264632251846, "mean_inference_ms": 3.702719412831189, "mean_action_processing_ms": 0.18535560563385772, "mean_env_wait_ms": 0.14077751263892538, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 210210, "agent_timesteps_total": 420420, "timers": {"sample_time_ms": 4498.596, "sample_throughput": 1335.083, "learn_time_ms": 20665.505, "learn_throughput": 290.629, "update_time_ms": 4.695}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25872507490.042553, "policy_loss": -0.0027694761396405546, "vf_loss": 25872507490.042553, "vf_explained_var": 2.2827311596529398e-08, "kl": 0.008050096082560559, "entropy": 2.8032574602898133, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25971544979.06383, "policy_loss": -0.003966658653572519, "vf_loss": 25971544979.06383, "vf_explained_var": -3.804551695907321e-08, "kl": 0.009302169342148812, "entropy": 2.7007333471419965, "entropy_coeff": 0.0}}}, "num_steps_sampled": 210210, "num_agent_steps_sampled": 420420, "num_steps_trained": 210210, "num_agent_steps_trained": 420420}, "done": false, "episodes_total": 210, "training_iteration": 35, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-31-12", "timestamp": 1624962672, "time_this_iter_s": 25.010468006134033, "time_total_s": 880.3218047618866, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0617510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 880.3218047618866, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 30.560606060606062, "ram_util_percent": 66.86666666666667, "gpu_util_percent0": 0.3809090909090909, "vram_util_percent0": 0.30661008466872974}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1401842.0341777513}, "policy_reward_max": {"pol0": -1401842.0341777513, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1752497.987919046, "pol1": 1752497.987919046}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1504147.7394341638, -1465089.9090677812, -1814643.517309103, -1850061.9514866122, -1401842.0341777513, -1814059.0682465732, -1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299], "policy_pol1_reward": [1504147.7394341638, 1465089.9090677812, 1814643.517309103, 1850061.9514866122, 1401842.0341777513, 1814059.0682465732, 1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2699395797886054, "mean_inference_ms": 3.704459752508635, "mean_action_processing_ms": 0.18544210860918436, "mean_env_wait_ms": 0.14084305510596798, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 216216, "agent_timesteps_total": 432432, "timers": {"sample_time_ms": 4485.384, "sample_throughput": 1339.016, "learn_time_ms": 20640.308, "learn_throughput": 290.984, "update_time_ms": 4.71}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26590116014.29787, "policy_loss": -0.001459344428904513, "vf_loss": 26590116014.29787, "vf_explained_var": 9.130924638611759e-08, "kl": 0.011400893885404505, "entropy": 2.859143490486957, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26694371284.425533, "policy_loss": -0.002727073676725651, "vf_loss": 26694371284.425533, "vf_explained_var": -4.5654623193058796e-08, "kl": 0.005437200621483808, "entropy": 2.734577386937243, "entropy_coeff": 0.0}}}, "num_steps_sampled": 216216, "num_agent_steps_sampled": 432432, "num_steps_trained": 216216, "num_agent_steps_trained": 432432}, "done": false, "episodes_total": 216, "training_iteration": 36, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-31-38", "timestamp": 1624962698, "time_this_iter_s": 25.041836500167847, "time_total_s": 905.3636412620544, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 905.3636412620544, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 30.254545454545458, "ram_util_percent": 66.99393939393939, "gpu_util_percent0": 0.38575757575757574, "vram_util_percent0": 0.306681578167928}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1481160.461418301}, "policy_reward_max": {"pol0": -1481160.461418301, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1758626.5308194913, "pol1": 1758626.5308194913}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1651628.4680582609, -1824576.1668537057, -1805652.6007306736, -1521555.1252212266, -1899244.2235667377, -1616937.1717601165, -1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056], "policy_pol1_reward": [1651628.4680582609, 1824576.1668537057, 1805652.6007306736, 1521555.1252212266, 1899244.2235667377, 1616937.1717601165, 1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2700642785782743, "mean_inference_ms": 3.706673462362972, "mean_action_processing_ms": 0.1855478754996169, "mean_env_wait_ms": 0.1409235333326119, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 222222, "agent_timesteps_total": 444444, "timers": {"sample_time_ms": 4506.411, "sample_throughput": 1332.768, "learn_time_ms": 20627.67, "learn_throughput": 291.162, "update_time_ms": 4.703}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25619498833.70213, "policy_loss": -0.0016922281975758837, "vf_loss": 25619498833.70213, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.012279506852018071, "entropy": 2.8007951949505094, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25731096270.97872, "policy_loss": -0.0037383657503635326, "vf_loss": 25731096270.97872, "vf_explained_var": -2.4095495376741383e-08, "kl": 0.01217047753248443, "entropy": 2.952757561460454, "entropy_coeff": 0.0}}}, "num_steps_sampled": 222222, "num_agent_steps_sampled": 444444, "num_steps_trained": 222222, "num_agent_steps_trained": 444444}, "done": false, "episodes_total": 222, "training_iteration": 37, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-32-03", "timestamp": 1624962723, "time_this_iter_s": 25.28531265258789, "time_total_s": 930.6489539146423, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0617598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 930.6489539146423, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 30.92727272727273, "ram_util_percent": 66.86363636363637, "gpu_util_percent0": 0.3824242424242424, "vram_util_percent0": 0.30664072473981474}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1481160.461418301}, "policy_reward_max": {"pol0": -1481160.461418301, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1762344.409757892, "pol1": 1762344.409757892}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1743164.3855103387, -1645590.4954750123, -1736409.500450665, -1826954.7129915825, -1866221.337430558, -1910609.2683752428, -1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898], "policy_pol1_reward": [1743164.3855103387, 1645590.4954750123, 1736409.500450665, 1826954.7129915825, 1866221.337430558, 1910609.2683752428, 1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2702357329581508, "mean_inference_ms": 3.7091856369290137, "mean_action_processing_ms": 0.18566590189972654, "mean_env_wait_ms": 0.14100739983249733, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 228228, "agent_timesteps_total": 456456, "timers": {"sample_time_ms": 4545.55, "sample_throughput": 1321.292, "learn_time_ms": 20663.447, "learn_throughput": 290.658, "update_time_ms": 4.818}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27067324459.574467, "policy_loss": -0.0011559368131008553, "vf_loss": 27067324459.574467, "vf_explained_var": 1.154047382101453e-07, "kl": 0.011504459412808114, "entropy": 2.783338998226409, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 27182918285.61702, "policy_loss": -0.002325189319696832, "vf_loss": 27182918285.61702, "vf_explained_var": -7.609103569450326e-09, "kl": 0.008324533879281358, "entropy": 2.978744735109045, "entropy_coeff": 0.0}}}, "num_steps_sampled": 228228, "num_agent_steps_sampled": 456456, "num_steps_trained": 228228, "num_agent_steps_trained": 456456}, "done": false, "episodes_total": 228, "training_iteration": 38, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-32-28", "timestamp": 1624962748, "time_this_iter_s": 25.620354175567627, "time_total_s": 956.26930809021, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e8d400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f7ae4194400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 956.26930809021, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 32.017647058823535, "ram_util_percent": 67.24117647058824, "gpu_util_percent0": 0.37176470588235294, "vram_util_percent0": 0.30659806895457875}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1470712.640933017}, "policy_reward_max": {"pol0": -1470712.640933017, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1756442.8531997083, "pol1": 1756442.8531997083}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1956733.045137202, -1870217.150239239, -1736198.1220349332, -1811972.1213436762, -1762381.0039751949, -1868229.9515614838, -1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017], "policy_pol1_reward": [1956733.045137202, 1870217.150239239, 1736198.1220349332, 1811972.1213436762, 1762381.0039751949, 1868229.9515614838, 1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27039011569219956, "mean_inference_ms": 3.711589157273792, "mean_action_processing_ms": 0.1857777556170468, "mean_env_wait_ms": 0.1410891206980448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 234234, "agent_timesteps_total": 468468, "timers": {"sample_time_ms": 4543.912, "sample_throughput": 1321.769, "learn_time_ms": 20663.885, "learn_throughput": 290.652, "update_time_ms": 4.796}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24052337729.361702, "policy_loss": 0.0008236746046137302, "vf_loss": 24052337729.361702, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.014482395604569862, "entropy": 2.7620242301453937, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24152010229.106384, "policy_loss": -0.003136590876160784, "vf_loss": 24152010229.106384, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.008203784231730599, "entropy": 3.029826169318341, "entropy_coeff": 0.0}}}, "num_steps_sampled": 234234, "num_agent_steps_sampled": 468468, "num_steps_trained": 234234, "num_agent_steps_trained": 468468}, "done": false, "episodes_total": 234, "training_iteration": 39, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-32-54", "timestamp": 1624962774, "time_this_iter_s": 25.2156023979187, "time_total_s": 981.4849104881287, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 981.4849104881287, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 31.306060606060605, "ram_util_percent": 66.78484848484848, "gpu_util_percent0": 0.37757575757575756, "vram_util_percent0": 0.30671221823901296}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1470712.640933017}, "policy_reward_max": {"pol0": -1470712.640933017, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1756200.673642205, "pol1": 1756200.673642205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1746028.2573087842, -1753850.8992295172, -1851258.976696947, -1749533.8236934193, -1835495.6288792302, -1828829.9759778294, -1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517], "policy_pol1_reward": [1746028.2573087842, 1753850.8992295172, 1851258.976696947, 1749533.8236934193, 1835495.6288792302, 1828829.9759778294, 1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2705414446691192, "mean_inference_ms": 3.714011841028449, "mean_action_processing_ms": 0.18589174948430054, "mean_env_wait_ms": 0.1411725017419422, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 240240, "agent_timesteps_total": 480480, "timers": {"sample_time_ms": 4546.734, "sample_throughput": 1320.948, "learn_time_ms": 20668.409, "learn_throughput": 290.588, "update_time_ms": 4.89}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27971906494.638298, "policy_loss": 0.0004187462791959022, "vf_loss": 27971906494.638298, "vf_explained_var": -1.2681839223205316e-07, "kl": 0.008682175737587696, "entropy": 2.7906504945552095, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 28090920611.404255, "policy_loss": -0.003549326369737057, "vf_loss": 28090920611.404255, "vf_explained_var": 8.87728734966231e-09, "kl": 0.011411656764276485, "entropy": 3.0129550974419774, "entropy_coeff": 0.0}}}, "num_steps_sampled": 240240, "num_agent_steps_sampled": 480480, "num_steps_trained": 240240, "num_agent_steps_trained": 480480}, "done": false, "episodes_total": 240, "training_iteration": 40, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-33-19", "timestamp": 1624962799, "time_this_iter_s": 25.418745279312134, "time_total_s": 1006.9036557674408, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1006.9036557674408, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 31.27058823529412, "ram_util_percent": 66.74117647058826, "gpu_util_percent0": 0.3835294117647059, "vram_util_percent0": 0.3066129384008406}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956996.4837947597, "pol1": 1395391.6798120015}, "policy_reward_max": {"pol0": -1395391.6798120015, "pol1": 1956996.4837947597}, "policy_reward_mean": {"pol0": -1751742.3331209123, "pol1": 1751742.3331209123}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1663737.8561762692, -1850907.8156955952, -1632555.0475380244, -1956996.4837947597, -1509679.3903261747, -1808518.256568393, -1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416], "policy_pol1_reward": [1663737.8561762692, 1850907.8156955952, 1632555.0475380244, 1956996.4837947597, 1509679.3903261747, 1808518.256568393, 1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27071239859211454, "mean_inference_ms": 3.7164073515264464, "mean_action_processing_ms": 0.18600348521037713, "mean_env_wait_ms": 0.14125574217183756, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 246246, "agent_timesteps_total": 492492, "timers": {"sample_time_ms": 4550.456, "sample_throughput": 1319.868, "learn_time_ms": 20664.479, "learn_throughput": 290.644, "update_time_ms": 4.895}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24994351757.61702, "policy_loss": -0.003735771779208741, "vf_loss": 24994351757.61702, "vf_explained_var": 1.3696386247374903e-07, "kl": 0.00460748285292945, "entropy": 2.812917171640599, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25112088488.851063, "policy_loss": -0.004418576492908153, "vf_loss": 25112088488.851063, "vf_explained_var": -1.0272290040802545e-07, "kl": 0.01040046107261739, "entropy": 2.6499692531342203, "entropy_coeff": 0.0}}}, "num_steps_sampled": 246246, "num_agent_steps_sampled": 492492, "num_steps_trained": 246246, "num_agent_steps_trained": 492492}, "done": false, "episodes_total": 246, "training_iteration": 41, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-33-44", "timestamp": 1624962824, "time_this_iter_s": 25.229563236236572, "time_total_s": 1032.1332190036774, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0617598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1032.1332190036774, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 30.933333333333334, "ram_util_percent": 66.86363636363637, "gpu_util_percent0": 0.3839393939393939, "vram_util_percent0": 0.30669689820347046}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1750878.3484479042, "pol1": 1750878.3484479042}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1730742.0360323878, -1642052.370310432, -1788962.2882008017, -1901413.0004242356, -1781492.5731779567, -1902414.8581525823, -1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217], "policy_pol1_reward": [1730742.0360323878, 1642052.370310432, 1788962.2882008017, 1901413.0004242356, 1781492.5731779567, 1902414.8581525823, 1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2709005758331497, "mean_inference_ms": 3.7188079152922637, "mean_action_processing_ms": 0.18611635846345137, "mean_env_wait_ms": 0.14133891723678071, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 252252, "agent_timesteps_total": 504504, "timers": {"sample_time_ms": 4554.359, "sample_throughput": 1318.737, "learn_time_ms": 20644.179, "learn_throughput": 290.929, "update_time_ms": 4.876}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25742369247.31915, "policy_loss": -0.0021128245688816333, "vf_loss": 25742369247.31915, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.007337178153164209, "entropy": 2.7858893617670586, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25865404808.17021, "policy_loss": -0.004589876635594571, "vf_loss": 25865404808.17021, "vf_explained_var": 8.750468794005428e-08, "kl": 0.007813553246570395, "entropy": 2.6076443296797733, "entropy_coeff": 0.0}}}, "num_steps_sampled": 252252, "num_agent_steps_sampled": 504504, "num_steps_trained": 252252, "num_agent_steps_trained": 504504}, "done": false, "episodes_total": 252, "training_iteration": 42, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-34-10", "timestamp": 1624962850, "time_this_iter_s": 25.077455520629883, "time_total_s": 1057.2106745243073, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0617f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0617488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1057.2106745243073, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 30.55757575757576, "ram_util_percent": 66.99393939393939, "gpu_util_percent0": 0.37636363636363634, "vram_util_percent0": 0.30662540470427224}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1747067.3709538959, "pol1": 1747067.3709538959}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1807346.5970769576, -1783521.2268728127, -1481160.461418301, -1745371.0137727873, -1793299.546363945, -1699596.505358076, -1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113], "policy_pol1_reward": [1807346.5970769576, 1783521.2268728127, 1481160.461418301, 1745371.0137727873, 1793299.546363945, 1699596.505358076, 1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2710567686825798, "mean_inference_ms": 3.720980209614983, "mean_action_processing_ms": 0.18622248794907303, "mean_env_wait_ms": 0.1414157558959868, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 258258, "agent_timesteps_total": 516516, "timers": {"sample_time_ms": 4554.264, "sample_throughput": 1318.764, "learn_time_ms": 20642.19, "learn_throughput": 290.957, "update_time_ms": 4.934}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 24803541602.042553, "policy_loss": -0.001188970448330362, "vf_loss": 24803541602.042553, "vf_explained_var": -1.5218206783629284e-07, "kl": 0.00582557594641409, "entropy": 2.796996233311105, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24920392290.042553, "policy_loss": -0.004021810575764864, "vf_loss": 24920392290.042553, "vf_explained_var": -3.804551784725163e-09, "kl": 0.007781385671981471, "entropy": 2.6964006423950195, "entropy_coeff": 0.0}}}, "num_steps_sampled": 258258, "num_agent_steps_sampled": 516516, "num_steps_trained": 258258, "num_agent_steps_trained": 516516}, "done": false, "episodes_total": 258, "training_iteration": 43, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-34-35", "timestamp": 1624962875, "time_this_iter_s": 25.203553915023804, "time_total_s": 1082.414228439331, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c77b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1082.414228439331, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 31.354545454545455, "ram_util_percent": 66.7878787878788, "gpu_util_percent0": 0.37393939393939396, "vram_util_percent0": 0.30664072473981474}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1749004.5753129558, "pol1": 1749004.5753129558}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1849534.783178777, -1488588.376929447, -1905308.4302373258, -1705238.7928270062, -1709617.336696216, -1756020.8792082, -1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016], "policy_pol1_reward": [1849534.783178777, 1488588.376929447, 1905308.4302373258, 1705238.7928270062, 1709617.336696216, 1756020.8792082, 1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2712177442410307, "mean_inference_ms": 3.723410032512548, "mean_action_processing_ms": 0.1863330558211032, "mean_env_wait_ms": 0.1414898825548333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 264264, "agent_timesteps_total": 528528, "timers": {"sample_time_ms": 4592.171, "sample_throughput": 1307.878, "learn_time_ms": 20642.178, "learn_throughput": 290.958, "update_time_ms": 4.9}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25859005810.38298, "policy_loss": 0.0014784506502303672, "vf_loss": 25859005810.38298, "vf_explained_var": -3.0436414277801305e-08, "kl": 0.013146472678698123, "entropy": 2.775771455561861, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25987364297.531914, "policy_loss": -0.004639201995698695, "vf_loss": 25987364297.531914, "vf_explained_var": -1.154047382101453e-07, "kl": 0.011135511694753424, "entropy": 2.825764204593415, "entropy_coeff": 0.0}}}, "num_steps_sampled": 264264, "num_agent_steps_sampled": 528528, "num_steps_trained": 264264, "num_agent_steps_trained": 528528}, "done": false, "episodes_total": 264, "training_iteration": 44, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-35-00", "timestamp": 1624962900, "time_this_iter_s": 25.37411665916443, "time_total_s": 1107.7883450984955, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f7ae4194400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1107.7883450984955, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 30.876470588235293, "ram_util_percent": 66.87058823529412, "gpu_util_percent0": 0.37941176470588234, "vram_util_percent0": 0.30664763377545157}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1750037.3571777237, "pol1": 1750037.3571777237}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1616422.8365835545, -1812925.1445643026, -1801881.1051678115, -1662045.1541138664, -1826587.6478972943, -1788700.5785440446, -1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323], "policy_pol1_reward": [1616422.8365835545, 1812925.1445643026, 1801881.1051678115, 1662045.1541138664, 1826587.6478972943, 1788700.5785440446, 1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27137099285204525, "mean_inference_ms": 3.725798544657199, "mean_action_processing_ms": 0.18644058506111658, "mean_env_wait_ms": 0.14156144300158424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 270270, "agent_timesteps_total": 540540, "timers": {"sample_time_ms": 4586.286, "sample_throughput": 1309.556, "learn_time_ms": 20652.804, "learn_throughput": 290.808, "update_time_ms": 4.892}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25897907613.957447, "policy_loss": -0.004245869676641961, "vf_loss": 25897907613.957447, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.009838807000283232, "entropy": 2.7903607753997153, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26031669988.765957, "policy_loss": -0.0053677276331693564, "vf_loss": 26031669988.765957, "vf_explained_var": 1.0525926796844942e-07, "kl": 0.006800894982161674, "entropy": 2.681424937349685, "entropy_coeff": 0.0}}}, "num_steps_sampled": 270270, "num_agent_steps_sampled": 540540, "num_steps_trained": 270270, "num_agent_steps_trained": 540540}, "done": false, "episodes_total": 270, "training_iteration": 45, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-35-25", "timestamp": 1624962925, "time_this_iter_s": 25.057446479797363, "time_total_s": 1132.8457915782928, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c72f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c71e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1132.8457915782928, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 30.184848484848487, "ram_util_percent": 67.07878787878789, "gpu_util_percent0": 0.3709090909090909, "vram_util_percent0": 0.3066305113827864}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1746284.6539319167, "pol1": 1746284.6539319167}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1687223.624521247, -1810619.538272666, -1731487.8051203378, -1823552.0848123261, -1822240.3508253281, -1883564.7670576042, -1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673], "policy_pol1_reward": [1687223.624521247, 1810619.538272666, 1731487.8051203378, 1823552.0848123261, 1822240.3508253281, 1883564.7670576042, 1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2715208554456416, "mean_inference_ms": 3.7282352221281627, "mean_action_processing_ms": 0.1865457573987258, "mean_env_wait_ms": 0.14163523952471568, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 276276, "agent_timesteps_total": 552552, "timers": {"sample_time_ms": 4606.519, "sample_throughput": 1303.805, "learn_time_ms": 20673.547, "learn_throughput": 290.516, "update_time_ms": 5.011}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 23911039673.19149, "policy_loss": -0.0031183310090861422, "vf_loss": 23911039673.19149, "vf_explained_var": 1.2681839223205316e-07, "kl": 0.010705455265780713, "entropy": 2.8090999938072043, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24035024765.276596, "policy_loss": -0.0035959018909550726, "vf_loss": 24035024765.276596, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.0072849236448553015, "entropy": 2.6761129358981517, "entropy_coeff": 0.0}}}, "num_steps_sampled": 276276, "num_agent_steps_sampled": 552552, "num_steps_trained": 276276, "num_agent_steps_trained": 552552}, "done": false, "episodes_total": 276, "training_iteration": 46, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-35-51", "timestamp": 1624962951, "time_this_iter_s": 25.45267391204834, "time_total_s": 1158.2984654903412, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1158.2984654903412, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 30.841176470588238, "ram_util_percent": 66.95294117647057, "gpu_util_percent0": 0.3811764705882353, "vram_util_percent0": 0.306692242114237}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1742913.535189831, "pol1": 1742913.535189831}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1562990.1518248008, -1703701.6866217642, -1659261.971705976, -1806670.5487763416, -1718118.9286720196, -1796855.5245549127, -1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252], "policy_pol1_reward": [1562990.1518248008, 1703701.6866217642, 1659261.971705976, 1806670.5487763416, 1718118.9286720196, 1796855.5245549127, 1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27165994036679086, "mean_inference_ms": 3.7306207273433194, "mean_action_processing_ms": 0.1866501497964099, "mean_env_wait_ms": 0.1417076234179344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 282282, "agent_timesteps_total": 564564, "timers": {"sample_time_ms": 4584.057, "sample_throughput": 1310.193, "learn_time_ms": 20692.875, "learn_throughput": 290.245, "update_time_ms": 5.008}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25282745452.93617, "policy_loss": 0.007137332785319775, "vf_loss": 25282745452.93617, "vf_explained_var": 9.89183490673895e-08, "kl": 0.02125486779086133, "entropy": 2.8246639890873686, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25416286556.595745, "policy_loss": -0.008123785732908452, "vf_loss": 25416286556.595745, "vf_explained_var": -4.8190990753482765e-08, "kl": 0.011605964517815317, "entropy": 2.6174369720702475, "entropy_coeff": 0.0}}}, "num_steps_sampled": 282282, "num_agent_steps_sampled": 564564, "num_steps_trained": 282282, "num_agent_steps_trained": 564564}, "done": false, "episodes_total": 282, "training_iteration": 47, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-36-16", "timestamp": 1624962976, "time_this_iter_s": 25.254483938217163, "time_total_s": 1183.5529494285583, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1183.5529494285583, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 30.31818181818182, "ram_util_percent": 67.28181818181818, "gpu_util_percent0": 0.37757575757575756, "vram_util_percent0": 0.3066049779902157}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1746213.3620036906, "pol1": 1746213.3620036906}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1745405.3317882698, -1842992.1357590016, -1839007.423998586, -1709036.6503274331, -1743617.6373214016, -1907353.9198579832, -1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807], "policy_pol1_reward": [1745405.3317882698, 1842992.1357590016, 1839007.423998586, 1709036.6503274331, 1743617.6373214016, 1907353.9198579832, 1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.271781874531605, "mean_inference_ms": 3.732787541015268, "mean_action_processing_ms": 0.18674442083110485, "mean_env_wait_ms": 0.1417724885658274, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 288288, "agent_timesteps_total": 576576, "timers": {"sample_time_ms": 4547.075, "sample_throughput": 1320.849, "learn_time_ms": 20670.302, "learn_throughput": 290.562, "update_time_ms": 4.956}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.000000000000002e-05, "total_loss": 26414772180.425533, "policy_loss": 0.0001579682005846754, "vf_loss": 26414772180.425533, "vf_explained_var": 1.1160018686950934e-07, "kl": 0.00931948266844166, "entropy": 2.791092679855671, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26555242365.276596, "policy_loss": -0.003481935313407411, "vf_loss": 26555242365.276596, "vf_explained_var": -1.0145471662781347e-07, "kl": 0.009216197429502264, "entropy": 2.673718574199271, "entropy_coeff": 0.0}}}, "num_steps_sampled": 288288, "num_agent_steps_sampled": 576576, "num_steps_trained": 288288, "num_agent_steps_trained": 576576}, "done": false, "episodes_total": 288, "training_iteration": 48, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-36-41", "timestamp": 1624963001, "time_this_iter_s": 25.023584365844727, "time_total_s": 1208.576533794403, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c78c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1208.576533794403, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 30.166666666666668, "ram_util_percent": 67.24848484848485, "gpu_util_percent0": 0.3742424242424242, "vram_util_percent0": 0.3067071115604988}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1742477.1886587006, "pol1": 1742477.1886587006}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1756489.4796789135, -1797503.6495250256, -1571010.3715057177, -1797194.8683364058, -1751623.9576547414, -1823722.0967128999, -1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864], "policy_pol1_reward": [1756489.4796789135, 1797503.6495250256, 1571010.3715057177, 1797194.8683364058, 1751623.9576547414, 1823722.0967128999, 1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2718794251621109, "mean_inference_ms": 3.734936389792652, "mean_action_processing_ms": 0.18683498099533985, "mean_env_wait_ms": 0.14183616405781282, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 294294, "agent_timesteps_total": 588588, "timers": {"sample_time_ms": 4563.815, "sample_throughput": 1316.004, "learn_time_ms": 20663.832, "learn_throughput": 290.653, "update_time_ms": 4.953}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.000000000000002e-05, "total_loss": 25203164181.787235, "policy_loss": -0.0014497862058751127, "vf_loss": 25203164181.787235, "vf_explained_var": 1.3950023358688668e-08, "kl": 0.008181095866367538, "entropy": 2.7698853979719447, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25341549284.765957, "policy_loss": -0.005914919534103668, "vf_loss": 25341549284.765957, "vf_explained_var": -1.1794110577056927e-07, "kl": 0.010083905064520683, "entropy": 2.745965308331429, "entropy_coeff": 0.0}}}, "num_steps_sampled": 294294, "num_agent_steps_sampled": 588588, "num_steps_trained": 294294, "num_agent_steps_trained": 588588}, "done": false, "episodes_total": 294, "training_iteration": 49, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-37-06", "timestamp": 1624963026, "time_this_iter_s": 25.31739830970764, "time_total_s": 1233.8939321041107, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1233.8939321041107, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 31.290909090909096, "ram_util_percent": 66.97878787878787, "gpu_util_percent0": 0.3751515151515152, "vram_util_percent0": 0.3066151913472439}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1740562.1212446627, "pol1": 1740562.1212446627}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1606073.6818527034, -1825076.510966159, -1640314.6053551086, -1631336.3023745532, -1606346.7755718238, -1715052.6616615898, -1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211], "policy_pol1_reward": [1606073.6818527034, 1825076.510966159, 1640314.6053551086, 1631336.3023745532, 1606346.7755718238, 1715052.6616615898, 1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2719556572560283, "mean_inference_ms": 3.737072053250289, "mean_action_processing_ms": 0.18692438159802024, "mean_env_wait_ms": 0.1419010288266552, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 300300, "agent_timesteps_total": 600600, "timers": {"sample_time_ms": 4551.293, "sample_throughput": 1319.625, "learn_time_ms": 20635.375, "learn_throughput": 291.054, "update_time_ms": 4.947}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.000000000000002e-05, "total_loss": 24869586856.851063, "policy_loss": -7.69818162030362e-05, "vf_loss": 24869586856.851063, "vf_explained_var": 7.609103569450326e-09, "kl": 0.009120158494469966, "entropy": 2.7763644380772368, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25016309454.97872, "policy_loss": -0.008477550594413534, "vf_loss": 25016309454.97872, "vf_explained_var": -1.065274517486614e-07, "kl": 0.009580231786883891, "entropy": 2.821339931893856, "entropy_coeff": 0.0}}}, "num_steps_sampled": 300300, "num_agent_steps_sampled": 600600, "num_steps_trained": 300300, "num_agent_steps_trained": 600600}, "done": false, "episodes_total": 300, "training_iteration": 50, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-37-32", "timestamp": 1624963052, "time_this_iter_s": 25.00907564163208, "time_total_s": 1258.9030077457428, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eaca60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1258.9030077457428, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 30.303030303030305, "ram_util_percent": 67.14545454545456, "gpu_util_percent0": 0.3775757575757576, "vram_util_percent0": 0.3066407247398148}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1750958.0479655594, "pol1": 1750958.0479655594}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1661975.4292206853, -1879683.7757859123, -1802665.9538898296, -1846534.7193870149, -1733166.067700083, -1736013.624745109, -1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088], "policy_pol1_reward": [1661975.4292206853, 1879683.7757859123, 1802665.9538898296, 1846534.7193870149, 1733166.067700083, 1736013.624745109, 1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2720559459911324, "mean_inference_ms": 3.7393524970473813, "mean_action_processing_ms": 0.1870236896820555, "mean_env_wait_ms": 0.14197149045066396, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 306306, "agent_timesteps_total": 612612, "timers": {"sample_time_ms": 4565.133, "sample_throughput": 1315.624, "learn_time_ms": 20639.885, "learn_throughput": 290.99, "update_time_ms": 4.923}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.000000000000002e-05, "total_loss": 28629541604.765957, "policy_loss": -0.0013771638115669818, "vf_loss": 28629541604.765957, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.012015394489974417, "entropy": 2.7349718124308486, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 28793759526.12766, "policy_loss": -0.004823045844727374, "vf_loss": 28793759526.12766, "vf_explained_var": -8.877287172026627e-08, "kl": 0.011887888285390873, "entropy": 3.078967738658824, "entropy_coeff": 0.0}}}, "num_steps_sampled": 306306, "num_agent_steps_sampled": 612612, "num_steps_trained": 306306, "num_agent_steps_trained": 612612}, "done": false, "episodes_total": 306, "training_iteration": 51, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-37-57", "timestamp": 1624963077, "time_this_iter_s": 25.413118839263916, "time_total_s": 1284.3161265850067, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1284.3161265850067, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 31.17941176470588, "ram_util_percent": 66.90882352941175, "gpu_util_percent0": 0.37823529411764706, "vram_util_percent0": 0.30667241618588786}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1746763.884867051, "pol1": 1746763.884867051}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1880090.9152816124, -1765027.1878975183, -1781233.8864549615, -1776207.163096299, -1742007.8673250268, -1816658.3247901734, -1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103], "policy_pol1_reward": [1880090.9152816124, 1765027.1878975183, 1781233.8864549615, 1776207.163096299, 1742007.8673250268, 1816658.3247901734, 1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27217327404317965, "mean_inference_ms": 3.741631648395759, "mean_action_processing_ms": 0.18712323987109308, "mean_env_wait_ms": 0.14204428336201483, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 312312, "agent_timesteps_total": 624624, "timers": {"sample_time_ms": 4570.759, "sample_throughput": 1314.005, "learn_time_ms": 20641.226, "learn_throughput": 290.971, "update_time_ms": 4.89}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.000000000000002e-05, "total_loss": 24471763771.914894, "policy_loss": 0.002675176499054787, "vf_loss": 24471763771.914894, "vf_explained_var": 8.877287172026627e-08, "kl": 0.02207476039357642, "entropy": 2.7388139227603343, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24609308802.723404, "policy_loss": -0.004724804113836999, "vf_loss": 24609308802.723404, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.017257480228200874, "entropy": 3.1462269336619277, "entropy_coeff": 0.0}}}, "num_steps_sampled": 312312, "num_agent_steps_sampled": 624624, "num_steps_trained": 312312, "num_agent_steps_trained": 624624}, "done": false, "episodes_total": 312, "training_iteration": 52, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-38-22", "timestamp": 1624963102, "time_this_iter_s": 25.1462140083313, "time_total_s": 1309.462340593338, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1309.462340593338, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 30.945454545454545, "ram_util_percent": 67.04545454545453, "gpu_util_percent0": 0.37545454545454543, "vram_util_percent0": 0.3066100846687298}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1741123.4173759264, "pol1": 1741123.4173759264}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1750097.4203295629, -1759550.691915681, -1842351.365404972, -1552032.8400011056, -1742408.979897528, -1547751.471726816, -1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954], "policy_pol1_reward": [1750097.4203295629, 1759550.691915681, 1842351.365404972, 1552032.8400011056, 1742408.979897528, 1547751.471726816, 1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2722994001164689, "mean_inference_ms": 3.743766449912239, "mean_action_processing_ms": 0.187217631042097, "mean_env_wait_ms": 0.14211122317684932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 318318, "agent_timesteps_total": 636636, "timers": {"sample_time_ms": 4562.925, "sample_throughput": 1316.261, "learn_time_ms": 20648.242, "learn_throughput": 290.872, "update_time_ms": 4.829}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9610839843750002, "cur_lr": 5.000000000000002e-05, "total_loss": 24877062231.148937, "policy_loss": 0.00468603872317583, "vf_loss": 24877062231.148937, "vf_explained_var": 4.438643586013313e-08, "kl": 0.028541959980700877, "entropy": 2.616630234616868, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25023948451.404255, "policy_loss": 0.001069127562198233, "vf_loss": 25023948451.404255, "vf_explained_var": 1.3823205335938837e-07, "kl": 0.013976874325345171, "entropy": 3.28290375242842, "entropy_coeff": 0.0}}}, "num_steps_sampled": 318318, "num_agent_steps_sampled": 636636, "num_steps_trained": 318318, "num_agent_steps_trained": 636636}, "done": false, "episodes_total": 318, "training_iteration": 53, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-38-47", "timestamp": 1624963127, "time_this_iter_s": 25.193527936935425, "time_total_s": 1334.6558685302734, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1334.6558685302734, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 30.327272727272724, "ram_util_percent": 67.24545454545455, "gpu_util_percent0": 0.38090909090909086, "vram_util_percent0": 0.30637007077856426}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947378.6570139898, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1947378.6570139898}, "policy_reward_mean": {"pol0": -1745617.3183550576, "pol1": 1745617.3183550576}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1893306.5835229375, -1822011.5851274086, -1738524.3727421092, -1947378.6570139898, -1722993.2531933163, -1798240.343978124, -1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346], "policy_pol1_reward": [1893306.5835229375, 1822011.5851274086, 1738524.3727421092, 1947378.6570139898, 1722993.2531933163, 1798240.343978124, 1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2724050967719169, "mean_inference_ms": 3.745851068223981, "mean_action_processing_ms": 0.1873126701894991, "mean_env_wait_ms": 0.14217673884745513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 324324, "agent_timesteps_total": 648648, "timers": {"sample_time_ms": 4548.727, "sample_throughput": 1320.369, "learn_time_ms": 20653.598, "learn_throughput": 290.797, "update_time_ms": 4.876}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 26425993738.893616, "policy_loss": 0.00517163318680956, "vf_loss": 26425993738.893616, "vf_explained_var": -9.511379772675355e-08, "kl": 0.014551745806919767, "entropy": 2.6345115925403353, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26590858828.255318, "policy_loss": -0.0035502871577727034, "vf_loss": 26590858828.255318, "vf_explained_var": 1.6486390919112637e-08, "kl": 0.010141056130065563, "entropy": 3.3586707419537483, "entropy_coeff": 0.0}}}, "num_steps_sampled": 324324, "num_agent_steps_sampled": 648648, "num_steps_trained": 324324, "num_agent_steps_trained": 648648}, "done": false, "episodes_total": 324, "training_iteration": 54, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-39-13", "timestamp": 1624963153, "time_this_iter_s": 25.28604769706726, "time_total_s": 1359.9419162273407, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c79d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1359.9419162273407, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 30.76470588235295, "ram_util_percent": 67.04411764705881, "gpu_util_percent0": 0.38294117647058823, "vram_util_percent0": 0.30288566387121074}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937735.5465297957, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1937735.5465297957}, "policy_reward_mean": {"pol0": -1739232.5353879298, "pol1": 1739232.5353879298}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1823937.8728815638, -1534594.3394614093, -1788315.593967623, -1470712.640933017, -1896965.0336246537, -1758105.985663343, -1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683], "policy_pol1_reward": [1823937.8728815638, 1534594.3394614093, 1788315.593967623, 1470712.640933017, 1896965.0336246537, 1758105.985663343, 1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27249135361087556, "mean_inference_ms": 3.7476043014155507, "mean_action_processing_ms": 0.18739419429696189, "mean_env_wait_ms": 0.14223324302585436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 330330, "agent_timesteps_total": 660660, "timers": {"sample_time_ms": 4553.878, "sample_throughput": 1318.876, "learn_time_ms": 20666.726, "learn_throughput": 290.612, "update_time_ms": 4.95}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 24386398730.893616, "policy_loss": -0.00020203471897130317, "vf_loss": 24386398730.893616, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.007893643659004506, "entropy": 2.6857295797226275, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24529178013.957447, "policy_loss": -0.0033325296925737504, "vf_loss": 24529178013.957447, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.011118836324424185, "entropy": 3.3450604651836637, "entropy_coeff": 0.0}}}, "num_steps_sampled": 330330, "num_agent_steps_sampled": 660660, "num_steps_trained": 330330, "num_agent_steps_trained": 660660}, "done": false, "episodes_total": 330, "training_iteration": 55, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-39-38", "timestamp": 1624963178, "time_this_iter_s": 25.24124240875244, "time_total_s": 1385.1831586360931, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1385.1831586360931, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 30.3, "ram_util_percent": 67.15151515151516, "gpu_util_percent0": 0.3809090909090909, "vram_util_percent0": 0.3029996629592181}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937735.5465297957, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1937735.5465297957}, "policy_reward_mean": {"pol0": -1740763.982388735, "pol1": 1740763.982388735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1816967.9425344202, -1782147.7753619808, -1875116.005495242, -1852210.6958617517, -1395391.6798120015, -1831108.0444518887, -1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636], "policy_pol1_reward": [1816967.9425344202, 1782147.7753619808, 1875116.005495242, 1852210.6958617517, 1395391.6798120015, 1831108.0444518887, 1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2725830825835309, "mean_inference_ms": 3.7493404839081497, "mean_action_processing_ms": 0.18747586786719694, "mean_env_wait_ms": 0.1422892948297874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 336336, "agent_timesteps_total": 672672, "timers": {"sample_time_ms": 4540.829, "sample_throughput": 1322.666, "learn_time_ms": 20662.739, "learn_throughput": 290.668, "update_time_ms": 4.826}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 25481702029.61702, "policy_loss": 0.003329355665977965, "vf_loss": 25481702029.61702, "vf_explained_var": -2.916823049758932e-08, "kl": 0.01300764973572594, "entropy": 2.660460223542883, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25646604941.61702, "policy_loss": -0.0048050976140384975, "vf_loss": 25646604941.61702, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.009406537610165615, "entropy": 3.1383839921748384, "entropy_coeff": 0.0}}}, "num_steps_sampled": 336336, "num_agent_steps_sampled": 672672, "num_steps_trained": 336336, "num_agent_steps_trained": 672672}, "done": false, "episodes_total": 336, "training_iteration": 56, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-40-03", "timestamp": 1624963203, "time_this_iter_s": 25.279993534088135, "time_total_s": 1410.4631521701813, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c76a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c77b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1410.4631521701813, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 30.88181818181818, "ram_util_percent": 67.03333333333333, "gpu_util_percent0": 0.3827272727272727, "vram_util_percent0": 0.30289242271042066}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937735.5465297957, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1937735.5465297957}, "policy_reward_mean": {"pol0": -1735773.972186906, "pol1": 1735773.972186906}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1771905.6013152981, -1730417.934177284, -1733214.584019615, -1857125.665880416, -1668314.241896785, -1932727.9422278027, -1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417], "policy_pol1_reward": [1771905.6013152981, 1730417.934177284, 1733214.584019615, 1857125.665880416, 1668314.241896785, 1932727.9422278027, 1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2726828566686274, "mean_inference_ms": 3.7509122930131076, "mean_action_processing_ms": 0.18754883136380973, "mean_env_wait_ms": 0.14233884407639386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 342342, "agent_timesteps_total": 684684, "timers": {"sample_time_ms": 4537.622, "sample_throughput": 1323.601, "learn_time_ms": 20657.98, "learn_throughput": 290.735, "update_time_ms": 4.88}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 23438251814.12766, "policy_loss": -0.00043165493518748183, "vf_loss": 23438251814.12766, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.01601942567194396, "entropy": 2.627701373810464, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 23583445863.48936, "policy_loss": -0.0016611395998204009, "vf_loss": 23583445863.48936, "vf_explained_var": 6.340919789238342e-09, "kl": 0.011260136664706343, "entropy": 3.163494140543836, "entropy_coeff": 0.0}}}, "num_steps_sampled": 342342, "num_agent_steps_sampled": 684684, "num_steps_trained": 342342, "num_agent_steps_trained": 684684}, "done": false, "episodes_total": 342, "training_iteration": 57, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-40-29", "timestamp": 1624963229, "time_this_iter_s": 25.175320625305176, "time_total_s": 1435.6384727954865, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e358c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1435.6384727954865, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 30.184848484848484, "ram_util_percent": 67.16363636363637, "gpu_util_percent0": 0.38333333333333336, "vram_util_percent0": 0.3029179561029915}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937735.5465297957, "pol1": 1064785.1955132217}, "policy_reward_max": {"pol0": -1064785.1955132217, "pol1": 1937735.5465297957}, "policy_reward_mean": {"pol0": -1731045.3204467609, "pol1": 1731045.3204467609}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1919900.6673216, -1937735.5465297957, -1812532.7893091647, -1064785.1955132217, -1599005.7757109064, -1800182.3759139844, -1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746], "policy_pol1_reward": [1919900.6673216, 1937735.5465297957, 1812532.7893091647, 1064785.1955132217, 1599005.7757109064, 1800182.3759139844, 1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.272773269564562, "mean_inference_ms": 3.7525411287092396, "mean_action_processing_ms": 0.1876277395144702, "mean_env_wait_ms": 0.14239158255590134, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 348348, "agent_timesteps_total": 696696, "timers": {"sample_time_ms": 4560.021, "sample_throughput": 1317.099, "learn_time_ms": 20681.301, "learn_throughput": 290.407, "update_time_ms": 4.901}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 24325863424.0, "policy_loss": 0.004263778791782704, "vf_loss": 24325863424.0, "vf_explained_var": -1.68668464084476e-07, "kl": 0.008833151271051548, "entropy": 2.640223295130628, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24488400808.851063, "policy_loss": -0.00635234405227164, "vf_loss": 24488400808.851063, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.009742760674116458, "entropy": 3.2090634031498686, "entropy_coeff": 0.0}}}, "num_steps_sampled": 348348, "num_agent_steps_sampled": 696696, "num_steps_trained": 348348, "num_agent_steps_trained": 696696}, "done": false, "episodes_total": 348, "training_iteration": 58, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-40-54", "timestamp": 1624963254, "time_this_iter_s": 25.483168125152588, "time_total_s": 1461.121640920639, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05caa60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05caae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1461.121640920639, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 30.720588235294116, "ram_util_percent": 67.05294117647058, "gpu_util_percent0": 0.37529411764705883, "vram_util_percent0": 0.30303435833382897}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1735736.365839495, "pol1": 1735736.365839495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1748169.0311623737, -1640679.0010444068, -1805080.7208184646, -1772862.4722474113, -1724362.6453248898, -1662864.7471103205, -1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708], "policy_pol1_reward": [1748169.0311623737, 1640679.0010444068, 1805080.7208184646, 1772862.4722474113, 1724362.6453248898, 1662864.7471103205, 1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27285448873596796, "mean_inference_ms": 3.7540315996054363, "mean_action_processing_ms": 0.1876995450523403, "mean_env_wait_ms": 0.142439916398246, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 354354, "agent_timesteps_total": 708708, "timers": {"sample_time_ms": 4536.34, "sample_throughput": 1323.975, "learn_time_ms": 20686.386, "learn_throughput": 290.336, "update_time_ms": 4.935}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 26304212556.255318, "policy_loss": -0.0013069978944877994, "vf_loss": 26304212556.255318, "vf_explained_var": -3.0436414277801305e-08, "kl": 0.009505579604747448, "entropy": 2.6967499053224606, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26480041940.425533, "policy_loss": -0.0015999804785911073, "vf_loss": 26480041940.425533, "vf_explained_var": -1.775457469932462e-08, "kl": 0.008545618880777917, "entropy": 2.9280393377263496, "entropy_coeff": 0.0}}}, "num_steps_sampled": 354354, "num_agent_steps_sampled": 708708, "num_steps_trained": 354354, "num_agent_steps_trained": 708708}, "done": false, "episodes_total": 354, "training_iteration": 59, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-41-19", "timestamp": 1624963279, "time_this_iter_s": 25.132875680923462, "time_total_s": 1486.2545166015625, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cac80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cad90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1486.2545166015625, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 30.066666666666663, "ram_util_percent": 67.17575757575757, "gpu_util_percent0": 0.37696969696969695, "vram_util_percent0": 0.30296902288813304}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1736854.6962667054, "pol1": 1736854.6962667054}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1752601.657252023, -1715868.7039457816, -1853649.3260809707, -1794668.7070549016, -1738215.5215732919, -1775025.2343994959, -1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605], "policy_pol1_reward": [1752601.657252023, 1715868.7039457816, 1853649.3260809707, 1794668.7070549016, 1738215.5215732919, 1775025.2343994959, 1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2729490235473455, "mean_inference_ms": 3.7554015293599474, "mean_action_processing_ms": 0.1877675810029595, "mean_env_wait_ms": 0.14248511212716067, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 360360, "agent_timesteps_total": 720720, "timers": {"sample_time_ms": 4554.073, "sample_throughput": 1318.819, "learn_time_ms": 20688.434, "learn_throughput": 290.307, "update_time_ms": 4.931}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 25482536393.531914, "policy_loss": -0.0036025378020836953, "vf_loss": 25482536393.531914, "vf_explained_var": 1.154047382101453e-07, "kl": 0.010950781642756563, "entropy": 2.6589744293943363, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25651867691.574467, "policy_loss": -0.004191237799030669, "vf_loss": 25651867691.574467, "vf_explained_var": 3.804551784725163e-09, "kl": 0.012671767258422171, "entropy": 2.6393974638999778, "entropy_coeff": 0.0}}}, "num_steps_sampled": 360360, "num_agent_steps_sampled": 720720, "num_steps_trained": 360360, "num_agent_steps_trained": 720720}, "done": false, "episodes_total": 360, "training_iteration": 60, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-41-44", "timestamp": 1624963304, "time_this_iter_s": 25.206398248672485, "time_total_s": 1511.460914850235, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1511.460914850235, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 30.848484848484848, "ram_util_percent": 66.95151515151515, "gpu_util_percent0": 0.3748484848484849, "vram_util_percent0": 0.30308647649395876}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1736818.3701639718, "pol1": 1736818.3701639718}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1561251.8018325143, -1811841.5515218482, -1896608.141717358, -1734644.5345092323, -1860505.5090812042, -1787621.8117349497, -1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432], "policy_pol1_reward": [1561251.8018325143, 1811841.5515218482, 1896608.141717358, 1734644.5345092323, 1860505.5090812042, 1787621.8117349497, 1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2730379956976547, "mean_inference_ms": 3.7567111122726278, "mean_action_processing_ms": 0.1878380042367133, "mean_env_wait_ms": 0.14253197416143304, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 366366, "agent_timesteps_total": 732732, "timers": {"sample_time_ms": 4554.608, "sample_throughput": 1318.664, "learn_time_ms": 20687.087, "learn_throughput": 290.326, "update_time_ms": 4.968}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 26408703084.93617, "policy_loss": 0.001675784468967864, "vf_loss": 26408703084.93617, "vf_explained_var": -3.677733317886123e-08, "kl": 0.009838447628661673, "entropy": 2.6437597173325558, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26590614593.361702, "policy_loss": -0.005190672630325277, "vf_loss": 26590614593.361702, "vf_explained_var": -4.1850068299709164e-08, "kl": 0.011188025308891814, "entropy": 2.635082610110019, "entropy_coeff": 0.0}}}, "num_steps_sampled": 366366, "num_agent_steps_sampled": 732732, "num_steps_trained": 366366, "num_agent_steps_trained": 732732}, "done": false, "episodes_total": 366, "training_iteration": 61, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-42-10", "timestamp": 1624963330, "time_this_iter_s": 25.405302047729492, "time_total_s": 1536.8662168979645, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e359d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1536.8662168979645, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 30.74411764705882, "ram_util_percent": 67.12352941176471, "gpu_util_percent0": 0.37970588235294117, "vram_util_percent0": 0.30282618608616346}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1735824.8289044881, "pol1": 1735824.8289044881}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1658912.7861025312, -1734094.6835375924, -1508216.7586320245, -1583940.5932018673, -1753927.8020050027, -1621382.4720663256, -1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478], "policy_pol1_reward": [1658912.7861025312, 1734094.6835375924, 1508216.7586320245, 1583940.5932018673, 1753927.8020050027, 1621382.4720663256, 1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27314253771727987, "mean_inference_ms": 3.7579288442005305, "mean_action_processing_ms": 0.18790196697104297, "mean_env_wait_ms": 0.14257651376279756, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 372372, "agent_timesteps_total": 744744, "timers": {"sample_time_ms": 4549.044, "sample_throughput": 1320.277, "learn_time_ms": 20737.44, "learn_throughput": 289.621, "update_time_ms": 4.976}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 25890353979.914894, "policy_loss": 0.00220066895510288, "vf_loss": 25890353979.914894, "vf_explained_var": 1.0399108418823744e-07, "kl": 0.018851352815932417, "entropy": 2.7186609075424517, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26072915096.51064, "policy_loss": -0.00561645850935515, "vf_loss": 26072915096.51064, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.010817506251500008, "entropy": 2.757410795130628, "entropy_coeff": 0.0}}}, "num_steps_sampled": 372372, "num_agent_steps_sampled": 744744, "num_steps_trained": 372372, "num_agent_steps_trained": 744744}, "done": false, "episodes_total": 372, "training_iteration": 62, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-42-36", "timestamp": 1624963356, "time_this_iter_s": 25.59459376335144, "time_total_s": 1562.460810661316, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1562.460810661316, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 30.958823529411763, "ram_util_percent": 67.6970588235294, "gpu_util_percent0": 0.385, "vram_util_percent0": 0.3028856638712108}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1742198.8323594185, "pol1": 1742198.8323594185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1684860.298794114, -1866108.1226169586, -1753255.6668633358, -1742041.9340552252, -1846432.2995768127, -1802961.7181633303, -1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684], "policy_pol1_reward": [1684860.298794114, 1866108.1226169586, 1753255.6668633358, 1742041.9340552252, 1846432.2995768127, 1802961.7181633303, 1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2732276272782664, "mean_inference_ms": 3.7590114501772542, "mean_action_processing_ms": 0.18795967332791932, "mean_env_wait_ms": 0.14261694363496163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 378378, "agent_timesteps_total": 756756, "timers": {"sample_time_ms": 4551.131, "sample_throughput": 1319.672, "learn_time_ms": 20733.775, "learn_throughput": 289.672, "update_time_ms": 5.037}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 25604347424.68085, "policy_loss": 0.0025005692893520313, "vf_loss": 25604347424.68085, "vf_explained_var": 8.87728734966231e-09, "kl": 0.01889786572056882, "entropy": 2.7485613772209656, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25787517450.893616, "policy_loss": -0.005207151154729914, "vf_loss": 25787517450.893616, "vf_explained_var": 0.0, "kl": 0.009264845123633425, "entropy": 2.9488478366364825, "entropy_coeff": 0.0}}}, "num_steps_sampled": 378378, "num_agent_steps_sampled": 756756, "num_steps_trained": 378378, "num_agent_steps_trained": 756756}, "done": false, "episodes_total": 378, "training_iteration": 63, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-43-01", "timestamp": 1624963381, "time_this_iter_s": 25.17847990989685, "time_total_s": 1587.6392905712128, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c71e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c78c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1587.6392905712128, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 29.387878787878787, "ram_util_percent": 67.32727272727271, "gpu_util_percent0": 0.37666666666666665, "vram_util_percent0": 0.302902636067449}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1737002.92730072, "pol1": 1737002.92730072}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1821993.7220881814, -1783703.142066746, -1844980.6360993457, -1477509.9755473807, -1797402.6335568326, -1766516.1925801497, -1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895], "policy_pol1_reward": [1821993.7220881814, 1783703.142066746, 1844980.6360993457, 1477509.9755473807, 1797402.6335568326, 1766516.1925801497, 1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2733204398138784, "mean_inference_ms": 3.7602510955485426, "mean_action_processing_ms": 0.18802419087883607, "mean_env_wait_ms": 0.14266191376122386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 384384, "agent_timesteps_total": 768768, "timers": {"sample_time_ms": 4551.824, "sample_throughput": 1319.471, "learn_time_ms": 20759.319, "learn_throughput": 289.316, "update_time_ms": 5.045}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 24131776817.02128, "policy_loss": -0.004764164005346755, "vf_loss": 24131776817.02128, "vf_explained_var": -1.3442749491332506e-07, "kl": 0.005374678816804861, "entropy": 2.7333242639582207, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24306011854.97872, "policy_loss": -0.005850469039634187, "vf_loss": 24306011854.97872, "vf_explained_var": -7.609103391814642e-08, "kl": 0.012518344169601481, "entropy": 2.9030445890223726, "entropy_coeff": 0.0}}}, "num_steps_sampled": 384384, "num_agent_steps_sampled": 768768, "num_steps_trained": 384384, "num_agent_steps_trained": 768768}, "done": false, "episodes_total": 384, "training_iteration": 64, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-43-26", "timestamp": 1624963406, "time_this_iter_s": 25.54835844039917, "time_total_s": 1613.187649011612, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e359d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e350d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1613.187649011612, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 31.487878787878792, "ram_util_percent": 67.03939393939395, "gpu_util_percent0": 0.38060606060606056, "vram_util_percent0": 0.3028464626037932}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1734346.7629420748, "pol1": 1734346.7629420748}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1619116.3899326643, -1746635.808366366, -1811045.6396407755, -1673079.1004768864, -1755406.3712468243, -1826524.4175834723, -1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428], "policy_pol1_reward": [1619116.3899326643, 1746635.808366366, 1811045.6396407755, 1673079.1004768864, 1755406.3712468243, 1826524.4175834723, 1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2734259169803284, "mean_inference_ms": 3.7614664180971613, "mean_action_processing_ms": 0.1880877249242157, "mean_env_wait_ms": 0.14270656579151342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 390390, "agent_timesteps_total": 780780, "timers": {"sample_time_ms": 4558.741, "sample_throughput": 1317.469, "learn_time_ms": 20764.235, "learn_throughput": 289.247, "update_time_ms": 5.133}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 24307799366.80851, "policy_loss": 0.0039410179758325534, "vf_loss": 24307799366.80851, "vf_explained_var": 1.318911273529011e-07, "kl": 0.008155614415064771, "entropy": 2.8100230085088853, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24485229807.659573, "policy_loss": -0.003484622119589055, "vf_loss": 24485229807.659573, "vf_explained_var": -2.5363679156953367e-08, "kl": 0.007411843789939551, "entropy": 2.6635508841656623, "entropy_coeff": 0.0}}}, "num_steps_sampled": 390390, "num_agent_steps_sampled": 780780, "num_steps_trained": 390390, "num_agent_steps_trained": 780780}, "done": false, "episodes_total": 390, "training_iteration": 65, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-43-52", "timestamp": 1624963432, "time_this_iter_s": 25.360124826431274, "time_total_s": 1638.5477738380432, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06277b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1638.5477738380432, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 30.129411764705885, "ram_util_percent": 67.11176470588235, "gpu_util_percent0": 0.38, "vram_util_percent0": 0.3019141933821052}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1731259.1537703967, "pol1": 1731259.1537703967}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1866061.6727837522, -1715634.6285092817, -1437919.691164219, -1704490.9007223211, -1871998.3016250622, -1836360.1467226339, -1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543], "policy_pol1_reward": [1866061.6727837522, 1715634.6285092817, 1437919.691164219, 1704490.9007223211, 1871998.3016250622, 1836360.1467226339, 1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27353393420011757, "mean_inference_ms": 3.7625905727368694, "mean_action_processing_ms": 0.18814800602949533, "mean_env_wait_ms": 0.14274863675206043, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 396396, "agent_timesteps_total": 792792, "timers": {"sample_time_ms": 4556.829, "sample_throughput": 1318.022, "learn_time_ms": 20752.569, "learn_throughput": 289.41, "update_time_ms": 5.178}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4416259765625001, "cur_lr": 5.000000000000002e-05, "total_loss": 24181278327.82979, "policy_loss": -0.0015204506827161668, "vf_loss": 24181278327.82979, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.0032590263116946245, "entropy": 2.8613313512599214, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24359760046.29787, "policy_loss": -0.0026076120086648362, "vf_loss": 24359760046.29787, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.010777008462142437, "entropy": 2.6579590097386787, "entropy_coeff": 0.0}}}, "num_steps_sampled": 396396, "num_agent_steps_sampled": 792792, "num_steps_trained": 396396, "num_agent_steps_trained": 792792}, "done": false, "episodes_total": 396, "training_iteration": 66, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-44-17", "timestamp": 1624963457, "time_this_iter_s": 25.144871473312378, "time_total_s": 1663.6926453113556, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05ca268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1663.6926453113556, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 30.060606060606062, "ram_util_percent": 67.26969696969695, "gpu_util_percent0": 0.373939393939394, "vram_util_percent0": 0.2995424416051312}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933676.4554074565, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933676.4554074565}, "policy_reward_mean": {"pol0": -1730901.5655306277, "pol1": 1730901.5655306277}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1813367.4027043525, -1861071.896484421, -1830270.6194107002, -1850724.8429244088, -1824240.508438614, -1626424.5248003916, -1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016], "policy_pol1_reward": [1813367.4027043525, 1861071.896484421, 1830270.6194107002, 1850724.8429244088, 1824240.508438614, 1626424.5248003916, 1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2736285015741546, "mean_inference_ms": 3.7637911046802865, "mean_action_processing_ms": 0.18821365827607633, "mean_env_wait_ms": 0.14279112149205345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 402402, "agent_timesteps_total": 804804, "timers": {"sample_time_ms": 4574.962, "sample_throughput": 1312.798, "learn_time_ms": 20734.106, "learn_throughput": 289.668, "update_time_ms": 5.12}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7208129882812501, "cur_lr": 5.000000000000002e-05, "total_loss": 25242319240.17021, "policy_loss": -0.002339947374260172, "vf_loss": 25242319240.17021, "vf_explained_var": -2.029094225974859e-08, "kl": 0.003704661706541764, "entropy": 2.781356152067793, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25430676763.234043, "policy_loss": -0.003865506737790209, "vf_loss": 25430676763.234043, "vf_explained_var": 0.0, "kl": 0.009145673384216237, "entropy": 2.6288482483397138, "entropy_coeff": 0.0}}}, "num_steps_sampled": 402402, "num_agent_steps_sampled": 804804, "num_steps_trained": 402402, "num_agent_steps_trained": 804804}, "done": false, "episodes_total": 402, "training_iteration": 67, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-44-42", "timestamp": 1624963482, "time_this_iter_s": 25.17129898071289, "time_total_s": 1688.8639442920685, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1688.8639442920685, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 30.88484848484849, "ram_util_percent": 67.15454545454544, "gpu_util_percent0": 0.3851515151515152, "vram_util_percent0": 0.2996037217473011}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1727301.484459693, "pol1": 1727301.484459693}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1649185.340468582, -1549456.3349558013, -1856897.9408899483, -1734418.6113245103, -1732734.8253846401, -1933676.4554074565, -1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432], "policy_pol1_reward": [1649185.340468582, 1549456.3349558013, 1856897.9408899483, 1734418.6113245103, 1732734.8253846401, 1933676.4554074565, 1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2737148269584425, "mean_inference_ms": 3.7650168574869394, "mean_action_processing_ms": 0.18827422402018212, "mean_env_wait_ms": 0.14283004840798547, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 408408, "agent_timesteps_total": 816816, "timers": {"sample_time_ms": 4579.961, "sample_throughput": 1311.365, "learn_time_ms": 20696.929, "learn_throughput": 290.188, "update_time_ms": 5.076}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5.000000000000002e-05, "total_loss": 25548889676.255318, "policy_loss": 0.00036690185995812114, "vf_loss": 25548889676.255318, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.007180164786095315, "entropy": 2.7816191226878066, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25742722331.234043, "policy_loss": -0.004257596771609276, "vf_loss": 25742722331.234043, "vf_explained_var": -1.5725480295714078e-07, "kl": 0.011801529616276, "entropy": 2.7405180981818664, "entropy_coeff": 0.0}}}, "num_steps_sampled": 408408, "num_agent_steps_sampled": 816816, "num_steps_trained": 408408, "num_agent_steps_trained": 816816}, "done": false, "episodes_total": 408, "training_iteration": 68, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-45-07", "timestamp": 1624963507, "time_this_iter_s": 25.159953594207764, "time_total_s": 1714.0238978862762, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1714.0238978862762, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 29.89090909090909, "ram_util_percent": 67.45454545454545, "gpu_util_percent0": 0.376060606060606, "vram_util_percent0": 0.29952201489107455}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1152708.7794148892}, "policy_reward_max": {"pol0": -1152708.7794148892, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1725909.343182943, "pol1": 1725909.343182943}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1677951.2953732046, -1152708.7794148892, -1886031.634683175, -1814075.6054697954, -1816945.5073884837, -1681516.8020799796, -1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291], "policy_pol1_reward": [1677951.2953732046, 1152708.7794148892, 1886031.634683175, 1814075.6054697954, 1816945.5073884837, 1681516.8020799796, 1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2738061907643363, "mean_inference_ms": 3.76619032878402, "mean_action_processing_ms": 0.18833353529195698, "mean_env_wait_ms": 0.1428671173139945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 414414, "agent_timesteps_total": 828828, "timers": {"sample_time_ms": 4584.89, "sample_throughput": 1309.955, "learn_time_ms": 20718.599, "learn_throughput": 289.884, "update_time_ms": 5.083}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5.000000000000002e-05, "total_loss": 24689068685.61702, "policy_loss": 0.002006346141879863, "vf_loss": 24689068685.61702, "vf_explained_var": -1.1033200308929736e-07, "kl": 0.01877454680172687, "entropy": 2.794835476165122, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24880610892.255318, "policy_loss": -0.006445023904931038, "vf_loss": 24880610892.255318, "vf_explained_var": -3.804551784725163e-09, "kl": 0.011989845418708121, "entropy": 2.8196572953082146, "entropy_coeff": 0.0}}}, "num_steps_sampled": 414414, "num_agent_steps_sampled": 828828, "num_steps_trained": 414414, "num_agent_steps_trained": 828828}, "done": false, "episodes_total": 414, "training_iteration": 69, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-45-33", "timestamp": 1624963533, "time_this_iter_s": 25.397393941879272, "time_total_s": 1739.4212918281555, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c79d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1739.4212918281555, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 30.16176470588235, "ram_util_percent": 67.38823529411764, "gpu_util_percent0": 0.38029411764705884, "vram_util_percent0": 0.2995449949443883}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1733936.087186213, "pol1": 1733936.087186213}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1859429.2861924933, -1899529.9234053951, -1688476.766427955, -1697684.5816944346, -1651253.2898127674, -1720729.5196248135, -1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686], "policy_pol1_reward": [1859429.2861924933, 1899529.9234053951, 1688476.766427955, 1697684.5816944346, 1651253.2898127674, 1720729.5196248135, 1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27390999471107735, "mean_inference_ms": 3.7674377306606424, "mean_action_processing_ms": 0.18839833437454445, "mean_env_wait_ms": 0.14290695060252323, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 420420, "agent_timesteps_total": 840840, "timers": {"sample_time_ms": 4592.398, "sample_throughput": 1307.813, "learn_time_ms": 20739.387, "learn_throughput": 289.594, "update_time_ms": 5.241}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5.000000000000002e-05, "total_loss": 27374178434.723404, "policy_loss": 0.0017538467778804455, "vf_loss": 27374178434.723404, "vf_explained_var": 3.0436414277801305e-08, "kl": 0.011677822950197028, "entropy": 2.8212066203989883, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 27587051825.02128, "policy_loss": -0.004314565198852661, "vf_loss": 27587051825.02128, "vf_explained_var": -1.065274517486614e-07, "kl": 0.019198416593544026, "entropy": 3.0113475931451674, "entropy_coeff": 0.0}}}, "num_steps_sampled": 420420, "num_agent_steps_sampled": 840840, "num_steps_trained": 420420, "num_agent_steps_trained": 840840}, "done": false, "episodes_total": 420, "training_iteration": 70, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-45-58", "timestamp": 1624963558, "time_this_iter_s": 25.492274522781372, "time_total_s": 1764.913566350937, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05caea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca7b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1764.913566350937, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 31.730303030303027, "ram_util_percent": 67.21515151515153, "gpu_util_percent0": 0.3839393939393939, "vram_util_percent0": 0.3039546118413661}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1733232.639281413, "pol1": 1733232.639281413}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1746717.9867937798, -1684467.0834067685, -1599190.8182623193, -1881617.800964683, -1679809.9542048895, -1837862.0027131764, -1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892], "policy_pol1_reward": [1746717.9867937798, 1684467.0834067685, 1599190.8182623193, 1881617.800964683, 1679809.9542048895, 1837862.0027131764, 1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2740054110738701, "mean_inference_ms": 3.7687791647934232, "mean_action_processing_ms": 0.18846160084304472, "mean_env_wait_ms": 0.14294502189676858, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 426426, "agent_timesteps_total": 852852, "timers": {"sample_time_ms": 4603.51, "sample_throughput": 1304.657, "learn_time_ms": 20724.54, "learn_throughput": 289.801, "update_time_ms": 5.237}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5.000000000000002e-05, "total_loss": 25479099500.93617, "policy_loss": -0.0038286425529959352, "vf_loss": 25479099500.93617, "vf_explained_var": -1.0018653284760148e-07, "kl": 0.01028778271234416, "entropy": 2.8121498341256, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25683705812.425533, "policy_loss": -0.0048818447567681045, "vf_loss": 25683705812.425533, "vf_explained_var": 8.87728734966231e-09, "kl": 0.0095883300726084, "entropy": 3.2201309660647777, "entropy_coeff": 0.0}}}, "num_steps_sampled": 426426, "num_agent_steps_sampled": 852852, "num_steps_trained": 426426, "num_agent_steps_trained": 852852}, "done": false, "episodes_total": 426, "training_iteration": 71, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-46-24", "timestamp": 1624963584, "time_this_iter_s": 25.368374347686768, "time_total_s": 1790.2819406986237, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cad90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1790.2819406986237, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 30.34705882352941, "ram_util_percent": 67.25294117647057, "gpu_util_percent0": 0.3708823529411765, "vram_util_percent0": 0.30653363468744427}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1730072.6915597299, "pol1": 1730072.6915597299}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1866127.1225882918, -1427524.9720724851, -1690191.1585664516, -1924260.9564668636, -1723236.3108609156, -1772299.8111768127, -1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823], "policy_pol1_reward": [1866127.1225882918, 1427524.9720724851, 1690191.1585664516, 1924260.9564668636, 1723236.3108609156, 1772299.8111768127, 1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2741166944697641, "mean_inference_ms": 3.77017286425208, "mean_action_processing_ms": 0.18852578675191559, "mean_env_wait_ms": 0.1429838534300111, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 432432, "agent_timesteps_total": 864864, "timers": {"sample_time_ms": 4613.061, "sample_throughput": 1301.955, "learn_time_ms": 20699.307, "learn_throughput": 290.155, "update_time_ms": 5.237}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5.000000000000002e-05, "total_loss": 23913455572.425533, "policy_loss": 0.003209870308637619, "vf_loss": 23913455572.425533, "vf_explained_var": 1.2174565711120522e-07, "kl": 0.02899788050575459, "entropy": 2.8139855354390244, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24099966235.234043, "policy_loss": -0.0011687479080989005, "vf_loss": 24099966235.234043, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.012974555782498197, "entropy": 3.392048480662894, "entropy_coeff": 0.0}}}, "num_steps_sampled": 432432, "num_agent_steps_sampled": 864864, "num_steps_trained": 432432, "num_agent_steps_trained": 864864}, "done": false, "episodes_total": 432, "training_iteration": 72, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-46-49", "timestamp": 1624963609, "time_this_iter_s": 25.438740968704224, "time_total_s": 1815.7206816673279, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05ca840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1815.7206816673279, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 30.91212121212121, "ram_util_percent": 67.14545454545454, "gpu_util_percent0": 0.3827272727272727, "vram_util_percent0": 0.30662540470427224}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1728709.8026715666, "pol1": 1728709.8026715666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1750499.4143177802, -1689713.0777258233, -1595319.445525968, -1522873.0637270417, -1595977.4156404906, -1648609.4436400207, -1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082], "policy_pol1_reward": [1750499.4143177802, 1689713.0777258233, 1595319.445525968, 1522873.0637270417, 1595977.4156404906, 1648609.4436400207, 1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2742324316880432, "mean_inference_ms": 3.77147479919965, "mean_action_processing_ms": 0.188586590968933, "mean_env_wait_ms": 0.14301964478549395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 438438, "agent_timesteps_total": 876876, "timers": {"sample_time_ms": 4608.23, "sample_throughput": 1303.32, "learn_time_ms": 20725.694, "learn_throughput": 289.785, "update_time_ms": 5.264}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 24464173317.446808, "policy_loss": 0.004449264047310707, "vf_loss": 24464173317.446808, "vf_explained_var": 1.280865831176925e-07, "kl": 0.015574533175280753, "entropy": 2.7779020552939557, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24657085026.042553, "policy_loss": -0.0025160130351147753, "vf_loss": 24657085026.042553, "vf_explained_var": 1.242820246716292e-07, "kl": 0.013470711543204937, "entropy": 3.44990492374339, "entropy_coeff": 0.0}}}, "num_steps_sampled": 438438, "num_agent_steps_sampled": 876876, "num_steps_trained": 438438, "num_agent_steps_trained": 876876}, "done": false, "episodes_total": 438, "training_iteration": 73, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-47-15", "timestamp": 1624963635, "time_this_iter_s": 25.394328594207764, "time_total_s": 1841.1150102615356, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1841.1150102615356, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 30.129411764705885, "ram_util_percent": 67.33529411764707, "gpu_util_percent0": 0.38529411764705884, "vram_util_percent0": 0.30653859116953147}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1733984.7119691975, "pol1": 1733984.7119691975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1490749.7341304035, -1754472.4773448051, -1899463.659748626, -1831568.0649983746, -1663048.126882021, -1733923.5087744407, -1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663], "policy_pol1_reward": [1490749.7341304035, 1754472.4773448051, 1899463.659748626, 1831568.0649983746, 1663048.126882021, 1733923.5087744407, 1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.274354877987085, "mean_inference_ms": 3.772820695303464, "mean_action_processing_ms": 0.18864773166592685, "mean_env_wait_ms": 0.14305705638921778, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 444444, "agent_timesteps_total": 888888, "timers": {"sample_time_ms": 4605.73, "sample_throughput": 1304.028, "learn_time_ms": 20702.658, "learn_throughput": 290.108, "update_time_ms": 5.241}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 24862439641.87234, "policy_loss": -0.003553439526164785, "vf_loss": 24862439641.87234, "vf_explained_var": 3.2972781838225274e-08, "kl": 0.011825205262829649, "entropy": 2.812540348539961, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25064118141.276596, "policy_loss": -0.002871687187159315, "vf_loss": 25064118141.276596, "vf_explained_var": -3.170459805801329e-08, "kl": 0.013647323117611255, "entropy": 3.4703581688251903, "entropy_coeff": 0.0}}}, "num_steps_sampled": 444444, "num_agent_steps_sampled": 888888, "num_steps_trained": 444444, "num_agent_steps_trained": 888888}, "done": false, "episodes_total": 444, "training_iteration": 74, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-47-40", "timestamp": 1624963660, "time_this_iter_s": 25.29321050643921, "time_total_s": 1866.4082207679749, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05caa60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1866.4082207679749, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 31.690909090909088, "ram_util_percent": 67.0848484848485, "gpu_util_percent0": 0.3833333333333333, "vram_util_percent0": 0.30661008466872974}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1733808.1041138708, "pol1": 1733808.1041138708}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1880556.4520337936, -1832539.300646848, -1750045.3221093153, -1743134.1791256708, -1649269.9870360498, -1700112.5956712419, -1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289], "policy_pol1_reward": [1880556.4520337936, 1832539.300646848, 1750045.3221093153, 1743134.1791256708, 1649269.9870360498, 1700112.5956712419, 1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2744912020224998, "mean_inference_ms": 3.7741949540542366, "mean_action_processing_ms": 0.18870905035414196, "mean_env_wait_ms": 0.14309481385052136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 450450, "agent_timesteps_total": 900900, "timers": {"sample_time_ms": 4610.432, "sample_throughput": 1302.698, "learn_time_ms": 20796.575, "learn_throughput": 288.798, "update_time_ms": 5.15}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 24943404053.787235, "policy_loss": 0.0008748425765240446, "vf_loss": 24943404053.787235, "vf_explained_var": -3.424096561843726e-08, "kl": 0.016550240305034405, "entropy": 2.7069194063227227, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25159475156.425533, "policy_loss": -0.004726519233527336, "vf_loss": 25159475156.425533, "vf_explained_var": 1.3823205335938837e-07, "kl": 0.012221571117481018, "entropy": 3.3448238677166877, "entropy_coeff": 0.0}}}, "num_steps_sampled": 450450, "num_agent_steps_sampled": 900900, "num_steps_trained": 450450, "num_agent_steps_trained": 900900}, "done": false, "episodes_total": 450, "training_iteration": 75, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-48-06", "timestamp": 1624963686, "time_this_iter_s": 26.345083951950073, "time_total_s": 1892.753304719925, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1892.753304719925, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 31.39411764705882, "ram_util_percent": 67.12058823529412, "gpu_util_percent0": 0.37852941176470584, "vram_util_percent0": 0.3065187652411825}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1732044.3433542808, "pol1": 1732044.3433542808}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1725703.8517998126, -1848550.2965329972, -1809819.9679701892, -1732394.961418605, -1848777.8420305306, -1805650.7650259708, -1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562], "policy_pol1_reward": [1725703.8517998126, 1848550.2965329972, 1809819.9679701892, 1732394.961418605, 1848777.8420305306, 1805650.7650259708, 1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2746241525572353, "mean_inference_ms": 3.7754926086216924, "mean_action_processing_ms": 0.18876827489158482, "mean_env_wait_ms": 0.14313022324317573, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 456456, "agent_timesteps_total": 912912, "timers": {"sample_time_ms": 4606.627, "sample_throughput": 1303.774, "learn_time_ms": 20805.309, "learn_throughput": 288.676, "update_time_ms": 5.169}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 25203015723.574467, "policy_loss": -0.0002985570104198253, "vf_loss": 25203015723.574467, "vf_explained_var": 4.058188451949718e-08, "kl": 0.013437454450003643, "entropy": 2.7518443148186864, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25422122964.425533, "policy_loss": -0.003241437873704002, "vf_loss": 25422122964.425533, "vf_explained_var": -7.609103569450326e-09, "kl": 0.01061128418734099, "entropy": 3.190561532974243, "entropy_coeff": 0.0}}}, "num_steps_sampled": 456456, "num_agent_steps_sampled": 912912, "num_steps_trained": 456456, "num_agent_steps_trained": 912912}, "done": false, "episodes_total": 456, "training_iteration": 76, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-48-32", "timestamp": 1624963712, "time_this_iter_s": 25.19498634338379, "time_total_s": 1917.9482910633087, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c78c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1917.9482910633087, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 30.224242424242426, "ram_util_percent": 67.29090909090908, "gpu_util_percent0": 0.38363636363636366, "vram_util_percent0": 0.30650284441993236}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1730922.4050109792, "pol1": 1730922.4050109792}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1893949.6790484588, -1673675.4322561263, -1807722.6365244742, -1596620.1851475432, -1582949.967607253, -1777219.191564655, -1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103], "policy_pol1_reward": [1893949.6790484588, 1673675.4322561263, 1807722.6365244742, 1596620.1851475432, 1582949.967607253, 1777219.191564655, 1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27475347788687016, "mean_inference_ms": 3.7767667731419357, "mean_action_processing_ms": 0.18882692976536075, "mean_env_wait_ms": 0.14316575028487977, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 462462, "agent_timesteps_total": 924924, "timers": {"sample_time_ms": 4609.309, "sample_throughput": 1303.015, "learn_time_ms": 20839.425, "learn_throughput": 288.204, "update_time_ms": 5.131}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5406097412109373, "cur_lr": 5.000000000000002e-05, "total_loss": 26431420110.97872, "policy_loss": 0.0025587368439486686, "vf_loss": 26431420110.97872, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.021771684526763063, "entropy": 2.733608088594802, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26662688332.255318, "policy_loss": -0.005447267455623505, "vf_loss": 26662688332.255318, "vf_explained_var": -6.340919789238342e-09, "kl": 0.013363645372397088, "entropy": 3.106273093122117, "entropy_coeff": 0.0}}}, "num_steps_sampled": 462462, "num_agent_steps_sampled": 924924, "num_steps_trained": 462462, "num_agent_steps_trained": 924924}, "done": false, "episodes_total": 462, "training_iteration": 77, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-48-57", "timestamp": 1624963737, "time_this_iter_s": 25.539206981658936, "time_total_s": 1943.4874980449677, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06277b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1943.4874980449677, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 31.497058823529407, "ram_util_percent": 67.04117647058823, "gpu_util_percent0": 0.3811764705882353, "vram_util_percent0": 0.30660302543666607}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1734956.6288093328, "pol1": 1734956.6288093328}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1867994.7727651738, -1789774.7741413591, -1777485.27570264, -1757695.2426676478, -1703838.343007941, -1726485.5572167346, -1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153], "policy_pol1_reward": [1867994.7727651738, 1789774.7741413591, 1777485.27570264, 1757695.2426676478, 1703838.343007941, 1726485.5572167346, 1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2748793645740752, "mean_inference_ms": 3.777993865734506, "mean_action_processing_ms": 0.18888174473162983, "mean_env_wait_ms": 0.143198475584126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 468468, "agent_timesteps_total": 936936, "timers": {"sample_time_ms": 4602.092, "sample_throughput": 1305.059, "learn_time_ms": 20862.433, "learn_throughput": 287.886, "update_time_ms": 5.183}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 26736863232.0, "policy_loss": -0.0018749680528615384, "vf_loss": 26736863232.0, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.016427184078604617, "entropy": 2.752085675584509, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26974356414.638298, "policy_loss": -0.007903517005925483, "vf_loss": 26974356414.638298, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.014882521802916172, "entropy": 3.064787966139773, "entropy_coeff": 0.0}}}, "num_steps_sampled": 468468, "num_agent_steps_sampled": 936936, "num_steps_trained": 468468, "num_agent_steps_trained": 936936}, "done": false, "episodes_total": 468, "training_iteration": 78, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-49-22", "timestamp": 1624963762, "time_this_iter_s": 25.318916082382202, "time_total_s": 1968.8064141273499, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1968.8064141273499, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 31.009090909090908, "ram_util_percent": 67.16363636363636, "gpu_util_percent0": 0.3784848484848484, "vram_util_percent0": 0.3065436978480457}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1734339.9976008844, "pol1": 1734339.9976008844}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1810155.1214825346, -1858444.2832687744, -1635571.5772055732, -1763380.55885684, -1658808.415769965, -1746944.9793525792, -1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097], "policy_pol1_reward": [1810155.1214825346, 1858444.2832687744, 1635571.5772055732, 1763380.55885684, 1658808.415769965, 1746944.9793525792, 1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27498450156373605, "mean_inference_ms": 3.7792550568511563, "mean_action_processing_ms": 0.18893843714594394, "mean_env_wait_ms": 0.14323293691582875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 474474, "agent_timesteps_total": 948948, "timers": {"sample_time_ms": 4607.435, "sample_throughput": 1303.545, "learn_time_ms": 20857.903, "learn_throughput": 287.948, "update_time_ms": 5.162}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 25964864490.212765, "policy_loss": -0.0011162593009624076, "vf_loss": 25964864490.212765, "vf_explained_var": -1.3442749491332506e-07, "kl": 0.006975475064617522, "entropy": 2.6950147101219666, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26196451850.893616, "policy_loss": -0.005717662381047898, "vf_loss": 26196451850.893616, "vf_explained_var": -3.677733317886123e-08, "kl": 0.011495755153133514, "entropy": 3.020541145446453, "entropy_coeff": 0.0}}}, "num_steps_sampled": 474474, "num_agent_steps_sampled": 948948, "num_steps_trained": 474474, "num_agent_steps_trained": 948948}, "done": false, "episodes_total": 474, "training_iteration": 79, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-49-48", "timestamp": 1624963788, "time_this_iter_s": 25.405704498291016, "time_total_s": 1994.2121186256409, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1994.2121186256409, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 30.57272727272727, "ram_util_percent": 67.24242424242425, "gpu_util_percent0": 0.37787878787878787, "vram_util_percent0": 0.3067326449530697}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1732318.6268178558, "pol1": 1732318.6268178558}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1671688.510640228, -1389550.1800446417, -1872419.174825094, -1836658.2735673895, -1824774.4216729363, -1681558.563384267, -1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507], "policy_pol1_reward": [1671688.510640228, 1389550.1800446417, 1872419.174825094, 1836658.2735673895, 1824774.4216729363, 1681558.563384267, 1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27509086745148587, "mean_inference_ms": 3.7805961497097886, "mean_action_processing_ms": 0.18899896592694396, "mean_env_wait_ms": 0.14326939001126976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 480480, "agent_timesteps_total": 960960, "timers": {"sample_time_ms": 4606.553, "sample_throughput": 1303.795, "learn_time_ms": 20874.813, "learn_throughput": 287.715, "update_time_ms": 4.966}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 24478101634.723404, "policy_loss": 0.0027207115149878443, "vf_loss": 24478101634.723404, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.012690633059816157, "entropy": 2.6398267644516964, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24700058515.06383, "policy_loss": -0.005908665742645872, "vf_loss": 24700058515.06383, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.0076210344547128425, "entropy": 3.0846702443792466, "entropy_coeff": 0.0}}}, "num_steps_sampled": 480480, "num_agent_steps_sampled": 960960, "num_steps_trained": 480480, "num_agent_steps_trained": 960960}, "done": false, "episodes_total": 480, "training_iteration": 80, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-50-14", "timestamp": 1624963814, "time_this_iter_s": 25.649339199066162, "time_total_s": 2019.861457824707, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05ca730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca7b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2019.861457824707, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 31.335294117647067, "ram_util_percent": 67.0205882352941, "gpu_util_percent0": 0.38058823529411767, "vram_util_percent0": 0.30664763377545157}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1734268.5174784965, "pol1": 1734268.5174784965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1700194.8095606684, -1719502.3714662043, -1723256.2619615444, -1577203.4380285428, -1910504.802136956, -1856152.6761548058, -1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738], "policy_pol1_reward": [1700194.8095606684, 1719502.3714662043, 1723256.2619615444, 1577203.4380285428, 1910504.802136956, 1856152.6761548058, 1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2751966550946021, "mean_inference_ms": 3.7819629506586887, "mean_action_processing_ms": 0.18906023295422741, "mean_env_wait_ms": 0.1433054341180959, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 486486, "agent_timesteps_total": 972972, "timers": {"sample_time_ms": 4600.537, "sample_throughput": 1305.5, "learn_time_ms": 20903.823, "learn_throughput": 287.316, "update_time_ms": 4.947}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 25609660895.31915, "policy_loss": -0.0002884362487399832, "vf_loss": 25609660895.31915, "vf_explained_var": -1.3696386247374903e-07, "kl": 0.011561985642827571, "entropy": 2.6564564197621445, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25849838613.787235, "policy_loss": -0.003875871169123244, "vf_loss": 25849838613.787235, "vf_explained_var": -4.945917453369475e-08, "kl": 0.007457325353901437, "entropy": 3.162511079869372, "entropy_coeff": 0.0}}}, "num_steps_sampled": 486486, "num_agent_steps_sampled": 972972, "num_steps_trained": 486486, "num_agent_steps_trained": 972972}, "done": false, "episodes_total": 486, "training_iteration": 81, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-50-39", "timestamp": 1624963839, "time_this_iter_s": 25.597503185272217, "time_total_s": 2045.4589610099792, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7ae4194400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2045.4589610099792, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 30.914705882352937, "ram_util_percent": 67.14999999999998, "gpu_util_percent0": 0.37970588235294117, "vram_util_percent0": 0.3067665893455461}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1733725.2783003738, "pol1": 1733725.2783003738}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1507866.711479719, -1720941.0685562969, -1333063.6942378676, -1794517.8575134543, -1785485.449976417, -1846109.6876927551, -1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075], "policy_pol1_reward": [1507866.711479719, 1720941.0685562969, 1333063.6942378676, 1794517.8575134543, 1785485.449976417, 1846109.6876927551, 1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2753103673241291, "mean_inference_ms": 3.7833537808139335, "mean_action_processing_ms": 0.18912271613741397, "mean_env_wait_ms": 0.1433432029812096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 492492, "agent_timesteps_total": 984984, "timers": {"sample_time_ms": 4608.655, "sample_throughput": 1303.2, "learn_time_ms": 20894.606, "learn_throughput": 287.443, "update_time_ms": 4.97}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 25163432371.744682, "policy_loss": 0.006711954825577584, "vf_loss": 25163432371.744682, "vf_explained_var": -1.4203659759459697e-07, "kl": 0.013199984076175285, "entropy": 2.6738516675665025, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25394146848.68085, "policy_loss": -0.0044054396727934795, "vf_loss": 25394146848.68085, "vf_explained_var": -1.065274517486614e-07, "kl": 0.008843840763686186, "entropy": 3.096408209902175, "entropy_coeff": 0.0}}}, "num_steps_sampled": 492492, "num_agent_steps_sampled": 984984, "num_steps_trained": 492492, "num_agent_steps_trained": 984984}, "done": false, "episodes_total": 492, "training_iteration": 82, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-51-05", "timestamp": 1624963865, "time_this_iter_s": 25.426650285720825, "time_total_s": 2070.8856112957, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05ca400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2070.8856112957, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 30.660606060606067, "ram_util_percent": 67.29696969696968, "gpu_util_percent0": 0.37606060606060604, "vram_util_percent0": 0.30664072473981474}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933833.9052309182, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1933833.9052309182}, "policy_reward_mean": {"pol0": -1731019.197372378, "pol1": 1731019.197372378}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1706696.1116882009, -1600963.499619993, -1582360.7261300269, -1875091.042443016, -1933833.9052309182, -1801837.859756165, -1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794], "policy_pol1_reward": [1706696.1116882009, 1600963.499619993, 1582360.7261300269, 1875091.042443016, 1933833.9052309182, 1801837.859756165, 1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27542435824502665, "mean_inference_ms": 3.7848676353322275, "mean_action_processing_ms": 0.18919101128839494, "mean_env_wait_ms": 0.14338504246163578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 498498, "agent_timesteps_total": 996996, "timers": {"sample_time_ms": 4631.549, "sample_throughput": 1296.758, "learn_time_ms": 20887.992, "learn_throughput": 287.534, "update_time_ms": 4.944}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 22143748357.446808, "policy_loss": -0.0005043185454733828, "vf_loss": 22143748357.446808, "vf_explained_var": -1.0906381930908537e-07, "kl": 0.011445030391691847, "entropy": 2.713765083475316, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 22342940454.12766, "policy_loss": -0.004324409872927564, "vf_loss": 22342940454.12766, "vf_explained_var": -5.199554209411872e-08, "kl": 0.009887491828425134, "entropy": 3.0408420359834714, "entropy_coeff": 0.0}}}, "num_steps_sampled": 498498, "num_agent_steps_sampled": 996996, "num_steps_trained": 498498, "num_agent_steps_trained": 996996}, "done": false, "episodes_total": 498, "training_iteration": 83, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-51-30", "timestamp": 1624963890, "time_this_iter_s": 25.556732416152954, "time_total_s": 2096.442343711853, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2096.442343711853, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 31.270588235294113, "ram_util_percent": 67.04117647058823, "gpu_util_percent0": 0.3861764705882353, "vram_util_percent0": 0.3066278078471025}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1314355.7091603721}, "policy_reward_max": {"pol0": -1314355.7091603721, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1731464.7262399495, "pol1": 1731464.7262399495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1717129.6770776878, -1828721.9335805906, -1314355.7091603721, -1850212.6028637432, -1643433.9150805385, -1737774.2681420017, -1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622], "policy_pol1_reward": [1717129.6770776878, 1828721.9335805906, 1314355.7091603721, 1850212.6028637432, 1643433.9150805385, 1737774.2681420017, 1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2755551575249885, "mean_inference_ms": 3.7863481465728275, "mean_action_processing_ms": 0.18925682999331295, "mean_env_wait_ms": 0.14342801691709328, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 504504, "agent_timesteps_total": 1009008, "timers": {"sample_time_ms": 4638.389, "sample_throughput": 1294.846, "learn_time_ms": 20891.13, "learn_throughput": 287.49, "update_time_ms": 4.932}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 25844319994.553192, "policy_loss": 0.002608731706091698, "vf_loss": 25844319994.553192, "vf_explained_var": 1.2681839578476684e-08, "kl": 0.015518210511258308, "entropy": 2.761123961590706, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26090978412.93617, "policy_loss": -0.006461034667618731, "vf_loss": 26090978412.93617, "vf_explained_var": 3.804551784725163e-09, "kl": 0.013986608112587574, "entropy": 2.980457234889903, "entropy_coeff": 0.0}}}, "num_steps_sampled": 504504, "num_agent_steps_sampled": 1009008, "num_steps_trained": 504504, "num_agent_steps_trained": 1009008}, "done": false, "episodes_total": 504, "training_iteration": 84, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-51-56", "timestamp": 1624963916, "time_this_iter_s": 25.393664121627808, "time_total_s": 2121.836007833481, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c71e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2121.836007833481, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 30.966666666666665, "ram_util_percent": 67.14848484848484, "gpu_util_percent0": 0.37333333333333335, "vram_util_percent0": 0.3067479649886122}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1421714.565770825}, "policy_reward_max": {"pol0": -1421714.565770825, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1737862.5280489314, "pol1": 1737862.5280489314}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1675834.2165347163, -1724087.1618671669, -1767948.6337462035, -1768077.185385291, -1843527.5426089575, -1906037.0720395776, -1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874], "policy_pol1_reward": [1675834.2165347163, 1724087.1618671669, 1767948.6337462035, 1768077.185385291, 1843527.5426089575, 1906037.0720395776, 1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2756908409685162, "mean_inference_ms": 3.7877509876551896, "mean_action_processing_ms": 0.1893235087814216, "mean_env_wait_ms": 0.1434698527680071, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 510510, "agent_timesteps_total": 1021020, "timers": {"sample_time_ms": 4635.776, "sample_throughput": 1295.576, "learn_time_ms": 20845.333, "learn_throughput": 288.122, "update_time_ms": 4.892}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 26655958517.106384, "policy_loss": 0.0019627770488249495, "vf_loss": 26655958517.106384, "vf_explained_var": 9.765016528717751e-08, "kl": 0.016687252895629154, "entropy": 2.7760980839424945, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26905938137.87234, "policy_loss": -0.0030527164010291405, "vf_loss": 26905938137.87234, "vf_explained_var": -4.438643586013313e-08, "kl": 0.009817007711117572, "entropy": 3.0242215724701578, "entropy_coeff": 0.0}}}, "num_steps_sampled": 510510, "num_agent_steps_sampled": 1021020, "num_steps_trained": 510510, "num_agent_steps_trained": 1021020}, "done": false, "episodes_total": 510, "training_iteration": 85, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-52-22", "timestamp": 1624963942, "time_this_iter_s": 25.85990858078003, "time_total_s": 2147.695916414261, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2147.695916414261, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 31.76176470588235, "ram_util_percent": 67.55294117647058, "gpu_util_percent0": 0.37882352941176467, "vram_util_percent0": 0.3066773726679752}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1421714.565770825}, "policy_reward_max": {"pol0": -1421714.565770825, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1737998.678374798, "pol1": 1737998.678374798}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1819177.5359767668, -1766937.3727788778, -1872716.764225607, -1623507.737106686, -1687145.0425605322, -1728539.2165356076, -1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456], "policy_pol1_reward": [1819177.5359767668, 1766937.3727788778, 1872716.764225607, 1623507.737106686, 1687145.0425605322, 1728539.2165356076, 1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27582328124073063, "mean_inference_ms": 3.7892095698240653, "mean_action_processing_ms": 0.18939392873258692, "mean_env_wait_ms": 0.14351268052685562, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 516516, "agent_timesteps_total": 1033032, "timers": {"sample_time_ms": 4655.995, "sample_throughput": 1289.95, "learn_time_ms": 20872.868, "learn_throughput": 287.742, "update_time_ms": 4.838}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 26598283438.29787, "policy_loss": -0.0007414599246484168, "vf_loss": 26598283438.29787, "vf_explained_var": -9.765016528717751e-08, "kl": 0.007283665695564544, "entropy": 2.7822485883185206, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26861370433.361702, "policy_loss": -0.005902944766777627, "vf_loss": 26861370433.361702, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.013814615878335972, "entropy": 3.0433584629221166, "entropy_coeff": 0.0}}}, "num_steps_sampled": 516516, "num_agent_steps_sampled": 1033032, "num_steps_trained": 516516, "num_agent_steps_trained": 1033032}, "done": false, "episodes_total": 516, "training_iteration": 86, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-52-47", "timestamp": 1624963967, "time_this_iter_s": 25.67098116874695, "time_total_s": 2173.366897583008, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e8d400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2173.366897583008, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 30.86764705882353, "ram_util_percent": 67.21176470588235, "gpu_util_percent0": 0.38382352941176473, "vram_util_percent0": 0.30671702452467337}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1421714.565770825}, "policy_reward_max": {"pol0": -1421714.565770825, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1737356.9754165346, "pol1": 1737356.9754165346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1785853.9339111694, -1818152.7060213042, -1836575.2670966717, -1590492.4105525892, -1894869.3745546069, -1704653.2767287395, -1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482], "policy_pol1_reward": [1785853.9339111694, 1818152.7060213042, 1836575.2670966717, 1590492.4105525892, 1894869.3745546069, 1704653.2767287395, 1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2759451060142563, "mean_inference_ms": 3.7905114533936506, "mean_action_processing_ms": 0.18945569743281557, "mean_env_wait_ms": 0.1435525586570711, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 522522, "agent_timesteps_total": 1045044, "timers": {"sample_time_ms": 4653.084, "sample_throughput": 1290.757, "learn_time_ms": 20853.832, "learn_throughput": 288.005, "update_time_ms": 5.006}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 25295407714.042553, "policy_loss": -0.0009079962731041807, "vf_loss": 25295407714.042553, "vf_explained_var": 2.029094225974859e-08, "kl": 0.004848262513096028, "entropy": 2.7843102546448404, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25539386738.38298, "policy_loss": -0.0037979169035370045, "vf_loss": 25539386738.38298, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.014939837910710498, "entropy": 3.049635171890259, "entropy_coeff": 0.0}}}, "num_steps_sampled": 522522, "num_agent_steps_sampled": 1045044, "num_steps_trained": 522522, "num_agent_steps_trained": 1045044}, "done": false, "episodes_total": 522, "training_iteration": 87, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-53-13", "timestamp": 1624963993, "time_this_iter_s": 25.322333097457886, "time_total_s": 2198.6892306804657, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2198.6892306804657, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 67.27647058823528, "gpu_util_percent0": 0.38529411764705884, "vram_util_percent0": 0.30658815599040423}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1421714.565770825}, "policy_reward_max": {"pol0": -1421714.565770825, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1737389.2280737048, "pol1": 1737389.2280737048}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1790851.3666449005, -1421714.565770825, -1602190.0858806612, -1699392.2045975823, -1787525.9235253136, -1571434.3846261026, -1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183], "policy_pol1_reward": [1790851.3666449005, 1421714.565770825, 1602190.0858806612, 1699392.2045975823, 1787525.9235253136, 1571434.3846261026, 1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2760751562508041, "mean_inference_ms": 3.7917775921414703, "mean_action_processing_ms": 0.18952130312026547, "mean_env_wait_ms": 0.14359527744237033, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 528528, "agent_timesteps_total": 1057056, "timers": {"sample_time_ms": 4659.647, "sample_throughput": 1288.939, "learn_time_ms": 20865.669, "learn_throughput": 287.841, "update_time_ms": 5.0}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4054573059082032, "cur_lr": 5.000000000000002e-05, "total_loss": 26303594147.404255, "policy_loss": 0.001338948238086193, "vf_loss": 26303594147.404255, "vf_explained_var": -1.065274517486614e-07, "kl": 0.01005146509789406, "entropy": 2.8102131650802935, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26563507962.553192, "policy_loss": -0.005073124067263401, "vf_loss": 26563507962.553192, "vf_explained_var": 1.0906381930908537e-07, "kl": 0.010093788180421007, "entropy": 2.8397705757871585, "entropy_coeff": 0.0}}}, "num_steps_sampled": 528528, "num_agent_steps_sampled": 1057056, "num_steps_trained": 528528, "num_agent_steps_trained": 1057056}, "done": false, "episodes_total": 528, "training_iteration": 88, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-53-38", "timestamp": 1624964018, "time_this_iter_s": 25.50306534767151, "time_total_s": 2224.192296028137, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05ca620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ca2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2224.192296028137, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 31.503030303030307, "ram_util_percent": 67.18484848484849, "gpu_util_percent0": 0.38363636363636366, "vram_util_percent0": 0.3067377516315838}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1431406.6775278852}, "policy_reward_max": {"pol0": -1431406.6775278852, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1742693.4423711214, "pol1": 1742693.4423711214}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1728760.0461643666, -1690751.7678120036, -1691986.1223126156, -1796893.198475082, -1840890.7537475615, -1622432.0631364032, -1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937], "policy_pol1_reward": [1728760.0461643666, 1690751.7678120036, 1691986.1223126156, 1796893.198475082, 1840890.7537475615, 1622432.0631364032, 1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27618550266477443, "mean_inference_ms": 3.7930046089741007, "mean_action_processing_ms": 0.1895846461789234, "mean_env_wait_ms": 0.14363726191996073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 534534, "agent_timesteps_total": 1069068, "timers": {"sample_time_ms": 4661.487, "sample_throughput": 1288.43, "learn_time_ms": 20854.575, "learn_throughput": 287.994, "update_time_ms": 5.107}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4054573059082032, "cur_lr": 5.000000000000002e-05, "total_loss": 25213959538.38298, "policy_loss": -0.0008368163983872596, "vf_loss": 25213959538.38298, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.008447927373283088, "entropy": 2.653043949857671, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25469071665.02128, "policy_loss": -0.005288586733823127, "vf_loss": 25469071665.02128, "vf_explained_var": 2.029094225974859e-08, "kl": 0.00949089960294201, "entropy": 2.7669612600448286, "entropy_coeff": 0.0}}}, "num_steps_sampled": 534534, "num_agent_steps_sampled": 1069068, "num_steps_trained": 534534, "num_agent_steps_trained": 1069068}, "done": false, "episodes_total": 534, "training_iteration": 89, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-54-04", "timestamp": 1624964044, "time_this_iter_s": 25.31637406349182, "time_total_s": 2249.508670091629, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05ca7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cae18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2249.508670091629, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 30.079411764705885, "ram_util_percent": 67.3, "gpu_util_percent0": 0.3832352941176471, "vram_util_percent0": 0.30148297944051233}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1431406.6775278852}, "policy_reward_max": {"pol0": -1431406.6775278852, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1746205.1581435977, "pol1": 1746205.1581435977}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1515540.3362432271, -1814338.5588672098, -1684002.2558392605, -1853278.8225065663, -1819761.7343961075, -1723786.8642947944, -1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073], "policy_pol1_reward": [1515540.3362432271, 1814338.5588672098, 1684002.2558392605, 1853278.8225065663, 1819761.7343961075, 1723786.8642947944, 1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27628202378118066, "mean_inference_ms": 3.7943011615358806, "mean_action_processing_ms": 0.189650882727736, "mean_env_wait_ms": 0.1436807496255867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 540540, "agent_timesteps_total": 1081080, "timers": {"sample_time_ms": 4665.606, "sample_throughput": 1287.293, "learn_time_ms": 20846.627, "learn_throughput": 288.104, "update_time_ms": 5.086}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4054573059082032, "cur_lr": 5.000000000000002e-05, "total_loss": 26768317636.085106, "policy_loss": 0.012704887090528265, "vf_loss": 26768317636.085106, "vf_explained_var": 3.170459805801329e-08, "kl": 0.0554965355611862, "entropy": 2.775898715283008, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 27042344698.553192, "policy_loss": -0.006342147100479045, "vf_loss": 27042344698.553192, "vf_explained_var": 1.2555021555726853e-07, "kl": 0.013096539977383106, "entropy": 2.8357250132459275, "entropy_coeff": 0.0}}}, "num_steps_sampled": 540540, "num_agent_steps_sampled": 1081080, "num_steps_trained": 540540, "num_agent_steps_trained": 1081080}, "done": false, "episodes_total": 540, "training_iteration": 90, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-54-29", "timestamp": 1624964069, "time_this_iter_s": 25.611244201660156, "time_total_s": 2275.119914293289, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e352f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2275.119914293289, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 31.46969696969697, "ram_util_percent": 67.14242424242425, "gpu_util_percent0": 0.3748484848484848, "vram_util_percent0": 0.29960882842581527}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924849.7091810412, "pol1": 1431406.6775278852}, "policy_reward_max": {"pol0": -1431406.6775278852, "pol1": 1924849.7091810412}, "policy_reward_mean": {"pol0": -1747006.7572300246, "pol1": 1747006.7572300246}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1747892.9607369, -1491809.9132084276, -1924849.7091810412, -1647463.6045287289, -1700686.527729671, -1822445.320218288, -1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679], "policy_pol1_reward": [1747892.9607369, 1491809.9132084276, 1924849.7091810412, 1647463.6045287289, 1700686.527729671, 1822445.320218288, 1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27635809686028906, "mean_inference_ms": 3.7956134058020523, "mean_action_processing_ms": 0.18971728500513474, "mean_env_wait_ms": 0.1437237989321329, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 546546, "agent_timesteps_total": 1093092, "timers": {"sample_time_ms": 4675.283, "sample_throughput": 1284.628, "learn_time_ms": 20826.659, "learn_throughput": 288.38, "update_time_ms": 5.135}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6081859588623046, "cur_lr": 5.000000000000002e-05, "total_loss": 25640623822.97872, "policy_loss": 0.014987452134014444, "vf_loss": 25640623822.97872, "vf_explained_var": 2.916823049758932e-08, "kl": 0.04179311052281806, "entropy": 2.9439253147612225, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25906222886.12766, "policy_loss": -0.0031877874614710503, "vf_loss": 25906222886.12766, "vf_explained_var": 9.257743016632958e-08, "kl": 0.007140039327613851, "entropy": 2.894129367584878, "entropy_coeff": 0.0}}}, "num_steps_sampled": 546546, "num_agent_steps_sampled": 1093092, "num_steps_trained": 546546, "num_agent_steps_trained": 1093092}, "done": false, "episodes_total": 546, "training_iteration": 91, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-54-55", "timestamp": 1624964095, "time_this_iter_s": 25.494751930236816, "time_total_s": 2300.614666223526, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c79d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2300.614666223526, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 31.08823529411765, "ram_util_percent": 67.25000000000001, "gpu_util_percent0": 0.38323529411764706, "vram_util_percent0": 0.2996788199607447}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904328.3198146964, "pol1": 1431406.6775278852}, "policy_reward_max": {"pol0": -1431406.6775278852, "pol1": 1904328.3198146964}, "policy_reward_mean": {"pol0": -1747951.5622415093, "pol1": 1747951.5622415093}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1865897.9959975143, -1431406.6775278852, -1836107.2657510906, -1722737.9734394562, -1728710.620101245, -1837238.191866161, -1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935], "policy_pol1_reward": [1865897.9959975143, 1431406.6775278852, 1836107.2657510906, 1722737.9734394562, 1728710.620101245, 1837238.191866161, 1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27642469926097607, "mean_inference_ms": 3.796888977623553, "mean_action_processing_ms": 0.18978082804038268, "mean_env_wait_ms": 0.1437650442493254, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 552552, "agent_timesteps_total": 1105104, "timers": {"sample_time_ms": 4668.311, "sample_throughput": 1286.547, "learn_time_ms": 20819.835, "learn_throughput": 288.475, "update_time_ms": 5.101}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 25149041380.765957, "policy_loss": 0.0005642741997825339, "vf_loss": 25149041380.765957, "vf_explained_var": 3.170459805801329e-08, "kl": 0.020037344518177052, "entropy": 2.883168342265677, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25408479188.425533, "policy_loss": -0.00789604403395602, "vf_loss": 25408479188.425533, "vf_explained_var": 9.638198150696553e-08, "kl": 0.015408449727011489, "entropy": 2.910875457398435, "entropy_coeff": 0.0}}}, "num_steps_sampled": 552552, "num_agent_steps_sampled": 1105104, "num_steps_trained": 552552, "num_agent_steps_trained": 1105104}, "done": false, "episodes_total": 552, "training_iteration": 92, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-55-20", "timestamp": 1624964120, "time_this_iter_s": 25.288981199264526, "time_total_s": 2325.9036474227905, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06278c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2325.9036474227905, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 30.73939393939394, "ram_util_percent": 67.4030303030303, "gpu_util_percent0": 0.38272727272727275, "vram_util_percent0": 0.30120211212223347}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904328.3198146964, "pol1": 1449523.996570688}, "policy_reward_max": {"pol0": -1449523.996570688, "pol1": 1904328.3198146964}, "policy_reward_mean": {"pol0": -1745032.1528111636, "pol1": 1745032.1528111636}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1826957.749763586, -1807422.1489695746, -1759526.4131722935, -1698848.726575103, -1793483.1793967022, -1786906.6571196574, -1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015], "policy_pol1_reward": [1826957.749763586, 1807422.1489695746, 1759526.4131722935, 1698848.726575103, 1793483.1793967022, 1786906.6571196574, 1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27649526429879406, "mean_inference_ms": 3.7981756642795284, "mean_action_processing_ms": 0.18984532884426297, "mean_env_wait_ms": 0.14380660548391344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 558558, "agent_timesteps_total": 1117116, "timers": {"sample_time_ms": 4662.729, "sample_throughput": 1288.087, "learn_time_ms": 20819.862, "learn_throughput": 288.475, "update_time_ms": 5.082}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 23825631972.765957, "policy_loss": 0.002522327174293868, "vf_loss": 23825631972.765957, "vf_explained_var": -3.550914939864924e-08, "kl": 0.014218111760280233, "entropy": 2.8721678459897952, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24071752595.06383, "policy_loss": -0.0052486664833540616, "vf_loss": 24071752595.06383, "vf_explained_var": 3.804551784725163e-09, "kl": 0.008328173537441391, "entropy": 2.8510243892669678, "entropy_coeff": 0.0}}}, "num_steps_sampled": 558558, "num_agent_steps_sampled": 1117116, "num_steps_trained": 558558, "num_agent_steps_trained": 1117116}, "done": false, "episodes_total": 558, "training_iteration": 93, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-55-46", "timestamp": 1624964146, "time_this_iter_s": 25.5016987323761, "time_total_s": 2351.4053461551666, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06279d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2351.4053461551666, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 31.273529411764706, "ram_util_percent": 67.21470588235294, "gpu_util_percent0": 0.38205882352941173, "vram_util_percent0": 0.30682606713059335}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904328.3198146964, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1904328.3198146964}, "policy_reward_mean": {"pol0": -1737483.0459346399, "pol1": 1737483.0459346399}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1860378.9355050717, -1791232.7397849457, -1718582.1354603355, -1784975.824717153, -1575011.2308500295, -1860280.6143378178, -1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094], "policy_pol1_reward": [1860378.9355050717, 1791232.7397849457, 1718582.1354603355, 1784975.824717153, 1575011.2308500295, 1860280.6143378178, 1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2765605256449022, "mean_inference_ms": 3.799473731193012, "mean_action_processing_ms": 0.18991439938608665, "mean_env_wait_ms": 0.1438504251641337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 564564, "agent_timesteps_total": 1129128, "timers": {"sample_time_ms": 4668.014, "sample_throughput": 1286.628, "learn_time_ms": 20846.749, "learn_throughput": 288.102, "update_time_ms": 5.07}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 22847692102.80851, "policy_loss": 0.0014554872276618125, "vf_loss": 22847692102.80851, "vf_explained_var": -1.2681839223205316e-07, "kl": 0.007987668648599944, "entropy": 2.9181345625126616, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 23083754169.19149, "policy_loss": -0.00614526297183747, "vf_loss": 23083754169.19149, "vf_explained_var": 2.2827311596529398e-08, "kl": 0.009601570764913204, "entropy": 2.764345382122283, "entropy_coeff": 0.0}}}, "num_steps_sampled": 564564, "num_agent_steps_sampled": 1129128, "num_steps_trained": 564564, "num_agent_steps_trained": 1129128}, "done": false, "episodes_total": 564, "training_iteration": 94, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-56-11", "timestamp": 1624964171, "time_this_iter_s": 25.714291095733643, "time_total_s": 2377.1196372509003, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2377.1196372509003, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 31.03529411764706, "ram_util_percent": 67.26176470588234, "gpu_util_percent0": 0.3773529411764706, "vram_util_percent0": 0.30674676341719703}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904328.3198146964, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1904328.3198146964}, "policy_reward_mean": {"pol0": -1737656.4234390077, "pol1": 1737656.4234390077}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847651.1700823316, -1692616.53430834, -1751953.2646834303, -1834098.0303947097, -1827246.3431304845, -1632073.4839092218, -1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417], "policy_pol1_reward": [1847651.1700823316, 1692616.53430834, 1751953.2646834303, 1834098.0303947097, 1827246.3431304845, 1632073.4839092218, 1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.276622030784649, "mean_inference_ms": 3.8006838664040727, "mean_action_processing_ms": 0.18997990303614723, "mean_env_wait_ms": 0.14389118324605965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 570570, "agent_timesteps_total": 1141140, "timers": {"sample_time_ms": 4657.503, "sample_throughput": 1289.532, "learn_time_ms": 20791.756, "learn_throughput": 288.864, "update_time_ms": 5.031}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 26053697405.276596, "policy_loss": -0.0016235376292086663, "vf_loss": 26053697405.276596, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.005834242140755374, "entropy": 2.853722541890246, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26330428132.765957, "policy_loss": -0.005493753074490009, "vf_loss": 26330428132.765957, "vf_explained_var": 1.2681839578476684e-08, "kl": 0.012190169714232708, "entropy": 2.6013388126454453, "entropy_coeff": 0.0}}}, "num_steps_sampled": 570570, "num_agent_steps_sampled": 1141140, "num_steps_trained": 570570, "num_agent_steps_trained": 1141140}, "done": false, "episodes_total": 570, "training_iteration": 95, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-56-37", "timestamp": 1624964197, "time_this_iter_s": 25.20466709136963, "time_total_s": 2402.32430434227, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7aedc99e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c77b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2402.32430434227, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 30.04848484848485, "ram_util_percent": 67.28484848484847, "gpu_util_percent0": 0.37333333333333335, "vram_util_percent0": 0.30668668484644224}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904328.3198146964, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1904328.3198146964}, "policy_reward_mean": {"pol0": -1733397.220340917, "pol1": 1733397.220340917}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1759108.561453436, -1584005.4913556313, -1621132.674247758, -1847601.3035368507, -1795889.6028727016, -1626093.8728933458, -1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531], "policy_pol1_reward": [1759108.561453436, 1584005.4913556313, 1621132.674247758, 1847601.3035368507, 1795889.6028727016, 1626093.8728933458, 1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27667930539988833, "mean_inference_ms": 3.8018991002458318, "mean_action_processing_ms": 0.1900460862793668, "mean_env_wait_ms": 0.14393205377354754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 576576, "agent_timesteps_total": 1153152, "timers": {"sample_time_ms": 4647.536, "sample_throughput": 1292.298, "learn_time_ms": 20758.97, "learn_throughput": 289.321, "update_time_ms": 5.083}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 23968215737.19149, "policy_loss": -0.00030717449857199446, "vf_loss": 23968215737.19149, "vf_explained_var": -3.804551695907321e-08, "kl": 0.0055070800825636436, "entropy": 2.76936600563374, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24219529738.893616, "policy_loss": -0.007830342594930467, "vf_loss": 24219529738.893616, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.01274196936332799, "entropy": 2.3175891612438444, "entropy_coeff": 0.0}}}, "num_steps_sampled": 576576, "num_agent_steps_sampled": 1153152, "num_steps_trained": 576576, "num_agent_steps_trained": 1153152}, "done": false, "episodes_total": 576, "training_iteration": 96, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-57-02", "timestamp": 1624964222, "time_this_iter_s": 25.244925022125244, "time_total_s": 2427.569229364395, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2427.569229364395, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 30.915151515151518, "ram_util_percent": 67.17878787878787, "gpu_util_percent0": 0.37333333333333335, "vram_util_percent0": 0.30664072473981474}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904328.3198146964, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1904328.3198146964}, "policy_reward_mean": {"pol0": -1737427.9088512636, "pol1": 1737427.9088512636}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1869715.7031324708, -1813245.7999796348, -1618007.7877169158, -1748685.4236035738, -1739648.5332236586, -1849734.2184253032, -1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083], "policy_pol1_reward": [1869715.7031324708, 1813245.7999796348, 1618007.7877169158, 1748685.4236035738, 1739648.5332236586, 1849734.2184253032, 1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27673304376699703, "mean_inference_ms": 3.803025294285459, "mean_action_processing_ms": 0.19010988304032, "mean_env_wait_ms": 0.14397049700433429, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 582582, "agent_timesteps_total": 1165164, "timers": {"sample_time_ms": 4647.254, "sample_throughput": 1292.376, "learn_time_ms": 20750.469, "learn_throughput": 289.439, "update_time_ms": 4.949}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 26266212657.02128, "policy_loss": 0.0018955872176175423, "vf_loss": 26266212657.02128, "vf_explained_var": 1.1413655442993331e-07, "kl": 0.008960039582737583, "entropy": 2.746622232680625, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26555069200.340427, "policy_loss": -0.007469252148207197, "vf_loss": 26555069200.340427, "vf_explained_var": 3.424096561843726e-08, "kl": 0.011981519315629564, "entropy": 2.1782543811392276, "entropy_coeff": 0.0}}}, "num_steps_sampled": 582582, "num_agent_steps_sampled": 1165164, "num_steps_trained": 582582, "num_agent_steps_trained": 1165164}, "done": false, "episodes_total": 582, "training_iteration": 97, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-57-27", "timestamp": 1624964247, "time_this_iter_s": 25.23231315612793, "time_total_s": 2452.801542520523, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7ae4194400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2452.801542520523, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 30.72121212121212, "ram_util_percent": 67.43030303030302, "gpu_util_percent0": 0.3784848484848485, "vram_util_percent0": 0.30669179152495635}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1906729.621917562, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1906729.621917562}, "policy_reward_mean": {"pol0": -1737803.9748298742, "pol1": 1737803.9748298742}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1693458.000449325, -1811903.4510447478, -1812186.6828373715, -1525559.555516075, -1808303.6121014259, -1511663.9377329221, -1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562], "policy_pol1_reward": [1693458.000449325, 1811903.4510447478, 1812186.6828373715, 1525559.555516075, 1808303.6121014259, 1511663.9377329221, 1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2767860592120207, "mean_inference_ms": 3.804084494563928, "mean_action_processing_ms": 0.19016970202623207, "mean_env_wait_ms": 0.1440056349301272, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 588588, "agent_timesteps_total": 1177176, "timers": {"sample_time_ms": 4642.661, "sample_throughput": 1293.655, "learn_time_ms": 20753.155, "learn_throughput": 289.402, "update_time_ms": 5.083}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 26507985941.787235, "policy_loss": 0.002450676991584453, "vf_loss": 26507985941.787235, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.014257078653478876, "entropy": 2.768595594040891, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26797599896.51064, "policy_loss": 0.0024622774663123678, "vf_loss": 26797599896.51064, "vf_explained_var": -6.340919789238342e-09, "kl": 0.02021648714992594, "entropy": 2.288878430711462, "entropy_coeff": 0.0}}}, "num_steps_sampled": 588588, "num_agent_steps_sampled": 1177176, "num_steps_trained": 588588, "num_agent_steps_trained": 1177176}, "done": false, "episodes_total": 588, "training_iteration": 98, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-57-53", "timestamp": 1624964273, "time_this_iter_s": 25.484564542770386, "time_total_s": 2478.2861070632935, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2478.2861070632935, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 31.514705882352942, "ram_util_percent": 67.1, "gpu_util_percent0": 0.3841176470588235, "vram_util_percent0": 0.3067566763813716}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1906729.621917562, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1906729.621917562}, "policy_reward_mean": {"pol0": -1740416.4380906196, "pol1": 1740416.4380906196}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1716960.5090050306, -1449523.996570688, -1627458.407832281, -1603465.9134145794, -1524378.2956285428, -1784650.9964486386, -1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346], "policy_pol1_reward": [1716960.5090050306, 1449523.996570688, 1627458.407832281, 1603465.9134145794, 1524378.2956285428, 1784650.9964486386, 1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2768323753631978, "mean_inference_ms": 3.805127033365107, "mean_action_processing_ms": 0.19022905542764332, "mean_env_wait_ms": 0.14404004093182576, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 594594, "agent_timesteps_total": 1189188, "timers": {"sample_time_ms": 4657.801, "sample_throughput": 1289.45, "learn_time_ms": 20745.223, "learn_throughput": 289.512, "update_time_ms": 4.971}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 25153160388.085106, "policy_loss": 0.0006332859159150022, "vf_loss": 25153160388.085106, "vf_explained_var": -7.609103569450326e-09, "kl": 0.010168236383098238, "entropy": 2.739984243474108, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25432699054.29787, "policy_loss": -0.00580570620900773, "vf_loss": 25432699054.29787, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.011173048472784936, "entropy": 2.3249684800492956, "entropy_coeff": 0.0}}}, "num_steps_sampled": 594594, "num_agent_steps_sampled": 1189188, "num_steps_trained": 594594, "num_agent_steps_trained": 1189188}, "done": false, "episodes_total": 594, "training_iteration": 99, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-58-18", "timestamp": 1624964298, "time_this_iter_s": 25.38514804840088, "time_total_s": 2503.6712551116943, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2503.6712551116943, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 31.390909090909094, "ram_util_percent": 67.14848484848484, "gpu_util_percent0": 0.38545454545454544, "vram_util_percent0": 0.30663561806130063}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1906729.621917562, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1906729.621917562}, "policy_reward_mean": {"pol0": -1750042.227694208, "pol1": 1750042.227694208}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1749989.9014473008, -1809599.3371832983, -1875442.7435000525, -1801274.757417622, -1706669.108546469, -1699090.3918272094, -1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722], "policy_pol1_reward": [1749989.9014473008, 1809599.3371832983, 1875442.7435000525, 1801274.757417622, 1706669.108546469, 1699090.3918272094, 1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27686806423079763, "mean_inference_ms": 3.806050679736289, "mean_action_processing_ms": 0.1902822511646209, "mean_env_wait_ms": 0.14407022916780682, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 600600, "agent_timesteps_total": 1201200, "timers": {"sample_time_ms": 4634.517, "sample_throughput": 1295.928, "learn_time_ms": 20727.046, "learn_throughput": 289.766, "update_time_ms": 5.253}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 26446258524.595745, "policy_loss": 0.0013935195797301354, "vf_loss": 26446258524.595745, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.006035197991877794, "entropy": 2.829189305609845, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26738649610.893616, "policy_loss": 5.5021784724073205e-05, "vf_loss": 26738649610.893616, "vf_explained_var": 6.340919789238342e-09, "kl": 0.013877018870032847, "entropy": 2.2183872131591147, "entropy_coeff": 0.0}}}, "num_steps_sampled": 600600, "num_agent_steps_sampled": 1201200, "num_steps_trained": 600600, "num_agent_steps_trained": 1201200}, "done": false, "episodes_total": 600, "training_iteration": 100, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-58-43", "timestamp": 1624964323, "time_this_iter_s": 25.20338010787964, "time_total_s": 2528.874635219574, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2528.874635219574, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 29.908823529411762, "ram_util_percent": 67.26470588235294, "gpu_util_percent0": 0.3788235294117647, "vram_util_percent0": 0.3067219810067607}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1906729.621917562, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1906729.621917562}, "policy_reward_mean": {"pol0": -1744724.544100921, "pol1": 1744724.544100921}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1788543.3597313901, -1809377.3526822901, -1903666.8698193436, -1824061.2041963874, -1659511.6395153606, -1725539.1620779743, -1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632], "policy_pol1_reward": [1788543.3597313901, 1809377.3526822901, 1903666.8698193436, 1824061.2041963874, 1659511.6395153606, 1725539.1620779743, 1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2768929559899654, "mean_inference_ms": 3.8069738464936824, "mean_action_processing_ms": 0.19033456214365124, "mean_env_wait_ms": 0.1441012868652349, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 606606, "agent_timesteps_total": 1213212, "timers": {"sample_time_ms": 4632.837, "sample_throughput": 1296.398, "learn_time_ms": 20729.324, "learn_throughput": 289.734, "update_time_ms": 5.229}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 23638869798.12766, "policy_loss": 0.001476523089916148, "vf_loss": 23638869798.12766, "vf_explained_var": 2.4095495376741383e-08, "kl": 0.009952360447099868, "entropy": 2.7973980852898133, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23908726784.0, "policy_loss": -0.0051841375398192, "vf_loss": 23908726784.0, "vf_explained_var": -8.87728734966231e-09, "kl": 0.008133667253671175, "entropy": 2.182976316898427, "entropy_coeff": 0.0}}}, "num_steps_sampled": 606606, "num_agent_steps_sampled": 1213212, "num_steps_trained": 606606, "num_agent_steps_trained": 1213212}, "done": false, "episodes_total": 606, "training_iteration": 101, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-59-09", "timestamp": 1624964349, "time_this_iter_s": 25.502309322357178, "time_total_s": 2554.376944541931, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2554.376944541931, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 31.230303030303034, "ram_util_percent": 67.1909090909091, "gpu_util_percent0": 0.37757575757575756, "vram_util_percent0": 0.3066764714894139}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1906729.621917562, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1906729.621917562}, "policy_reward_mean": {"pol0": -1746230.6699157243, "pol1": 1746230.6699157243}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1904328.3198146964, -1874774.7383593097, -1876218.7367701165, -1658754.2482311456, -1713341.6285915256, -1785114.0933194153, -1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023], "policy_pol1_reward": [1904328.3198146964, 1874774.7383593097, 1876218.7367701165, 1658754.2482311456, 1713341.6285915256, 1785114.0933194153, 1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769061437998137, "mean_inference_ms": 3.807841681000875, "mean_action_processing_ms": 0.19038429550425576, "mean_env_wait_ms": 0.14413157806055285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 612612, "agent_timesteps_total": 1225224, "timers": {"sample_time_ms": 4636.506, "sample_throughput": 1295.372, "learn_time_ms": 20735.127, "learn_throughput": 289.653, "update_time_ms": 5.31}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 27325546408.851063, "policy_loss": 0.0008737811858349658, "vf_loss": 27325546408.851063, "vf_explained_var": 9.638198150696553e-08, "kl": 0.004180687459859442, "entropy": 2.7794397283107677, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27631114980.765957, "policy_loss": -0.0017210891113636341, "vf_loss": 27631114980.765957, "vf_explained_var": 1.775457469932462e-08, "kl": 0.01245062447529524, "entropy": 2.1570558903065136, "entropy_coeff": 0.0}}}, "num_steps_sampled": 612612, "num_agent_steps_sampled": 1225224, "num_steps_trained": 612612, "num_agent_steps_trained": 1225224}, "done": false, "episodes_total": 612, "training_iteration": 102, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_13-59-34", "timestamp": 1624964374, "time_this_iter_s": 25.384183168411255, "time_total_s": 2579.7611277103424, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c78c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2579.7611277103424, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 29.602941176470587, "ram_util_percent": 67.34411764705882, "gpu_util_percent0": 0.38235294117647056, "vram_util_percent0": 0.3066971985963243}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1906729.621917562, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1906729.621917562}, "policy_reward_mean": {"pol0": -1740229.5017403555, "pol1": 1740229.5017403555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1891020.1087015946, -1703437.190416513, -1679175.1574554075, -1661765.1948732482, -1653249.4008156648, -1844823.4295998083, -1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973], "policy_pol1_reward": [1891020.1087015946, 1703437.190416513, 1679175.1574554075, 1661765.1948732482, 1653249.4008156648, 1844823.4295998083, 1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27690954755795527, "mean_inference_ms": 3.8086912586864963, "mean_action_processing_ms": 0.19043053280927213, "mean_env_wait_ms": 0.14416068918464578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 618618, "agent_timesteps_total": 1237236, "timers": {"sample_time_ms": 4639.716, "sample_throughput": 1294.476, "learn_time_ms": 20728.91, "learn_throughput": 289.74, "update_time_ms": 5.302}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.684209203720093, "cur_lr": 5.000000000000002e-05, "total_loss": 23942527455.31915, "policy_loss": -0.0024113874644675153, "vf_loss": 23942527455.31915, "vf_explained_var": -8.243195281920634e-08, "kl": 0.007165655999028302, "entropy": 2.7372323908704392, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24211932138.212765, "policy_loss": -0.005085125486267374, "vf_loss": 24211932138.212765, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.010699356232393296, "entropy": 2.0703556689810245, "entropy_coeff": 0.0}}}, "num_steps_sampled": 618618, "num_agent_steps_sampled": 1237236, "num_steps_trained": 618618, "num_agent_steps_trained": 1237236}, "done": false, "episodes_total": 618, "training_iteration": 103, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-00-00", "timestamp": 1624964400, "time_this_iter_s": 25.472351551055908, "time_total_s": 2605.2334792613983, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2605.2334792613983, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 31.881818181818186, "ram_util_percent": 67.12727272727273, "gpu_util_percent0": 0.3796969696969697, "vram_util_percent0": 0.3067173249175272}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1936888.1579030026, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1936888.1579030026}, "policy_reward_mean": {"pol0": -1743202.1601985455, "pol1": 1743202.1601985455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1729825.7445569125, -1865085.0543261503, -1812532.5601007522, -1728306.0451828183, -1901832.0305864736, -1541667.2404050722, -1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067], "policy_pol1_reward": [1729825.7445569125, 1865085.0543261503, 1812532.5601007522, 1728306.0451828183, 1901832.0305864736, 1541667.2404050722, 1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769167018293887, "mean_inference_ms": 3.8095486913106846, "mean_action_processing_ms": 0.190477611993105, "mean_env_wait_ms": 0.144190576659283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 624624, "agent_timesteps_total": 1249248, "timers": {"sample_time_ms": 4638.829, "sample_throughput": 1294.723, "learn_time_ms": 20721.292, "learn_throughput": 289.847, "update_time_ms": 5.287}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.684209203720093, "cur_lr": 5.000000000000002e-05, "total_loss": 26900251713.361702, "policy_loss": -0.0014928572395063462, "vf_loss": 26900251713.361702, "vf_explained_var": -1.5598662628235616e-07, "kl": 0.004719600477751265, "entropy": 2.86661392577151, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27220907116.93617, "policy_loss": -0.0067380899253816524, "vf_loss": 27220907116.93617, "vf_explained_var": 2.2827311596529398e-08, "kl": 0.013766672759455569, "entropy": 2.069108618066666, "entropy_coeff": 0.0}}}, "num_steps_sampled": 624624, "num_agent_steps_sampled": 1249248, "num_steps_trained": 624624, "num_agent_steps_trained": 1249248}, "done": false, "episodes_total": 624, "training_iteration": 104, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-00-25", "timestamp": 1624964425, "time_this_iter_s": 25.62900137901306, "time_total_s": 2630.8624806404114, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2630.8624806404114, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 31.735294117647058, "ram_util_percent": 67.11176470588236, "gpu_util_percent0": 0.388235294117647, "vram_util_percent0": 0.30658815599040423}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1743046.790263536, "pol1": 1743046.790263536}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1714887.438677689, -1630103.282153973, -1878710.4594085691, -1736329.5095552937, -1842449.9860812256, -1862930.101112522, -1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384], "policy_pol1_reward": [1714887.438677689, 1630103.282153973, 1878710.4594085691, 1736329.5095552937, 1842449.9860812256, 1862930.101112522, 1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27692545535007035, "mean_inference_ms": 3.8104180562103043, "mean_action_processing_ms": 0.19052468820665694, "mean_env_wait_ms": 0.14421974789993408, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 630630, "agent_timesteps_total": 1261260, "timers": {"sample_time_ms": 4658.094, "sample_throughput": 1289.369, "learn_time_ms": 20744.703, "learn_throughput": 289.52, "update_time_ms": 5.299}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3421046018600465, "cur_lr": 5.000000000000002e-05, "total_loss": 25885600005.446808, "policy_loss": -0.0019569279665642594, "vf_loss": 25885600005.446808, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.003559381344375458, "entropy": 2.785896144014724, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26200439045.446808, "policy_loss": -0.006591746900626954, "vf_loss": 26200439045.446808, "vf_explained_var": 3.170459805801329e-08, "kl": 0.01201915388253141, "entropy": 2.1078136728164996, "entropy_coeff": 0.0}}}, "num_steps_sampled": 630630, "num_agent_steps_sampled": 1261260, "num_steps_trained": 630630, "num_agent_steps_trained": 1261260}, "done": false, "episodes_total": 630, "training_iteration": 105, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-00-51", "timestamp": 1624964451, "time_this_iter_s": 25.632746696472168, "time_total_s": 2656.4952273368835, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2656.4952273368835, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 31.72352941176471, "ram_util_percent": 67.07941176470587, "gpu_util_percent0": 0.38794117647058823, "vram_util_percent0": 0.306746763417197}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1740076.1617874969, "pol1": 1740076.1617874969}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1801670.6298894347, -1634439.1284099706, -1845987.1721375124, -1735408.5112650073, -1634970.1596108812, -1722376.8917138623, -1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095], "policy_pol1_reward": [1801670.6298894347, 1634439.1284099706, 1845987.1721375124, 1735408.5112650073, 1634970.1596108812, 1722376.8917138623, 1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769404895117583, "mean_inference_ms": 3.811337928155421, "mean_action_processing_ms": 0.19057447629396054, "mean_env_wait_ms": 0.14425180172168045, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 636636, "agent_timesteps_total": 1273272, "timers": {"sample_time_ms": 4668.258, "sample_throughput": 1286.561, "learn_time_ms": 20749.052, "learn_throughput": 289.459, "update_time_ms": 5.262}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.17105230093002324, "cur_lr": 5.000000000000002e-05, "total_loss": 24830546486.468086, "policy_loss": 0.003660712341599642, "vf_loss": 24830546486.468086, "vf_explained_var": 1.0145471129874295e-08, "kl": 0.011402431697128936, "entropy": 2.7783135860524277, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25125346979.404255, "policy_loss": -0.003317634178761472, "vf_loss": 25125346979.404255, "vf_explained_var": 1.2681839578476684e-08, "kl": 0.011052591250614916, "entropy": 2.1630927451113435, "entropy_coeff": 0.0}}}, "num_steps_sampled": 636636, "num_agent_steps_sampled": 1273272, "num_steps_trained": 636636, "num_agent_steps_trained": 1273272}, "done": false, "episodes_total": 636, "training_iteration": 106, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-01-17", "timestamp": 1624964477, "time_this_iter_s": 25.388612270355225, "time_total_s": 2681.8838396072388, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2681.8838396072388, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 30.890909090909094, "ram_util_percent": 67.24545454545455, "gpu_util_percent0": 0.38181818181818183, "vram_util_percent0": 0.3066458314183289}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1735540.4700906568, "pol1": 1735540.4700906568}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1808553.4468134923, -1752755.0769893515, -1779326.6901045723, -1792886.215557679, -1873428.496411612, -1645469.5771263065, -1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859], "policy_pol1_reward": [1808553.4468134923, 1752755.0769893515, 1779326.6901045723, 1792886.215557679, 1873428.496411612, 1645469.5771263065, 1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769574331735552, "mean_inference_ms": 3.8121523304900453, "mean_action_processing_ms": 0.19061917194622333, "mean_env_wait_ms": 0.14428061861574962, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 642642, "agent_timesteps_total": 1285284, "timers": {"sample_time_ms": 4665.358, "sample_throughput": 1287.361, "learn_time_ms": 20759.394, "learn_throughput": 289.315, "update_time_ms": 5.283}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.17105230093002324, "cur_lr": 5.000000000000002e-05, "total_loss": 22905332147.744682, "policy_loss": 0.002100032258858072, "vf_loss": 22905332147.744682, "vf_explained_var": -2.4095495376741383e-08, "kl": 0.007325018508399421, "entropy": 2.729141159260527, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23188551854.29787, "policy_loss": -0.004921565347529472, "vf_loss": 23188551854.29787, "vf_explained_var": 0.0, "kl": 0.009608963197295336, "entropy": 2.0316002825473216, "entropy_coeff": 0.0}}}, "num_steps_sampled": 642642, "num_agent_steps_sampled": 1285284, "num_steps_trained": 642642, "num_agent_steps_trained": 1285284}, "done": false, "episodes_total": 642, "training_iteration": 107, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-01-42", "timestamp": 1624964502, "time_this_iter_s": 25.306657552719116, "time_total_s": 2707.190497159958, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2707.190497159958, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 29.981818181818177, "ram_util_percent": 67.35757575757576, "gpu_util_percent0": 0.3790909090909091, "vram_util_percent0": 0.30675307166712634}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1729901.337690516, "pol1": 1729901.337690516}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1741049.3687577047, -1652387.3542155256, -1692632.7786828512, -1824660.9615574935, -1849449.3684250046, -1723973.5043883156, -1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987], "policy_pol1_reward": [1741049.3687577047, 1652387.3542155256, 1692632.7786828512, 1824660.9615574935, 1849449.3684250046, 1723973.5043883156, 1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27697838415087306, "mean_inference_ms": 3.8129042784456084, "mean_action_processing_ms": 0.1906617335455608, "mean_env_wait_ms": 0.14430881116882788, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 648648, "agent_timesteps_total": 1297296, "timers": {"sample_time_ms": 4663.981, "sample_throughput": 1287.741, "learn_time_ms": 20752.974, "learn_throughput": 289.404, "update_time_ms": 5.136}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.17105230093002324, "cur_lr": 5.000000000000002e-05, "total_loss": 23486975782.12766, "policy_loss": 0.005873633152309885, "vf_loss": 23486975782.12766, "vf_explained_var": 1.6486390919112637e-08, "kl": 0.03199650164931379, "entropy": 2.7449944120772343, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23771558933.787235, "policy_loss": -0.004799211794074545, "vf_loss": 23771558933.787235, "vf_explained_var": 1.318911273529011e-07, "kl": 0.010449852437732067, "entropy": 1.983388510156185, "entropy_coeff": 0.0}}}, "num_steps_sampled": 648648, "num_agent_steps_sampled": 1297296, "num_steps_trained": 648648, "num_agent_steps_trained": 1297296}, "done": false, "episodes_total": 648, "training_iteration": 108, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-02-07", "timestamp": 1624964527, "time_this_iter_s": 25.404802322387695, "time_total_s": 2732.5952994823456, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c78c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2732.5952994823456, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 31.56176470588235, "ram_util_percent": 67.11764705882354, "gpu_util_percent0": 0.37823529411764706, "vram_util_percent0": 0.3066129384008406}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1730033.7067565457, "pol1": 1730033.7067565457}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1620980.7391614558, -1639493.8419255049, -1695576.8597642616, -1600683.4679843015, -1719488.6722056821, -1695620.7312740183, -1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076], "policy_pol1_reward": [1620980.7391614558, 1639493.8419255049, 1695576.8597642616, 1600683.4679843015, 1719488.6722056821, 1695620.7312740183, 1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.277000668490081, "mean_inference_ms": 3.8137434998420896, "mean_action_processing_ms": 0.19070803363652877, "mean_env_wait_ms": 0.1443394583268037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 654654, "agent_timesteps_total": 1309308, "timers": {"sample_time_ms": 4660.994, "sample_throughput": 1288.566, "learn_time_ms": 20760.754, "learn_throughput": 289.296, "update_time_ms": 5.146}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 25762628804.085106, "policy_loss": 0.002250633460093052, "vf_loss": 25762628804.085106, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.00695007874016115, "entropy": 2.845915900900009, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26081719971.404255, "policy_loss": -0.006826285748405659, "vf_loss": 26081719971.404255, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.012369179959468384, "entropy": 1.9522297940355666, "entropy_coeff": 0.0}}}, "num_steps_sampled": 654654, "num_agent_steps_sampled": 1309308, "num_steps_trained": 654654, "num_agent_steps_trained": 1309308}, "done": false, "episodes_total": 654, "training_iteration": 109, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-02-33", "timestamp": 1624964553, "time_this_iter_s": 25.43313455581665, "time_total_s": 2758.0284340381622, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2758.0284340381622, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 31.615151515151513, "ram_util_percent": 67.2848484848485, "gpu_util_percent0": 0.386060606060606, "vram_util_percent0": 0.30663561806130063}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1356099.009629764}, "policy_reward_max": {"pol0": -1356099.009629764, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1730446.9219664896, "pol1": 1730446.9219664896}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1356099.009629764, -1712676.7355708915, -1719642.6900232567, -1714706.34864094, -1843627.5512777125, -1733343.8454413218, -1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688], "policy_pol1_reward": [1356099.009629764, 1712676.7355708915, 1719642.6900232567, 1714706.34864094, 1843627.5512777125, 1733343.8454413218, 1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770166173430733, "mean_inference_ms": 3.8144972014256298, "mean_action_processing_ms": 0.19074837756003937, "mean_env_wait_ms": 0.14436842674263087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 660660, "agent_timesteps_total": 1321320, "timers": {"sample_time_ms": 4672.905, "sample_throughput": 1285.282, "learn_time_ms": 20762.539, "learn_throughput": 289.271, "update_time_ms": 4.871}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 23252568107.574467, "policy_loss": -6.78633359518457e-05, "vf_loss": 23252568107.574467, "vf_explained_var": 1.5725480295714078e-07, "kl": 0.016146428605660477, "entropy": 2.732764036097425, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23539836143.659573, "policy_loss": -0.0043962897257284915, "vf_loss": 23539836143.659573, "vf_explained_var": -4.058188451949718e-08, "kl": 0.009293275488976469, "entropy": 1.9218976523013824, "entropy_coeff": 0.0}}}, "num_steps_sampled": 660660, "num_agent_steps_sampled": 1321320, "num_steps_trained": 660660, "num_agent_steps_trained": 1321320}, "done": false, "episodes_total": 660, "training_iteration": 110, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-02-58", "timestamp": 1624964578, "time_this_iter_s": 25.333317756652832, "time_total_s": 2783.361751794815, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2783.361751794815, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 30.53529411764706, "ram_util_percent": 67.27058823529411, "gpu_util_percent0": 0.3952941176470588, "vram_util_percent0": 0.3065782430262297}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1734332.6350685803, "pol1": 1734332.6350685803}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1877060.635512032, -1566308.6675857655, -1779462.9286910256, -1807995.6025842417, -1573829.7913169328, -1409054.3757262577, -1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925], "policy_pol1_reward": [1877060.635512032, 1566308.6675857655, 1779462.9286910256, 1807995.6025842417, 1573829.7913169328, 1409054.3757262577, 1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770391048388807, "mean_inference_ms": 3.8151975180547906, "mean_action_processing_ms": 0.19078353150652988, "mean_env_wait_ms": 0.1443934992247824, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 666666, "agent_timesteps_total": 1333332, "timers": {"sample_time_ms": 4662.347, "sample_throughput": 1288.192, "learn_time_ms": 20766.978, "learn_throughput": 289.209, "update_time_ms": 4.862}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 25234979295.31915, "policy_loss": -0.0009409139487654604, "vf_loss": 25234979295.31915, "vf_explained_var": 1.6486390919112637e-08, "kl": 0.008090479041826217, "entropy": 2.8265550491657665, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25547048829.276596, "policy_loss": -0.006646529870464447, "vf_loss": 25547048829.276596, "vf_explained_var": -4.8190990753482765e-08, "kl": 0.011841480897620637, "entropy": 1.8323992845859933, "entropy_coeff": 0.0}}}, "num_steps_sampled": 666666, "num_agent_steps_sampled": 1333332, "num_steps_trained": 666666, "num_agent_steps_trained": 1333332}, "done": false, "episodes_total": 666, "training_iteration": 111, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-03-24", "timestamp": 1624964604, "time_this_iter_s": 25.43942642211914, "time_total_s": 2808.801178216934, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2808.801178216934, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 31.03939393939394, "ram_util_percent": 67.16969696969697, "gpu_util_percent0": 0.38363636363636366, "vram_util_percent0": 0.3065130577769607}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1739004.2522258747, "pol1": 1739004.2522258747}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1843050.322878688, -1651232.380818243, -1839905.4941957435, -1842646.151763531, -1841337.2484328446, -1756727.2425005324, -1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834], "policy_pol1_reward": [1843050.322878688, 1651232.380818243, 1839905.4941957435, 1842646.151763531, 1841337.2484328446, 1756727.2425005324, 1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770611006421942, "mean_inference_ms": 3.8158643926313407, "mean_action_processing_ms": 0.19081622757921987, "mean_env_wait_ms": 0.14441788372187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 672672, "agent_timesteps_total": 1345344, "timers": {"sample_time_ms": 4644.985, "sample_throughput": 1293.007, "learn_time_ms": 20774.577, "learn_throughput": 289.103, "update_time_ms": 4.824}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 25489611057.02128, "policy_loss": 0.004809379696528962, "vf_loss": 25489611057.02128, "vf_explained_var": -1.318911273529011e-07, "kl": 0.01906883756214, "entropy": 2.7874866850832674, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25815383584.68085, "policy_loss": -0.004920513428589131, "vf_loss": 25815383584.68085, "vf_explained_var": -2.663186293716535e-08, "kl": 0.01273069923069883, "entropy": 1.7482939197662029, "entropy_coeff": 0.0}}}, "num_steps_sampled": 672672, "num_agent_steps_sampled": 1345344, "num_steps_trained": 672672, "num_agent_steps_trained": 1345344}, "done": false, "episodes_total": 672, "training_iteration": 112, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-03-49", "timestamp": 1624964629, "time_this_iter_s": 25.28684711456299, "time_total_s": 2834.088025331497, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cda60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2834.088025331497, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 29.591176470588238, "ram_util_percent": 67.26764705882351, "gpu_util_percent0": 0.38264705882352945, "vram_util_percent0": 0.30538373084319675}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1740803.073026745, "pol1": 1740803.073026745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1757145.034592849, -1799977.0467406383, -1810023.7790883514, -1671690.0060392083, -1877375.9993214326, -1805280.9503099811, -1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846], "policy_pol1_reward": [1757145.034592849, 1799977.0467406383, 1810023.7790883514, 1671690.0060392083, 1877375.9993214326, 1805280.9503099811, 1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.277082932239256, "mean_inference_ms": 3.816537789021353, "mean_action_processing_ms": 0.1908486497095687, "mean_env_wait_ms": 0.14444236511181438, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 678678, "agent_timesteps_total": 1357356, "timers": {"sample_time_ms": 4635.383, "sample_throughput": 1295.686, "learn_time_ms": 20789.21, "learn_throughput": 288.9, "update_time_ms": 4.812}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 27700138724.765957, "policy_loss": -0.0029920450352290844, "vf_loss": 27700138724.765957, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.0070541698010043894, "entropy": 2.8872694411176316, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07500000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 28049495584.68085, "policy_loss": -0.0018965180249924355, "vf_loss": 28049495584.68085, "vf_explained_var": 1.065274517486614e-07, "kl": 0.025134508676351384, "entropy": 1.8582371955222272, "entropy_coeff": 0.0}}}, "num_steps_sampled": 678678, "num_agent_steps_sampled": 1357356, "num_steps_trained": 678678, "num_agent_steps_trained": 1357356}, "done": false, "episodes_total": 678, "training_iteration": 113, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-04-14", "timestamp": 1624964654, "time_this_iter_s": 25.521677017211914, "time_total_s": 2859.609702348709, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd9d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2859.609702348709, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 31.24545454545455, "ram_util_percent": 67.22424242424245, "gpu_util_percent0": 0.38303030303030305, "vram_util_percent0": 0.29941988132079134}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1736930.0233938184, "pol1": 1736930.0233938184}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1506699.1620278782, -1756721.0316166917, -1823837.298749086, -1906729.621917562, -1775813.9292796312, -1705502.7223750192, -1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698], "policy_pol1_reward": [1506699.1620278782, 1756721.0316166917, 1823837.298749086, 1906729.621917562, 1775813.9292796312, 1705502.7223750192, 1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2771088832076385, "mean_inference_ms": 3.817170560704443, "mean_action_processing_ms": 0.19087679424749918, "mean_env_wait_ms": 0.14446552456117245, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 684684, "agent_timesteps_total": 1369368, "timers": {"sample_time_ms": 4617.242, "sample_throughput": 1300.776, "learn_time_ms": 20750.769, "learn_throughput": 289.435, "update_time_ms": 4.84}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 24691135422.638298, "policy_loss": 0.0005285842542318588, "vf_loss": 24691135422.638298, "vf_explained_var": 3.0436414277801305e-08, "kl": 0.016547907896815463, "entropy": 2.776096029484526, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25012824456.17021, "policy_loss": -0.0061363218788136826, "vf_loss": 25012824456.17021, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.010858317936195972, "entropy": 1.9608504873640993, "entropy_coeff": 0.0}}}, "num_steps_sampled": 684684, "num_agent_steps_sampled": 1369368, "num_steps_trained": 684684, "num_agent_steps_trained": 1369368}, "done": false, "episodes_total": 684, "training_iteration": 114, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-04-40", "timestamp": 1624964680, "time_this_iter_s": 25.063152313232422, "time_total_s": 2884.6728546619415, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2884.6728546619415, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 29.575757575757578, "ram_util_percent": 67.47575757575757, "gpu_util_percent0": 0.3809090909090909, "vram_util_percent0": 0.2995475482836453}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1740213.296923047, "pol1": 1740213.296923047}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1748537.4680354071, -1828416.117561674, -1795988.8055884864, -1570062.5229162346, -1517277.5211924834, -1784775.7657595666, -1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596], "policy_pol1_reward": [1748537.4680354071, 1828416.117561674, 1795988.8055884864, 1570062.5229162346, 1517277.5211924834, 1784775.7657595666, 1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27712709264854507, "mean_inference_ms": 3.8177740025663733, "mean_action_processing_ms": 0.19090188429177687, "mean_env_wait_ms": 0.1444859453596069, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 690690, "agent_timesteps_total": 1381380, "timers": {"sample_time_ms": 4614.95, "sample_throughput": 1301.422, "learn_time_ms": 20705.442, "learn_throughput": 290.069, "update_time_ms": 4.897}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 27156934481.70213, "policy_loss": -0.002592753163202012, "vf_loss": 27156934481.70213, "vf_explained_var": 1.242820246716292e-07, "kl": 0.0064697007926062065, "entropy": 2.833471734473046, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27499628282.553192, "policy_loss": -0.005635159783699411, "vf_loss": 27499628282.553192, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.013526342650677295, "entropy": 1.9339388634296173, "entropy_coeff": 0.0}}}, "num_steps_sampled": 690690, "num_agent_steps_sampled": 1381380, "num_steps_trained": 690690, "num_agent_steps_trained": 1381380}, "done": false, "episodes_total": 690, "training_iteration": 115, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-05-05", "timestamp": 1624964705, "time_this_iter_s": 25.156167030334473, "time_total_s": 2909.829021692276, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2909.829021692276, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 29.757575757575758, "ram_util_percent": 67.64545454545456, "gpu_util_percent0": 0.3757575757575758, "vram_util_percent0": 0.3010693384808653}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1741703.94278827, "pol1": 1741703.94278827}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1811010.246770606, -1845953.3535422632, -1834912.1711665264, -1875088.0208270722, -1755870.055537521, -1748134.8351229958, -1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858], "policy_pol1_reward": [1811010.246770606, 1845953.3535422632, 1834912.1711665264, 1875088.0208270722, 1755870.055537521, 1748134.8351229958, 1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27714381312046527, "mean_inference_ms": 3.8183194019570688, "mean_action_processing_ms": 0.19092484781053165, "mean_env_wait_ms": 0.14450540950811708, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 696696, "agent_timesteps_total": 1393392, "timers": {"sample_time_ms": 4598.935, "sample_throughput": 1305.954, "learn_time_ms": 20711.936, "learn_throughput": 289.978, "update_time_ms": 4.912}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 24939973566.638298, "policy_loss": 0.004499999132562191, "vf_loss": 24939973566.638298, "vf_explained_var": 3.170459805801329e-08, "kl": 0.014238142448061325, "entropy": 2.7350954147095377, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25272548635.234043, "policy_loss": -0.006158049971340818, "vf_loss": 25272548635.234043, "vf_explained_var": -1.2681839223205316e-07, "kl": 0.00940208198463029, "entropy": 2.0452944370026285, "entropy_coeff": 0.0}}}, "num_steps_sampled": 696696, "num_agent_steps_sampled": 1393392, "num_steps_trained": 696696, "num_agent_steps_trained": 1393392}, "done": false, "episodes_total": 696, "training_iteration": 116, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-05-30", "timestamp": 1624964730, "time_this_iter_s": 25.29443860054016, "time_total_s": 2935.123460292816, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2935.123460292816, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 29.908823529411762, "ram_util_percent": 67.4794117647059, "gpu_util_percent0": 0.37676470588235295, "vram_util_percent0": 0.30280636015781437}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1739987.9675319507, "pol1": 1739987.9675319507}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1700024.1992074205, -1751375.1771527429, -1635045.5286655996, -1519848.0849069632, -1853302.8193705515, -1885979.5483563647, -1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965], "policy_pol1_reward": [1700024.1992074205, 1751375.1771527429, 1635045.5286655996, 1519848.0849069632, 1853302.8193705515, 1885979.5483563647, 1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27716491565082274, "mean_inference_ms": 3.818914595437302, "mean_action_processing_ms": 0.1909501605910204, "mean_env_wait_ms": 0.14452574048550532, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 702702, "agent_timesteps_total": 1405404, "timers": {"sample_time_ms": 4610.9, "sample_throughput": 1302.566, "learn_time_ms": 20727.784, "learn_throughput": 289.756, "update_time_ms": 5.038}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 26398601041.70213, "policy_loss": 0.0012329131602606875, "vf_loss": 26398601041.70213, "vf_explained_var": 9.511379772675355e-08, "kl": 0.012205737107928763, "entropy": 2.831098896391848, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26738483505.02128, "policy_loss": -0.006227335000925875, "vf_loss": 26738483505.02128, "vf_explained_var": -1.3315931823854044e-07, "kl": 0.013930731294478508, "entropy": 1.9413303973826956, "entropy_coeff": 0.0}}}, "num_steps_sampled": 702702, "num_agent_steps_sampled": 1405404, "num_steps_trained": 702702, "num_agent_steps_trained": 1405404}, "done": false, "episodes_total": 702, "training_iteration": 117, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-05-56", "timestamp": 1624964756, "time_this_iter_s": 25.585811614990234, "time_total_s": 2960.7092719078064, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2960.7092719078064, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 32.199999999999996, "ram_util_percent": 67.20606060606062, "gpu_util_percent0": 0.38, "vram_util_percent0": 0.30290263606744905}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1737570.5154966284, "pol1": 1737570.5154966284}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1613061.1533247225, -1891975.989218865, -1786981.9600572663, -1830010.6991754023, -1585074.5542035871, -1759919.545054012, -1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621], "policy_pol1_reward": [1613061.1533247225, 1891975.989218865, 1786981.9600572663, 1830010.6991754023, 1585074.5542035871, 1759919.545054012, 1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27718251979633185, "mean_inference_ms": 3.8194678784055305, "mean_action_processing_ms": 0.19097369922287816, "mean_env_wait_ms": 0.14454441954048136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 708708, "agent_timesteps_total": 1417416, "timers": {"sample_time_ms": 4617.192, "sample_throughput": 1300.791, "learn_time_ms": 20749.663, "learn_throughput": 289.45, "update_time_ms": 5.03}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 23426955743.31915, "policy_loss": 0.0034588215714122387, "vf_loss": 23426955743.31915, "vf_explained_var": 1.2174565711120522e-07, "kl": 0.016462573563640424, "entropy": 2.702389275774043, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 23737845149.957447, "policy_loss": -0.006814815975884174, "vf_loss": 23737845149.957447, "vf_explained_var": 1.0779563552887339e-07, "kl": 0.010502556774844515, "entropy": 1.8364700763783557, "entropy_coeff": 0.0}}}, "num_steps_sampled": 708708, "num_agent_steps_sampled": 1417416, "num_steps_trained": 708708, "num_agent_steps_trained": 1417416}, "done": false, "episodes_total": 708, "training_iteration": 118, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-06-21", "timestamp": 1624964781, "time_this_iter_s": 25.686715126037598, "time_total_s": 2986.395987033844, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c72f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c71e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2986.395987033844, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 67.23529411764707, "gpu_util_percent0": 0.3847058823529411, "vram_util_percent0": 0.30280140367572717}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1736866.2844358482, "pol1": 1736866.2844358482}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1712278.9338759158, -1743128.639896057, -1777468.317235164, -1634544.9572844973, -1910744.0347932542, -1688383.8913561036, -1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014], "policy_pol1_reward": [1712278.9338759158, 1743128.639896057, 1777468.317235164, 1634544.9572844973, 1910744.0347932542, 1688383.8913561036, 1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2771998815471432, "mean_inference_ms": 3.819908889973932, "mean_action_processing_ms": 0.1909923373832954, "mean_env_wait_ms": 0.14455922515826664, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 714714, "agent_timesteps_total": 1429428, "timers": {"sample_time_ms": 4588.782, "sample_throughput": 1308.844, "learn_time_ms": 20734.587, "learn_throughput": 289.661, "update_time_ms": 5.045}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 25171479530.212765, "policy_loss": 9.276715176615943e-05, "vf_loss": 25171479530.212765, "vf_explained_var": -2.916823049758932e-08, "kl": 0.00813537840037904, "entropy": 2.725209281799641, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25512174526.638298, "policy_loss": -0.003639424279173638, "vf_loss": 25512174526.638298, "vf_explained_var": 1.154047382101453e-07, "kl": 0.008494189088331891, "entropy": 1.7365695796114333, "entropy_coeff": 0.0}}}, "num_steps_sampled": 714714, "num_agent_steps_sampled": 1429428, "num_steps_trained": 714714, "num_agent_steps_trained": 1429428}, "done": false, "episodes_total": 714, "training_iteration": 119, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-06-46", "timestamp": 1624964806, "time_this_iter_s": 24.999640464782715, "time_total_s": 3011.3956274986267, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e8d400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3011.3956274986267, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 29.12424242424242, "ram_util_percent": 67.56666666666665, "gpu_util_percent0": 0.38181818181818183, "vram_util_percent0": 0.30290263606744894}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1944068.12540328, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1944068.12540328}, "policy_reward_mean": {"pol0": -1739207.2467376909, "pol1": 1739207.2467376909}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1798741.6095401065, -1936888.1579030026, -1626872.618100747, -1769106.015988067, -1713091.0211005781, -1944068.12540328, -1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327], "policy_pol1_reward": [1798741.6095401065, 1936888.1579030026, 1626872.618100747, 1769106.015988067, 1713091.0211005781, 1944068.12540328, 1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27721269562243145, "mean_inference_ms": 3.820231097262859, "mean_action_processing_ms": 0.19100569973313927, "mean_env_wait_ms": 0.1445707814062133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 720720, "agent_timesteps_total": 1441440, "timers": {"sample_time_ms": 4570.688, "sample_throughput": 1314.025, "learn_time_ms": 20751.548, "learn_throughput": 289.424, "update_time_ms": 5.046}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 26458035875.404255, "policy_loss": 0.0006839661918422009, "vf_loss": 26458035875.404255, "vf_explained_var": -3.804551695907321e-08, "kl": 0.012939711319322282, "entropy": 2.757908029759184, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26816781682.38298, "policy_loss": -0.00525647833784844, "vf_loss": 26816781682.38298, "vf_explained_var": 1.0906381930908537e-07, "kl": 0.014684634085031265, "entropy": 1.7028823076410498, "entropy_coeff": 0.0}}}, "num_steps_sampled": 720720, "num_agent_steps_sampled": 1441440, "num_steps_trained": 720720, "num_agent_steps_trained": 1441440}, "done": false, "episodes_total": 720, "training_iteration": 120, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-07-12", "timestamp": 1624964832, "time_this_iter_s": 25.322266817092896, "time_total_s": 3036.7178943157196, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06279d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3036.7178943157196, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 30.73030303030303, "ram_util_percent": 67.59696969696971, "gpu_util_percent0": 0.39060606060606057, "vram_util_percent0": 0.3028158225327083}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1733107.522675752, "pol1": 1733107.522675752}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1712040.589328357, -1659975.234986528, -1798660.4887944735, -1735876.2220440384, -1616436.3093334406, -1765829.3972445747, -1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467], "policy_pol1_reward": [1712040.589328357, 1659975.234986528, 1798660.4887944735, 1735876.2220440384, 1616436.3093334406, 1765829.3972445747, 1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.277226999243788, "mean_inference_ms": 3.8205195362740305, "mean_action_processing_ms": 0.19101604166518948, "mean_env_wait_ms": 0.14458023248952126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 726726, "agent_timesteps_total": 1453452, "timers": {"sample_time_ms": 4574.503, "sample_throughput": 1312.929, "learn_time_ms": 20769.733, "learn_throughput": 289.171, "update_time_ms": 5.024}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 23741893653.787235, "policy_loss": -0.002093646556456038, "vf_loss": 23741893653.787235, "vf_explained_var": -1.2681839223205316e-07, "kl": 0.006473738541628452, "entropy": 2.7992818659924446, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 24064618844.595745, "policy_loss": -0.003874474026738329, "vf_loss": 24064618844.595745, "vf_explained_var": 8.496832037963031e-08, "kl": 0.01231861131345021, "entropy": 1.7059148600760927, "entropy_coeff": 0.0}}}, "num_steps_sampled": 726726, "num_agent_steps_sampled": 1453452, "num_steps_trained": 726726, "num_agent_steps_trained": 1453452}, "done": false, "episodes_total": 726, "training_iteration": 121, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-07-38", "timestamp": 1624964858, "time_this_iter_s": 25.65998077392578, "time_total_s": 3062.3778750896454, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7aedcc3730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3062.3778750896454, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 31.597058823529416, "ram_util_percent": 67.20882352941177, "gpu_util_percent0": 0.38499999999999995, "vram_util_percent0": 0.30285096849659987}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1735770.5953139737, "pol1": 1735770.5953139737}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1624370.6995684286, -1791741.534392104, -1723301.7033694477, -1846668.2854773095, -1776795.547623051, -1420207.706437474, -1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883], "policy_pol1_reward": [1624370.6995684286, 1791741.534392104, 1723301.7033694477, 1846668.2854773095, 1776795.547623051, 1420207.706437474, 1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2772335263764165, "mean_inference_ms": 3.8207599383105104, "mean_action_processing_ms": 0.19102452320496485, "mean_env_wait_ms": 0.14458835217677954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 732732, "agent_timesteps_total": 1465464, "timers": {"sample_time_ms": 4597.814, "sample_throughput": 1306.273, "learn_time_ms": 20743.579, "learn_throughput": 289.535, "update_time_ms": 4.976}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25657845139503477, "cur_lr": 5.000000000000002e-05, "total_loss": 25788655398.12766, "policy_loss": -0.00014098867417332975, "vf_loss": 25788655398.12766, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.004625604646478562, "entropy": 2.809449591535203, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26144059958.468086, "policy_loss": -0.0073437044951826964, "vf_loss": 26144059958.468086, "vf_explained_var": 1.0145471662781347e-07, "kl": 0.010708179582465203, "entropy": 1.7089790207274416, "entropy_coeff": 0.0}}}, "num_steps_sampled": 732732, "num_agent_steps_sampled": 1465464, "num_steps_trained": 732732, "num_agent_steps_trained": 1465464}, "done": false, "episodes_total": 732, "training_iteration": 122, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-08-03", "timestamp": 1624964883, "time_this_iter_s": 25.257614135742188, "time_total_s": 3087.6354892253876, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3087.6354892253876, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 30.83030303030303, "ram_util_percent": 67.24848484848485, "gpu_util_percent0": 0.38151515151515153, "vram_util_percent0": 0.3028464626037932}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1742474.7560549243, "pol1": 1742474.7560549243}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1897168.1539937602, -1653938.5457978155, -1537924.07633174, -1635249.293158859, -1821915.4083548873, -1472620.612312228, -1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462], "policy_pol1_reward": [1897168.1539937602, 1653938.5457978155, 1537924.07633174, 1635249.293158859, 1821915.4083548873, 1472620.612312228, 1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2772365788546577, "mean_inference_ms": 3.8209438846544415, "mean_action_processing_ms": 0.1910298314821427, "mean_env_wait_ms": 0.1445940151579658, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 738738, "agent_timesteps_total": 1477476, "timers": {"sample_time_ms": 4587.982, "sample_throughput": 1309.072, "learn_time_ms": 20703.429, "learn_throughput": 290.097, "update_time_ms": 5.013}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 27305736279.148937, "policy_loss": 0.0020596108775823674, "vf_loss": 27305736279.148937, "vf_explained_var": -1.471093327154449e-07, "kl": 0.012317893967190956, "entropy": 2.7527579043773893, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27690503320.51064, "policy_loss": -0.006861068268722677, "vf_loss": 27690503320.51064, "vf_explained_var": 7.482285013793444e-08, "kl": 0.012164506347889596, "entropy": 1.4943047736553436, "entropy_coeff": 0.0}}}, "num_steps_sampled": 738738, "num_agent_steps_sampled": 1477476, "num_steps_trained": 738738, "num_agent_steps_trained": 1477476}, "done": false, "episodes_total": 738, "training_iteration": 123, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-08-28", "timestamp": 1624964908, "time_this_iter_s": 25.02143120765686, "time_total_s": 3112.6569204330444, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3112.6569204330444, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 29.978787878787877, "ram_util_percent": 67.34848484848484, "gpu_util_percent0": 0.3754545454545455, "vram_util_percent0": 0.3028873160319065}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1745447.541632862, "pol1": 1745447.541632862}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1772629.366428823, -1654148.3106924726, -1534024.0533392387, -1833168.5118612987, -1623897.6333824168, -1820282.1842057635, -1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612], "policy_pol1_reward": [1772629.366428823, 1654148.3106924726, 1534024.0533392387, 1833168.5118612987, 1623897.6333824168, 1820282.1842057635, 1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27723896095035244, "mean_inference_ms": 3.8211194839834737, "mean_action_processing_ms": 0.1910357165984498, "mean_env_wait_ms": 0.1445999708852094, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 744744, "agent_timesteps_total": 1489488, "timers": {"sample_time_ms": 4589.978, "sample_throughput": 1308.503, "learn_time_ms": 20732.343, "learn_throughput": 289.692, "update_time_ms": 5.05}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 24573688940.93617, "policy_loss": -0.0017077181329752536, "vf_loss": 24573688940.93617, "vf_explained_var": -1.065274517486614e-07, "kl": 0.007494875160541306, "entropy": 2.702964447914286, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 24916131883.574467, "policy_loss": -0.004025709240677509, "vf_loss": 24916131883.574467, "vf_explained_var": 1.204774804364206e-07, "kl": 0.010300674763052388, "entropy": 1.4511583054319341, "entropy_coeff": 0.0}}}, "num_steps_sampled": 744744, "num_agent_steps_sampled": 1489488, "num_steps_trained": 744744, "num_agent_steps_trained": 1489488}, "done": false, "episodes_total": 744, "training_iteration": 124, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-08-53", "timestamp": 1624964933, "time_this_iter_s": 25.372480630874634, "time_total_s": 3138.029401063919, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdd90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3138.029401063919, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 30.935294117647064, "ram_util_percent": 67.25, "gpu_util_percent0": 0.3779411764705882, "vram_util_percent0": 0.30292531572790893}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1746212.4801637041, "pol1": 1746212.4801637041}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1645198.8540561881, -1788049.9960328848, -1754570.5795525538, -1865390.9954000076, -1892982.4588454154, -1805788.0447714545, -1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868], "policy_pol1_reward": [1645198.8540561881, 1788049.9960328848, 1754570.5795525538, 1865390.9954000076, 1892982.4588454154, 1805788.0447714545, 1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27723568011563055, "mean_inference_ms": 3.8212385308277113, "mean_action_processing_ms": 0.1910390536036516, "mean_env_wait_ms": 0.1446038314512034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 750750, "agent_timesteps_total": 1501500, "timers": {"sample_time_ms": 4576.649, "sample_throughput": 1312.314, "learn_time_ms": 20749.001, "learn_throughput": 289.46, "update_time_ms": 5.156}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 24539836677.446808, "policy_loss": 0.000763028622307676, "vf_loss": 24539836677.446808, "vf_explained_var": 1.2935475979247713e-07, "kl": 0.006557564439370911, "entropy": 2.7765363480182406, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 24890595763.744682, "policy_loss": -0.00643771304253568, "vf_loss": 24890595763.744682, "vf_explained_var": 5.453190965454269e-08, "kl": 0.014803568832576275, "entropy": 1.3173976806884116, "entropy_coeff": 0.0}}}, "num_steps_sampled": 750750, "num_agent_steps_sampled": 1501500, "num_steps_trained": 750750, "num_agent_steps_trained": 1501500}, "done": false, "episodes_total": 750, "training_iteration": 125, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-09-19", "timestamp": 1624964959, "time_this_iter_s": 25.191097021102905, "time_total_s": 3163.220498085022, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3163.220498085022, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 30.54545454545454, "ram_util_percent": 67.38484848484848, "gpu_util_percent0": 0.38151515151515153, "vram_util_percent0": 0.3028464626037932}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1390738.3720522719}, "policy_reward_max": {"pol0": -1390738.3720522719, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1746868.82537569, "pol1": 1746868.82537569}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1560571.8220089506, -1390738.3720522719, -1657426.3626897132, -1705658.7729418688, -1804003.8504111217, -1711922.419247677, -1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577], "policy_pol1_reward": [1560571.8220089506, 1390738.3720522719, 1657426.3626897132, 1705658.7729418688, 1804003.8504111217, 1711922.419247677, 1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27722669007724193, "mean_inference_ms": 3.8213167565723545, "mean_action_processing_ms": 0.19104062539107075, "mean_env_wait_ms": 0.1446060127469549, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 756756, "agent_timesteps_total": 1513512, "timers": {"sample_time_ms": 4583.25, "sample_throughput": 1310.424, "learn_time_ms": 20746.968, "learn_throughput": 289.488, "update_time_ms": 5.319}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 27024410493.276596, "policy_loss": 0.0015529891119358387, "vf_loss": 27024410493.276596, "vf_explained_var": 2.916823049758932e-08, "kl": 0.007035648271917028, "entropy": 2.802358089609349, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27419933020.595745, "policy_loss": -0.0035298312320671183, "vf_loss": 27419933020.595745, "vf_explained_var": 7.735921769835841e-08, "kl": 0.011891778776461774, "entropy": 1.3289729813311963, "entropy_coeff": 0.0}}}, "num_steps_sampled": 756756, "num_agent_steps_sampled": 1513512, "num_steps_trained": 756756, "num_agent_steps_trained": 1513512}, "done": false, "episodes_total": 756, "training_iteration": 126, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-09-44", "timestamp": 1624964984, "time_this_iter_s": 25.341335773468018, "time_total_s": 3188.56183385849, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c78c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3188.56183385849, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 31.290909090909096, "ram_util_percent": 67.15151515151516, "gpu_util_percent0": 0.3775757575757576, "vram_util_percent0": 0.3029894496021897}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1746921.15733061, "pol1": 1746921.15733061}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1675036.6803442584, -1713772.0513726694, -1866568.0921969844, -1697364.3972201925, -1800683.0573186064, -1807793.6518806047, -1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695], "policy_pol1_reward": [1675036.6803442584, 1713772.0513726694, 1866568.0921969844, 1697364.3972201925, 1800683.0573186064, 1807793.6518806047, 1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27721329222724606, "mean_inference_ms": 3.821435981420535, "mean_action_processing_ms": 0.19104411496425588, "mean_env_wait_ms": 0.14460955503503747, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 762762, "agent_timesteps_total": 1525524, "timers": {"sample_time_ms": 4580.213, "sample_throughput": 1311.293, "learn_time_ms": 20731.253, "learn_throughput": 289.708, "update_time_ms": 5.156}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 22082798352.340427, "policy_loss": -0.0014373438551704934, "vf_loss": 22082798352.340427, "vf_explained_var": 1.0272290040802545e-07, "kl": 0.005292226837829072, "entropy": 2.8090867235305463, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 22392859626.212765, "policy_loss": -0.004036995839882404, "vf_loss": 22392859626.212765, "vf_explained_var": 9.638198150696553e-08, "kl": 0.015468168983909679, "entropy": 1.402512438753818, "entropy_coeff": 0.0}}}, "num_steps_sampled": 762762, "num_agent_steps_sampled": 1525524, "num_steps_trained": 762762, "num_agent_steps_trained": 1525524}, "done": false, "episodes_total": 762, "training_iteration": 127, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-10-09", "timestamp": 1624965009, "time_this_iter_s": 25.397255420684814, "time_total_s": 3213.959089279175, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e350d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3213.959089279175, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 31.014705882352942, "ram_util_percent": 67.24411764705884, "gpu_util_percent0": 0.385, "vram_util_percent0": 0.30292035924582167}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1747354.8820874, "pol1": 1747354.8820874}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1735688.2087795753, -1787632.0470637258, -1736717.2620956863, -1612359.4900074834, -1833058.4427182202, -1823619.9931066504, -1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504], "policy_pol1_reward": [1735688.2087795753, 1787632.0470637258, 1736717.2620956863, 1612359.4900074834, 1833058.4427182202, 1823619.9931066504, 1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2771949846570861, "mean_inference_ms": 3.821486545253805, "mean_action_processing_ms": 0.1910447839652614, "mean_env_wait_ms": 0.14461047222123263, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 768768, "agent_timesteps_total": 1537536, "timers": {"sample_time_ms": 4551.809, "sample_throughput": 1319.475, "learn_time_ms": 20698.963, "learn_throughput": 290.159, "update_time_ms": 5.112}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 26243263204.765957, "policy_loss": 0.0006029458389558057, "vf_loss": 26243263204.765957, "vf_explained_var": 9.257743016632958e-08, "kl": 0.013468734840763377, "entropy": 2.7476407111959253, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26619692445.957447, "policy_loss": -0.006154593991789412, "vf_loss": 26619692445.957447, "vf_explained_var": 9.638198150696553e-08, "kl": 0.014556657483286045, "entropy": 1.506768858179133, "entropy_coeff": 0.0}}}, "num_steps_sampled": 768768, "num_agent_steps_sampled": 1537536, "num_steps_trained": 768768, "num_agent_steps_trained": 1537536}, "done": false, "episodes_total": 768, "training_iteration": 128, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-10-34", "timestamp": 1624965034, "time_this_iter_s": 25.07886266708374, "time_total_s": 3239.0379519462585, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06278c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3239.0379519462585, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 29.78484848484849, "ram_util_percent": 67.37575757575758, "gpu_util_percent0": 0.3863636363636363, "vram_util_percent0": 0.30292306278150566}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932271.321651034, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1932271.321651034}, "policy_reward_mean": {"pol0": -1743586.3358816751, "pol1": 1743586.3358816751}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1796632.7434567362, -1932271.321651034, -1752485.5125561222, -1816712.907187846, -1674656.6222229227, -1807565.2179093761, -1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796], "policy_pol1_reward": [1796632.7434567362, 1932271.321651034, 1752485.5125561222, 1816712.907187846, 1674656.6222229227, 1807565.2179093761, 1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27717864490223926, "mean_inference_ms": 3.8215712274995353, "mean_action_processing_ms": 0.19104721573286207, "mean_env_wait_ms": 0.14461217355019207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 774774, "agent_timesteps_total": 1549548, "timers": {"sample_time_ms": 4578.934, "sample_throughput": 1311.659, "learn_time_ms": 20715.391, "learn_throughput": 289.929, "update_time_ms": 5.125}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 23792561827.404255, "policy_loss": 0.001535784254999871, "vf_loss": 23792561827.404255, "vf_explained_var": -2.5363679156953367e-08, "kl": 0.01039735003909532, "entropy": 2.6567934472510157, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 24139658348.93617, "policy_loss": -0.006611537247737671, "vf_loss": 24139658348.93617, "vf_explained_var": 1.1667292199035728e-07, "kl": 0.016075845887052253, "entropy": 1.3468029727327062, "entropy_coeff": 0.0}}}, "num_steps_sampled": 774774, "num_agent_steps_sampled": 1549548, "num_steps_trained": 774774, "num_agent_steps_trained": 1549548}, "done": false, "episodes_total": 774, "training_iteration": 129, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-11-00", "timestamp": 1624965060, "time_this_iter_s": 25.43429160118103, "time_total_s": 3264.4722435474396, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3264.4722435474396, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 30.936363636363637, "ram_util_percent": 67.25757575757576, "gpu_util_percent0": 0.3821212121212121, "vram_util_percent0": 0.3050780811144815}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1743504.943316611, "pol1": 1743504.943316611}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1628199.7301166458, -1760982.4361623963, -1690846.648111965, -1771937.1982765698, -1688347.4607652638, -1880156.8554474774, -1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639], "policy_pol1_reward": [1628199.7301166458, 1760982.4361623963, 1690846.648111965, 1771937.1982765698, 1688347.4607652638, 1880156.8554474774, 1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2771589983439165, "mean_inference_ms": 3.8216143880489604, "mean_action_processing_ms": 0.1910503464622884, "mean_env_wait_ms": 0.14461293688694715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 780780, "agent_timesteps_total": 1561560, "timers": {"sample_time_ms": 4586.104, "sample_throughput": 1309.608, "learn_time_ms": 20709.245, "learn_throughput": 290.015, "update_time_ms": 5.197}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.12828922569751738, "cur_lr": 5.000000000000002e-05, "total_loss": 26849993314.042553, "policy_loss": 0.005538698087664361, "vf_loss": 26849993314.042553, "vf_explained_var": -3.170459805801329e-08, "kl": 0.025538068661030304, "entropy": 2.9261801192101013, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27239840789.787235, "policy_loss": -0.003309858408063016, "vf_loss": 27239840789.787235, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.017649704114870823, "entropy": 1.4460020851581654, "entropy_coeff": 0.0}}}, "num_steps_sampled": 780780, "num_agent_steps_sampled": 1561560, "num_steps_trained": 780780, "num_agent_steps_trained": 1561560}, "done": false, "episodes_total": 780, "training_iteration": 130, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-11-25", "timestamp": 1624965085, "time_this_iter_s": 25.33272624015808, "time_total_s": 3289.8049697875977, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3289.8049697875977, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 30.073529411764707, "ram_util_percent": 67.36764705882354, "gpu_util_percent0": 0.38147058823529406, "vram_util_percent0": 0.3065980689545788}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1744932.6430909685, "pol1": 1744932.6430909685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1779995.2782127543, -1904851.7054116027, -1689327.2254462033, -1860952.5936053596, -1725221.4955419588, -1712870.6187723111, -1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382], "policy_pol1_reward": [1779995.2782127543, 1904851.7054116027, 1689327.2254462033, 1860952.5936053596, 1725221.4955419588, 1712870.6187723111, 1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27714022317614273, "mean_inference_ms": 3.8216486766021003, "mean_action_processing_ms": 0.19105427563127184, "mean_env_wait_ms": 0.14461397791502034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 786786, "agent_timesteps_total": 1573572, "timers": {"sample_time_ms": 4576.629, "sample_throughput": 1312.32, "learn_time_ms": 20697.258, "learn_throughput": 290.183, "update_time_ms": 5.225}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.19243383854627602, "cur_lr": 5.000000000000002e-05, "total_loss": 25857871305.531914, "policy_loss": 0.00046094059151537874, "vf_loss": 25857871305.531914, "vf_explained_var": -1.3823205335938837e-07, "kl": 0.012657886390831876, "entropy": 2.8543017722190696, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26247243514.553192, "policy_loss": -0.00802139474197905, "vf_loss": 26247243514.553192, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.012640471292778533, "entropy": 1.5738679398881628, "entropy_coeff": 0.0}}}, "num_steps_sampled": 786786, "num_agent_steps_sampled": 1573572, "num_steps_trained": 786786, "num_agent_steps_trained": 1573572}, "done": false, "episodes_total": 786, "training_iteration": 131, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-11-51", "timestamp": 1624965111, "time_this_iter_s": 25.445231437683105, "time_total_s": 3315.2502012252808, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd0d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3315.2502012252808, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 31.58787878787879, "ram_util_percent": 67.14848484848486, "gpu_util_percent0": 0.3757575757575758, "vram_util_percent0": 0.3067888184167254}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1745484.508352947, "pol1": 1745484.508352947}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1855312.552806886, -1763712.4882662273, -1577365.5520767972, -1759640.0801119858, -1748019.6056270301, -1755126.691956706, -1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515], "policy_pol1_reward": [1855312.552806886, 1763712.4882662273, 1577365.5520767972, 1759640.0801119858, 1748019.6056270301, 1755126.691956706, 1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27712234208117664, "mean_inference_ms": 3.821687452850479, "mean_action_processing_ms": 0.19105976229232138, "mean_env_wait_ms": 0.14461656554681807, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 792792, "agent_timesteps_total": 1585584, "timers": {"sample_time_ms": 4566.355, "sample_throughput": 1315.272, "learn_time_ms": 20743.134, "learn_throughput": 289.542, "update_time_ms": 5.24}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.19243383854627602, "cur_lr": 5.000000000000002e-05, "total_loss": 26694902370.042553, "policy_loss": -0.0028686412892482698, "vf_loss": 26694902370.042553, "vf_explained_var": 2.916823049758932e-08, "kl": 0.008539052908011574, "entropy": 2.710010721328411, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27086159000.51064, "policy_loss": -0.0029283400942036446, "vf_loss": 27086159000.51064, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.014647416552489108, "entropy": 1.5516442542380475, "entropy_coeff": 0.0}}}, "num_steps_sampled": 792792, "num_agent_steps_sampled": 1585584, "num_steps_trained": 792792, "num_agent_steps_trained": 1585584}, "done": false, "episodes_total": 792, "training_iteration": 132, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-12-16", "timestamp": 1624965136, "time_this_iter_s": 25.613715648651123, "time_total_s": 3340.863916873932, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3340.863916873932, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 31.79411764705883, "ram_util_percent": 67.43823529411765, "gpu_util_percent0": 0.3732352941176471, "vram_util_percent0": 0.3066476337754515}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1746821.6854245341, "pol1": 1746821.6854245341}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1851044.3377763154, -1820873.5893214708, -1668514.8217565482, -1855792.1108969965, -1691444.855139124, -1666675.8631131246, -1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184], "policy_pol1_reward": [1851044.3377763154, 1820873.5893214708, 1668514.8217565482, 1855792.1108969965, 1691444.855139124, 1666675.8631131246, 1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2771092926578835, "mean_inference_ms": 3.8217432903530475, "mean_action_processing_ms": 0.19106547769041157, "mean_env_wait_ms": 0.1446190651570407, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 798798, "agent_timesteps_total": 1597596, "timers": {"sample_time_ms": 4576.137, "sample_throughput": 1312.461, "learn_time_ms": 20753.293, "learn_throughput": 289.4, "update_time_ms": 5.199}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.19243383854627602, "cur_lr": 5.000000000000002e-05, "total_loss": 25865846217.531914, "policy_loss": 0.0013458870470206788, "vf_loss": 25865846217.531914, "vf_explained_var": -1.1794110577056927e-07, "kl": 0.006512838841832065, "entropy": 2.729484020395482, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26262996599.82979, "policy_loss": -0.004879280369966588, "vf_loss": 26262996599.82979, "vf_explained_var": 1.1794110577056927e-07, "kl": 0.008942856899205041, "entropy": 1.447958913255245, "entropy_coeff": 0.0}}}, "num_steps_sampled": 798798, "num_agent_steps_sampled": 1597596, "num_steps_trained": 798798, "num_agent_steps_trained": 1597596}, "done": false, "episodes_total": 798, "training_iteration": 133, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-12-42", "timestamp": 1624965162, "time_this_iter_s": 25.220972061157227, "time_total_s": 3366.084888935089, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3366.084888935089, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 30.78181818181818, "ram_util_percent": 67.45151515151515, "gpu_util_percent0": 0.3845454545454545, "vram_util_percent0": 0.3067377516315838}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1747289.204111752, "pol1": 1747289.204111752}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1820757.6436558294, -1522031.007690541, -1697938.3638801095, -1704982.4206486621, -1819729.197312232, -1669230.4913552117, -1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432], "policy_pol1_reward": [1820757.6436558294, 1522031.007690541, 1697938.3638801095, 1704982.4206486621, 1819729.197312232, 1669230.4913552117, 1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770951527447776, "mean_inference_ms": 3.821787332233758, "mean_action_processing_ms": 0.19106970183789096, "mean_env_wait_ms": 0.14462176434978527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 804804, "agent_timesteps_total": 1609608, "timers": {"sample_time_ms": 4575.621, "sample_throughput": 1312.609, "learn_time_ms": 20755.322, "learn_throughput": 289.372, "update_time_ms": 5.389}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.19243383854627602, "cur_lr": 5.000000000000002e-05, "total_loss": 26113876447.31915, "policy_loss": -0.0010581738810907018, "vf_loss": 26113876447.31915, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.003550723269383641, "entropy": 2.7764207150073763, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26513420026.553192, "policy_loss": -0.007233027289522455, "vf_loss": 26513420026.553192, "vf_explained_var": 1.2935475979247713e-07, "kl": 0.010980166316507979, "entropy": 1.4800460617592994, "entropy_coeff": 0.0}}}, "num_steps_sampled": 804804, "num_agent_steps_sampled": 1609608, "num_steps_trained": 804804, "num_agent_steps_trained": 1609608}, "done": false, "episodes_total": 804, "training_iteration": 134, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-13-07", "timestamp": 1624965187, "time_this_iter_s": 25.393484592437744, "time_total_s": 3391.478373527527, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3391.478373527527, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 30.22941176470588, "ram_util_percent": 67.24411764705884, "gpu_util_percent0": 0.37852941176470584, "vram_util_percent0": 0.3066079819187533}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1462428.5998389605}, "policy_reward_max": {"pol0": -1462428.5998389605, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1750161.6027384861, "pol1": 1750161.6027384861}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1462428.5998389605, -1800514.8613927076, -1791482.7117630222, -1853214.9332937014, -1906621.7571009998, -1863810.3176628656, -1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162], "policy_pol1_reward": [1462428.5998389605, 1800514.8613927076, 1791482.7117630222, 1853214.9332937014, 1906621.7571009998, 1863810.3176628656, 1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770824514339962, "mean_inference_ms": 3.821804736003941, "mean_action_processing_ms": 0.19107257787078447, "mean_env_wait_ms": 0.1446238500200849, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 810810, "agent_timesteps_total": 1621620, "timers": {"sample_time_ms": 4577.361, "sample_throughput": 1312.11, "learn_time_ms": 20764.337, "learn_throughput": 289.246, "update_time_ms": 5.259}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09621691927313801, "cur_lr": 5.000000000000002e-05, "total_loss": 25546177993.531914, "policy_loss": -0.0025891322404780286, "vf_loss": 25546177993.531914, "vf_explained_var": 1.3823205335938837e-07, "kl": 0.007838696964639933, "entropy": 2.760294559154105, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25944592689.02128, "policy_loss": -0.008526980203199894, "vf_loss": 25944592689.02128, "vf_explained_var": -1.4964570027586888e-07, "kl": 0.012267466832665688, "entropy": 1.6434296369552612, "entropy_coeff": 0.0}}}, "num_steps_sampled": 810810, "num_agent_steps_sampled": 1621620, "num_steps_trained": 810810, "num_agent_steps_trained": 1621620}, "done": false, "episodes_total": 810, "training_iteration": 135, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-13-32", "timestamp": 1624965212, "time_this_iter_s": 25.297733306884766, "time_total_s": 3416.7761068344116, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacc80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3416.7761068344116, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 30.433333333333337, "ram_util_percent": 67.36060606060606, "gpu_util_percent0": 0.3839393939393939, "vram_util_percent0": 0.306681578167928}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1486609.0504425364}, "policy_reward_max": {"pol0": -1486609.0504425364, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1751959.9940740135, "pol1": 1751959.9940740135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1717011.644441612, -1735913.7278357767, -1793410.2761579247, -1683877.2814261327, -1665453.0275158728, -1546737.5451378948, -1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998], "policy_pol1_reward": [1717011.644441612, 1735913.7278357767, 1793410.2761579247, 1683877.2814261327, 1665453.0275158728, 1546737.5451378948, 1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27707757302233627, "mean_inference_ms": 3.8219358700417247, "mean_action_processing_ms": 0.19108125437741086, "mean_env_wait_ms": 0.1446292757557438, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 816816, "agent_timesteps_total": 1633632, "timers": {"sample_time_ms": 4580.076, "sample_throughput": 1311.332, "learn_time_ms": 20764.901, "learn_throughput": 289.238, "update_time_ms": 5.084}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09621691927313801, "cur_lr": 5.000000000000002e-05, "total_loss": 27303165777.70213, "policy_loss": -0.003965658829250234, "vf_loss": 27303165777.70213, "vf_explained_var": -9.638198150696553e-08, "kl": 0.008214218452810607, "entropy": 2.7314734408195984, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27737625926.80851, "policy_loss": -0.007968302479291216, "vf_loss": 27737625926.80851, "vf_explained_var": -1.2935475979247713e-07, "kl": 0.011091588372166486, "entropy": 1.746299774088758, "entropy_coeff": 0.0}}}, "num_steps_sampled": 816816, "num_agent_steps_sampled": 1633632, "num_steps_trained": 816816, "num_agent_steps_trained": 1633632}, "done": false, "episodes_total": 816, "training_iteration": 136, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-13-58", "timestamp": 1624965238, "time_this_iter_s": 25.372992277145386, "time_total_s": 3442.149099111557, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06279d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06278c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3442.149099111557, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 31.521212121212123, "ram_util_percent": 67.2, "gpu_util_percent0": 0.3778787878787879, "vram_util_percent0": 0.3067479649886121}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1486609.0504425364}, "policy_reward_max": {"pol0": -1486609.0504425364, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1756329.40942802, "pol1": 1756329.40942802}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1659501.5667416337, -1839529.270803253, -1818078.6299754968, -1649495.1016677467, -1839502.5506697395, -1612377.0042046541, -1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952], "policy_pol1_reward": [1659501.5667416337, 1839529.270803253, 1818078.6299754968, 1649495.1016677467, 1839502.5506697395, 1612377.0042046541, 1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770714460715069, "mean_inference_ms": 3.8220776325524293, "mean_action_processing_ms": 0.19109104165437762, "mean_env_wait_ms": 0.14463511784087102, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 822822, "agent_timesteps_total": 1645644, "timers": {"sample_time_ms": 4566.331, "sample_throughput": 1315.279, "learn_time_ms": 20764.785, "learn_throughput": 289.24, "update_time_ms": 5.133}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09621691927313801, "cur_lr": 5.000000000000002e-05, "total_loss": 25853359474.38298, "policy_loss": 0.0006168529074242774, "vf_loss": 25853359474.38298, "vf_explained_var": -6.340919789238342e-09, "kl": 0.004810034916637109, "entropy": 2.7100274562835693, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26257876076.93617, "policy_loss": -0.006686499401768471, "vf_loss": 26257876076.93617, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.014029242831500286, "entropy": 1.6400220292679808, "entropy_coeff": 0.0}}}, "num_steps_sampled": 822822, "num_agent_steps_sampled": 1645644, "num_steps_trained": 822822, "num_agent_steps_trained": 1645644}, "done": false, "episodes_total": 822, "training_iteration": 137, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-14-23", "timestamp": 1624965263, "time_this_iter_s": 25.25782322883606, "time_total_s": 3467.406922340393, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06277b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3467.406922340393, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 30.647058823529413, "ram_util_percent": 67.20882352941175, "gpu_util_percent0": 0.37705882352941184, "vram_util_percent0": 0.3066228513650152}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1486609.0504425364}, "policy_reward_max": {"pol0": -1486609.0504425364, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1756717.6836807246, "pol1": 1756717.6836807246}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1814088.2447777465, -1824461.849090669, -1622616.106234768, -1842079.7505759883, -1824334.2452861553, -1866109.8434264646, -1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095], "policy_pol1_reward": [1814088.2447777465, 1824461.849090669, 1622616.106234768, 1842079.7505759883, 1824334.2452861553, 1866109.8434264646, 1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770620332778989, "mean_inference_ms": 3.822125820079191, "mean_action_processing_ms": 0.19109717811791677, "mean_env_wait_ms": 0.14463874949499372, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 828828, "agent_timesteps_total": 1657656, "timers": {"sample_time_ms": 4561.626, "sample_throughput": 1316.636, "learn_time_ms": 20760.543, "learn_throughput": 289.299, "update_time_ms": 5.17}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.048108459636569005, "cur_lr": 5.000000000000002e-05, "total_loss": 25448001230.97872, "policy_loss": 0.0007963677313416563, "vf_loss": 25448001230.97872, "vf_explained_var": 2.5363679156953367e-08, "kl": 0.0031650747628288066, "entropy": 2.7347319024674435, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25855166899.744682, "policy_loss": -0.006069466689641171, "vf_loss": 25855166899.744682, "vf_explained_var": 3.9313700739285196e-08, "kl": 0.011393250600296133, "entropy": 1.578393578529358, "entropy_coeff": 0.0}}}, "num_steps_sampled": 828828, "num_agent_steps_sampled": 1657656, "num_steps_trained": 828828, "num_agent_steps_trained": 1657656}, "done": false, "episodes_total": 828, "training_iteration": 138, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-14-48", "timestamp": 1624965288, "time_this_iter_s": 24.989994049072266, "time_total_s": 3492.3969163894653, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdbf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3492.3969163894653, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 29.59375, "ram_util_percent": 67.49375, "gpu_util_percent0": 0.37312500000000004, "vram_util_percent0": 0.30671237782271654}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1486609.0504425364}, "policy_reward_max": {"pol0": -1486609.0504425364, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1753658.2173569696, "pol1": 1753658.2173569696}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1726252.232529586, -1847419.2965449572, -1868036.0193350625, -1721349.9138406462, -1713474.3855898124, -1562117.642288741, -1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054], "policy_pol1_reward": [1726252.232529586, 1847419.2965449572, 1868036.0193350625, 1721349.9138406462, 1713474.3855898124, 1562117.642288741, 1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770484253378011, "mean_inference_ms": 3.8221920628927557, "mean_action_processing_ms": 0.19110188104164777, "mean_env_wait_ms": 0.1446412494267173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 834834, "agent_timesteps_total": 1669668, "timers": {"sample_time_ms": 4552.081, "sample_throughput": 1319.396, "learn_time_ms": 20755.875, "learn_throughput": 289.364, "update_time_ms": 5.146}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.024054229818284503, "cur_lr": 5.000000000000002e-05, "total_loss": 25367968049.02128, "policy_loss": -0.00021417056547200425, "vf_loss": 25367968049.02128, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.008148726343395227, "entropy": 2.8084841078900276, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25772638818.042553, "policy_loss": -0.007227708446852704, "vf_loss": 25772638818.042553, "vf_explained_var": 1.1160018686950934e-07, "kl": 0.011979012551935429, "entropy": 1.6984224776004224, "entropy_coeff": 0.0}}}, "num_steps_sampled": 834834, "num_agent_steps_sampled": 1669668, "num_steps_trained": 834834, "num_agent_steps_trained": 1669668}, "done": false, "episodes_total": 834, "training_iteration": 139, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-15-13", "timestamp": 1624965313, "time_this_iter_s": 25.291202783584595, "time_total_s": 3517.68811917305, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdd90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3517.68811917305, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 30.055882352941175, "ram_util_percent": 67.42647058823528, "gpu_util_percent0": 0.38029411764705884, "vram_util_percent0": 0.3066079819187534}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1486609.0504425364}, "policy_reward_max": {"pol0": -1486609.0504425364, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1751282.076142739, "pol1": 1751282.076142739}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1793530.2933794612, -1729915.834644305, -1734291.2061058532, -1782765.2857348612, -1794508.4944927103, -1632769.6085087429, -1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397], "policy_pol1_reward": [1793530.2933794612, 1729915.834644305, 1734291.2061058532, 1782765.2857348612, 1794508.4944927103, 1632769.6085087429, 1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27704191243713544, "mean_inference_ms": 3.8222919153811024, "mean_action_processing_ms": 0.19110813633449011, "mean_env_wait_ms": 0.14464470953788477, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 840840, "agent_timesteps_total": 1681680, "timers": {"sample_time_ms": 4567.564, "sample_throughput": 1314.924, "learn_time_ms": 20754.595, "learn_throughput": 289.382, "update_time_ms": 5.078}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.024054229818284503, "cur_lr": 5.000000000000002e-05, "total_loss": 23837800404.425533, "policy_loss": -0.0015459042339724428, "vf_loss": 23837800404.425533, "vf_explained_var": -1.0525926796844942e-07, "kl": 0.00738397344669446, "entropy": 2.801024010840883, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 24218867189.106384, "policy_loss": -0.003218861782249618, "vf_loss": 24218867189.106384, "vf_explained_var": 1.280865831176925e-07, "kl": 0.010434995841314184, "entropy": 1.5756485157824578, "entropy_coeff": 0.0}}}, "num_steps_sampled": 840840, "num_agent_steps_sampled": 1681680, "num_steps_trained": 840840, "num_agent_steps_trained": 1681680}, "done": false, "episodes_total": 840, "training_iteration": 140, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-15-39", "timestamp": 1624965339, "time_this_iter_s": 25.474421977996826, "time_total_s": 3543.1625411510468, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c78c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c72f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3543.1625411510468, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 32.084848484848486, "ram_util_percent": 67.0969696969697, "gpu_util_percent0": 0.3784848484848485, "vram_util_percent0": 0.30678881841672545}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1457972.424371127}, "policy_reward_max": {"pol0": -1457972.424371127, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1748257.7945167571, "pol1": 1748257.7945167571}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1589025.98606536, -1817190.7997212226, -1890441.063899138, -1590707.9603070868, -1762019.9807603317, -1799149.383958023, -1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365], "policy_pol1_reward": [1589025.98606536, 1817190.7997212226, 1890441.063899138, 1590707.9603070868, 1762019.9807603317, 1799149.383958023, 1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27703692693161386, "mean_inference_ms": 3.822406916409073, "mean_action_processing_ms": 0.19111473741010576, "mean_env_wait_ms": 0.1446485215482106, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 846846, "agent_timesteps_total": 1693692, "timers": {"sample_time_ms": 4566.501, "sample_throughput": 1315.23, "learn_time_ms": 20766.851, "learn_throughput": 289.211, "update_time_ms": 5.061}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.024054229818284503, "cur_lr": 5.000000000000002e-05, "total_loss": 23900200480.68085, "policy_loss": 0.00022352688965645242, "vf_loss": 23900200480.68085, "vf_explained_var": -1.5471843539671681e-07, "kl": 0.010610308240544288, "entropy": 2.7852173916837004, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 24290710724.085106, "policy_loss": -0.005110386006058531, "vf_loss": 24290710724.085106, "vf_explained_var": 1.2681839223205316e-07, "kl": 0.011685264871475544, "entropy": 1.4997875360732382, "entropy_coeff": 0.0}}}, "num_steps_sampled": 846846, "num_agent_steps_sampled": 1693692, "num_steps_trained": 846846, "num_agent_steps_trained": 1693692}, "done": false, "episodes_total": 846, "training_iteration": 141, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-16-05", "timestamp": 1624965365, "time_this_iter_s": 25.55801224708557, "time_total_s": 3568.7205533981323, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3568.7205533981323, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 30.773529411764706, "ram_util_percent": 67.1441176470588, "gpu_util_percent0": 0.3820588235294118, "vram_util_percent0": 0.30666250322171335}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1457972.424371127}, "policy_reward_max": {"pol0": -1457972.424371127, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1750568.3084199387, "pol1": 1750568.3084199387}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1594411.2730444751, -1914863.4183923765, -1824655.5604572743, -1922515.833244577, -1625682.5482100784, -1670020.211198562, -1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807], "policy_pol1_reward": [1594411.2730444751, 1914863.4183923765, 1824655.5604572743, 1922515.833244577, 1625682.5482100784, 1670020.211198562, 1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770259463815464, "mean_inference_ms": 3.8224820727285196, "mean_action_processing_ms": 0.19111923671850625, "mean_env_wait_ms": 0.14465115665580744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 852852, "agent_timesteps_total": 1705704, "timers": {"sample_time_ms": 4543.241, "sample_throughput": 1321.964, "learn_time_ms": 20736.974, "learn_throughput": 289.628, "update_time_ms": 5.048}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.024054229818284503, "cur_lr": 5.000000000000002e-05, "total_loss": 26346450944.0, "policy_loss": 0.0007095864597470202, "vf_loss": 26346450944.0, "vf_explained_var": -3.424096561843726e-08, "kl": 0.005646944818820091, "entropy": 2.84494549670118, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26781607195.234043, "policy_loss": -0.0071112599937205615, "vf_loss": 26781607195.234043, "vf_explained_var": 1.0145471662781347e-07, "kl": 0.010036224638052444, "entropy": 1.5928184073022071, "entropy_coeff": 0.0}}}, "num_steps_sampled": 852852, "num_agent_steps_sampled": 1705704, "num_steps_trained": 852852, "num_agent_steps_trained": 1705704}, "done": false, "episodes_total": 852, "training_iteration": 142, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-16-30", "timestamp": 1624965390, "time_this_iter_s": 25.082709312438965, "time_total_s": 3593.8032627105713, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3593.8032627105713, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 30.215151515151515, "ram_util_percent": 67.29999999999998, "gpu_util_percent0": 0.38363636363636366, "vram_util_percent0": 0.30663561806130063}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926449.9529282097, "pol1": 1457972.424371127}, "policy_reward_max": {"pol0": -1457972.424371127, "pol1": 1926449.9529282097}, "policy_reward_mean": {"pol0": -1748115.930371123, "pol1": 1748115.930371123}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1794231.8279267303, -1653448.8933802627, -1486609.0504425364, -1605562.2636854695, -1537245.4585810031, -1926449.9529282097, -1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532], "policy_pol1_reward": [1794231.8279267303, 1653448.8933802627, 1486609.0504425364, 1605562.2636854695, 1537245.4585810031, 1926449.9529282097, 1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27701435829402493, "mean_inference_ms": 3.822528424191803, "mean_action_processing_ms": 0.1911223407662083, "mean_env_wait_ms": 0.14465353169830222, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 858858, "agent_timesteps_total": 1717716, "timers": {"sample_time_ms": 4544.778, "sample_throughput": 1321.517, "learn_time_ms": 20753.761, "learn_throughput": 289.393, "update_time_ms": 5.072}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.024054229818284503, "cur_lr": 5.000000000000002e-05, "total_loss": 24441427140.085106, "policy_loss": 0.0005802452326455015, "vf_loss": 24441427140.085106, "vf_explained_var": -7.609103569450326e-09, "kl": 0.003441247930552097, "entropy": 2.873540756550241, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11249999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 24825716474.553192, "policy_loss": -0.004828334667105624, "vf_loss": 24825716474.553192, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.021653518219418983, "entropy": 1.7445821077265637, "entropy_coeff": 0.0}}}, "num_steps_sampled": 858858, "num_agent_steps_sampled": 1717716, "num_steps_trained": 858858, "num_agent_steps_trained": 1717716}, "done": false, "episodes_total": 858, "training_iteration": 143, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-16-55", "timestamp": 1624965415, "time_this_iter_s": 25.404572010040283, "time_total_s": 3619.2078347206116, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3619.2078347206116, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 31.312121212121212, "ram_util_percent": 67.12121212121212, "gpu_util_percent0": 0.38393939393939386, "vram_util_percent0": 0.3067071115604988}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1917536.6666969215, "pol1": 1457972.424371127}, "policy_reward_max": {"pol0": -1457972.424371127, "pol1": 1917536.6666969215}, "policy_reward_mean": {"pol0": -1753779.4016325227, "pol1": 1753779.4016325227}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1845615.5386860177, -1631979.8432875567, -1829830.5132111672, -1833469.0993183504, -1493375.9822050584, -1584080.721163838, -1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154], "policy_pol1_reward": [1845615.5386860177, 1631979.8432875567, 1829830.5132111672, 1833469.0993183504, 1493375.9822050584, 1584080.721163838, 1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770087055506464, "mean_inference_ms": 3.8225792136901813, "mean_action_processing_ms": 0.1911255601172672, "mean_env_wait_ms": 0.14465586816665107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 864864, "agent_timesteps_total": 1729728, "timers": {"sample_time_ms": 4553.894, "sample_throughput": 1318.871, "learn_time_ms": 20736.713, "learn_throughput": 289.631, "update_time_ms": 4.876}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 25945468056.51064, "policy_loss": -0.001907547579166737, "vf_loss": 25945468056.51064, "vf_explained_var": 1.1920928955078125e-07, "kl": 0.007928397070537222, "entropy": 2.869974318971025, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26374597828.085106, "policy_loss": -0.004852640977565279, "vf_loss": 26374597828.085106, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.008432677431785046, "entropy": 2.0146741511973927, "entropy_coeff": 0.0}}}, "num_steps_sampled": 864864, "num_agent_steps_sampled": 1729728, "num_steps_trained": 864864, "num_agent_steps_trained": 1729728}, "done": false, "episodes_total": 864, "training_iteration": 144, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-17-20", "timestamp": 1624965440, "time_this_iter_s": 25.309693574905396, "time_total_s": 3644.517528295517, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3644.517528295517, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 30.40588235294118, "ram_util_percent": 67.30000000000001, "gpu_util_percent0": 0.3741176470588236, "vram_util_percent0": 0.30668232915006255}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1917536.6666969215, "pol1": 1457972.424371127}, "policy_reward_max": {"pol0": -1457972.424371127, "pol1": 1917536.6666969215}, "policy_reward_mean": {"pol0": -1752994.7048390422, "pol1": 1752994.7048390422}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1595259.4325222396, -1888753.1903832532, -1782124.952034627, -1808626.544889796, -1863293.036411481, -1809860.33281848, -1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539], "policy_pol1_reward": [1595259.4325222396, 1888753.1903832532, 1782124.952034627, 1808626.544889796, 1863293.036411481, 1809860.33281848, 1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2770049351010931, "mean_inference_ms": 3.8226430312239885, "mean_action_processing_ms": 0.19112864603984142, "mean_env_wait_ms": 0.14465831993758713, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 870870, "agent_timesteps_total": 1741740, "timers": {"sample_time_ms": 4548.497, "sample_throughput": 1320.436, "learn_time_ms": 20730.968, "learn_throughput": 289.712, "update_time_ms": 4.886}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 23575369771.574467, "policy_loss": -0.0021290943185065655, "vf_loss": 23575369771.574467, "vf_explained_var": 9.638198150696553e-08, "kl": 0.0073560465602798665, "entropy": 2.8096633718368853, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23953963313.02128, "policy_loss": -0.007770031948197395, "vf_loss": 23953963313.02128, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.010369612458855548, "entropy": 2.0132523318554494, "entropy_coeff": 0.0}}}, "num_steps_sampled": 870870, "num_agent_steps_sampled": 1741740, "num_steps_trained": 870870, "num_agent_steps_trained": 1741740}, "done": false, "episodes_total": 870, "training_iteration": 145, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-17-46", "timestamp": 1624965466, "time_this_iter_s": 25.18494486808777, "time_total_s": 3669.7024731636047, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3669.7024731636047, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 30.55757575757576, "ram_util_percent": 67.34848484848484, "gpu_util_percent0": 0.38484848484848483, "vram_util_percent0": 0.3067530716671263}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1917536.6666969215, "pol1": 1457972.424371127}, "policy_reward_max": {"pol0": -1457972.424371127, "pol1": 1917536.6666969215}, "policy_reward_mean": {"pol0": -1751428.4795541437, "pol1": 1751428.4795541437}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1832170.4254515881, -1826784.4886859888, -1760362.6709079382, -1679714.1142021639, -1638950.1523760715, -1800141.833369943, -1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022], "policy_pol1_reward": [1832170.4254515881, 1826784.4886859888, 1760362.6709079382, 1679714.1142021639, 1638950.1523760715, 1800141.833369943, 1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27700408080161465, "mean_inference_ms": 3.8227234084818287, "mean_action_processing_ms": 0.19113295672371, "mean_env_wait_ms": 0.14466171814732842, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 876876, "agent_timesteps_total": 1753752, "timers": {"sample_time_ms": 4553.018, "sample_throughput": 1319.125, "learn_time_ms": 20722.041, "learn_throughput": 289.836, "update_time_ms": 4.924}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 25788069060.085106, "policy_loss": -0.0019715830604446695, "vf_loss": 25788069060.085106, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.007295336901269695, "entropy": 2.858786664110549, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26210982105.87234, "policy_loss": -0.008136123101762, "vf_loss": 26210982105.87234, "vf_explained_var": -1.2174565711120522e-07, "kl": 0.011920097878480211, "entropy": 2.1430173427500625, "entropy_coeff": 0.0}}}, "num_steps_sampled": 876876, "num_agent_steps_sampled": 1753752, "num_steps_trained": 876876, "num_agent_steps_trained": 1753752}, "done": false, "episodes_total": 876, "training_iteration": 146, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-18-11", "timestamp": 1624965491, "time_this_iter_s": 25.327878952026367, "time_total_s": 3695.030352115631, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06279d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3695.030352115631, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 30.884848484848487, "ram_util_percent": 67.23636363636363, "gpu_util_percent0": 0.3787878787878788, "vram_util_percent0": 0.3065998713117014}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1917536.6666969215, "pol1": 1457972.424371127}, "policy_reward_max": {"pol0": -1457972.424371127, "pol1": 1917536.6666969215}, "policy_reward_mean": {"pol0": -1754351.4064532993, "pol1": 1754351.4064532993}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1644038.4984363564, -1800345.459561304, -1850129.4492066163, -1829634.9133657382, -1704546.1787060571, -1792262.5477021094, -1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002], "policy_pol1_reward": [1644038.4984363564, 1800345.459561304, 1850129.4492066163, 1829634.9133657382, 1704546.1787060571, 1792262.5477021094, 1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27700166665140097, "mean_inference_ms": 3.8228215799526857, "mean_action_processing_ms": 0.19113535411241603, "mean_env_wait_ms": 0.14466567611036107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 882882, "agent_timesteps_total": 1765764, "timers": {"sample_time_ms": 4559.212, "sample_throughput": 1317.333, "learn_time_ms": 20718.289, "learn_throughput": 289.889, "update_time_ms": 4.893}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 27110811212.255318, "policy_loss": 0.0006246457391596855, "vf_loss": 27110811212.255318, "vf_explained_var": -1.0906381930908537e-07, "kl": 0.0054128901894263766, "entropy": 2.8108053866853107, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27559666143.31915, "policy_loss": -0.0034867826096237975, "vf_loss": 27559666143.31915, "vf_explained_var": -1.1667292199035728e-07, "kl": 0.008679732591151557, "entropy": 2.3419432995167186, "entropy_coeff": 0.0}}}, "num_steps_sampled": 882882, "num_agent_steps_sampled": 1765764, "num_steps_trained": 882882, "num_agent_steps_trained": 1765764}, "done": false, "episodes_total": 882, "training_iteration": 147, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-18-36", "timestamp": 1624965516, "time_this_iter_s": 25.28305959701538, "time_total_s": 3720.3134117126465, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3720.3134117126465, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 30.023529411764702, "ram_util_percent": 67.32058823529414, "gpu_util_percent0": 0.3826470588235294, "vram_util_percent0": 0.3066724161858879}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1917536.6666969215, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1917536.6666969215}, "policy_reward_mean": {"pol0": -1749718.816324087, "pol1": 1749718.816324087}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1902828.9251635985, -1917536.6666969215, -1800872.9373238687, -1610358.187595515, -1830916.7177496972, -1764046.8702783573, -1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606], "policy_pol1_reward": [1902828.9251635985, 1917536.6666969215, 1800872.9373238687, 1610358.187595515, 1830916.7177496972, 1764046.8702783573, 1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27699963890919954, "mean_inference_ms": 3.822929545816549, "mean_action_processing_ms": 0.1911385554147835, "mean_env_wait_ms": 0.14467005861623133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 888888, "agent_timesteps_total": 1777776, "timers": {"sample_time_ms": 4582.84, "sample_throughput": 1310.541, "learn_time_ms": 20739.741, "learn_throughput": 289.589, "update_time_ms": 4.857}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 23643679112.17021, "policy_loss": -0.005364136730736875, "vf_loss": 23643679112.17021, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.013016245010843936, "entropy": 2.7365802957656538, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24042379481.87234, "policy_loss": -0.005320651734128911, "vf_loss": 24042379481.87234, "vf_explained_var": -1.2555021555726853e-07, "kl": 0.008160650640963874, "entropy": 2.3215385396429835, "entropy_coeff": 0.0}}}, "num_steps_sampled": 888888, "num_agent_steps_sampled": 1777776, "num_steps_trained": 888888, "num_agent_steps_trained": 1777776}, "done": false, "episodes_total": 888, "training_iteration": 148, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-19-02", "timestamp": 1624965542, "time_this_iter_s": 25.44087839126587, "time_total_s": 3745.7542901039124, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3745.7542901039124, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 31.62121212121212, "ram_util_percent": 67.06363636363635, "gpu_util_percent0": 0.373030303030303, "vram_util_percent0": 0.3017536334017628}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1908228.7879346458, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1908228.7879346458}, "policy_reward_mean": {"pol0": -1747773.3691513839, "pol1": 1747773.3691513839}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1633148.7258637182, -1775665.5776156653, -1775889.78854189, -1813226.9979550184, -1908228.7879346458, -1659281.9956113962, -1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508], "policy_pol1_reward": [1633148.7258637182, 1775665.5776156653, 1775889.78854189, 1813226.9979550184, 1908228.7879346458, 1659281.9956113962, 1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27699663905351435, "mean_inference_ms": 3.8230137923703302, "mean_action_processing_ms": 0.19114070725781596, "mean_env_wait_ms": 0.14467326631954092, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 894894, "agent_timesteps_total": 1789788, "timers": {"sample_time_ms": 4586.232, "sample_throughput": 1309.572, "learn_time_ms": 20748.621, "learn_throughput": 289.465, "update_time_ms": 4.863}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 26031158555.234043, "policy_loss": 0.0006396132224100701, "vf_loss": 26031158555.234043, "vf_explained_var": 8.116376903899436e-08, "kl": 0.011827587883206123, "entropy": 2.8204278337194566, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26484202125.61702, "policy_loss": -0.006385204679471381, "vf_loss": 26484202125.61702, "vf_explained_var": -8.370013659941833e-08, "kl": 0.006355800408315152, "entropy": 2.4953963705833924, "entropy_coeff": 0.0}}}, "num_steps_sampled": 894894, "num_agent_steps_sampled": 1789788, "num_steps_trained": 894894, "num_agent_steps_trained": 1789788}, "done": false, "episodes_total": 894, "training_iteration": 149, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-19-27", "timestamp": 1624965567, "time_this_iter_s": 25.415035486221313, "time_total_s": 3771.1693255901337, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3771.1693255901337, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 30.83823529411765, "ram_util_percent": 67.03529411764706, "gpu_util_percent0": 0.38235294117647056, "vram_util_percent0": 0.2996094292115229}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1748269.5493309062, "pol1": 1748269.5493309062}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1745008.7870183613, -1786193.97657308, -1809405.303583295, -1692978.5960046432, -1528974.1602955307, -1823187.3359376565, -1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363], "policy_pol1_reward": [1745008.7870183613, 1786193.97657308, 1809405.303583295, 1692978.5960046432, 1528974.1602955307, 1823187.3359376565, 1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769925452529128, "mean_inference_ms": 3.8230796542639536, "mean_action_processing_ms": 0.19114179062062017, "mean_env_wait_ms": 0.14467571728046255, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 900900, "agent_timesteps_total": 1801800, "timers": {"sample_time_ms": 4582.849, "sample_throughput": 1310.538, "learn_time_ms": 20745.24, "learn_throughput": 289.512, "update_time_ms": 4.859}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 25896963006.638298, "policy_loss": -0.0006120939679602359, "vf_loss": 25896963006.638298, "vf_explained_var": 2.916823049758932e-08, "kl": 0.0073231497898380805, "entropy": 2.953028415111785, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26344967538.38298, "policy_loss": -0.0052797831594944, "vf_loss": 26344967538.38298, "vf_explained_var": -1.0906381930908537e-07, "kl": 0.008778877358170265, "entropy": 2.399412637061261, "entropy_coeff": 0.0}}}, "num_steps_sampled": 900900, "num_agent_steps_sampled": 1801800, "num_steps_trained": 900900, "num_agent_steps_trained": 1801800}, "done": false, "episodes_total": 900, "training_iteration": 150, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-19-53", "timestamp": 1624965593, "time_this_iter_s": 25.407068967819214, "time_total_s": 3796.576394557953, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3796.576394557953, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 30.951515151515146, "ram_util_percent": 67.1969696969697, "gpu_util_percent0": 0.3833333333333333, "vram_util_percent0": 0.299695641960556}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1751485.7619632992, "pol1": 1751485.7619632992}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1860156.0151545869, -1797593.4222781337, -1655915.6576319404, -1856082.3959181162, -1821608.6017419056, -1777201.4512841431, -1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059], "policy_pol1_reward": [1860156.0151545869, 1797593.4222781337, 1655915.6576319404, 1856082.3959181162, 1821608.6017419056, 1777201.4512841431, 1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769858432001721, "mean_inference_ms": 3.8231278220500298, "mean_action_processing_ms": 0.19114240509848127, "mean_env_wait_ms": 0.144677741096279, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 906906, "agent_timesteps_total": 1813812, "timers": {"sample_time_ms": 4573.161, "sample_throughput": 1313.315, "learn_time_ms": 20716.303, "learn_throughput": 289.917, "update_time_ms": 4.919}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 26452758266.553192, "policy_loss": -0.0011646487710482263, "vf_loss": 26452758266.553192, "vf_explained_var": 3.804551784725163e-09, "kl": 0.014072076972336211, "entropy": 2.840429539376117, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26913596176.340427, "policy_loss": -0.005995279059131095, "vf_loss": 26913596176.340427, "vf_explained_var": -1.0145471662781347e-07, "kl": 0.008760079691939532, "entropy": 2.510929599721381, "entropy_coeff": 0.0}}}, "num_steps_sampled": 906906, "num_agent_steps_sampled": 1813812, "num_steps_trained": 906906, "num_agent_steps_trained": 1813812}, "done": false, "episodes_total": 906, "training_iteration": 151, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-20-18", "timestamp": 1624965618, "time_this_iter_s": 25.172173500061035, "time_total_s": 3821.748568058014, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cda60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd6a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3821.748568058014, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 30.336363636363636, "ram_util_percent": 67.37272727272727, "gpu_util_percent0": 0.386060606060606, "vram_util_percent0": 0.2996139351043295}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1747160.9286503845, "pol1": 1747160.9286503845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1829781.2564128027, -1853117.3396528056, -1837602.2985404322, -1738601.3669728998, -1720497.7933603595, -1811785.8842218104, -1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272], "policy_pol1_reward": [1829781.2564128027, 1853117.3396528056, 1837602.2985404322, 1738601.3669728998, 1720497.7933603595, 1811785.8842218104, 1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769757025698829, "mean_inference_ms": 3.8231894961137316, "mean_action_processing_ms": 0.19114204006631166, "mean_env_wait_ms": 0.14467998048498998, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 912912, "agent_timesteps_total": 1825824, "timers": {"sample_time_ms": 4595.319, "sample_throughput": 1306.982, "learn_time_ms": 20737.308, "learn_throughput": 289.623, "update_time_ms": 4.949}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.012027114909142251, "cur_lr": 5.000000000000002e-05, "total_loss": 24691231504.340427, "policy_loss": 0.0010414047444120367, "vf_loss": 24691231504.340427, "vf_explained_var": 3.424096561843726e-08, "kl": 0.004431338723194092, "entropy": 2.7109994634668877, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25126631380.425533, "policy_loss": -0.008061019624484347, "vf_loss": 25126631380.425533, "vf_explained_var": 1.5218207138900652e-08, "kl": 0.008039647822288122, "entropy": 2.3892928843802594, "entropy_coeff": 0.0}}}, "num_steps_sampled": 912912, "num_agent_steps_sampled": 1825824, "num_steps_trained": 912912, "num_agent_steps_trained": 1825824}, "done": false, "episodes_total": 912, "training_iteration": 152, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-20-43", "timestamp": 1624965643, "time_this_iter_s": 25.515000343322754, "time_total_s": 3847.2635684013367, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3847.2635684013367, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 30.99411764705883, "ram_util_percent": 67.10294117647058, "gpu_util_percent0": 0.3852941176470588, "vram_util_percent0": 0.29967881996074464}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1740971.6891804202, "pol1": 1740971.6891804202}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1631985.5474536482, -1831336.8566496505, -1785682.533784335, -1798056.4224460952, -1615754.455009096, -1663640.4501534074, -1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453], "policy_pol1_reward": [1631985.5474536482, 1831336.8566496505, 1785682.533784335, 1798056.4224460952, 1615754.455009096, 1663640.4501534074, 1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27696339083458293, "mean_inference_ms": 3.823243751358882, "mean_action_processing_ms": 0.19114107507343692, "mean_env_wait_ms": 0.14468217921417015, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 918918, "agent_timesteps_total": 1837836, "timers": {"sample_time_ms": 4599.938, "sample_throughput": 1305.67, "learn_time_ms": 20734.197, "learn_throughput": 289.666, "update_time_ms": 4.927}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 23728400514.723404, "policy_loss": -0.002026280147974637, "vf_loss": 23728400514.723404, "vf_explained_var": -1.471093327154449e-07, "kl": 0.006900586514793178, "entropy": 2.6439756078923002, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24139299033.87234, "policy_loss": -0.0020919355583634783, "vf_loss": 24139299033.87234, "vf_explained_var": 3.170459805801329e-08, "kl": 0.007962504441433765, "entropy": 2.2718292449383024, "entropy_coeff": 0.0}}}, "num_steps_sampled": 918918, "num_agent_steps_sampled": 1837836, "num_steps_trained": 918918, "num_agent_steps_trained": 1837836}, "done": false, "episodes_total": 918, "training_iteration": 153, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-21-09", "timestamp": 1624965669, "time_this_iter_s": 25.41946005821228, "time_total_s": 3872.683028459549, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3872.683028459549, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 31.71515151515151, "ram_util_percent": 67.11818181818182, "gpu_util_percent0": 0.37333333333333335, "vram_util_percent0": 0.29960882842581527}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1746450.9858868078, "pol1": 1746450.9858868078}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1545487.5745191015, -1882584.2575504754, -1862583.6068857627, -1887261.205215095, -1738154.9794655403, -1756832.4520751308, -1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772], "policy_pol1_reward": [1545487.5745191015, 1882584.2575504754, 1862583.6068857627, 1887261.205215095, 1738154.9794655403, 1756832.4520751308, 1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769535837261716, "mean_inference_ms": 3.8233325628902306, "mean_action_processing_ms": 0.1911417117511756, "mean_env_wait_ms": 0.14468536739546292, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 924924, "agent_timesteps_total": 1849848, "timers": {"sample_time_ms": 4588.252, "sample_throughput": 1308.995, "learn_time_ms": 20730.653, "learn_throughput": 289.716, "update_time_ms": 4.896}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 27158937120.68085, "policy_loss": -0.0010479770283749763, "vf_loss": 27158937120.68085, "vf_explained_var": -1.5091389116150822e-07, "kl": 0.007045496760451413, "entropy": 2.6081541802020785, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27642501730.042553, "policy_loss": -0.005697389985335634, "vf_loss": 27642501730.042553, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.007428548863514307, "entropy": 2.1528341973081546, "entropy_coeff": 0.0}}}, "num_steps_sampled": 924924, "num_agent_steps_sampled": 1849848, "num_steps_trained": 924924, "num_agent_steps_trained": 1849848}, "done": false, "episodes_total": 924, "training_iteration": 154, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-21-34", "timestamp": 1624965694, "time_this_iter_s": 25.15616726875305, "time_total_s": 3897.839195728302, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e53c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e536a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3897.839195728302, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 30.945454545454545, "ram_util_percent": 67.22424242424243, "gpu_util_percent0": 0.38151515151515153, "vram_util_percent0": 0.2996037217473011}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1737796.1693835256, "pol1": 1737796.1693835256}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1843860.5491402412, -1707004.868769653, -1624427.2849905775, -1817463.2725752054, -1830569.5914146109, -1621680.5747120292, -1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011], "policy_pol1_reward": [1843860.5491402412, 1707004.868769653, 1624427.2849905775, 1817463.2725752054, 1830569.5914146109, 1621680.5747120292, 1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769370171475199, "mean_inference_ms": 3.823404721243477, "mean_action_processing_ms": 0.1911423152112187, "mean_env_wait_ms": 0.14468862539664015, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 930930, "agent_timesteps_total": 1861860, "timers": {"sample_time_ms": 4581.524, "sample_throughput": 1310.918, "learn_time_ms": 20734.363, "learn_throughput": 289.664, "update_time_ms": 4.895}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 22035285580.255318, "policy_loss": -0.004091158747038943, "vf_loss": 22035285580.255318, "vf_explained_var": 1.0525926796844942e-07, "kl": 0.012089702855557837, "entropy": 2.7685843477857874, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22432054860.255318, "policy_loss": -0.005595724772107094, "vf_loss": 22432054860.255318, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.009403055395059128, "entropy": 2.1625012894894216, "entropy_coeff": 0.0}}}, "num_steps_sampled": 930930, "num_agent_steps_sampled": 1861860, "num_steps_trained": 930930, "num_agent_steps_trained": 1861860}, "done": false, "episodes_total": 930, "training_iteration": 155, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-21-59", "timestamp": 1624965719, "time_this_iter_s": 25.156182050704956, "time_total_s": 3922.995377779007, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e53400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e53378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3922.995377779007, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 29.670588235294115, "ram_util_percent": 67.33235294117647, "gpu_util_percent0": 0.37764705882352945, "vram_util_percent0": 0.29966890699657006}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1737224.7607347753, "pol1": 1737224.7607347753}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1814396.8428422778, -1574543.2444148543, -1637470.072589545, -1722375.042732397, -1457972.424371127, -1867578.6927338638, -1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432], "policy_pol1_reward": [1814396.8428422778, 1574543.2444148543, 1637470.072589545, 1722375.042732397, 1457972.424371127, 1867578.6927338638, 1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27692811997889594, "mean_inference_ms": 3.8234808432403984, "mean_action_processing_ms": 0.19114433337744888, "mean_env_wait_ms": 0.14469258678466404, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 936936, "agent_timesteps_total": 1873872, "timers": {"sample_time_ms": 4584.581, "sample_throughput": 1310.043, "learn_time_ms": 20765.311, "learn_throughput": 289.232, "update_time_ms": 4.84}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 24620432972.255318, "policy_loss": -0.001460449829539086, "vf_loss": 24620432972.255318, "vf_explained_var": 6.21410123358146e-08, "kl": 0.011378491317179608, "entropy": 2.7888683461128396, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25051359711.31915, "policy_loss": -0.00721370555618976, "vf_loss": 25051359711.31915, "vf_explained_var": 1.2555021555726853e-07, "kl": 0.010321810583960502, "entropy": 2.1340520635564277, "entropy_coeff": 0.0}}}, "num_steps_sampled": 936936, "num_agent_steps_sampled": 1873872, "num_steps_trained": 936936, "num_agent_steps_trained": 1873872}, "done": false, "episodes_total": 936, "training_iteration": 156, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-22-25", "timestamp": 1624965745, "time_this_iter_s": 25.667953729629517, "time_total_s": 3948.6633315086365, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e53bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e537b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3948.6633315086365, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 32.018181818181816, "ram_util_percent": 67.24242424242425, "gpu_util_percent0": 0.3745454545454545, "vram_util_percent0": 0.299567974997702}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1741112.9668044606, "pol1": 1741112.9668044606}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1882907.0262856467, -1758838.4093043245, -1536982.3064918362, -1661073.7010809365, -1669299.0882366218, -1795377.527179692, -1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771], "policy_pol1_reward": [1882907.0262856467, 1758838.4093043245, 1536982.3064918362, 1661073.7010809365, 1669299.0882366218, 1795377.527179692, 1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769182734384008, "mean_inference_ms": 3.823531213435477, "mean_action_processing_ms": 0.19114485148563268, "mean_env_wait_ms": 0.14469546255114574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 942942, "agent_timesteps_total": 1885884, "timers": {"sample_time_ms": 4582.575, "sample_throughput": 1310.617, "learn_time_ms": 20759.762, "learn_throughput": 289.31, "update_time_ms": 4.951}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 25249931612.595745, "policy_loss": -0.00047348273244309934, "vf_loss": 25249931612.595745, "vf_explained_var": 1.5218207138900652e-08, "kl": 0.007977074844406006, "entropy": 2.8385176709357727, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25707923194.553192, "policy_loss": -0.006234373223591358, "vf_loss": 25707923194.553192, "vf_explained_var": 9.004106260590561e-08, "kl": 0.006481353134075378, "entropy": 2.118756537741803, "entropy_coeff": 0.0}}}, "num_steps_sampled": 942942, "num_agent_steps_sampled": 1885884, "num_steps_trained": 942942, "num_agent_steps_trained": 1885884}, "done": false, "episodes_total": 942, "training_iteration": 157, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-22-50", "timestamp": 1624965770, "time_this_iter_s": 25.20788550376892, "time_total_s": 3973.8712170124054, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e359d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3973.8712170124054, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 30.541176470588237, "ram_util_percent": 67.21176470588235, "gpu_util_percent0": 0.3835294117647059, "vram_util_percent0": 0.29970855885326825}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1742214.5746324519, "pol1": 1742214.5746324519}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1756661.3934151141, -1693708.023245655, -1872438.258245635, -1892102.2747065807, -1560533.4760148001, -1650598.6460325925, -1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922], "policy_pol1_reward": [1756661.3934151141, 1693708.023245655, 1872438.258245635, 1892102.2747065807, 1560533.4760148001, 1650598.6460325925, 1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27691079234592864, "mean_inference_ms": 3.8235810084138375, "mean_action_processing_ms": 0.19114718706399456, "mean_env_wait_ms": 0.14469855194142744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 948948, "agent_timesteps_total": 1897896, "timers": {"sample_time_ms": 4575.492, "sample_throughput": 1312.646, "learn_time_ms": 20736.67, "learn_throughput": 289.632, "update_time_ms": 5.005}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 25046965618.38298, "policy_loss": -0.0017513102316792976, "vf_loss": 25046965618.38298, "vf_explained_var": 1.5091389116150822e-07, "kl": 0.008982145068968864, "entropy": 2.845041833025344, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25494212520.851063, "policy_loss": -0.00470910851467163, "vf_loss": 25494212520.851063, "vf_explained_var": 9.89183490673895e-08, "kl": 0.015154337609543446, "entropy": 2.1209362212647784, "entropy_coeff": 0.0}}}, "num_steps_sampled": 948948, "num_agent_steps_sampled": 1897896, "num_steps_trained": 948948, "num_agent_steps_trained": 1897896}, "done": false, "episodes_total": 948, "training_iteration": 158, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-23-15", "timestamp": 1624965795, "time_this_iter_s": 25.13937759399414, "time_total_s": 3999.0105946063995, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3999.0105946063995, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 30.142424242424244, "ram_util_percent": 67.42121212121212, "gpu_util_percent0": 0.38545454545454544, "vram_util_percent0": 0.29957308167621616}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1739975.6269031453, "pol1": 1739975.6269031453}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1777291.4418707439, -1821399.0864517603, -1854576.6786537264, -1642511.7106421532, -1865779.213106862, -1794321.4595999767, -1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923], "policy_pol1_reward": [1777291.4418707439, 1821399.0864517603, 1854576.6786537264, 1642511.7106421532, 1865779.213106862, 1794321.4595999767, 1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2769064654720622, "mean_inference_ms": 3.823704517846571, "mean_action_processing_ms": 0.1911529334493257, "mean_env_wait_ms": 0.14470365402434912, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 954954, "agent_timesteps_total": 1909908, "timers": {"sample_time_ms": 4575.904, "sample_throughput": 1312.528, "learn_time_ms": 20718.188, "learn_throughput": 289.89, "update_time_ms": 5.004}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 24046215603.744682, "policy_loss": -0.0006274792583698922, "vf_loss": 24046215603.744682, "vf_explained_var": -2.1559126039960574e-08, "kl": 0.006408843310906532, "entropy": 2.8258745416681816, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24486206572.93617, "policy_loss": -0.006217104006320872, "vf_loss": 24486206572.93617, "vf_explained_var": 8.62365041598423e-08, "kl": 0.007682278336204113, "entropy": 2.039329523735858, "entropy_coeff": 0.0}}}, "num_steps_sampled": 954954, "num_agent_steps_sampled": 1909908, "num_steps_trained": 954954, "num_agent_steps_trained": 1909908}, "done": false, "episodes_total": 954, "training_iteration": 159, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-23-41", "timestamp": 1624965821, "time_this_iter_s": 25.233973741531372, "time_total_s": 4024.244568347931, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4024.244568347931, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 30.866666666666664, "ram_util_percent": 67.24848484848485, "gpu_util_percent0": 0.3784848484848485, "vram_util_percent0": 0.2997109619960985}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1904816.8381401612, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1904816.8381401612}, "policy_reward_mean": {"pol0": -1730835.0173945576, "pol1": 1730835.0173945576}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1727921.3653886395, -1527815.6467972563, -1869608.7728740477, -1784448.1153174154, -1788876.9718763605, -1791016.1925600222, -1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227], "policy_pol1_reward": [1727921.3653886395, 1527815.6467972563, 1869608.7728740477, 1784448.1153174154, 1788876.9718763605, 1791016.1925600222, 1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27690480177026233, "mean_inference_ms": 3.8237900389477453, "mean_action_processing_ms": 0.19115736491393193, "mean_env_wait_ms": 0.14470674573361297, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 960960, "agent_timesteps_total": 1921920, "timers": {"sample_time_ms": 4563.366, "sample_throughput": 1316.134, "learn_time_ms": 20702.413, "learn_throughput": 290.111, "update_time_ms": 5.175}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 22314633433.87234, "policy_loss": -0.0021477414176185082, "vf_loss": 22314633433.87234, "vf_explained_var": 1.2935475979247713e-07, "kl": 0.00854625709434139, "entropy": 2.7810400090319045, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22713191184.340427, "policy_loss": -0.005301797722882413, "vf_loss": 22713191184.340427, "vf_explained_var": 0.0, "kl": 0.009478976107896008, "entropy": 1.9344137399754626, "entropy_coeff": 0.0}}}, "num_steps_sampled": 960960, "num_agent_steps_sampled": 1921920, "num_steps_trained": 960960, "num_agent_steps_trained": 1921920}, "done": false, "episodes_total": 960, "training_iteration": 160, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-24-06", "timestamp": 1624965846, "time_this_iter_s": 25.124674558639526, "time_total_s": 4049.3692429065704, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cda60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd6a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4049.3692429065704, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 30.142424242424244, "ram_util_percent": 67.42121212121211, "gpu_util_percent0": 0.38030303030303025, "vram_util_percent0": 0.2996190417828436}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930804.5626507064, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1930804.5626507064}, "policy_reward_mean": {"pol0": -1730436.0009548506, "pol1": 1730436.0009548506}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1608178.8648231516, -1631054.1871496232, -1543095.7616825444, -1777660.0404322539, -1702216.4238190108, -1805124.0102083092, -1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743], "policy_pol1_reward": [1608178.8648231516, 1631054.1871496232, 1543095.7616825444, 1777660.0404322539, 1702216.4238190108, 1805124.0102083092, 1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27689941605286184, "mean_inference_ms": 3.8238675533524016, "mean_action_processing_ms": 0.19116104666939548, "mean_env_wait_ms": 0.14471025532277607, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 966966, "agent_timesteps_total": 1933932, "timers": {"sample_time_ms": 4567.274, "sample_throughput": 1315.008, "learn_time_ms": 20699.171, "learn_throughput": 290.157, "update_time_ms": 5.092}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.006013557454571126, "cur_lr": 5.000000000000002e-05, "total_loss": 25080299345.70213, "policy_loss": -0.00011872030556836026, "vf_loss": 25080299345.70213, "vf_explained_var": 1.39500230034173e-07, "kl": 0.0029941808749386605, "entropy": 2.8065913636633693, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25546381006.97872, "policy_loss": -0.00641958817760361, "vf_loss": 25546381006.97872, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.009640707723558583, "entropy": 1.9985179951850405, "entropy_coeff": 0.0}}}, "num_steps_sampled": 966966, "num_agent_steps_sampled": 1933932, "num_steps_trained": 966966, "num_agent_steps_trained": 1933932}, "done": false, "episodes_total": 966, "training_iteration": 161, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-24-31", "timestamp": 1624965871, "time_this_iter_s": 25.177204847335815, "time_total_s": 4074.5464477539062, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e53bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e53f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4074.5464477539062, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 30.96969696969697, "ram_util_percent": 67.25454545454545, "gpu_util_percent0": 0.37636363636363634, "vram_util_percent0": 0.2995781883547303}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930804.5626507064, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1930804.5626507064}, "policy_reward_mean": {"pol0": -1736451.1363140724, "pol1": 1736451.1363140724}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1713899.7522363917, -1895593.8051448024, -1784428.1561295222, -1690032.8130320022, -1830828.1943744724, -1874562.649128952, -1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803], "policy_pol1_reward": [1713899.7522363917, 1895593.8051448024, 1784428.1561295222, 1690032.8130320022, 1830828.1943744724, 1874562.649128952, 1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27688713648979396, "mean_inference_ms": 3.823959068698987, "mean_action_processing_ms": 0.1911641934607977, "mean_env_wait_ms": 0.14471336034912025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 972972, "agent_timesteps_total": 1945944, "timers": {"sample_time_ms": 4565.043, "sample_throughput": 1315.65, "learn_time_ms": 20661.55, "learn_throughput": 290.685, "update_time_ms": 5.074}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003006778727285563, "cur_lr": 5.000000000000002e-05, "total_loss": 26218292899.404255, "policy_loss": -0.0013292802378852317, "vf_loss": 26218292899.404255, "vf_explained_var": -2.5363679156953367e-08, "kl": 0.006655577590015341, "entropy": 2.8085992082636406, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26693502104.51064, "policy_loss": -0.0074328104470004425, "vf_loss": 26693502104.51064, "vf_explained_var": -7.609103569450326e-09, "kl": 0.011992156901892195, "entropy": 1.8724628306449729, "entropy_coeff": 0.0}}}, "num_steps_sampled": 972972, "num_agent_steps_sampled": 1945944, "num_steps_trained": 972972, "num_agent_steps_trained": 1945944}, "done": false, "episodes_total": 972, "training_iteration": 162, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-24-56", "timestamp": 1624965896, "time_this_iter_s": 25.115808963775635, "time_total_s": 4099.662256717682, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e53598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e53378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4099.662256717682, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 29.421212121212122, "ram_util_percent": 67.55757575757575, "gpu_util_percent0": 0.37787878787878787, "vram_util_percent0": 0.2997058553175843}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930804.5626507064, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1930804.5626507064}, "policy_reward_mean": {"pol0": -1724525.4821889058, "pol1": 1724525.4821889058}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1690932.8468900986, -1711194.9095969065, -1834493.1607675096, -1888404.6141513002, -1670117.199437903, -1840467.4482310277, -1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396], "policy_pol1_reward": [1690932.8468900986, 1711194.9095969065, 1834493.1607675096, 1888404.6141513002, 1670117.199437903, 1840467.4482310277, 1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27687208374812805, "mean_inference_ms": 3.823971531364508, "mean_action_processing_ms": 0.19116320194957684, "mean_env_wait_ms": 0.14471344170509276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 978978, "agent_timesteps_total": 1957956, "timers": {"sample_time_ms": 4536.425, "sample_throughput": 1323.95, "learn_time_ms": 20652.283, "learn_throughput": 290.815, "update_time_ms": 5.075}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003006778727285563, "cur_lr": 5.000000000000002e-05, "total_loss": 21148498486.468086, "policy_loss": -6.784867257513898e-05, "vf_loss": 21148498486.468086, "vf_explained_var": -2.663186293716535e-08, "kl": 0.00595969076644867, "entropy": 2.7297579684156053, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 21544115091.06383, "policy_loss": -0.006132692930863258, "vf_loss": 21544115091.06383, "vf_explained_var": -8.87728734966231e-09, "kl": 0.009411367924606546, "entropy": 2.0333837549737157, "entropy_coeff": 0.0}}}, "num_steps_sampled": 978978, "num_agent_steps_sampled": 1957956, "num_steps_trained": 978978, "num_agent_steps_trained": 1957956}, "done": false, "episodes_total": 978, "training_iteration": 163, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-25-21", "timestamp": 1624965921, "time_this_iter_s": 25.04021906852722, "time_total_s": 4124.702475786209, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05ee0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05ee510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4124.702475786209, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 30.26969696969697, "ram_util_percent": 67.4818181818182, "gpu_util_percent0": 0.38393939393939386, "vram_util_percent0": 0.2995781883547304}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930804.5626507064, "pol1": 1425815.584304448}, "policy_reward_max": {"pol0": -1425815.584304448, "pol1": 1930804.5626507064}, "policy_reward_mean": {"pol0": -1726431.2297920787, "pol1": 1726431.2297920787}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1425815.584304448, -1602257.336659933, -1763728.0846820578, -1855312.380741606, -1620449.8162452364, -1833045.23896843, -1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802], "policy_pol1_reward": [1425815.584304448, 1602257.336659933, 1763728.0846820578, 1855312.380741606, 1620449.8162452364, 1833045.23896843, 1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2768580165700036, "mean_inference_ms": 3.8240249985716654, "mean_action_processing_ms": 0.19116386049911252, "mean_env_wait_ms": 0.14471542812992372, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 984984, "agent_timesteps_total": 1969968, "timers": {"sample_time_ms": 4555.858, "sample_throughput": 1318.303, "learn_time_ms": 20649.969, "learn_throughput": 290.848, "update_time_ms": 5.053}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003006778727285563, "cur_lr": 5.000000000000002e-05, "total_loss": 27182071938.723404, "policy_loss": -0.0011103534129785096, "vf_loss": 27182071938.723404, "vf_explained_var": -8.87728734966231e-09, "kl": 0.00392017732473447, "entropy": 2.79749485786925, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27710406438.12766, "policy_loss": -0.005972892521543705, "vf_loss": 27710406438.12766, "vf_explained_var": -9.130924638611759e-08, "kl": 0.008459823790620616, "entropy": 2.0758190814484943, "entropy_coeff": 0.0}}}, "num_steps_sampled": 984984, "num_agent_steps_sampled": 1969968, "num_steps_trained": 984984, "num_agent_steps_trained": 1969968}, "done": false, "episodes_total": 984, "training_iteration": 164, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-25-47", "timestamp": 1624965947, "time_this_iter_s": 25.328068494796753, "time_total_s": 4150.030544281006, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e53ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e53730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4150.030544281006, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 30.57058823529412, "ram_util_percent": 67.24117647058826, "gpu_util_percent0": 0.37529411764705883, "vram_util_percent0": 0.29969864588909373}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930804.5626507064, "pol1": 1426016.564986011}, "policy_reward_max": {"pol0": -1426016.564986011, "pol1": 1930804.5626507064}, "policy_reward_mean": {"pol0": -1731747.4520252014, "pol1": 1731747.4520252014}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1838145.657908525, -1887809.4979837958, -1904816.8381401612, -1547748.5382914508, -1903629.8176529899, -1788951.5731593804, -1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001], "policy_pol1_reward": [1838145.657908525, 1887809.4979837958, 1904816.8381401612, 1547748.5382914508, 1903629.8176529899, 1788951.5731593804, 1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2768362520189718, "mean_inference_ms": 3.8240273798285678, "mean_action_processing_ms": 0.19116178275996773, "mean_env_wait_ms": 0.14471611040752527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 990990, "agent_timesteps_total": 1981980, "timers": {"sample_time_ms": 4552.508, "sample_throughput": 1319.273, "learn_time_ms": 20657.31, "learn_throughput": 290.745, "update_time_ms": 4.996}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015033893636427814, "cur_lr": 5.000000000000002e-05, "total_loss": 25994946254.97872, "policy_loss": -0.0021191905549866087, "vf_loss": 25994946254.97872, "vf_explained_var": -1.39500230034173e-07, "kl": 0.009256019534424264, "entropy": 2.79897795332239, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26488789645.61702, "policy_loss": -0.005805278196930885, "vf_loss": 26488789645.61702, "vf_explained_var": -1.280865831176925e-07, "kl": 0.008130289188170053, "entropy": 2.1170850713202296, "entropy_coeff": 0.0}}}, "num_steps_sampled": 990990, "num_agent_steps_sampled": 1981980, "num_steps_trained": 990990, "num_agent_steps_trained": 1981980}, "done": false, "episodes_total": 990, "training_iteration": 165, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-26-12", "timestamp": 1624965972, "time_this_iter_s": 25.195735931396484, "time_total_s": 4175.226280212402, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4175.226280212402, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 30.578787878787878, "ram_util_percent": 67.38787878787879, "gpu_util_percent0": 0.37636363636363634, "vram_util_percent0": 0.299598615068787}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930804.5626507064, "pol1": 1426016.564986011}, "policy_reward_max": {"pol0": -1426016.564986011, "pol1": 1930804.5626507064}, "policy_reward_mean": {"pol0": -1729317.3844261735, "pol1": 1729317.3844261735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1784814.9946980309, -1818186.6398506297, -1737406.615644261, -1582070.2504693363, -1763437.0862148977, -1867461.9543384223, -1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793], "policy_pol1_reward": [1784814.9946980309, 1818186.6398506297, 1737406.615644261, 1582070.2504693363, 1763437.0862148977, 1867461.9543384223, 1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2768147506037453, "mean_inference_ms": 3.824018693276419, "mean_action_processing_ms": 0.19115909323557514, "mean_env_wait_ms": 0.14471637167711626, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 996996, "agent_timesteps_total": 1993992, "timers": {"sample_time_ms": 4544.972, "sample_throughput": 1321.46, "learn_time_ms": 20616.878, "learn_throughput": 291.315, "update_time_ms": 5.004}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015033893636427814, "cur_lr": 5.000000000000002e-05, "total_loss": 26075642553.19149, "policy_loss": -0.0015211559911357596, "vf_loss": 26075642553.19149, "vf_explained_var": 3.0436414277801305e-08, "kl": 0.006291894242167473, "entropy": 2.7247811530498747, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26576954781.957447, "policy_loss": -0.006108198552689654, "vf_loss": 26576954781.957447, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.007752175016843892, "entropy": 2.0919212077526335, "entropy_coeff": 0.0}}}, "num_steps_sampled": 996996, "num_agent_steps_sampled": 1993992, "num_steps_trained": 996996, "num_agent_steps_trained": 1993992}, "done": false, "episodes_total": 996, "training_iteration": 166, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-26-37", "timestamp": 1624965997, "time_this_iter_s": 25.18791913986206, "time_total_s": 4200.414199352264, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4200.414199352264, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 30.533333333333335, "ram_util_percent": 67.24545454545455, "gpu_util_percent0": 0.3809090909090909, "vram_util_percent0": 0.29972117535312676}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930804.5626507064, "pol1": 1426016.564986011}, "policy_reward_max": {"pol0": -1426016.564986011, "pol1": 1930804.5626507064}, "policy_reward_mean": {"pol0": -1728419.7136893037, "pol1": 1728419.7136893037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1813085.8409309275, -1630245.919986226, -1774480.9643307815, -1858657.6568505059, -1444419.5377322317, -1854955.4306558105, -1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418], "policy_pol1_reward": [1813085.8409309275, 1630245.919986226, 1774480.9643307815, 1858657.6568505059, 1444419.5377322317, 1854955.4306558105, 1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27679847767502636, "mean_inference_ms": 3.8239807976833355, "mean_action_processing_ms": 0.1911553168426774, "mean_env_wait_ms": 0.1447155461855031, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1003002, "agent_timesteps_total": 2006004, "timers": {"sample_time_ms": 4537.821, "sample_throughput": 1323.543, "learn_time_ms": 20609.157, "learn_throughput": 291.424, "update_time_ms": 5.024}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015033893636427814, "cur_lr": 5.000000000000002e-05, "total_loss": 25430826572.255318, "policy_loss": -0.00038902415953418043, "vf_loss": 25430826572.255318, "vf_explained_var": -1.3442749491332506e-07, "kl": 0.004388694141179006, "entropy": 2.7651220027436603, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25915573531.234043, "policy_loss": -0.009644024450569711, "vf_loss": 25915573531.234043, "vf_explained_var": 1.318911273529011e-07, "kl": 0.010979271791082747, "entropy": 2.066297505764251, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1003002, "num_agent_steps_sampled": 2006004, "num_steps_trained": 1003002, "num_agent_steps_trained": 2006004}, "done": false, "episodes_total": 1002, "training_iteration": 167, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-27-02", "timestamp": 1624966022, "time_this_iter_s": 25.059740781784058, "time_total_s": 4225.4739401340485, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4225.4739401340485, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 30.293939393939397, "ram_util_percent": 67.45151515151515, "gpu_util_percent0": 0.3784848484848485, "vram_util_percent0": 0.29964457517541443}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1426016.564986011}, "policy_reward_max": {"pol0": -1426016.564986011, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1725910.3627332374, "pol1": 1725910.3627332374}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1887123.3129344792, -1875428.4985852686, -1562692.7464913134, -1711454.686318272, -1704978.0744596682, -1803278.7265146563, -1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963], "policy_pol1_reward": [1887123.3129344792, 1875428.4985852686, 1562692.7464913134, 1711454.686318272, 1704978.0744596682, 1803278.7265146563, 1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2767860971097703, "mean_inference_ms": 3.8239921821747247, "mean_action_processing_ms": 0.191154401750468, "mean_env_wait_ms": 0.14471569451509078, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1009008, "agent_timesteps_total": 2018016, "timers": {"sample_time_ms": 4547.421, "sample_throughput": 1320.749, "learn_time_ms": 20598.376, "learn_throughput": 291.576, "update_time_ms": 5.02}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0007516946818213907, "cur_lr": 5.000000000000002e-05, "total_loss": 23644175468.93617, "policy_loss": -0.003296375472811942, "vf_loss": 23644175468.93617, "vf_explained_var": 2.2827311596529398e-08, "kl": 0.010391889655209601, "entropy": 2.7623286754526992, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24103095753.531914, "policy_loss": -0.004830327459630814, "vf_loss": 24103095753.531914, "vf_explained_var": -9.130924638611759e-08, "kl": 0.007912802183009843, "entropy": 1.9638128407458042, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1009008, "num_agent_steps_sampled": 2018016, "num_steps_trained": 1009008, "num_agent_steps_trained": 2018016}, "done": false, "episodes_total": 1008, "training_iteration": 168, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-27-27", "timestamp": 1624966047, "time_this_iter_s": 25.127201318740845, "time_total_s": 4250.601141452789, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd6a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4250.601141452789, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 30.87878787878788, "ram_util_percent": 67.38181818181818, "gpu_util_percent0": 0.38060606060606056, "vram_util_percent0": 0.299598615068787}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1426016.564986011}, "policy_reward_max": {"pol0": -1426016.564986011, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1720648.1771127104, "pol1": 1720648.1771127104}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1656774.316382795, -1579934.0777548973, -1712657.008540881, -1714839.7885118453, -1808558.7311904228, -1851880.90235242, -1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096], "policy_pol1_reward": [1656774.316382795, 1579934.0777548973, 1712657.008540881, 1714839.7885118453, 1808558.7311904228, 1851880.90235242, 1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27677301262840504, "mean_inference_ms": 3.8239506887986447, "mean_action_processing_ms": 0.19115165714301896, "mean_env_wait_ms": 0.14471395437648105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1015014, "agent_timesteps_total": 2030028, "timers": {"sample_time_ms": 4540.048, "sample_throughput": 1322.893, "learn_time_ms": 20604.426, "learn_throughput": 291.491, "update_time_ms": 5.4}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0007516946818213907, "cur_lr": 5.000000000000002e-05, "total_loss": 23207490451.06383, "policy_loss": -0.0013358407515160582, "vf_loss": 23207490451.06383, "vf_explained_var": -8.87728734966231e-09, "kl": 0.005220480510925359, "entropy": 2.7316813671842533, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23659976486.12766, "policy_loss": -0.0043436138088161005, "vf_loss": 23659976486.12766, "vf_explained_var": -3.550914939864924e-08, "kl": 0.00832605386707694, "entropy": 1.793990320347725, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1015014, "num_agent_steps_sampled": 2030028, "num_steps_trained": 1015014, "num_agent_steps_trained": 2030028}, "done": false, "episodes_total": 1014, "training_iteration": 169, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-27-53", "timestamp": 1624966073, "time_this_iter_s": 25.2275390625, "time_total_s": 4275.828680515289, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e8d400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4275.828680515289, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 29.852941176470583, "ram_util_percent": 67.45588235294117, "gpu_util_percent0": 0.3855882352941176, "vram_util_percent0": 0.2997135153353555}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1426016.564986011}, "policy_reward_max": {"pol0": -1426016.564986011, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1716667.4709718933, "pol1": 1716667.4709718933}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1789291.8418853746, -1889332.5476474161, -1790506.4039185299, -1744815.5091407772, -1660172.4697862128, -1550495.0593281828, -1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118], "policy_pol1_reward": [1789291.8418853746, 1889332.5476474161, 1790506.4039185299, 1744815.5091407772, 1660172.4697862128, 1550495.0593281828, 1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27675398453507183, "mean_inference_ms": 3.8238935972265216, "mean_action_processing_ms": 0.19114788316105816, "mean_env_wait_ms": 0.1447115588814241, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1021020, "agent_timesteps_total": 2042040, "timers": {"sample_time_ms": 4551.403, "sample_throughput": 1319.593, "learn_time_ms": 20614.876, "learn_throughput": 291.343, "update_time_ms": 5.231}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0007516946818213907, "cur_lr": 5.000000000000002e-05, "total_loss": 22472810321.70213, "policy_loss": -0.0008311416914171361, "vf_loss": 22472810321.70213, "vf_explained_var": -1.318911273529011e-07, "kl": 0.00299958364067084, "entropy": 2.7884295849089926, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22900828290.723404, "policy_loss": -0.007694548481401611, "vf_loss": 22900828290.723404, "vf_explained_var": -3.170459805801329e-08, "kl": 0.00854728391711065, "entropy": 1.7354459762573242, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1021020, "num_agent_steps_sampled": 2042040, "num_steps_trained": 1021020, "num_agent_steps_trained": 2042040}, "done": false, "episodes_total": 1020, "training_iteration": 170, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-28-18", "timestamp": 1624966098, "time_this_iter_s": 25.34239673614502, "time_total_s": 4301.171077251434, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4301.171077251434, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 31.59393939393939, "ram_util_percent": 67.16666666666667, "gpu_util_percent0": 0.37696969696969695, "vram_util_percent0": 0.29957308167621616}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1426016.564986011}, "policy_reward_max": {"pol0": -1426016.564986011, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1716671.6741586789, "pol1": 1716671.6741586789}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1694435.8105292225, -1744882.5998361679, -1731419.920917094, -1426016.564986011, -1721935.1412310624, -1764338.7827404076, -1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245], "policy_pol1_reward": [1694435.8105292225, 1744882.5998361679, 1731419.920917094, 1426016.564986011, 1721935.1412310624, 1764338.7827404076, 1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27673700666397083, "mean_inference_ms": 3.8238683507521656, "mean_action_processing_ms": 0.19114577209966147, "mean_env_wait_ms": 0.14470991259735386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1027026, "agent_timesteps_total": 2054052, "timers": {"sample_time_ms": 4551.848, "sample_throughput": 1319.464, "learn_time_ms": 20606.839, "learn_throughput": 291.457, "update_time_ms": 5.227}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 25007750906.553192, "policy_loss": -0.0009167344566989453, "vf_loss": 25007750906.553192, "vf_explained_var": -1.775457469932462e-08, "kl": 0.006408754003016238, "entropy": 2.787145289968937, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25493689278.638298, "policy_loss": -0.006760602113493579, "vf_loss": 25493689278.638298, "vf_explained_var": -3.677733317886123e-08, "kl": 0.008211039115694608, "entropy": 1.8167393867005692, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1027026, "num_agent_steps_sampled": 2054052, "num_steps_trained": 1027026, "num_agent_steps_trained": 2054052}, "done": false, "episodes_total": 1026, "training_iteration": 171, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-28-43", "timestamp": 1624966123, "time_this_iter_s": 25.10066270828247, "time_total_s": 4326.271739959717, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4326.271739959717, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 30.45757575757576, "ram_util_percent": 67.2818181818182, "gpu_util_percent0": 0.3742424242424242, "vram_util_percent0": 0.29971606867461265}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1462613.988029798}, "policy_reward_max": {"pol0": -1462613.988029798, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1724893.3106355441, "pol1": 1724893.3106355441}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1767654.8659132584, -1727138.8097884404, -1683775.480228584, -1723022.1968255432, -1771886.4460158711, -1875670.8522345524, -1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631], "policy_pol1_reward": [1767654.8659132584, 1727138.8097884404, 1683775.480228584, 1723022.1968255432, 1771886.4460158711, 1875670.8522345524, 1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27672296747652947, "mean_inference_ms": 3.823813713858884, "mean_action_processing_ms": 0.19114165085674117, "mean_env_wait_ms": 0.14470738378752818, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1033032, "agent_timesteps_total": 2066064, "timers": {"sample_time_ms": 4536.099, "sample_throughput": 1324.045, "learn_time_ms": 20616.201, "learn_throughput": 291.324, "update_time_ms": 5.26}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 27467507755.574467, "policy_loss": -0.0010624219207687581, "vf_loss": 27467507755.574467, "vf_explained_var": -3.804551784725163e-09, "kl": 0.0059403289168914585, "entropy": 2.834264805976381, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 28017719688.17021, "policy_loss": -0.006627801250904165, "vf_loss": 28017719688.17021, "vf_explained_var": -3.0436414277801305e-08, "kl": 0.009301303687723392, "entropy": 1.888939340063866, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1033032, "num_agent_steps_sampled": 2066064, "num_steps_trained": 1033032, "num_agent_steps_trained": 2066064}, "done": false, "episodes_total": 1032, "training_iteration": 172, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-29-08", "timestamp": 1624966148, "time_this_iter_s": 25.05222487449646, "time_total_s": 4351.323964834213, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4351.323964834213, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 30.151515151515156, "ram_util_percent": 67.46969696969697, "gpu_util_percent0": 0.386060606060606, "vram_util_percent0": 0.2995781883547303}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1462613.988029798}, "policy_reward_max": {"pol0": -1462613.988029798, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1723457.1404243624, "pol1": 1723457.1404243624}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1662208.1126079382, -1769464.0808654446, -1869811.2857166084, -1514116.1492121771, -1628241.8979665535, -1866878.4164306966, -1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506], "policy_pol1_reward": [1662208.1126079382, 1769464.0808654446, 1869811.2857166084, 1514116.1492121771, 1628241.8979665535, 1866878.4164306966, 1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2767074279975266, "mean_inference_ms": 3.823759828641004, "mean_action_processing_ms": 0.19113788552991623, "mean_env_wait_ms": 0.14470547443374032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1039038, "agent_timesteps_total": 2078076, "timers": {"sample_time_ms": 4565.304, "sample_throughput": 1315.575, "learn_time_ms": 20623.276, "learn_throughput": 291.224, "update_time_ms": 5.267}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 24896757934.29787, "policy_loss": -0.005045703215960493, "vf_loss": 24896757934.29787, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.012175996252830992, "entropy": 2.762929064162234, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25386158559.31915, "policy_loss": -0.005671860927597005, "vf_loss": 25386158559.31915, "vf_explained_var": 5.960464477539063e-08, "kl": 0.008837356142937503, "entropy": 2.0455410734136055, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1039038, "num_agent_steps_sampled": 2078076, "num_steps_trained": 1039038, "num_agent_steps_trained": 2078076}, "done": false, "episodes_total": 1038, "training_iteration": 173, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-29-34", "timestamp": 1624966174, "time_this_iter_s": 25.423516750335693, "time_total_s": 4376.747481584549, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4376.747481584549, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 30.791176470588237, "ram_util_percent": 67.27352941176473, "gpu_util_percent0": 0.37764705882352945, "vram_util_percent0": 0.29962925513987193}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1718662.9788316395, "pol1": 1718662.9788316395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1609261.2919356478, -1739489.068489032, -1721413.3612401425, -1849354.8053160922, -1559423.8784969838, -1904651.7599891792, -1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819], "policy_pol1_reward": [1609261.2919356478, 1739489.068489032, 1721413.3612401425, 1849354.8053160922, 1559423.8784969838, 1904651.7599891792, 1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2766848803959719, "mean_inference_ms": 3.8236787622962876, "mean_action_processing_ms": 0.19113285917537357, "mean_env_wait_ms": 0.14470243603563662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1045044, "agent_timesteps_total": 2090088, "timers": {"sample_time_ms": 4538.476, "sample_throughput": 1323.352, "learn_time_ms": 20625.217, "learn_throughput": 291.197, "update_time_ms": 5.259}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 22333003340.255318, "policy_loss": -0.00176507525859361, "vf_loss": 22333003340.255318, "vf_explained_var": 6.97501150170865e-08, "kl": 0.0061735478824281945, "entropy": 2.8165042095995965, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22786816043.574467, "policy_loss": -0.0034914516764593885, "vf_loss": 22786816043.574467, "vf_explained_var": 1.2555021555726853e-07, "kl": 0.005374887016938722, "entropy": 1.9847178002621264, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1045044, "num_agent_steps_sampled": 2090088, "num_steps_trained": 1045044, "num_agent_steps_trained": 2090088}, "done": false, "episodes_total": 1044, "training_iteration": 174, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-29-59", "timestamp": 1624966199, "time_this_iter_s": 25.07877516746521, "time_total_s": 4401.826256752014, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4401.826256752014, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 29.924242424242426, "ram_util_percent": 67.37272727272727, "gpu_util_percent0": 0.3751515151515152, "vram_util_percent0": 0.29966500188947104}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1717742.5002813647, "pol1": 1717742.5002813647}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1628062.9637453293, -1725194.7824196012, -1548650.6093071878, -1836163.3047714923, -1462889.1312865254, -1462613.988029798, -1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464], "policy_pol1_reward": [1628062.9637453293, 1725194.7824196012, 1548650.6093071878, 1836163.3047714923, 1462889.1312865254, 1462613.988029798, 1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2766582055339151, "mean_inference_ms": 3.823581100282203, "mean_action_processing_ms": 0.1911262611076747, "mean_env_wait_ms": 0.14469880110060315, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1051050, "agent_timesteps_total": 2102100, "timers": {"sample_time_ms": 4545.252, "sample_throughput": 1321.379, "learn_time_ms": 20621.952, "learn_throughput": 291.243, "update_time_ms": 5.253}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 24266827122.38298, "policy_loss": -0.00016620870620170805, "vf_loss": 24266827122.38298, "vf_explained_var": -3.550914939864924e-08, "kl": 0.005762565930552305, "entropy": 2.7651764534889383, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24745891665.70213, "policy_loss": -0.0034329167745531875, "vf_loss": 24745891665.70213, "vf_explained_var": 1.2301384799684456e-07, "kl": 0.010080127422004304, "entropy": 1.8933649950839104, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1051050, "num_agent_steps_sampled": 2102100, "num_steps_trained": 1051050, "num_agent_steps_trained": 2102100}, "done": false, "episodes_total": 1050, "training_iteration": 175, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-30-24", "timestamp": 1624966224, "time_this_iter_s": 25.229707717895508, "time_total_s": 4427.05596446991, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4427.05596446991, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 30.199999999999996, "ram_util_percent": 67.27878787878787, "gpu_util_percent0": 0.3751515151515151, "vram_util_percent0": 0.29959350839027277}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937075.0177632337, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1937075.0177632337}, "policy_reward_mean": {"pol0": -1728755.7113343934, "pol1": 1728755.7113343934}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1734956.0338870273, -1763199.3013807796, -1796449.3241130898, -1621710.8607692227, -1781457.212996646, -1810279.0096671155, -1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797], "policy_pol1_reward": [1734956.0338870273, 1763199.3013807796, 1796449.3241130898, 1621710.8607692227, 1781457.212996646, 1810279.0096671155, 1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2766299933051194, "mean_inference_ms": 3.8234552467465477, "mean_action_processing_ms": 0.19111782501626318, "mean_env_wait_ms": 0.1446942162129012, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1057056, "agent_timesteps_total": 2114112, "timers": {"sample_time_ms": 4530.107, "sample_throughput": 1325.796, "learn_time_ms": 20627.85, "learn_throughput": 291.16, "update_time_ms": 5.268}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 26740002031.659573, "policy_loss": -0.0006042233014360388, "vf_loss": 26740002031.659573, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.005332194625380191, "entropy": 2.7712027823671384, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27286314964.425533, "policy_loss": -0.006094539369595178, "vf_loss": 27286314964.425533, "vf_explained_var": 1.1667292199035728e-07, "kl": 0.008557382356771764, "entropy": 1.7296133092109194, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1057056, "num_agent_steps_sampled": 2114112, "num_steps_trained": 1057056, "num_agent_steps_trained": 2114112}, "done": false, "episodes_total": 1056, "training_iteration": 176, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-30-49", "timestamp": 1624966249, "time_this_iter_s": 25.097023487091064, "time_total_s": 4452.152987957001, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdbf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4452.152987957001, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 30.11515151515151, "ram_util_percent": 67.39999999999999, "gpu_util_percent0": 0.37303030303030305, "vram_util_percent0": 0.299726282031641}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1732207.3224127109, "pol1": 1732207.3224127109}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1590907.5514383558, -1930804.5626507064, -1723041.402168459, -1613295.681921743, -1696400.7350627952, -1748679.764860055, -1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177], "policy_pol1_reward": [1590907.5514383558, 1930804.5626507064, 1723041.402168459, 1613295.681921743, 1696400.7350627952, 1748679.764860055, 1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27660183324620347, "mean_inference_ms": 3.823328056064982, "mean_action_processing_ms": 0.19110953646426346, "mean_env_wait_ms": 0.14469009435072164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1063062, "agent_timesteps_total": 2126124, "timers": {"sample_time_ms": 4536.157, "sample_throughput": 1324.028, "learn_time_ms": 20648.206, "learn_throughput": 290.873, "update_time_ms": 5.18}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 27166544525.61702, "policy_loss": -0.0035475758102504495, "vf_loss": 27166544525.61702, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.012363805613936261, "entropy": 2.7784937746981355, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27709128398.97872, "policy_loss": -0.005711151881420866, "vf_loss": 27709128398.97872, "vf_explained_var": 7.862740147857039e-08, "kl": 0.012272189490180066, "entropy": 1.6431105897781697, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1063062, "num_agent_steps_sampled": 2126124, "num_steps_trained": 1063062, "num_agent_steps_trained": 2126124}, "done": false, "episodes_total": 1062, "training_iteration": 177, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-31-15", "timestamp": 1624966275, "time_this_iter_s": 25.32302474975586, "time_total_s": 4477.476012706757, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4477.476012706757, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 31.387878787878787, "ram_util_percent": 67.16363636363639, "gpu_util_percent0": 0.3812121212121212, "vram_util_percent0": 0.2995781883547303}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1734107.5365730186, "pol1": 1734107.5365730186}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1850630.5808589407, -1907083.803035081, -1868328.4735491022, -1597719.4666710803, -1545324.3146774773, -1676916.7029174564, -1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492], "policy_pol1_reward": [1850630.5808589407, 1907083.803035081, 1868328.4735491022, 1597719.4666710803, 1545324.3146774773, 1676916.7029174564, 1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2765779729024222, "mean_inference_ms": 3.8232128377885912, "mean_action_processing_ms": 0.19110245616852958, "mean_env_wait_ms": 0.14468660390029903, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1069068, "agent_timesteps_total": 2138136, "timers": {"sample_time_ms": 4529.869, "sample_throughput": 1325.866, "learn_time_ms": 20659.208, "learn_throughput": 290.718, "update_time_ms": 5.156}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 25294414085.446808, "policy_loss": -0.0019359729411278634, "vf_loss": 25294414085.446808, "vf_explained_var": 8.243195281920634e-08, "kl": 0.009816264614779899, "entropy": 2.7205432475881373, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25816839625.531914, "policy_loss": -0.008343881313154038, "vf_loss": 25816839625.531914, "vf_explained_var": 1.1286837064972133e-07, "kl": 0.0099714703342699, "entropy": 1.6015646838127298, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1069068, "num_agent_steps_sampled": 2138136, "num_steps_trained": 1069068, "num_agent_steps_trained": 2138136}, "done": false, "episodes_total": 1068, "training_iteration": 178, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-31-40", "timestamp": 1624966300, "time_this_iter_s": 25.19181537628174, "time_total_s": 4502.667828083038, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06277b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4502.667828083038, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 30.797058823529415, "ram_util_percent": 67.32352941176472, "gpu_util_percent0": 0.3852941176470588, "vram_util_percent0": 0.2997630801562283}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1736064.8506998525, "pol1": 1736064.8506998525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1681766.6085097715, -1597597.505629157, -1493160.7989913237, -1602014.0268043396, -1805476.309013927, -1706404.6596032376, -1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781], "policy_pol1_reward": [1681766.6085097715, 1597597.505629157, 1493160.7989913237, 1602014.0268043396, 1805476.309013927, 1706404.6596032376, 1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2765536373664193, "mean_inference_ms": 3.823065402304373, "mean_action_processing_ms": 0.19109524525684177, "mean_env_wait_ms": 0.14468271060346152, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1075074, "agent_timesteps_total": 2150148, "timers": {"sample_time_ms": 4516.796, "sample_throughput": 1329.704, "learn_time_ms": 20654.23, "learn_throughput": 290.788, "update_time_ms": 4.761}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 26093746786.042553, "policy_loss": -0.0028620615918585595, "vf_loss": 26093746786.042553, "vf_explained_var": 1.3442749491332506e-07, "kl": 0.009734273254078753, "entropy": 2.742451830113188, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26640708063.31915, "policy_loss": -0.0047113254190759455, "vf_loss": 26640708063.31915, "vf_explained_var": 1.1160018686950934e-07, "kl": 0.00857967863533091, "entropy": 1.6856589165139706, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1075074, "num_agent_steps_sampled": 2150148, "num_steps_trained": 1075074, "num_agent_steps_trained": 2150148}, "done": false, "episodes_total": 1074, "training_iteration": 179, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-32-05", "timestamp": 1624966325, "time_this_iter_s": 25.04210901260376, "time_total_s": 4527.709937095642, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e350d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4527.709937095642, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 30.306060606060605, "ram_util_percent": 67.4030303030303, "gpu_util_percent0": 0.37636363636363634, "vram_util_percent0": 0.2995730816762161}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1743288.9662664023, "pol1": 1743288.9662664023}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1829521.2791668125, -1843518.2249304515, -1860518.6347156805, -1780745.8319618802, -1647276.5406424534, -1808743.4941108243, -1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835], "policy_pol1_reward": [1829521.2791668125, 1843518.2249304515, 1860518.6347156805, 1780745.8319618802, 1647276.5406424534, 1808743.4941108243, 1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2765351889519335, "mean_inference_ms": 3.8229824519529574, "mean_action_processing_ms": 0.1910916334869034, "mean_env_wait_ms": 0.14468109906581983, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1081080, "agent_timesteps_total": 2162160, "timers": {"sample_time_ms": 4524.992, "sample_throughput": 1327.295, "learn_time_ms": 20677.947, "learn_throughput": 290.454, "update_time_ms": 4.828}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 25829256388.085106, "policy_loss": -0.001966199223348435, "vf_loss": 25829256388.085106, "vf_explained_var": -1.3442749491332506e-07, "kl": 0.007874637336886309, "entropy": 2.751297265925306, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26367451441.02128, "policy_loss": -0.005268806611445356, "vf_loss": 26367451441.02128, "vf_explained_var": 1.0145471662781347e-07, "kl": 0.009515311806759935, "entropy": 1.5711278332040666, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1081080, "num_agent_steps_sampled": 2162160, "num_steps_trained": 1081080, "num_agent_steps_trained": 2162160}, "done": false, "episodes_total": 1080, "training_iteration": 180, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-32-31", "timestamp": 1624966351, "time_this_iter_s": 25.662429094314575, "time_total_s": 4553.372366189957, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4553.372366189957, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 33.05454545454546, "ram_util_percent": 67.47575757575758, "gpu_util_percent0": 0.3806060606060606, "vram_util_percent0": 0.29959350839027277}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1743054.651049321, "pol1": 1743054.651049321}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1824097.6654246885, -1757148.955750982, -1828651.0035842692, -1766313.0054008001, -1679847.801082812, -1715941.44191541, -1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494], "policy_pol1_reward": [1824097.6654246885, 1757148.955750982, 1828651.0035842692, 1766313.0054008001, 1679847.801082812, 1715941.44191541, 1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2765145947729621, "mean_inference_ms": 3.822929101635241, "mean_action_processing_ms": 0.19108906116211086, "mean_env_wait_ms": 0.14467972096103876, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1087086, "agent_timesteps_total": 2174172, "timers": {"sample_time_ms": 4533.373, "sample_throughput": 1324.841, "learn_time_ms": 20681.751, "learn_throughput": 290.401, "update_time_ms": 4.882}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 26458820085.106384, "policy_loss": -0.0021313393607418586, "vf_loss": 26458820085.106384, "vf_explained_var": 1.204774804364206e-07, "kl": 0.010096585179897064, "entropy": 2.6577289916099387, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27019374592.0, "policy_loss": -0.005525164108010049, "vf_loss": 27019374592.0, "vf_explained_var": 1.1286837064972133e-07, "kl": 0.0076416686296145965, "entropy": 1.5340580001790474, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1087086, "num_agent_steps_sampled": 2174172, "num_steps_trained": 1087086, "num_agent_steps_trained": 2174172}, "done": false, "episodes_total": 1086, "training_iteration": 181, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-32-56", "timestamp": 1624966376, "time_this_iter_s": 25.222834587097168, "time_total_s": 4578.595200777054, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd6a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4578.595200777054, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 30.317647058823535, "ram_util_percent": 67.15294117647059, "gpu_util_percent0": 0.3738235294117647, "vram_util_percent0": 0.3001645552052975}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1742783.0628225813, "pol1": 1742783.0628225813}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1906452.9410108184, -1718787.127641592, -1833324.675012961, -1773741.1765698793, -1796996.7148491174, -1678026.048155713, -1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638], "policy_pol1_reward": [1906452.9410108184, 1718787.127641592, 1833324.675012961, 1773741.1765698793, 1796996.7148491174, 1678026.048155713, 1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2764947980705716, "mean_inference_ms": 3.8229138938892264, "mean_action_processing_ms": 0.19108837396402134, "mean_env_wait_ms": 0.1446793360888524, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1093092, "agent_timesteps_total": 2186184, "timers": {"sample_time_ms": 4551.493, "sample_throughput": 1319.567, "learn_time_ms": 20689.77, "learn_throughput": 290.288, "update_time_ms": 4.861}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 25558517411.404255, "policy_loss": -0.0024613642549895227, "vf_loss": 25558517411.404255, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.008242495239098022, "entropy": 2.722017207044236, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26091738308.085106, "policy_loss": -0.005361170190921489, "vf_loss": 26091738308.085106, "vf_explained_var": 1.0272290040802545e-07, "kl": 0.007304471838188932, "entropy": 1.6144866512176839, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1093092, "num_agent_steps_sampled": 2186184, "num_steps_trained": 1093092, "num_agent_steps_trained": 2186184}, "done": false, "episodes_total": 1092, "training_iteration": 182, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-33-21", "timestamp": 1624966401, "time_this_iter_s": 25.31358027458191, "time_total_s": 4603.908781051636, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac0d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4603.908781051636, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 30.596969696969698, "ram_util_percent": 67.26969696969698, "gpu_util_percent0": 0.37909090909090903, "vram_util_percent0": 0.3029639162096189}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1741452.6827772325, "pol1": 1741452.6827772325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1623495.1487073235, -1568529.0528259112, -1924348.1509109556, -1872215.3520796418, -1730392.7384231086, -1937075.0177632337, -1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768], "policy_pol1_reward": [1623495.1487073235, 1568529.0528259112, 1924348.1509109556, 1872215.3520796418, 1730392.7384231086, 1937075.0177632337, 1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27647672296078046, "mean_inference_ms": 3.8228753362154, "mean_action_processing_ms": 0.19108662002832763, "mean_env_wait_ms": 0.14467866403404359, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1099098, "agent_timesteps_total": 2198196, "timers": {"sample_time_ms": 4534.41, "sample_throughput": 1324.538, "learn_time_ms": 20680.516, "learn_throughput": 290.418, "update_time_ms": 4.897}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00037584734091069535, "cur_lr": 5.000000000000002e-05, "total_loss": 25880579180.93617, "policy_loss": -0.0019945923556038674, "vf_loss": 25880579180.93617, "vf_explained_var": 2.4095495376741383e-08, "kl": 0.0036534000772665788, "entropy": 2.7944809274470552, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26438800492.93617, "policy_loss": -0.006821016285647737, "vf_loss": 26438800492.93617, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.008979534532161468, "entropy": 1.4646696790735771, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1099098, "num_agent_steps_sampled": 2198196, "num_steps_trained": 1099098, "num_agent_steps_trained": 2198196}, "done": false, "episodes_total": 1098, "training_iteration": 183, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-33-46", "timestamp": 1624966426, "time_this_iter_s": 25.139810800552368, "time_total_s": 4629.048591852188, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e358c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4629.048591852188, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 30.012121212121208, "ram_util_percent": 67.41818181818181, "gpu_util_percent0": 0.37999999999999995, "vram_util_percent0": 0.30309668985098714}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1735944.4782813936, "pol1": 1735944.4782813936}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1709929.7901636392, -1655017.8531155898, -1611832.3332146467, -1480662.5221995963, -1814397.1502536898, -1731796.8204477495, -1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793], "policy_pol1_reward": [1709929.7901636392, 1655017.8531155898, 1611832.3332146467, 1480662.5221995963, 1814397.1502536898, 1731796.8204477495, 1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2764532277740754, "mean_inference_ms": 3.8228542799241865, "mean_action_processing_ms": 0.19108580424637803, "mean_env_wait_ms": 0.14467888139471552, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1105104, "agent_timesteps_total": 2210208, "timers": {"sample_time_ms": 4540.462, "sample_throughput": 1322.773, "learn_time_ms": 20684.506, "learn_throughput": 290.362, "update_time_ms": 4.914}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00018792367045534768, "cur_lr": 5.000000000000002e-05, "total_loss": 23404501340.595745, "policy_loss": -0.001632037156439842, "vf_loss": 23404501340.595745, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.007047611278818643, "entropy": 2.7473035163067756, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23901127745.361702, "policy_loss": -0.005641531754047312, "vf_loss": 23901127745.361702, "vf_explained_var": 5.960464477539063e-08, "kl": 0.007929258306134255, "entropy": 1.6161389147981684, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1105104, "num_agent_steps_sampled": 2210208, "num_steps_trained": 1105104, "num_agent_steps_trained": 2210208}, "done": false, "episodes_total": 1104, "training_iteration": 184, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-34-12", "timestamp": 1624966452, "time_this_iter_s": 25.17925238609314, "time_total_s": 4654.227844238281, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4654.227844238281, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 31.03333333333333, "ram_util_percent": 67.32727272727273, "gpu_util_percent0": 0.3827272727272727, "vram_util_percent0": 0.30297412956664715}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1739595.9786891744, "pol1": 1739595.9786891744}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1756331.8742592486, -1531272.8678233335, -1475331.550712817, -1709607.2197541096, -1736182.586310217, -1594372.5098721646, -1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234], "policy_pol1_reward": [1756331.8742592486, 1531272.8678233335, 1475331.550712817, 1709607.2197541096, 1736182.586310217, 1594372.5098721646, 1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2764288324385433, "mean_inference_ms": 3.8227943244625417, "mean_action_processing_ms": 0.19108273583889368, "mean_env_wait_ms": 0.14467800295746636, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1111110, "agent_timesteps_total": 2222220, "timers": {"sample_time_ms": 4535.478, "sample_throughput": 1324.226, "learn_time_ms": 20669.439, "learn_throughput": 290.574, "update_time_ms": 4.915}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00018792367045534768, "cur_lr": 5.000000000000002e-05, "total_loss": 24633226305.361702, "policy_loss": -0.002842380407642811, "vf_loss": 24633226305.361702, "vf_explained_var": 1.0018653284760148e-07, "kl": 0.008952345263133658, "entropy": 2.728947051027988, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25164846886.12766, "policy_loss": -0.008104358661047955, "vf_loss": 25164846886.12766, "vf_explained_var": 1.1286837064972133e-07, "kl": 0.013058680882479282, "entropy": 1.5087348806097152, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1111110, "num_agent_steps_sampled": 2222220, "num_steps_trained": 1111110, "num_agent_steps_trained": 2222220}, "done": false, "episodes_total": 1110, "training_iteration": 185, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-34-37", "timestamp": 1624966477, "time_this_iter_s": 25.028839349746704, "time_total_s": 4679.256683588028, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdbf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4679.256683588028, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 30.22121212121212, "ram_util_percent": 67.42121212121212, "gpu_util_percent0": 0.38484848484848483, "vram_util_percent0": 0.3030507297443597}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1185745.8877900345}, "policy_reward_max": {"pol0": -1185745.8877900345, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1750062.9493912465, "pol1": 1750062.9493912465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1594237.5541938082, -1614361.7675068656, -1720242.7398847183, -1667177.0528838118, -1789901.3614942092, -1701391.5952712724, -1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397], "policy_pol1_reward": [1594237.5541938082, 1614361.7675068656, 1720242.7398847183, 1667177.0528838118, 1789901.3614942092, 1701391.5952712724, 1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27641238828931036, "mean_inference_ms": 3.82281321312694, "mean_action_processing_ms": 0.19108198557655073, "mean_env_wait_ms": 0.1446785875621446, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1117116, "agent_timesteps_total": 2234232, "timers": {"sample_time_ms": 4556.931, "sample_throughput": 1317.992, "learn_time_ms": 20672.43, "learn_throughput": 290.532, "update_time_ms": 4.882}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00018792367045534768, "cur_lr": 5.000000000000002e-05, "total_loss": 27165311019.574467, "policy_loss": -0.0009913112413375935, "vf_loss": 27165311019.574467, "vf_explained_var": 7.989558525878238e-08, "kl": 0.002637352977701007, "entropy": 2.795183902091168, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27751612895.31915, "policy_loss": -0.007293892588387144, "vf_loss": 27751612895.31915, "vf_explained_var": 7.101829879729848e-08, "kl": 0.010064648820998822, "entropy": 1.4896470714122692, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1117116, "num_agent_steps_sampled": 2234232, "num_steps_trained": 1117116, "num_agent_steps_trained": 2234232}, "done": false, "episodes_total": 1116, "training_iteration": 186, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-35-02", "timestamp": 1624966502, "time_this_iter_s": 25.340691328048706, "time_total_s": 4704.597374916077, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdc80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4704.597374916077, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 30.876470588235293, "ram_util_percent": 67.3294117647059, "gpu_util_percent0": 0.38323529411764706, "vram_util_percent0": 0.30297983703086895}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1745403.0334472784, "pol1": 1745403.0334472784}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1765666.9377839745, -1902850.5156228282, -1564549.7964461967, -1700673.9437665245, -1867220.0622010042, -1877294.9514723127, -1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736], "policy_pol1_reward": [1765666.9377839745, 1902850.5156228282, 1564549.7964461967, 1700673.9437665245, 1867220.0622010042, 1877294.9514723127, 1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27639422819183534, "mean_inference_ms": 3.8227626104842085, "mean_action_processing_ms": 0.19107827513991574, "mean_env_wait_ms": 0.14467784994041333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1123122, "agent_timesteps_total": 2246244, "timers": {"sample_time_ms": 4539.1, "sample_throughput": 1323.17, "learn_time_ms": 20658.473, "learn_throughput": 290.728, "update_time_ms": 4.849}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 21576724915.744682, "policy_loss": -0.00010873367415463671, "vf_loss": 21576724915.744682, "vf_explained_var": 1.3696386247374903e-07, "kl": 0.005276280177876036, "entropy": 2.7578295342465666, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22051962226.38298, "policy_loss": -0.006557203254642639, "vf_loss": 22051962226.38298, "vf_explained_var": -3.0436414277801305e-08, "kl": 0.008713111697517812, "entropy": 1.4887046611055414, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1123122, "num_agent_steps_sampled": 2246244, "num_steps_trained": 1123122, "num_agent_steps_trained": 2246244}, "done": false, "episodes_total": 1122, "training_iteration": 187, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-35-27", "timestamp": 1624966527, "time_this_iter_s": 25.004595041275024, "time_total_s": 4729.601969957352, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4729.601969957352, "timesteps_since_restore": 0, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 30.08787878787879, "ram_util_percent": 67.41818181818181, "gpu_util_percent0": 0.38636363636363635, "vram_util_percent0": 0.30297412956664715}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1742737.364856537, "pol1": 1742737.364856537}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1790880.9517049727, -1733162.321235361, -1819100.3129497387, -1817533.8683631, -1872534.9805123499, -1509505.7350909673, -1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962], "policy_pol1_reward": [1790880.9517049727, 1733162.321235361, 1819100.3129497387, 1817533.8683631, 1872534.9805123499, 1509505.7350909673, 1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27637941285922013, "mean_inference_ms": 3.822726766979861, "mean_action_processing_ms": 0.1910750110808327, "mean_env_wait_ms": 0.14467743098594552, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1129128, "agent_timesteps_total": 2258256, "timers": {"sample_time_ms": 4542.708, "sample_throughput": 1322.119, "learn_time_ms": 20660.909, "learn_throughput": 290.694, "update_time_ms": 5.036}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24779839923.744682, "policy_loss": -0.003099479375684515, "vf_loss": 24779839923.744682, "vf_explained_var": -3.550914939864924e-08, "kl": 0.009610650347585374, "entropy": 2.7545799752499196, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25301854643.744682, "policy_loss": -0.006451862170658213, "vf_loss": 25301854643.744682, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.012517290903215713, "entropy": 1.526764227988872, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1129128, "num_agent_steps_sampled": 2258256, "num_steps_trained": 1129128, "num_agent_steps_trained": 2258256}, "done": false, "episodes_total": 1128, "training_iteration": 188, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-35-52", "timestamp": 1624966552, "time_this_iter_s": 25.240142822265625, "time_total_s": 4754.842112779617, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4754.842112779617, "timesteps_since_restore": 0, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 30.987878787878785, "ram_util_percent": 67.31818181818183, "gpu_util_percent0": 0.37999999999999995, "vram_util_percent0": 0.30306604977990215}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1943844.5037754113, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1943844.5037754113}, "policy_reward_mean": {"pol0": -1739688.4451010553, "pol1": 1739688.4451010553}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1694654.3992474198, -1578553.585220127, -1880795.3703433021, -1869487.5594739506, -1185745.8877900345, -1787283.4093362181, -1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495], "policy_pol1_reward": [1694654.3992474198, 1578553.585220127, 1880795.3703433021, 1869487.5594739506, 1185745.8877900345, 1787283.4093362181, 1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.276361601094159, "mean_inference_ms": 3.8226489041554346, "mean_action_processing_ms": 0.1910702240253537, "mean_env_wait_ms": 0.14467593368573214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1135134, "agent_timesteps_total": 2270268, "timers": {"sample_time_ms": 4535.564, "sample_throughput": 1324.201, "learn_time_ms": 20680.367, "learn_throughput": 290.42, "update_time_ms": 5.031}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24194558997.787235, "policy_loss": -0.0006399810155655475, "vf_loss": 24194558997.787235, "vf_explained_var": -1.4203659759459697e-07, "kl": 0.007332831323939435, "entropy": 2.75464447508467, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24723561493.787235, "policy_loss": -0.004609621843283481, "vf_loss": 24723561493.787235, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.007851541834942837, "entropy": 1.4965630795093292, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1135134, "num_agent_steps_sampled": 2270268, "num_steps_trained": 1135134, "num_agent_steps_trained": 2270268}, "done": false, "episodes_total": 1134, "training_iteration": 189, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-36-18", "timestamp": 1624966578, "time_this_iter_s": 25.16340184211731, "time_total_s": 4780.005514621735, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06279d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4780.005514621735, "timesteps_since_restore": 0, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 30.539393939393943, "ram_util_percent": 67.4030303030303, "gpu_util_percent0": 0.37999999999999995, "vram_util_percent0": 0.30297412956664715}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946031.247761593, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1946031.247761593}, "policy_reward_mean": {"pol0": -1744815.230552521, "pol1": 1744815.230552521}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1677245.5980250787, -1738093.2694581146, -1723665.2951159906, -1719270.3238016819, -1574748.50061419, -1616680.7239139255, -1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463], "policy_pol1_reward": [1677245.5980250787, 1738093.2694581146, 1723665.2951159906, 1719270.3238016819, 1574748.50061419, 1616680.7239139255, 1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2763461387945003, "mean_inference_ms": 3.8225684096315105, "mean_action_processing_ms": 0.1910655243734353, "mean_env_wait_ms": 0.14467367767625547, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1141140, "agent_timesteps_total": 2282280, "timers": {"sample_time_ms": 4520.392, "sample_throughput": 1328.646, "learn_time_ms": 20630.848, "learn_throughput": 291.117, "update_time_ms": 4.982}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25293247248.340427, "policy_loss": -0.0022571861664665506, "vf_loss": 25293247248.340427, "vf_explained_var": -2.029094225974859e-08, "kl": 0.008368771533144916, "entropy": 2.7067697454006114, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25839916402.38298, "policy_loss": -0.006659706321326976, "vf_loss": 25839916402.38298, "vf_explained_var": -7.609103569450326e-09, "kl": 0.011173609089344106, "entropy": 1.5614285316873104, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1141140, "num_agent_steps_sampled": 2282280, "num_steps_trained": 1141140, "num_agent_steps_trained": 2282280}, "done": false, "episodes_total": 1140, "training_iteration": 190, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-36-43", "timestamp": 1624966603, "time_this_iter_s": 25.01428747177124, "time_total_s": 4805.019802093506, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4805.019802093506, "timesteps_since_restore": 0, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 30.933333333333337, "ram_util_percent": 67.33333333333333, "gpu_util_percent0": 0.3766666666666667, "vram_util_percent0": 0.3030762631369305}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1946031.247761593, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1946031.247761593}, "policy_reward_mean": {"pol0": -1749927.3714256806, "pol1": 1749927.3714256806}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1908692.9757326115, -1752239.3467813032, -1768771.8447496835, -1670412.9186478464, -1875881.2894352945, -1929860.2016078806, -1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515], "policy_pol1_reward": [1908692.9757326115, 1752239.3467813032, 1768771.8447496835, 1670412.9186478464, 1875881.2894352945, 1929860.2016078806, 1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27633209862942415, "mean_inference_ms": 3.8224575415313455, "mean_action_processing_ms": 0.1910596191234553, "mean_env_wait_ms": 0.14467074740568395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1147146, "agent_timesteps_total": 2294292, "timers": {"sample_time_ms": 4494.927, "sample_throughput": 1336.173, "learn_time_ms": 20631.085, "learn_throughput": 291.114, "update_time_ms": 5.023}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25598640433.02128, "policy_loss": -0.0012371142176871605, "vf_loss": 25598640433.02128, "vf_explained_var": -1.1160018686950934e-07, "kl": 0.009242041987624574, "entropy": 2.6842840580230063, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26168092759.148937, "policy_loss": -0.005215761013963121, "vf_loss": 26168092759.148937, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.008072048921058787, "entropy": 1.6169412186805239, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1147146, "num_agent_steps_sampled": 2294292, "num_steps_trained": 1147146, "num_agent_steps_trained": 2294292}, "done": false, "episodes_total": 1146, "training_iteration": 191, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-37-08", "timestamp": 1624966628, "time_this_iter_s": 24.971635341644287, "time_total_s": 4829.99143743515, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e352f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4829.99143743515, "timesteps_since_restore": 0, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 30.118181818181814, "ram_util_percent": 67.43636363636362, "gpu_util_percent0": 0.37636363636363634, "vram_util_percent0": 0.30296391620961893}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1744669.2124116132, "pol1": 1744669.2124116132}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1802344.3295376827, -1530119.7617198387, -1789970.435298513, -1836719.8672635797, -1765218.9971944666, -1943844.5037754113, -1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991], "policy_pol1_reward": [1802344.3295376827, 1530119.7617198387, 1789970.435298513, 1836719.8672635797, 1765218.9971944666, 1943844.5037754113, 1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27632123117209295, "mean_inference_ms": 3.8223786009562493, "mean_action_processing_ms": 0.19105520415900634, "mean_env_wait_ms": 0.14466826288097148, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1153152, "agent_timesteps_total": 2306304, "timers": {"sample_time_ms": 4493.589, "sample_throughput": 1336.571, "learn_time_ms": 20634.766, "learn_throughput": 291.062, "update_time_ms": 5.029}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24910360053.106384, "policy_loss": -0.00016760798369316345, "vf_loss": 24910360053.106384, "vf_explained_var": -2.4095495376741383e-08, "kl": 0.006115830126912036, "entropy": 2.7326723108900355, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25462815852.93617, "policy_loss": -0.007235368812813404, "vf_loss": 25462815852.93617, "vf_explained_var": 3.804551784725163e-09, "kl": 0.009597434701913215, "entropy": 1.5271020214608375, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1153152, "num_agent_steps_sampled": 2306304, "num_steps_trained": 1153152, "num_agent_steps_trained": 2306304}, "done": false, "episodes_total": 1152, "training_iteration": 192, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-37-33", "timestamp": 1624966653, "time_this_iter_s": 25.335930585861206, "time_total_s": 4855.327368021011, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e359d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4855.327368021011, "timesteps_since_restore": 0, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 31.63030303030303, "ram_util_percent": 67.3060606060606, "gpu_util_percent0": 0.38151515151515153, "vram_util_percent0": 0.30300476963773215}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1744264.3607445445, "pol1": 1744264.3607445445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1636501.6970577145, -1941893.8952156126, -1705149.2895189212, -1860604.4678835177, -1854328.7933805333, -1704648.9824698921, -1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725], "policy_pol1_reward": [1636501.6970577145, 1941893.8952156126, 1705149.2895189212, 1860604.4678835177, 1854328.7933805333, 1704648.9824698921, 1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2763126219202015, "mean_inference_ms": 3.8223045688783603, "mean_action_processing_ms": 0.19105083253660132, "mean_env_wait_ms": 0.14466594407198438, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1159158, "agent_timesteps_total": 2318316, "timers": {"sample_time_ms": 4496.021, "sample_throughput": 1335.848, "learn_time_ms": 20638.765, "learn_throughput": 291.006, "update_time_ms": 5.016}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25808017713.02128, "policy_loss": 0.00020889642628583503, "vf_loss": 25808017713.02128, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.005787723023999244, "entropy": 2.7697512596211533, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26383932917.106384, "policy_loss": -0.007166996875658948, "vf_loss": 26383932917.106384, "vf_explained_var": 3.804551784725163e-09, "kl": 0.010068336145040836, "entropy": 1.5786656166644806, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1159158, "num_agent_steps_sampled": 2318316, "num_steps_trained": 1159158, "num_agent_steps_trained": 2318316}, "done": false, "episodes_total": 1158, "training_iteration": 193, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-37-58", "timestamp": 1624966678, "time_this_iter_s": 25.204345703125, "time_total_s": 4880.531713724136, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4880.531713724136, "timesteps_since_restore": 0, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 31.526470588235302, "ram_util_percent": 67.2264705882353, "gpu_util_percent0": 0.38, "vram_util_percent0": 0.30300957592339256}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1741579.5484299662, "pol1": 1741579.5484299662}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1668573.4958442808, -1735749.5929301477, -1779250.2407584167, -1750600.0087496492, -1814219.6365510095, -1748317.9891045378, -1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249], "policy_pol1_reward": [1668573.4958442808, 1735749.5929301477, 1779250.2407584167, 1750600.0087496492, 1814219.6365510095, 1748317.9891045378, 1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2763032564403458, "mean_inference_ms": 3.82223894746946, "mean_action_processing_ms": 0.19104658856110607, "mean_env_wait_ms": 0.14466389994969064, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1165164, "agent_timesteps_total": 2330328, "timers": {"sample_time_ms": 4498.193, "sample_throughput": 1335.203, "learn_time_ms": 20644.424, "learn_throughput": 290.926, "update_time_ms": 4.983}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25167413465.87234, "policy_loss": -0.0016280406333030537, "vf_loss": 25167413465.87234, "vf_explained_var": -4.5654623193058796e-08, "kl": 0.00817064702154157, "entropy": 2.7430065134738353, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25735477553.02128, "policy_loss": -0.007328164407071915, "vf_loss": 25735477553.02128, "vf_explained_var": 1.0272290040802545e-07, "kl": 0.009247432948347735, "entropy": 1.5733434012595644, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1165164, "num_agent_steps_sampled": 2330328, "num_steps_trained": 1165164, "num_agent_steps_trained": 2330328}, "done": false, "episodes_total": 1164, "training_iteration": 194, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-38-24", "timestamp": 1624966704, "time_this_iter_s": 25.256657361984253, "time_total_s": 4905.788371086121, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06279d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4905.788371086121, "timesteps_since_restore": 0, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 30.863636363636363, "ram_util_percent": 67.31212121212121, "gpu_util_percent0": 0.3742424242424242, "vram_util_percent0": 0.3029792362451614}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1740710.1481171902, "pol1": 1740710.1481171902}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1791172.6297799118, -1747612.0409227444, -1659332.9585517286, -1881079.4994825781, -1774416.6534297804, -1785302.641057129, -1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783], "policy_pol1_reward": [1791172.6297799118, 1747612.0409227444, 1659332.9585517286, 1881079.4994825781, 1774416.6534297804, 1785302.641057129, 1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27628891870613415, "mean_inference_ms": 3.8221451366206507, "mean_action_processing_ms": 0.19104056206082848, "mean_env_wait_ms": 0.14466048103659904, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1171170, "agent_timesteps_total": 2342340, "timers": {"sample_time_ms": 4506.803, "sample_throughput": 1332.652, "learn_time_ms": 20644.832, "learn_throughput": 290.92, "update_time_ms": 4.976}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.396183522767384e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24798912904.17021, "policy_loss": -0.0006176794066708139, "vf_loss": 24798912904.17021, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.0043123909718099426, "entropy": 2.823284184679072, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25351302165.787235, "policy_loss": -0.005609665700095765, "vf_loss": 25351302165.787235, "vf_explained_var": 1.0906381930908537e-07, "kl": 0.007236976414284808, "entropy": 1.685125302761159, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1171170, "num_agent_steps_sampled": 2342340, "num_steps_trained": 1171170, "num_agent_steps_trained": 2342340}, "done": false, "episodes_total": 1170, "training_iteration": 195, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-38-49", "timestamp": 1624966729, "time_this_iter_s": 25.120530128479004, "time_total_s": 4930.9089012146, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4930.9089012146, "timesteps_since_restore": 0, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 30.08181818181818, "ram_util_percent": 67.39393939393939, "gpu_util_percent0": 0.37969696969696964, "vram_util_percent0": 0.30256048860700024}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1739661.7558445674, "pol1": 1739661.7558445674}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1821058.831279708, -1808481.229196848, -1862485.1598572093, -1557086.9503860835, -1866953.732369219, -1829522.7947104282, -1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283], "policy_pol1_reward": [1821058.831279708, 1808481.229196848, 1862485.1598572093, 1557086.9503860835, 1866953.732369219, 1829522.7947104282, 1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.276283922601311, "mean_inference_ms": 3.8220764512607177, "mean_action_processing_ms": 0.19103530480582545, "mean_env_wait_ms": 0.14465813354391627, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1177176, "agent_timesteps_total": 2354352, "timers": {"sample_time_ms": 4492.29, "sample_throughput": 1336.957, "learn_time_ms": 20653.912, "learn_throughput": 290.792, "update_time_ms": 4.997}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25535899517.276596, "policy_loss": -0.0025673126207387195, "vf_loss": 25535899517.276596, "vf_explained_var": 1.2935475979247713e-07, "kl": 0.005104143291394761, "entropy": 2.757639580584587, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26122126837.106384, "policy_loss": -0.007454405835968383, "vf_loss": 26122126837.106384, "vf_explained_var": -4.311825207992115e-08, "kl": 0.009031525208674212, "entropy": 1.7326631951839366, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1177176, "num_agent_steps_sampled": 2354352, "num_steps_trained": 1177176, "num_agent_steps_trained": 2354352}, "done": false, "episodes_total": 1176, "training_iteration": 196, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-39-14", "timestamp": 1624966754, "time_this_iter_s": 25.28624153137207, "time_total_s": 4956.195142745972, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e8d400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4956.195142745972, "timesteps_since_restore": 0, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 31.21212121212121, "ram_util_percent": 67.33636363636363, "gpu_util_percent0": 0.3821212121212121, "vram_util_percent0": 0.29960882842581527}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1736291.646913455, "pol1": 1736291.646913455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1699055.7222411106, -1811389.791172842, -1733314.1931186193, -1806656.2502077494, -1669830.8986806136, -1872632.3162591956, -1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797], "policy_pol1_reward": [1699055.7222411106, 1811389.791172842, 1733314.1931186193, 1806656.2502077494, 1669830.8986806136, 1872632.3162591956, 1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2762729725368582, "mean_inference_ms": 3.821935938087469, "mean_action_processing_ms": 0.19102660097387514, "mean_env_wait_ms": 0.14465374852720975, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1183182, "agent_timesteps_total": 2366364, "timers": {"sample_time_ms": 4499.24, "sample_throughput": 1334.892, "learn_time_ms": 20647.514, "learn_throughput": 290.882, "update_time_ms": 4.97}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24670988636.595745, "policy_loss": -0.0009755175957020293, "vf_loss": 24670988636.595745, "vf_explained_var": 9.004106260590561e-08, "kl": 0.00806501485962183, "entropy": 2.723626897690144, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25227575252.425533, "policy_loss": -0.006200500050599271, "vf_loss": 25227575252.425533, "vf_explained_var": -4.5654623193058796e-08, "kl": 0.00849366085009372, "entropy": 1.74632694873404, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1183182, "num_agent_steps_sampled": 2366364, "num_steps_trained": 1183182, "num_agent_steps_trained": 2366364}, "done": false, "episodes_total": 1182, "training_iteration": 197, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-39-39", "timestamp": 1624966779, "time_this_iter_s": 25.00989317893982, "time_total_s": 4981.2050359249115, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4981.2050359249115, "timesteps_since_restore": 0, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 30.06666666666667, "ram_util_percent": 67.46969696969697, "gpu_util_percent0": 0.38545454545454544, "vram_util_percent0": 0.29969564196055604}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1737443.4401240207, "pol1": 1737443.4401240207}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1736342.4061520046, -1687406.430526742, -1696931.2835877915, -1881697.715278638, -1883403.1380973319, -1898151.8655352665, -1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613], "policy_pol1_reward": [1736342.4061520046, 1687406.430526742, 1696931.2835877915, 1881697.715278638, 1883403.1380973319, 1898151.8655352665, 1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2762616616932442, "mean_inference_ms": 3.821753866985662, "mean_action_processing_ms": 0.1910160477144299, "mean_env_wait_ms": 0.14464788126411096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1189188, "agent_timesteps_total": 2378376, "timers": {"sample_time_ms": 4487.511, "sample_throughput": 1338.381, "learn_time_ms": 20653.441, "learn_throughput": 290.799, "update_time_ms": 4.811}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 26458882658.042553, "policy_loss": -0.002663047429411969, "vf_loss": 26458882658.042553, "vf_explained_var": -1.0145471662781347e-07, "kl": 0.006746126091147357, "entropy": 2.7543772230757044, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27067766043.234043, "policy_loss": -0.0048289152377463404, "vf_loss": 27067766043.234043, "vf_explained_var": 0.0, "kl": 0.009048859737417165, "entropy": 1.6701122319444697, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1189188, "num_agent_steps_sampled": 2378376, "num_steps_trained": 1189188, "num_agent_steps_trained": 2378376}, "done": false, "episodes_total": 1188, "training_iteration": 198, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-40-04", "timestamp": 1624966804, "time_this_iter_s": 25.17590069770813, "time_total_s": 5006.38093662262, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e352f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e359d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5006.38093662262, "timesteps_since_restore": 0, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 31.184848484848484, "ram_util_percent": 67.19696969696972, "gpu_util_percent0": 0.38393939393939386, "vram_util_percent0": 0.29960882842581527}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1732551.2169419893, "pol1": 1732551.2169419893}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1563052.4075521927, -1653954.9262459734, -1750874.5380403756, -1824853.8032340768, -1404701.2683224764, -1623755.757412457, -1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276], "policy_pol1_reward": [1563052.4075521927, 1653954.9262459734, 1750874.5380403756, 1824853.8032340768, 1404701.2683224764, 1623755.757412457, 1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27625291793911044, "mean_inference_ms": 3.8215931056633683, "mean_action_processing_ms": 0.19100613404222952, "mean_env_wait_ms": 0.1446427023315965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1195194, "agent_timesteps_total": 2390388, "timers": {"sample_time_ms": 4515.088, "sample_throughput": 1330.207, "learn_time_ms": 20647.863, "learn_throughput": 290.878, "update_time_ms": 4.872}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24199980358.80851, "policy_loss": 0.0004999135284030691, "vf_loss": 24199980358.80851, "vf_explained_var": -5.199554209411872e-08, "kl": 0.0076611270791197075, "entropy": 2.7214061097895845, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24757507790.97872, "policy_loss": -0.007453085478157439, "vf_loss": 24757507790.97872, "vf_explained_var": -3.677733317886123e-08, "kl": 0.008676528237125974, "entropy": 1.579851634958957, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1195194, "num_agent_steps_sampled": 2390388, "num_steps_trained": 1195194, "num_agent_steps_trained": 2390388}, "done": false, "episodes_total": 1194, "training_iteration": 199, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-40-30", "timestamp": 1624966830, "time_this_iter_s": 25.384557247161865, "time_total_s": 5031.7654938697815, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e358c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5031.7654938697815, "timesteps_since_restore": 0, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 31.18235294117647, "ram_util_percent": 67.16470588235295, "gpu_util_percent0": 0.3785294117647059, "vram_util_percent0": 0.2996143856936101}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1739649.576167345, "pol1": 1739649.576167345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1755622.0186448179, -1755406.0128145332, -1846121.9730136327, -1719627.9809183793, -1728635.560275589, -1805738.9678728238, -1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421], "policy_pol1_reward": [1755622.0186448179, 1755406.0128145332, 1846121.9730136327, 1719627.9809183793, 1728635.560275589, 1805738.9678728238, 1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27624442111950204, "mean_inference_ms": 3.8214642709858646, "mean_action_processing_ms": 0.19099752778030724, "mean_env_wait_ms": 0.14463835911000653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1201200, "agent_timesteps_total": 2402400, "timers": {"sample_time_ms": 4523.922, "sample_throughput": 1327.609, "learn_time_ms": 20672.78, "learn_throughput": 290.527, "update_time_ms": 5.025}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25644749061.446808, "policy_loss": -0.0019088090258709929, "vf_loss": 25644749061.446808, "vf_explained_var": 7.482285013793444e-08, "kl": 0.006412779793460319, "entropy": 2.6707996408990087, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26250399482.553192, "policy_loss": -0.006101607919690457, "vf_loss": 26250399482.553192, "vf_explained_var": -6.340919789238342e-09, "kl": 0.007196394736541712, "entropy": 1.4979004657014887, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1201200, "num_agent_steps_sampled": 2402400, "num_steps_trained": 1201200, "num_agent_steps_trained": 2402400}, "done": false, "episodes_total": 1200, "training_iteration": 200, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-40-55", "timestamp": 1624966855, "time_this_iter_s": 25.354531288146973, "time_total_s": 5057.1200251579285, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5057.1200251579285, "timesteps_since_restore": 0, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 30.766666666666666, "ram_util_percent": 67.27272727272728, "gpu_util_percent0": 0.37333333333333335, "vram_util_percent0": 0.2997058553175843}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1742467.9076982283, "pol1": 1742467.9076982283}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1630113.1906637056, -1666328.2927283526, -1754967.082574276, -1783003.416058234, -1802821.1323031737, -1863417.2534378937, -1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712], "policy_pol1_reward": [1630113.1906637056, 1666328.2927283526, 1754967.082574276, 1783003.416058234, 1802821.1323031737, 1863417.2534378937, 1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2762335608800919, "mean_inference_ms": 3.821297643026103, "mean_action_processing_ms": 0.19098732740902627, "mean_env_wait_ms": 0.1446328045036549, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1207206, "agent_timesteps_total": 2414412, "timers": {"sample_time_ms": 4521.473, "sample_throughput": 1328.328, "learn_time_ms": 20673.529, "learn_throughput": 290.516, "update_time_ms": 4.985}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 27282745082.553192, "policy_loss": -0.0016274544945422639, "vf_loss": 27282745082.553192, "vf_explained_var": -3.170459805801329e-08, "kl": 0.00989936234706894, "entropy": 2.715537329937549, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27925967632.340427, "policy_loss": -0.007457639229424456, "vf_loss": 27925967632.340427, "vf_explained_var": 1.6486390919112637e-08, "kl": 0.009402787382219066, "entropy": 1.4946911791537671, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1207206, "num_agent_steps_sampled": 2414412, "num_steps_trained": 1207206, "num_agent_steps_trained": 2414412}, "done": false, "episodes_total": 1206, "training_iteration": 201, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-41-20", "timestamp": 1624966880, "time_this_iter_s": 24.954484462738037, "time_total_s": 5082.0745096206665, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06278c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5082.0745096206665, "timesteps_since_restore": 0, "iterations_since_restore": 201, "perf": {"cpu_util_percent": 29.775757575757577, "ram_util_percent": 67.37575757575758, "gpu_util_percent0": 0.3772727272727273, "vram_util_percent0": 0.2996139351043295}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1735569.5735422503, "pol1": 1735569.5735422503}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1877985.4694108893, -1855784.151165936, -1722645.2289272328, -1727142.44369397, -1773266.2589226612, -1682197.6807601794, -1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932], "policy_pol1_reward": [1877985.4694108893, 1855784.151165936, 1722645.2289272328, 1727142.44369397, 1773266.2589226612, 1682197.6807601794, 1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27622404447712967, "mean_inference_ms": 3.821140974857359, "mean_action_processing_ms": 0.19097837252823402, "mean_env_wait_ms": 0.14462848855719346, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1213212, "agent_timesteps_total": 2426424, "timers": {"sample_time_ms": 4522.553, "sample_throughput": 1328.011, "learn_time_ms": 20656.988, "learn_throughput": 290.749, "update_time_ms": 4.982}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 22438921760.68085, "policy_loss": -0.0035327009935962393, "vf_loss": 22438921760.68085, "vf_explained_var": 1.0399108418823744e-07, "kl": 0.009741842568396254, "entropy": 2.735875368118286, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22978443961.19149, "policy_loss": -0.004932928426646965, "vf_loss": 22978443961.19149, "vf_explained_var": 7.228648257751047e-08, "kl": 0.007935097758123216, "entropy": 1.4845607077821772, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1213212, "num_agent_steps_sampled": 2426424, "num_steps_trained": 1213212, "num_agent_steps_trained": 2426424}, "done": false, "episodes_total": 1212, "training_iteration": 202, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-41-45", "timestamp": 1624966905, "time_this_iter_s": 25.182473182678223, "time_total_s": 5107.256982803345, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5107.256982803345, "timesteps_since_restore": 0, "iterations_since_restore": 202, "perf": {"cpu_util_percent": 30.503030303030304, "ram_util_percent": 67.25454545454546, "gpu_util_percent0": 0.3821212121212121, "vram_util_percent0": 0.29969564196055604}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1144502.8789615226}, "policy_reward_max": {"pol0": -1144502.8789615226, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1733892.0416720703, "pol1": 1733892.0416720703}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1451524.2304252218, -1144502.8789615226, -1798082.8230473178, -1771746.6047209736, -1704004.6275577664, -1830150.0227392225, -1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478], "policy_pol1_reward": [1451524.2304252218, 1144502.8789615226, 1798082.8230473178, 1771746.6047209736, 1704004.6275577664, 1830150.0227392225, 1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2762132658645582, "mean_inference_ms": 3.820929365480392, "mean_action_processing_ms": 0.19096794794522787, "mean_env_wait_ms": 0.14462277866552165, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1219218, "agent_timesteps_total": 2438436, "timers": {"sample_time_ms": 4519.026, "sample_throughput": 1329.047, "learn_time_ms": 20648.205, "learn_throughput": 290.873, "update_time_ms": 4.957}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25026686322.38298, "policy_loss": -0.001215123769609218, "vf_loss": 25026686322.38298, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.0070444124433747, "entropy": 2.7666420733675046, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25604404681.531914, "policy_loss": -0.0043186507326491335, "vf_loss": 25604404681.531914, "vf_explained_var": -6.087282855560261e-08, "kl": 0.010989786621103895, "entropy": 1.3314079147704103, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1219218, "num_agent_steps_sampled": 2438436, "num_steps_trained": 1219218, "num_agent_steps_trained": 2438436}, "done": false, "episodes_total": 1218, "training_iteration": 203, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-42-10", "timestamp": 1624966930, "time_this_iter_s": 25.082277059555054, "time_total_s": 5132.3392598629, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5132.3392598629, "timesteps_since_restore": 0, "iterations_since_restore": 203, "perf": {"cpu_util_percent": 29.790909090909093, "ram_util_percent": 67.51212121212122, "gpu_util_percent0": 0.376969696969697, "vram_util_percent0": 0.2996037217473011}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1734977.2332597226, "pol1": 1734977.2332597226}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1749423.7219608885, -1792246.7350105129, -1711474.604827715, -1624389.6361225962, -1770458.1780796295, -1751005.4464031884, -1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666], "policy_pol1_reward": [1749423.7219608885, 1792246.7350105129, 1711474.604827715, 1624389.6361225962, 1770458.1780796295, 1751005.4464031884, 1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27620430644046823, "mean_inference_ms": 3.820760690158541, "mean_action_processing_ms": 0.1909595651667736, "mean_env_wait_ms": 0.1446183123334092, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1225224, "agent_timesteps_total": 2450448, "timers": {"sample_time_ms": 4530.234, "sample_throughput": 1325.759, "learn_time_ms": 20694.242, "learn_throughput": 290.226, "update_time_ms": 4.982}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 22282758318.29787, "policy_loss": -0.001602338478365477, "vf_loss": 22282758318.29787, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.006461372252236655, "entropy": 2.7955284981017416, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22813212192.68085, "policy_loss": -0.004795807592095213, "vf_loss": 22813212192.68085, "vf_explained_var": -2.1559126039960574e-08, "kl": 0.008086678215322341, "entropy": 1.246310495315714, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1225224, "num_agent_steps_sampled": 2450448, "num_steps_trained": 1225224, "num_agent_steps_trained": 2450448}, "done": false, "episodes_total": 1224, "training_iteration": 204, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-42-36", "timestamp": 1624966956, "time_this_iter_s": 25.829060077667236, "time_total_s": 5158.168319940567, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5158.168319940567, "timesteps_since_restore": 0, "iterations_since_restore": 204, "perf": {"cpu_util_percent": 32.49411764705883, "ram_util_percent": 67.51176470588236, "gpu_util_percent0": 0.3788235294117647, "vram_util_percent0": 0.2996391681040465}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1737732.9900750138, "pol1": 1737732.9900750138}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1881537.5292909485, -1366018.4710151092, -1769969.9251550809, -1698836.6443643495, -1719319.5312505139, -1713472.7140762198, -1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421], "policy_pol1_reward": [1881537.5292909485, 1366018.4710151092, 1769969.9251550809, 1698836.6443643495, 1719319.5312505139, 1713472.7140762198, 1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27619472964913044, "mean_inference_ms": 3.8205989121234154, "mean_action_processing_ms": 0.19095164119006827, "mean_env_wait_ms": 0.14461408922264463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1231230, "agent_timesteps_total": 2462460, "timers": {"sample_time_ms": 4527.871, "sample_throughput": 1326.451, "learn_time_ms": 20697.823, "learn_throughput": 290.175, "update_time_ms": 5.056}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 26113298606.29787, "policy_loss": -0.00042095764520320484, "vf_loss": 26113298606.29787, "vf_explained_var": -1.1160018686950934e-07, "kl": 0.006501466769011731, "entropy": 2.7844677580163832, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26718165079.148937, "policy_loss": -0.004411897641864229, "vf_loss": 26718165079.148937, "vf_explained_var": 7.609103391814642e-08, "kl": 0.010016059205728643, "entropy": 1.2849367273614762, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1231230, "num_agent_steps_sampled": 2462460, "num_steps_trained": 1231230, "num_agent_steps_trained": 2462460}, "done": false, "episodes_total": 1230, "training_iteration": 205, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-43-01", "timestamp": 1624966981, "time_this_iter_s": 25.13321542739868, "time_total_s": 5183.301535367966, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5183.301535367966, "timesteps_since_restore": 0, "iterations_since_restore": 205, "perf": {"cpu_util_percent": 30.354545454545452, "ram_util_percent": 67.47575757575757, "gpu_util_percent0": 0.38363636363636366, "vram_util_percent0": 0.29964457517541443}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1745366.930652947, "pol1": 1745366.930652947}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1768616.5261241768, -1946031.247761593, -1783033.430088994, -1578725.3072561463, -1679329.6685688721, -1882307.6213208064, -1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701], "policy_pol1_reward": [1768616.5261241768, 1946031.247761593, 1783033.430088994, 1578725.3072561463, 1679329.6685688721, 1882307.6213208064, 1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27618316011759264, "mean_inference_ms": 3.8204743411051734, "mean_action_processing_ms": 0.1909453398154706, "mean_env_wait_ms": 0.14461141337301972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1237236, "agent_timesteps_total": 2474472, "timers": {"sample_time_ms": 4526.229, "sample_throughput": 1326.932, "learn_time_ms": 20685.534, "learn_throughput": 290.348, "update_time_ms": 5.051}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 27317920964.085106, "policy_loss": -0.0023489294454772424, "vf_loss": 27317920964.085106, "vf_explained_var": -3.550914939864924e-08, "kl": 0.01095344354101318, "entropy": 2.7289623554716718, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 27973831745.361702, "policy_loss": -0.006897831137510056, "vf_loss": 27973831745.361702, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.009773191847303447, "entropy": 1.3128660917282104, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1237236, "num_agent_steps_sampled": 2474472, "num_steps_trained": 1237236, "num_agent_steps_trained": 2474472}, "done": false, "episodes_total": 1236, "training_iteration": 206, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-43-27", "timestamp": 1624967007, "time_this_iter_s": 25.14703893661499, "time_total_s": 5208.448574304581, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e352f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5208.448574304581, "timesteps_since_restore": 0, "iterations_since_restore": 206, "perf": {"cpu_util_percent": 30.517647058823528, "ram_util_percent": 67.34117647058825, "gpu_util_percent0": 0.38558823529411757, "vram_util_percent0": 0.2995796903189992}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1744320.2073947764, "pol1": 1744320.2073947764}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1575800.3517136462, -1868266.6809996916, -1834722.950461938, -1720490.5251799515, -1780589.984759623, -1476842.0187405366, -1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037], "policy_pol1_reward": [1575800.3517136462, 1868266.6809996916, 1834722.950461938, 1720490.5251799515, 1780589.984759623, 1476842.0187405366, 1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2761695459495763, "mean_inference_ms": 3.8203186005031773, "mean_action_processing_ms": 0.19093738463689675, "mean_env_wait_ms": 0.14460796002909695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1243242, "agent_timesteps_total": 2486484, "timers": {"sample_time_ms": 4523.718, "sample_throughput": 1327.669, "learn_time_ms": 20700.138, "learn_throughput": 290.143, "update_time_ms": 5.099}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25442173668.765957, "policy_loss": -0.0013499167212780486, "vf_loss": 25442173668.765957, "vf_explained_var": 9.765016528717751e-08, "kl": 0.009341608554600402, "entropy": 2.7339450805745225, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26049026222.29787, "policy_loss": -0.006645552160099466, "vf_loss": 26049026222.29787, "vf_explained_var": -1.2555021555726853e-07, "kl": 0.015732349154162915, "entropy": 1.3535030877336542, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1243242, "num_agent_steps_sampled": 2486484, "num_steps_trained": 1243242, "num_agent_steps_trained": 2486484}, "done": false, "episodes_total": 1242, "training_iteration": 207, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-43-52", "timestamp": 1624967032, "time_this_iter_s": 25.132246732711792, "time_total_s": 5233.5808210372925, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c72f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5233.5808210372925, "timesteps_since_restore": 0, "iterations_since_restore": 207, "perf": {"cpu_util_percent": 30.03939393939394, "ram_util_percent": 67.46666666666665, "gpu_util_percent0": 0.3851515151515152, "vram_util_percent0": 0.29970074863907015}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1956565.4776854496, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1956565.4776854496}, "policy_reward_mean": {"pol0": -1747406.0646672146, "pol1": 1747406.0646672146}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1448901.0429718192, -1956565.4776854496, -1892078.2781164595, -1825065.873273991, -1697151.572027432, -1856464.995277053, -1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667], "policy_pol1_reward": [1448901.0429718192, 1956565.4776854496, 1892078.2781164595, 1825065.873273991, 1697151.572027432, 1856464.995277053, 1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27616019073886205, "mean_inference_ms": 3.8201859900123933, "mean_action_processing_ms": 0.19093022107241053, "mean_env_wait_ms": 0.14460539384079338, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1249248, "agent_timesteps_total": 2498496, "timers": {"sample_time_ms": 4534.231, "sample_throughput": 1324.591, "learn_time_ms": 20695.657, "learn_throughput": 290.206, "update_time_ms": 5.041}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25440972494.97872, "policy_loss": -0.002813633570962764, "vf_loss": 25440972494.97872, "vf_explained_var": -1.1413655442993331e-07, "kl": 0.009268066964726498, "entropy": 2.779390258991972, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26052718069.106384, "policy_loss": -0.009642271968991832, "vf_loss": 26052718069.106384, "vf_explained_var": -1.5218206783629284e-07, "kl": 0.011630735934731807, "entropy": 1.1164009469620726, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1249248, "num_agent_steps_sampled": 2498496, "num_steps_trained": 1249248, "num_agent_steps_trained": 2498496}, "done": false, "episodes_total": 1248, "training_iteration": 208, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-44-17", "timestamp": 1624967057, "time_this_iter_s": 25.23634171485901, "time_total_s": 5258.8171627521515, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5258.8171627521515, "timesteps_since_restore": 0, "iterations_since_restore": 208, "perf": {"cpu_util_percent": 31.02121212121212, "ram_util_percent": 67.35757575757576, "gpu_util_percent0": 0.3790909090909091, "vram_util_percent0": 0.2996139351043295}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1745695.4417150777, "pol1": 1745695.4417150777}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1732381.1582594838, -1814360.3329685812, -1667075.0609353802, -1860299.608614725, -1905942.682864774, -1530122.7038301989, -1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282], "policy_pol1_reward": [1732381.1582594838, 1814360.3329685812, 1667075.0609353802, 1860299.608614725, 1905942.682864774, 1530122.7038301989, 1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2761486661974719, "mean_inference_ms": 3.819989574389213, "mean_action_processing_ms": 0.19091986752222517, "mean_env_wait_ms": 0.1446007302541129, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1255254, "agent_timesteps_total": 2510508, "timers": {"sample_time_ms": 4508.034, "sample_throughput": 1332.288, "learn_time_ms": 20682.312, "learn_throughput": 290.393, "update_time_ms": 5.031}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.698091761383692e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25053747505.02128, "policy_loss": 0.0009539048286511543, "vf_loss": 25053747505.02128, "vf_explained_var": 2.2827311596529398e-08, "kl": 0.004386437293934695, "entropy": 2.7422347220968692, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25653672633.19149, "policy_loss": -0.006663332534755798, "vf_loss": 25653672633.19149, "vf_explained_var": -1.4457296515502094e-07, "kl": 0.008926778358030827, "entropy": 1.1562424695238154, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1255254, "num_agent_steps_sampled": 2510508, "num_steps_trained": 1255254, "num_agent_steps_trained": 2510508}, "done": false, "episodes_total": 1254, "training_iteration": 209, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-44-42", "timestamp": 1624967082, "time_this_iter_s": 24.988763570785522, "time_total_s": 5283.805926322937, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05e32f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05e3400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5283.805926322937, "timesteps_since_restore": 0, "iterations_since_restore": 209, "perf": {"cpu_util_percent": 30.09393939393939, "ram_util_percent": 67.47272727272727, "gpu_util_percent0": 0.37696969696969695, "vram_util_percent0": 0.2996905352820418}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1742326.8203570368, "pol1": 1742326.8203570368}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1732779.0772254623, -1860161.4791023151, -1607040.8289402477, -1798599.1221053249, -1752285.8468534225, -1772933.4052101658, -1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939], "policy_pol1_reward": [1732779.0772254623, 1860161.4791023151, 1607040.8289402477, 1798599.1221053249, 1752285.8468534225, 1772933.4052101658, 1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27613828790284317, "mean_inference_ms": 3.8198273112631074, "mean_action_processing_ms": 0.19091009620211352, "mean_env_wait_ms": 0.14459613961928403, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1261260, "agent_timesteps_total": 2522520, "timers": {"sample_time_ms": 4513.445, "sample_throughput": 1330.691, "learn_time_ms": 20657.592, "learn_throughput": 290.741, "update_time_ms": 4.867}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.349045880691846e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 23775085981.957447, "policy_loss": -0.0006093307536967257, "vf_loss": 23775085981.957447, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.00402899754748858, "entropy": 2.7267786797056806, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24354867374.29787, "policy_loss": -0.007257661385897627, "vf_loss": 24354867374.29787, "vf_explained_var": -1.2935475979247713e-07, "kl": 0.011618337187757517, "entropy": 1.2654900703024357, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1261260, "num_agent_steps_sampled": 2522520, "num_steps_trained": 1261260, "num_agent_steps_trained": 2522520}, "done": false, "episodes_total": 1260, "training_iteration": 210, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-45-07", "timestamp": 1624967107, "time_this_iter_s": 25.158303260803223, "time_total_s": 5308.96422958374, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05e3f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05e37b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5308.96422958374, "timesteps_since_restore": 0, "iterations_since_restore": 210, "perf": {"cpu_util_percent": 30.80606060606061, "ram_util_percent": 67.34848484848484, "gpu_util_percent0": 0.3745454545454545, "vram_util_percent0": 0.2996037217473011}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1736004.8855428728, "pol1": 1736004.8855428728}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1813430.444594284, -1743133.0250695322, -1713363.1950086812, -1614625.0159243783, -1879758.7747737833, -1788398.1458976308, -1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267], "policy_pol1_reward": [1813430.444594284, 1743133.0250695322, 1713363.1950086812, 1614625.0159243783, 1879758.7747737833, 1788398.1458976308, 1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2761236274560929, "mean_inference_ms": 3.819659431166042, "mean_action_processing_ms": 0.1909000881163282, "mean_env_wait_ms": 0.14459129521741954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1267266, "agent_timesteps_total": 2534532, "timers": {"sample_time_ms": 4521.385, "sample_throughput": 1328.354, "learn_time_ms": 20662.579, "learn_throughput": 290.67, "update_time_ms": 4.837}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 22394968064.0, "policy_loss": -0.0011196818916087456, "vf_loss": 22394968064.0, "vf_explained_var": 9.004106260590561e-08, "kl": 0.008085405117178217, "entropy": 2.7323443382344346, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 22949783464.851063, "policy_loss": -0.002605403218656144, "vf_loss": 22949783464.851063, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.008025116039479667, "entropy": 1.2993080793543066, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1267266, "num_agent_steps_sampled": 2534532, "num_steps_trained": 1267266, "num_agent_steps_trained": 2534532}, "done": false, "episodes_total": 1266, "training_iteration": 211, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-45-32", "timestamp": 1624967132, "time_this_iter_s": 25.084362030029297, "time_total_s": 5334.0485916137695, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdbf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5334.0485916137695, "timesteps_since_restore": 0, "iterations_since_restore": 211, "perf": {"cpu_util_percent": 30.006060606060604, "ram_util_percent": 67.53030303030303, "gpu_util_percent0": 0.38242424242424244, "vram_util_percent0": 0.299598615068787}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1732659.2637246666, "pol1": 1732659.2637246666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1721371.6518254722, -1629642.917459698, -1640552.8727882213, -1874352.8332168283, -1650054.8161664957, -1878415.160978373, -1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149], "policy_pol1_reward": [1721371.6518254722, 1629642.917459698, 1640552.8727882213, 1874352.8332168283, 1650054.8161664957, 1878415.160978373, 1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27611234604744284, "mean_inference_ms": 3.819531130774214, "mean_action_processing_ms": 0.19089243042386086, "mean_env_wait_ms": 0.1445879335590983, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1273272, "agent_timesteps_total": 2546544, "timers": {"sample_time_ms": 4531.506, "sample_throughput": 1325.387, "learn_time_ms": 20671.749, "learn_throughput": 290.541, "update_time_ms": 4.835}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 23926224983.148937, "policy_loss": -0.0022633959479788517, "vf_loss": 23926224983.148937, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.008586263848825338, "entropy": 2.709032373225435, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24527159775.31915, "policy_loss": -0.006900604338722026, "vf_loss": 24527159775.31915, "vf_explained_var": -1.0906381930908537e-07, "kl": 0.008888540383269812, "entropy": 1.1622864667405473, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1273272, "num_agent_steps_sampled": 2546544, "num_steps_trained": 1273272, "num_agent_steps_trained": 2546544}, "done": false, "episodes_total": 1272, "training_iteration": 212, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-45-58", "timestamp": 1624967158, "time_this_iter_s": 25.376174211502075, "time_total_s": 5359.424765825272, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eacf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac9d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5359.424765825272, "timesteps_since_restore": 0, "iterations_since_restore": 212, "perf": {"cpu_util_percent": 30.102941176470583, "ram_util_percent": 67.31764705882354, "gpu_util_percent0": 0.38147058823529406, "vram_util_percent0": 0.29967881996074464}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1733909.3155373437, "pol1": 1733909.3155373437}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1672605.4373872941, -1596377.2150634339, -1845704.5371048755, -1765420.6379877797, -1877387.668636234, -1834230.7880901436, -1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086], "policy_pol1_reward": [1672605.4373872941, 1596377.2150634339, 1845704.5371048755, 1765420.6379877797, 1877387.668636234, 1834230.7880901436, 1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27609710396329235, "mean_inference_ms": 3.8194315044512903, "mean_action_processing_ms": 0.19088411850719195, "mean_env_wait_ms": 0.14458344036461043, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1279278, "agent_timesteps_total": 2558556, "timers": {"sample_time_ms": 4554.806, "sample_throughput": 1318.607, "learn_time_ms": 20654.111, "learn_throughput": 290.79, "update_time_ms": 4.818}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25271433782.468086, "policy_loss": -0.0014573980241696885, "vf_loss": 25271433782.468086, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.009047484718897242, "entropy": 2.678352883521547, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25889723500.93617, "policy_loss": -0.005970585932756992, "vf_loss": 25889723500.93617, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.009861352962461557, "entropy": 0.9890394806861877, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1279278, "num_agent_steps_sampled": 2558556, "num_steps_trained": 1279278, "num_agent_steps_trained": 2558556}, "done": false, "episodes_total": 1278, "training_iteration": 213, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-46-23", "timestamp": 1624967183, "time_this_iter_s": 25.138526678085327, "time_total_s": 5384.563292503357, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5384.563292503357, "timesteps_since_restore": 0, "iterations_since_restore": 213, "perf": {"cpu_util_percent": 29.54848484848485, "ram_util_percent": 67.58484848484848, "gpu_util_percent0": 0.37696969696969695, "vram_util_percent0": 0.2995730816762161}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1733606.8028335178, "pol1": 1733606.8028335178}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1757865.8489146437, -1824769.5606941362, -1592932.4136519155, -1820872.2127495613, -1875278.719793926, -1597729.2562122522, -1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054], "policy_pol1_reward": [1757865.8489146437, 1824769.5606941362, 1592932.4136519155, 1820872.2127495613, 1875278.719793926, 1597729.2562122522, 1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27607701675738433, "mean_inference_ms": 3.819332053352781, "mean_action_processing_ms": 0.19087567366427013, "mean_env_wait_ms": 0.14457859449919408, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1285284, "agent_timesteps_total": 2570568, "timers": {"sample_time_ms": 4528.522, "sample_throughput": 1326.26, "learn_time_ms": 20609.955, "learn_throughput": 291.413, "update_time_ms": 4.854}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25575931598.97872, "policy_loss": -0.002079314294647663, "vf_loss": 25575931598.97872, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.007944127792452878, "entropy": 2.7120428846237505, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 26214442397.957447, "policy_loss": -0.006583539452007476, "vf_loss": 26214442397.957447, "vf_explained_var": -1.0779563552887339e-07, "kl": 0.008658707508460638, "entropy": 0.9630693856706011, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1285284, "num_agent_steps_sampled": 2570568, "num_steps_trained": 1285284, "num_agent_steps_trained": 2570568}, "done": false, "episodes_total": 1284, "training_iteration": 214, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-46-48", "timestamp": 1624967208, "time_this_iter_s": 25.12529492378235, "time_total_s": 5409.688587427139, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5409.688587427139, "timesteps_since_restore": 0, "iterations_since_restore": 214, "perf": {"cpu_util_percent": 30.1, "ram_util_percent": 67.55151515151516, "gpu_util_percent0": 0.37787878787878787, "vram_util_percent0": 0.2997007486390702}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1733485.4769358533, "pol1": 1733485.4769358533}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1706308.5657672095, -1653210.9130200483, -1834309.191604549, -1627873.8745767276, -1722242.142131109, -1491998.6943297267, -1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469], "policy_pol1_reward": [1706308.5657672095, 1653210.9130200483, 1834309.191604549, 1627873.8745767276, 1722242.142131109, 1491998.6943297267, 1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27605993583793426, "mean_inference_ms": 3.819265632091215, "mean_action_processing_ms": 0.19086885355201852, "mean_env_wait_ms": 0.14457441838129795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1291290, "agent_timesteps_total": 2582580, "timers": {"sample_time_ms": 4548.081, "sample_throughput": 1320.557, "learn_time_ms": 20618.364, "learn_throughput": 291.294, "update_time_ms": 4.833}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25006072330.893616, "policy_loss": -0.0016599068457775928, "vf_loss": 25006072330.893616, "vf_explained_var": 1.0399108418823744e-07, "kl": 0.010331973611832933, "entropy": 2.6724248946981226, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25624970653.957447, "policy_loss": -0.006099126856536307, "vf_loss": 25624970653.957447, "vf_explained_var": -1.065274517486614e-07, "kl": 0.008012615936867733, "entropy": 0.9881537404466183, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1291290, "num_agent_steps_sampled": 2582580, "num_steps_trained": 1291290, "num_agent_steps_trained": 2582580}, "done": false, "episodes_total": 1290, "training_iteration": 215, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-47-14", "timestamp": 1624967234, "time_this_iter_s": 25.41274404525757, "time_total_s": 5435.101331472397, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c72f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5435.101331472397, "timesteps_since_restore": 0, "iterations_since_restore": 215, "perf": {"cpu_util_percent": 31.545454545454547, "ram_util_percent": 67.37878787878788, "gpu_util_percent0": 0.37363636363636366, "vram_util_percent0": 0.29959861506878693}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1930184.5230260137, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1930184.5230260137}, "policy_reward_mean": {"pol0": -1738047.2521298518, "pol1": 1738047.2521298518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1805942.542909967, -1930184.5230260137, -1836875.7477631953, -1743784.9731830421, -1824713.560390002, -1902142.5660735576, -1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111], "policy_pol1_reward": [1805942.542909967, 1930184.5230260137, 1836875.7477631953, 1743784.9731830421, 1824713.560390002, 1902142.5660735576, 1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27603645692125256, "mean_inference_ms": 3.8191488977849986, "mean_action_processing_ms": 0.19086010360651162, "mean_env_wait_ms": 0.1445686601907443, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1297296, "agent_timesteps_total": 2594592, "timers": {"sample_time_ms": 4544.05, "sample_throughput": 1321.729, "learn_time_ms": 20609.8, "learn_throughput": 291.415, "update_time_ms": 4.83}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25231755481.87234, "policy_loss": -0.0004521825925466862, "vf_loss": 25231755481.87234, "vf_explained_var": 1.2935475979247713e-07, "kl": 0.006680702513202708, "entropy": 2.6819088915561107, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25866435300.765957, "policy_loss": -0.005774749977950086, "vf_loss": 25866435300.765957, "vf_explained_var": -1.1667292199035728e-07, "kl": 0.00739969230910882, "entropy": 0.9244942005644453, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1297296, "num_agent_steps_sampled": 2594592, "num_steps_trained": 1297296, "num_agent_steps_trained": 2594592}, "done": false, "episodes_total": 1296, "training_iteration": 216, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-47-39", "timestamp": 1624967259, "time_this_iter_s": 25.020843982696533, "time_total_s": 5460.122175455093, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06278c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5460.122175455093, "timesteps_since_restore": 0, "iterations_since_restore": 216, "perf": {"cpu_util_percent": 30.190909090909088, "ram_util_percent": 67.45757575757577, "gpu_util_percent0": 0.3827272727272727, "vram_util_percent0": 0.2996905352820418}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1903188.7532275096, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1903188.7532275096}, "policy_reward_mean": {"pol0": -1728338.0068452351, "pol1": 1728338.0068452351}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1794316.362605309, -1868630.0016168756, -1841598.8697329946, -1661584.3062093712, -1855961.1644593417, -1505420.4206298096, -1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943], "policy_pol1_reward": [1794316.362605309, 1868630.0016168756, 1841598.8697329946, 1661584.3062093712, 1855961.1644593417, 1505420.4206298096, 1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2760116815974033, "mean_inference_ms": 3.819029377117741, "mean_action_processing_ms": 0.1908510542877728, "mean_env_wait_ms": 0.14456274071351996, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1303302, "agent_timesteps_total": 2606604, "timers": {"sample_time_ms": 4558.717, "sample_throughput": 1317.476, "learn_time_ms": 20612.748, "learn_throughput": 291.373, "update_time_ms": 4.819}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 23216315326.638298, "policy_loss": -0.0017111479760484492, "vf_loss": 23216315326.638298, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.008118756115436554, "entropy": 2.727375679827751, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 23793189604.765957, "policy_loss": -0.0045336984454634344, "vf_loss": 23793189604.765957, "vf_explained_var": -1.2681839223205316e-07, "kl": 0.00818598654834514, "entropy": 0.7945833941723438, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1303302, "num_agent_steps_sampled": 2606604, "num_steps_trained": 1303302, "num_agent_steps_trained": 2606604}, "done": false, "episodes_total": 1302, "training_iteration": 217, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-48-04", "timestamp": 1624967284, "time_this_iter_s": 25.308311462402344, "time_total_s": 5485.430486917496, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac9d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5485.430486917496, "timesteps_since_restore": 0, "iterations_since_restore": 217, "perf": {"cpu_util_percent": 30.508823529411764, "ram_util_percent": 67.26764705882354, "gpu_util_percent0": 0.3773529411764706, "vram_util_percent0": 0.29962429865778467}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1734446.2724290334, "pol1": 1734446.2724290334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1487906.7730255343, -1516355.2915849877, -1895696.3349874886, -1549476.9674806932, -1738323.6149195072, -1809287.2889983258, -1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612], "policy_pol1_reward": [1487906.7730255343, 1516355.2915849877, 1895696.3349874886, 1549476.9674806932, 1738323.6149195072, 1809287.2889983258, 1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2759871132566463, "mean_inference_ms": 3.818906429389622, "mean_action_processing_ms": 0.19084211603428725, "mean_env_wait_ms": 0.14455673659353618, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1309308, "agent_timesteps_total": 2618616, "timers": {"sample_time_ms": 4539.656, "sample_throughput": 1323.008, "learn_time_ms": 20620.04, "learn_throughput": 291.27, "update_time_ms": 4.865}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.174522940345923e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 28486091623.48936, "policy_loss": -0.0009290332053887083, "vf_loss": 28486091623.48936, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.00458175603775902, "entropy": 2.6769700354718147, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 29191180680.17021, "policy_loss": -0.004452107176977269, "vf_loss": 29191180680.17021, "vf_explained_var": -9.004106260590561e-08, "kl": 0.013322453826982925, "entropy": 0.5972922254115978, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1309308, "num_agent_steps_sampled": 2618616, "num_steps_trained": 1309308, "num_agent_steps_trained": 2618616}, "done": false, "episodes_total": 1308, "training_iteration": 218, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-48-29", "timestamp": 1624967309, "time_this_iter_s": 25.11883854866028, "time_total_s": 5510.549325466156, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5510.549325466156, "timesteps_since_restore": 0, "iterations_since_restore": 218, "perf": {"cpu_util_percent": 30.19090909090909, "ram_util_percent": 67.45151515151515, "gpu_util_percent0": 0.3809090909090909, "vram_util_percent0": 0.3056755625006384}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1735897.5340671262, "pol1": 1735897.5340671262}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1797316.6339455552, -1756984.1233401638, -1684552.0309598488, -1684804.353699478, -1817446.653392648, -1690010.2865731106, -1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644], "policy_pol1_reward": [1797316.6339455552, 1756984.1233401638, 1684552.0309598488, 1684804.353699478, 1817446.653392648, 1690010.2865731106, 1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2759636868006221, "mean_inference_ms": 3.8187923950189417, "mean_action_processing_ms": 0.19083330391137246, "mean_env_wait_ms": 0.1445501960147143, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1315314, "agent_timesteps_total": 2630628, "timers": {"sample_time_ms": 4556.794, "sample_throughput": 1318.032, "learn_time_ms": 20626.231, "learn_throughput": 291.183, "update_time_ms": 4.825}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.872614701729615e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 23526083518.638298, "policy_loss": -0.000557926245667833, "vf_loss": 23526083518.638298, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.0072308845936935, "entropy": 2.6683413272208356, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 24131818299.914894, "policy_loss": -0.007864590258674418, "vf_loss": 24131818299.914894, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.012717782916065226, "entropy": 0.6246966275763004, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1315314, "num_agent_steps_sampled": 2630628, "num_steps_trained": 1315314, "num_agent_steps_trained": 2630628}, "done": false, "episodes_total": 1314, "training_iteration": 219, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-48-54", "timestamp": 1624967334, "time_this_iter_s": 25.220780849456787, "time_total_s": 5535.770106315613, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdd08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5535.770106315613, "timesteps_since_restore": 0, "iterations_since_restore": 219, "perf": {"cpu_util_percent": 31.29090909090909, "ram_util_percent": 67.28787878787878, "gpu_util_percent0": 0.3836363636363636, "vram_util_percent0": 0.3068858453084945}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1251666.813965549}, "policy_reward_max": {"pol0": -1251666.813965549, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1735861.2550808373, "pol1": 1735861.2550808373}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1251666.813965549, -1764481.689333819, -1858059.4551118312, -1426865.4478402666, -1868740.0277586135, -1782776.1941605974, -1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989], "policy_pol1_reward": [1251666.813965549, 1764481.689333819, 1858059.4551118312, 1426865.4478402666, 1868740.0277586135, 1782776.1941605974, 1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27594447782888837, "mean_inference_ms": 3.8186842519367277, "mean_action_processing_ms": 0.19082498886825985, "mean_env_wait_ms": 0.14454356017142408, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1321320, "agent_timesteps_total": 2642640, "timers": {"sample_time_ms": 4540.823, "sample_throughput": 1322.668, "learn_time_ms": 20650.813, "learn_throughput": 290.836, "update_time_ms": 4.898}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.872614701729615e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 24696659837.276596, "policy_loss": -0.0008270674573376457, "vf_loss": 24696659837.276596, "vf_explained_var": -1.3696386247374903e-07, "kl": 0.005310292623223777, "entropy": 2.6974786291731165, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.000000000000002e-05, "total_loss": 25313082302.638298, "policy_loss": -0.0012073343064873776, "vf_loss": 25313082302.638298, "vf_explained_var": -1.065274517486614e-07, "kl": 0.021591575935165933, "entropy": 0.647651990677448, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1321320, "num_agent_steps_sampled": 2642640, "num_steps_trained": 1321320, "num_agent_steps_trained": 2642640}, "done": false, "episodes_total": 1320, "training_iteration": 220, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-49-20", "timestamp": 1624967360, "time_this_iter_s": 25.24525737762451, "time_total_s": 5561.015363693237, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e8d400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5561.015363693237, "timesteps_since_restore": 0, "iterations_since_restore": 220, "perf": {"cpu_util_percent": 30.569696969696967, "ram_util_percent": 67.36666666666667, "gpu_util_percent0": 0.37939393939393945, "vram_util_percent0": 0.3067479649886121}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1451110.3206029697}, "policy_reward_max": {"pol0": -1451110.3206029697, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1742853.7594199982, "pol1": 1742853.7594199982}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1600418.4044202548, -1756982.8680749214, -1826595.875669913, -1839060.6338493421, -1790102.1691403475, -1834756.1285869812, -1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743], "policy_pol1_reward": [1600418.4044202548, 1756982.8680749214, 1826595.875669913, 1839060.6338493421, 1790102.1691403475, 1834756.1285869812, 1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27592643053741045, "mean_inference_ms": 3.8185443624164606, "mean_action_processing_ms": 0.19081470273961137, "mean_env_wait_ms": 0.14453607363684154, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1327326, "agent_timesteps_total": 2654652, "timers": {"sample_time_ms": 4533.704, "sample_throughput": 1324.745, "learn_time_ms": 20647.607, "learn_throughput": 290.881, "update_time_ms": 4.915}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.872614701729615e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 25830673429.787235, "policy_loss": -0.001966476598952679, "vf_loss": 25830673429.787235, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.007216726944960178, "entropy": 2.7312519753232913, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26494237630.638298, "policy_loss": -0.005546030291217439, "vf_loss": 26494237630.638298, "vf_explained_var": -1.0145471662781347e-07, "kl": 0.008196314459944025, "entropy": 0.7908888535296663, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1327326, "num_agent_steps_sampled": 2654652, "num_steps_trained": 1327326, "num_agent_steps_trained": 2654652}, "done": false, "episodes_total": 1326, "training_iteration": 221, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-49-45", "timestamp": 1624967385, "time_this_iter_s": 24.980542421340942, "time_total_s": 5585.995906114578, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5585.995906114578, "timesteps_since_restore": 0, "iterations_since_restore": 221, "perf": {"cpu_util_percent": 30.109090909090913, "ram_util_percent": 67.44545454545455, "gpu_util_percent0": 0.3748484848484849, "vram_util_percent0": 0.30677349838118295}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1737218.3108841607, "pol1": 1737218.3108841607}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1839913.0895995274, -1853525.859515136, -1841477.1899665294, -1752774.43613701, -1798581.2502259815, -1813728.256684895, -1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215], "policy_pol1_reward": [1839913.0895995274, 1853525.859515136, 1841477.1899665294, 1752774.43613701, 1798581.2502259815, 1813728.256684895, 1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27591455352622896, "mean_inference_ms": 3.8184157505150047, "mean_action_processing_ms": 0.1908049890327889, "mean_env_wait_ms": 0.1445288842209681, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1333332, "agent_timesteps_total": 2666664, "timers": {"sample_time_ms": 4520.869, "sample_throughput": 1328.506, "learn_time_ms": 20637.997, "learn_throughput": 291.017, "update_time_ms": 4.961}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.872614701729615e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 23374078736.340427, "policy_loss": -0.0006596854828456615, "vf_loss": 23374078736.340427, "vf_explained_var": 1.2681839223205316e-07, "kl": 0.005649109797037029, "entropy": 2.738943541303594, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 23966373757.276596, "policy_loss": -0.0038872000147053536, "vf_loss": 23966373757.276596, "vf_explained_var": 6.340919789238342e-09, "kl": 0.013405845064590586, "entropy": 0.7736327280389502, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1333332, "num_agent_steps_sampled": 2666664, "num_steps_trained": 1333332, "num_agent_steps_trained": 2666664}, "done": false, "episodes_total": 1332, "training_iteration": 222, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-50-10", "timestamp": 1624967410, "time_this_iter_s": 25.151293516159058, "time_total_s": 5611.147199630737, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06278c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5611.147199630737, "timesteps_since_restore": 0, "iterations_since_restore": 222, "perf": {"cpu_util_percent": 31.393939393939394, "ram_util_percent": 67.23333333333335, "gpu_util_percent0": 0.38, "vram_util_percent0": 0.3066509380968431}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1737880.1811193135, "pol1": 1737880.1811193135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1709557.3505723467, -1718772.9039059253, -1868343.92745138, -1624387.786463037, -1676316.870545005, -1789660.3567750487, -1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612], "policy_pol1_reward": [1709557.3505723467, 1718772.9039059253, 1868343.92745138, 1624387.786463037, 1676316.870545005, 1789660.3567750487, 1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2759071425492468, "mean_inference_ms": 3.818320598963773, "mean_action_processing_ms": 0.19079677503133463, "mean_env_wait_ms": 0.1445226320506683, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1339338, "agent_timesteps_total": 2678676, "timers": {"sample_time_ms": 4514.193, "sample_throughput": 1330.47, "learn_time_ms": 20667.223, "learn_throughput": 290.605, "update_time_ms": 4.967}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.872614701729615e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 27578620993.361702, "policy_loss": -0.0013966308114059427, "vf_loss": 27578620993.361702, "vf_explained_var": 1.0272290040802545e-07, "kl": 0.008152963167571642, "entropy": 2.7267665355763535, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 28308691597.61702, "policy_loss": -0.002050409648329654, "vf_loss": 28308691597.61702, "vf_explained_var": 1.775457469932462e-08, "kl": 0.007202968179704027, "entropy": 0.5517576425633532, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1339338, "num_agent_steps_sampled": 2678676, "num_steps_trained": 1339338, "num_agent_steps_trained": 2678676}, "done": false, "episodes_total": 1338, "training_iteration": 223, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-50-35", "timestamp": 1624967435, "time_this_iter_s": 25.363733053207397, "time_total_s": 5636.510932683945, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7aedcc3730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5636.510932683945, "timesteps_since_restore": 0, "iterations_since_restore": 223, "perf": {"cpu_util_percent": 31.173529411764708, "ram_util_percent": 67.17647058823529, "gpu_util_percent0": 0.3770588235294118, "vram_util_percent0": 0.3067219810067607}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1737565.425644685, "pol1": 1737565.425644685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1714152.2183243423, -1723265.9427201336, -1792455.2582681442, -1869447.5924665667, -1667175.6240533947, -1822633.045857018, -1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747], "policy_pol1_reward": [1714152.2183243423, 1723265.9427201336, 1792455.2582681442, 1869447.5924665667, 1667175.6240533947, 1822633.045857018, 1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27590270723952065, "mean_inference_ms": 3.818247651223021, "mean_action_processing_ms": 0.19079021318804432, "mean_env_wait_ms": 0.14451686863928562, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1345344, "agent_timesteps_total": 2690688, "timers": {"sample_time_ms": 4527.978, "sample_throughput": 1326.42, "learn_time_ms": 20654.06, "learn_throughput": 290.79, "update_time_ms": 4.974}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.872614701729615e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 24548232736.68085, "policy_loss": -0.0005071144848269351, "vf_loss": 24548232736.68085, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.004426309447537394, "entropy": 2.7443533095907657, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25192957821.276596, "policy_loss": -0.008668757103225018, "vf_loss": 25192957821.276596, "vf_explained_var": 2.5363679156953367e-08, "kl": 0.010626156210027476, "entropy": 0.5432691003413911, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1345344, "num_agent_steps_sampled": 2690688, "num_steps_trained": 1345344, "num_agent_steps_trained": 2690688}, "done": false, "episodes_total": 1344, "training_iteration": 224, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-51-00", "timestamp": 1624967460, "time_this_iter_s": 25.1319522857666, "time_total_s": 5661.642884969711, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e350d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5661.642884969711, "timesteps_since_restore": 0, "iterations_since_restore": 224, "perf": {"cpu_util_percent": 30.815151515151513, "ram_util_percent": 67.36060606060606, "gpu_util_percent0": 0.37393939393939396, "vram_util_percent0": 0.3067683917026688}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1732057.2494238422, "pol1": 1732057.2494238422}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1787468.7545443007, -1830840.293252562, -1725975.7706937296, -1671071.4557375282, -1828014.1602072155, -1654030.792358381, -1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087], "policy_pol1_reward": [1787468.7545443007, 1830840.293252562, 1725975.7706937296, 1671071.4557375282, 1828014.1602072155, 1654030.792358381, 1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2758905244394846, "mean_inference_ms": 3.818174905645642, "mean_action_processing_ms": 0.1907835225141048, "mean_env_wait_ms": 0.1445110065369159, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1351350, "agent_timesteps_total": 2702700, "timers": {"sample_time_ms": 4503.406, "sample_throughput": 1333.657, "learn_time_ms": 20626.889, "learn_throughput": 291.173, "update_time_ms": 4.985}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 22886357732.765957, "policy_loss": -0.004185970238548644, "vf_loss": 22886357732.765957, "vf_explained_var": 1.0272290040802545e-07, "kl": 0.01258162999565297, "entropy": 2.675222746869351, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 23474081443.404255, "policy_loss": -0.005397359642418141, "vf_loss": 23474081443.404255, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.009032288774293153, "entropy": 0.5043954494151663, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1351350, "num_agent_steps_sampled": 2702700, "num_steps_trained": 1351350, "num_agent_steps_trained": 2702700}, "done": false, "episodes_total": 1350, "training_iteration": 225, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-51-25", "timestamp": 1624967485, "time_this_iter_s": 24.894179821014404, "time_total_s": 5686.537064790726, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5686.537064790726, "timesteps_since_restore": 0, "iterations_since_restore": 225, "perf": {"cpu_util_percent": 29.415151515151518, "ram_util_percent": 67.5909090909091, "gpu_util_percent0": 0.38121212121212117, "vram_util_percent0": 0.3066611514538714}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1727069.5119401389, "pol1": 1727069.5119401389}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1879529.0586029817, -1451110.3206029697, -1539800.00698283, -1820835.0729145939, -1668929.829491339, -1822190.2296215827, -1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846], "policy_pol1_reward": [1879529.0586029817, 1451110.3206029697, 1539800.00698283, 1820835.0729145939, 1668929.829491339, 1822190.2296215827, 1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.275874854213696, "mean_inference_ms": 3.8180909835038306, "mean_action_processing_ms": 0.19077765549479442, "mean_env_wait_ms": 0.14450540213052712, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1357356, "agent_timesteps_total": 2714712, "timers": {"sample_time_ms": 4498.548, "sample_throughput": 1335.097, "learn_time_ms": 20629.205, "learn_throughput": 291.141, "update_time_ms": 5.042}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 22701251344.340427, "policy_loss": -0.002887332336382663, "vf_loss": 22701251344.340427, "vf_explained_var": 1.1033200308929736e-07, "kl": 0.00901621881317585, "entropy": 2.6635253581594913, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 23303034923.574467, "policy_loss": -0.004373622998753761, "vf_loss": 23303034923.574467, "vf_explained_var": -4.8190990753482765e-08, "kl": 0.008266508490084968, "entropy": 0.33331953528079583, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1357356, "num_agent_steps_sampled": 2714712, "num_steps_trained": 1357356, "num_agent_steps_trained": 2714712}, "done": false, "episodes_total": 1356, "training_iteration": 226, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-51-50", "timestamp": 1624967510, "time_this_iter_s": 24.996464490890503, "time_total_s": 5711.533529281616, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5711.533529281616, "timesteps_since_restore": 0, "iterations_since_restore": 226, "perf": {"cpu_util_percent": 29.675757575757576, "ram_util_percent": 67.48484848484848, "gpu_util_percent0": 0.38575757575757574, "vram_util_percent0": 0.3067888184167254}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1728884.4863281846, "pol1": 1728884.4863281846}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1633608.0857810252, -1502830.474108161, -1483775.858609183, -1780271.800409267, -1753484.203404349, -1733448.7889856873, -1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688], "policy_pol1_reward": [1633608.0857810252, 1502830.474108161, 1483775.858609183, 1780271.800409267, 1753484.203404349, 1733448.7889856873, 1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2758581911552313, "mean_inference_ms": 3.8179753122257507, "mean_action_processing_ms": 0.19077106872640862, "mean_env_wait_ms": 0.14449927924589576, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1363362, "agent_timesteps_total": 2726724, "timers": {"sample_time_ms": 4492.16, "sample_throughput": 1336.996, "learn_time_ms": 20675.81, "learn_throughput": 290.484, "update_time_ms": 4.995}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 24455155450.553192, "policy_loss": -0.00028210237344845814, "vf_loss": 24455155450.553192, "vf_explained_var": -8.877287172026627e-08, "kl": 0.005250148504893196, "entropy": 2.6628979216230677, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25104321949.957447, "policy_loss": -0.005535534166909279, "vf_loss": 25104321949.957447, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.008096944005723963, "entropy": 0.2813480350565403, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1363362, "num_agent_steps_sampled": 2726724, "num_steps_trained": 1363362, "num_agent_steps_trained": 2726724}, "done": false, "episodes_total": 1362, "training_iteration": 227, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-52-16", "timestamp": 1624967536, "time_this_iter_s": 25.708902597427368, "time_total_s": 5737.242431879044, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c70d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5737.242431879044, "timesteps_since_restore": 0, "iterations_since_restore": 227, "perf": {"cpu_util_percent": 32.64848484848484, "ram_util_percent": 67.36666666666666, "gpu_util_percent0": 0.38272727272727275, "vram_util_percent0": 0.3066305113827864}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1736688.2496468923, "pol1": 1736688.2496468923}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1672405.352366281, -1858523.0920538544, -1717427.0083153471, -1482857.974322149, -1699728.9543931675, -1820419.7029617599, -1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709], "policy_pol1_reward": [1672405.352366281, 1858523.0920538544, 1717427.0083153471, 1482857.974322149, 1699728.9543931675, 1820419.7029617599, 1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2758435436641633, "mean_inference_ms": 3.8178790635125863, "mean_action_processing_ms": 0.19076539970845524, "mean_env_wait_ms": 0.14449346889760403, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1369368, "agent_timesteps_total": 2738736, "timers": {"sample_time_ms": 4510.482, "sample_throughput": 1331.565, "learn_time_ms": 20680.201, "learn_throughput": 290.423, "update_time_ms": 4.984}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 25877633503.31915, "policy_loss": -0.00168213038209905, "vf_loss": 25877633503.31915, "vf_explained_var": 1.0779563552887339e-07, "kl": 0.009596668005465193, "entropy": 2.6688014750785016, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26565486025.531914, "policy_loss": -0.008877403776537864, "vf_loss": 26565486025.531914, "vf_explained_var": -1.065274517486614e-07, "kl": 0.011210490909821175, "entropy": 0.19482126166211797, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1369368, "num_agent_steps_sampled": 2738736, "num_steps_trained": 1369368, "num_agent_steps_trained": 2738736}, "done": false, "episodes_total": 1368, "training_iteration": 228, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-52-42", "timestamp": 1624967562, "time_this_iter_s": 25.347419261932373, "time_total_s": 5762.589851140976, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5762.589851140976, "timesteps_since_restore": 0, "iterations_since_restore": 228, "perf": {"cpu_util_percent": 31.164705882352944, "ram_util_percent": 67.22058823529413, "gpu_util_percent0": 0.38205882352941173, "vram_util_percent0": 0.3066971985963243}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1737062.1090107844, "pol1": 1737062.1090107844}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1735086.398183499, -1813820.9082804066, -1845704.927609895, -1604634.542274086, -1852584.7130085407, -1903188.7532275096, -1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744], "policy_pol1_reward": [1735086.398183499, 1813820.9082804066, 1845704.927609895, 1604634.542274086, 1852584.7130085407, 1903188.7532275096, 1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27582591834220854, "mean_inference_ms": 3.8177657757141246, "mean_action_processing_ms": 0.19075965969183695, "mean_env_wait_ms": 0.144487713335815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1375374, "agent_timesteps_total": 2750748, "timers": {"sample_time_ms": 4516.502, "sample_throughput": 1329.79, "learn_time_ms": 20684.396, "learn_throughput": 290.364, "update_time_ms": 4.977}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 24183129676.255318, "policy_loss": -0.001983803796007278, "vf_loss": 24183129676.255318, "vf_explained_var": -1.3315931823854044e-07, "kl": 0.007862868352218512, "entropy": 2.700598691372161, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 24841215869.276596, "policy_loss": -0.006061822889333076, "vf_loss": 24841215869.276596, "vf_explained_var": -1.471093327154449e-07, "kl": 0.01240227152494357, "entropy": 0.0991054911245691, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1375374, "num_agent_steps_sampled": 2750748, "num_steps_trained": 1375374, "num_agent_steps_trained": 2750748}, "done": false, "episodes_total": 1374, "training_iteration": 229, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-53-07", "timestamp": 1624967587, "time_this_iter_s": 25.323307037353516, "time_total_s": 5787.9131581783295, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd6a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5787.9131581783295, "timesteps_since_restore": 0, "iterations_since_restore": 229, "perf": {"cpu_util_percent": 30.954545454545453, "ram_util_percent": 67.24848484848485, "gpu_util_percent0": 0.3827272727272727, "vram_util_percent0": 0.30659987131170147}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1734701.6319679609, "pol1": 1734701.6319679609}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1519914.0008714816, -1744903.1155200738, -1752323.1218690407, -1788561.30939054, -1680147.9001675725, -1585440.7676067129, -1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176], "policy_pol1_reward": [1519914.0008714816, 1744903.1155200738, 1752323.1218690407, 1788561.30939054, 1680147.9001675725, 1585440.7676067129, 1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2758090785368745, "mean_inference_ms": 3.8176239339571434, "mean_action_processing_ms": 0.19075380656691915, "mean_env_wait_ms": 0.14448239067528595, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1381380, "agent_timesteps_total": 2762760, "timers": {"sample_time_ms": 4514.505, "sample_throughput": 1330.378, "learn_time_ms": 20669.706, "learn_throughput": 290.57, "update_time_ms": 4.915}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 25205553064.851063, "policy_loss": -0.00330795537918172, "vf_loss": 25205553064.851063, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.013909317771012479, "entropy": 2.625767357805942, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25880865813.787235, "policy_loss": -0.007086990757825527, "vf_loss": 25880865813.787235, "vf_explained_var": -1.204774804364206e-07, "kl": 0.01153966268286743, "entropy": 0.06720337390582612, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1381380, "num_agent_steps_sampled": 2762760, "num_steps_trained": 1381380, "num_agent_steps_trained": 2762760}, "done": false, "episodes_total": 1380, "training_iteration": 230, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-53-32", "timestamp": 1624967612, "time_this_iter_s": 25.078003883361816, "time_total_s": 5812.991162061691, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05eb268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05eb1e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5812.991162061691, "timesteps_since_restore": 0, "iterations_since_restore": 230, "perf": {"cpu_util_percent": 29.757575757575758, "ram_util_percent": 67.56666666666665, "gpu_util_percent0": 0.3884848484848485, "vram_util_percent0": 0.30668668484644224}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1738741.809562074, "pol1": 1738741.809562074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1805897.4247672516, -1845951.561070112, -1661088.091525822, -1878789.6771124469, -1721617.569480119, -1862542.6959449775, -1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308], "policy_pol1_reward": [1805897.4247672516, 1845951.561070112, 1661088.091525822, 1878789.6771124469, 1721617.569480119, 1862542.6959449775, 1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2757919427553053, "mean_inference_ms": 3.8174516896241464, "mean_action_processing_ms": 0.19074642373483763, "mean_env_wait_ms": 0.14447614660227212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1387386, "agent_timesteps_total": 2774772, "timers": {"sample_time_ms": 4516.131, "sample_throughput": 1329.899, "learn_time_ms": 20671.562, "learn_throughput": 290.544, "update_time_ms": 4.889}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 24953647496.17021, "policy_loss": -0.003236424019362064, "vf_loss": 24953647496.17021, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.01676958074119497, "entropy": 2.6384409843607153, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 25625313192.851063, "policy_loss": -0.003689009636799072, "vf_loss": 25625313192.851063, "vf_explained_var": -1.471093327154449e-07, "kl": 0.009533111927436387, "entropy": 0.02585062354882347, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1387386, "num_agent_steps_sampled": 2774772, "num_steps_trained": 1387386, "num_agent_steps_trained": 2774772}, "done": false, "episodes_total": 1386, "training_iteration": 231, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-53-57", "timestamp": 1624967637, "time_this_iter_s": 25.014793157577515, "time_total_s": 5838.005955219269, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05eb950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05eb840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5838.005955219269, "timesteps_since_restore": 0, "iterations_since_restore": 231, "perf": {"cpu_util_percent": 29.8, "ram_util_percent": 67.53333333333335, "gpu_util_percent0": 0.376969696969697, "vram_util_percent0": 0.3067530716671263}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1736984.248203299, "pol1": 1736984.248203299}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1806083.8434089357, -1776100.9081812182, -1591047.128254006, -1734728.7555600111, -1786271.1060053823, -1723642.693449509, -1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864], "policy_pol1_reward": [1806083.8434089357, 1776100.9081812182, 1591047.128254006, 1734728.7555600111, 1786271.1060053823, 1723642.693449509, 1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27577515116613954, "mean_inference_ms": 3.817276437842391, "mean_action_processing_ms": 0.1907390237620306, "mean_env_wait_ms": 0.14447016806453397, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1393392, "agent_timesteps_total": 2786784, "timers": {"sample_time_ms": 4515.637, "sample_throughput": 1330.045, "learn_time_ms": 20681.343, "learn_throughput": 290.407, "update_time_ms": 7.057}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9363073508648074e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 25603846361.87234, "policy_loss": -0.0012829637432352026, "vf_loss": 25603846361.87234, "vf_explained_var": -3.0436414277801305e-08, "kl": 0.0028932474880538723, "entropy": 2.7376959526792484, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 26296872088.51064, "policy_loss": -0.005337757197149256, "vf_loss": 26296872088.51064, "vf_explained_var": -9.89183490673895e-08, "kl": 0.007666519268396053, "entropy": 0.0015696963552940398, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1393392, "num_agent_steps_sampled": 2786784, "num_steps_trained": 1393392, "num_agent_steps_trained": 2786784}, "done": false, "episodes_total": 1392, "training_iteration": 232, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-54-22", "timestamp": 1624967662, "time_this_iter_s": 25.268660306930542, "time_total_s": 5863.274615526199, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5863.274615526199, "timesteps_since_restore": 0, "iterations_since_restore": 232, "perf": {"cpu_util_percent": 30.482352941176472, "ram_util_percent": 67.21176470588235, "gpu_util_percent0": 0.3797058823529411, "vram_util_percent0": 0.3066178948829279}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1745937.0664193674, "pol1": 1745937.0664193674}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1477704.7031535902, -1749874.6003205895, -1604688.7573206748, -1730537.5246343943, -1934421.6112575277, -1763414.892661085, -1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653], "policy_pol1_reward": [1477704.7031535902, 1749874.6003205895, 1604688.7573206748, 1730537.5246343943, 1934421.6112575277, 1763414.892661085, 1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2757594516882041, "mean_inference_ms": 3.8170877369208545, "mean_action_processing_ms": 0.19073121800854007, "mean_env_wait_ms": 0.14446429553289042, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1399398, "agent_timesteps_total": 2798796, "timers": {"sample_time_ms": 4491.064, "sample_throughput": 1337.322, "learn_time_ms": 20661.738, "learn_throughput": 290.682, "update_time_ms": 7.08}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 29497846936.51064, "policy_loss": -0.0011010490199352832, "vf_loss": 29497846936.51064, "vf_explained_var": 1.2681839578476684e-08, "kl": 0.008381514027318421, "entropy": 2.7487586051859756, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 30286020651.574467, "policy_loss": -0.0002726762297939747, "vf_loss": 30286020651.574467, "vf_explained_var": 1.0145471129874295e-08, "kl": 0.02415662223195776, "entropy": 0.007931920878113584, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1399398, "num_agent_steps_sampled": 2798796, "num_steps_trained": 1399398, "num_agent_steps_trained": 2798796}, "done": false, "episodes_total": 1398, "training_iteration": 233, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-54-47", "timestamp": 1624967687, "time_this_iter_s": 24.921854257583618, "time_total_s": 5888.196469783783, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5888.196469783783, "timesteps_since_restore": 0, "iterations_since_restore": 233, "perf": {"cpu_util_percent": 29.306250000000002, "ram_util_percent": 67.53125, "gpu_util_percent0": 0.38093749999999993, "vram_util_percent0": 0.30672291034715204}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1937576.9365486386, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1937576.9365486386}, "policy_reward_mean": {"pol0": -1749085.822257587, "pol1": 1749085.822257587}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1889926.2992647574, -1937576.9365486386, -1739521.6878653257, -1873476.2560361612, -1819689.3640907186, -1811513.6343658997, -1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603], "policy_pol1_reward": [1889926.2992647574, 1937576.9365486386, 1739521.6878653257, 1873476.2560361612, 1819689.3640907186, 1811513.6343658997, 1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2757455110312612, "mean_inference_ms": 3.8168911831200756, "mean_action_processing_ms": 0.1907225184177145, "mean_env_wait_ms": 0.14445767273847335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1405404, "agent_timesteps_total": 2810808, "timers": {"sample_time_ms": 4485.318, "sample_throughput": 1339.035, "learn_time_ms": 20657.121, "learn_throughput": 290.747, "update_time_ms": 7.032}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 25473704981.787235, "policy_loss": -0.002380131050310236, "vf_loss": 25473704981.787235, "vf_explained_var": 0.0, "kl": 0.00970706924241274, "entropy": 2.7373165019015047, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26172104093.957447, "policy_loss": -0.006632316619791883, "vf_loss": 26172104093.957447, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.007620459590899817, "entropy": 0.0447107630762014, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1405404, "num_agent_steps_sampled": 2810808, "num_steps_trained": 1405404, "num_agent_steps_trained": 2810808}, "done": false, "episodes_total": 1404, "training_iteration": 234, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-55-12", "timestamp": 1624967712, "time_this_iter_s": 25.027650117874146, "time_total_s": 5913.224119901657, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5913.224119901657, "timesteps_since_restore": 0, "iterations_since_restore": 234, "perf": {"cpu_util_percent": 30.436363636363637, "ram_util_percent": 67.4818181818182, "gpu_util_percent0": 0.38060606060606056, "vram_util_percent0": 0.30664072473981474}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1748301.66994873, "pol1": 1748301.66994873}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1657075.9849315784, -1785421.7411889012, -1582926.5774301414, -1485545.1327985644, -1803393.0918566592, -1675121.1864387328, -1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821], "policy_pol1_reward": [1657075.9849315784, 1785421.7411889012, 1582926.5774301414, 1485545.1327985644, 1803393.0918566592, 1675121.1864387328, 1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27573205641522214, "mean_inference_ms": 3.816735320423262, "mean_action_processing_ms": 0.1907152758811164, "mean_env_wait_ms": 0.14445252076943518, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1411410, "agent_timesteps_total": 2822820, "timers": {"sample_time_ms": 4503.689, "sample_throughput": 1333.573, "learn_time_ms": 20687.903, "learn_throughput": 290.315, "update_time_ms": 6.98}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 27828559872.0, "policy_loss": -0.0014595499242398334, "vf_loss": 27828559872.0, "vf_explained_var": 2.4095495376741383e-08, "kl": 0.006592625098184068, "entropy": 2.722790839824271, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 28578111618.723404, "policy_loss": -0.001263963890836594, "vf_loss": 28578111618.723404, "vf_explained_var": 2.2827311596529398e-08, "kl": 0.0182172367349267, "entropy": 0.1551228165626526, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1411410, "num_agent_steps_sampled": 2822820, "num_steps_trained": 1411410, "num_agent_steps_trained": 2822820}, "done": false, "episodes_total": 1410, "training_iteration": 235, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-55-38", "timestamp": 1624967738, "time_this_iter_s": 25.38549566268921, "time_total_s": 5938.609615564346, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5938.609615564346, "timesteps_since_restore": 0, "iterations_since_restore": 235, "perf": {"cpu_util_percent": 31.08235294117647, "ram_util_percent": 67.23823529411766, "gpu_util_percent0": 0.37529411764705883, "vram_util_percent0": 0.3067665893455462}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1752565.2628566285, "pol1": 1752565.2628566285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1744983.4964231981, -1580639.459921677, -1720729.238122681, -1902619.710518989, -1741191.7175178616, -1830611.9694692742, -1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722], "policy_pol1_reward": [1744983.4964231981, 1580639.459921677, 1720729.238122681, 1902619.710518989, 1741191.7175178616, 1830611.9694692742, 1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27571694848869316, "mean_inference_ms": 3.8165488800692287, "mean_action_processing_ms": 0.19070689380791309, "mean_env_wait_ms": 0.14444679491805792, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1417416, "agent_timesteps_total": 2834832, "timers": {"sample_time_ms": 4499.213, "sample_throughput": 1334.9, "learn_time_ms": 20708.968, "learn_throughput": 290.019, "update_time_ms": 6.933}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 24709547509.106384, "policy_loss": 4.463460534176928e-05, "vf_loss": 24709547509.106384, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.006752619004630028, "entropy": 2.7417837203817164, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25391656088.51064, "policy_loss": -0.006188342149587388, "vf_loss": 25391656088.51064, "vf_explained_var": 2.663186293716535e-08, "kl": 0.010538992065777804, "entropy": 0.2199075202992622, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1417416, "num_agent_steps_sampled": 2834832, "num_steps_trained": 1417416, "num_agent_steps_trained": 2834832}, "done": false, "episodes_total": 1416, "training_iteration": 236, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-56-03", "timestamp": 1624967763, "time_this_iter_s": 25.161954879760742, "time_total_s": 5963.771570444107, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06278c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5963.771570444107, "timesteps_since_restore": 0, "iterations_since_restore": 236, "perf": {"cpu_util_percent": 30.299999999999997, "ram_util_percent": 67.32424242424241, "gpu_util_percent0": 0.3803030303030303, "vram_util_percent0": 0.3066509380968431}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1448347.5743079262}, "policy_reward_max": {"pol0": -1448347.5743079262, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1757467.228082201, "pol1": 1757467.228082201}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1801515.3593234788, -1858907.3076486182, -1796308.3018107568, -1623305.406316743, -1637252.8600782377, -1703162.3179369755, -1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716], "policy_pol1_reward": [1801515.3593234788, 1858907.3076486182, 1796308.3018107568, 1623305.406316743, 1637252.8600782377, 1703162.3179369755, 1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27570234688289547, "mean_inference_ms": 3.8163708539846435, "mean_action_processing_ms": 0.19069818733585414, "mean_env_wait_ms": 0.14444166478707915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1423422, "agent_timesteps_total": 2846844, "timers": {"sample_time_ms": 4499.654, "sample_throughput": 1334.769, "learn_time_ms": 20648.168, "learn_throughput": 290.873, "update_time_ms": 6.986}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 27707768701.276596, "policy_loss": -0.0010214194734679892, "vf_loss": 27707768701.276596, "vf_explained_var": 1.1033200308929736e-07, "kl": 0.005242011638635651, "entropy": 2.7621114558361946, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 28459127916.93617, "policy_loss": -0.002103442504526453, "vf_loss": 28459127916.93617, "vf_explained_var": 3.170459805801329e-08, "kl": 0.012227336578863733, "entropy": 0.22485249695625711, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1423422, "num_agent_steps_sampled": 2846844, "num_steps_trained": 1423422, "num_agent_steps_trained": 2846844}, "done": false, "episodes_total": 1422, "training_iteration": 237, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-56-28", "timestamp": 1624967788, "time_this_iter_s": 25.106735467910767, "time_total_s": 5988.878305912018, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06279d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5988.878305912018, "timesteps_since_restore": 0, "iterations_since_restore": 237, "perf": {"cpu_util_percent": 30.554545454545455, "ram_util_percent": 67.23333333333333, "gpu_util_percent0": 0.3842424242424242, "vram_util_percent0": 0.3066049779902157}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1433819.8853682447}, "policy_reward_max": {"pol0": -1433819.8853682447, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1755943.636050404, "pol1": 1755943.636050404}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1705476.315640098, -1448347.5743079262, -1918533.800343787, -1671598.3578510215, -1868209.8719870085, -1907917.7748678569, -1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794], "policy_pol1_reward": [1705476.315640098, 1448347.5743079262, 1918533.800343787, 1671598.3578510215, 1868209.8719870085, 1907917.7748678569, 1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2756829225076371, "mean_inference_ms": 3.816173475097327, "mean_action_processing_ms": 0.19068900040918632, "mean_env_wait_ms": 0.14443588626032589, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1429428, "agent_timesteps_total": 2858856, "timers": {"sample_time_ms": 4477.455, "sample_throughput": 1341.387, "learn_time_ms": 20633.383, "learn_throughput": 291.082, "update_time_ms": 6.997}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 24241146291.744682, "policy_loss": -0.0015941159007080057, "vf_loss": 24241146291.744682, "vf_explained_var": 4.692280697327078e-08, "kl": 0.005411453604539658, "entropy": 2.7583466844355806, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24928272776.17021, "policy_loss": -0.006093434751667875, "vf_loss": 24928272776.17021, "vf_explained_var": -1.242820246716292e-07, "kl": 0.006033813660132124, "entropy": 0.19915234440184654, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1429428, "num_agent_steps_sampled": 2858856, "num_steps_trained": 1429428, "num_agent_steps_trained": 2858856}, "done": false, "episodes_total": 1428, "training_iteration": 238, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-56-53", "timestamp": 1624967813, "time_this_iter_s": 24.97636079788208, "time_total_s": 6013.8546667099, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e359d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6013.8546667099, "timesteps_since_restore": 0, "iterations_since_restore": 238, "perf": {"cpu_util_percent": 30.009090909090908, "ram_util_percent": 67.44848484848485, "gpu_util_percent0": 0.3824242424242424, "vram_util_percent0": 0.3067377516315838}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1433819.8853682447}, "policy_reward_max": {"pol0": -1433819.8853682447, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1750561.6867463933, "pol1": 1750561.6867463933}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1803999.9115808827, -1840615.3683967965, -1762911.5412372623, -1782532.6375745612, -1689670.2236951888, -1712879.6165069048, -1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783], "policy_pol1_reward": [1803999.9115808827, 1840615.3683967965, 1762911.5412372623, 1782532.6375745612, 1689670.2236951888, 1712879.6165069048, 1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27565842446043615, "mean_inference_ms": 3.8159704269265458, "mean_action_processing_ms": 0.19067957950956368, "mean_env_wait_ms": 0.14442970273291766, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1435434, "agent_timesteps_total": 2870868, "timers": {"sample_time_ms": 4472.662, "sample_throughput": 1342.825, "learn_time_ms": 20637.774, "learn_throughput": 291.02, "update_time_ms": 7.073}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 22720536576.0, "policy_loss": -0.0050063818851684, "vf_loss": 22720536576.0, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.0152010390376474, "entropy": 2.638553670112123, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 23353708282.553192, "policy_loss": -0.005736276428116129, "vf_loss": 23353708282.553192, "vf_explained_var": 4.311825207992115e-08, "kl": 0.006637116151049416, "entropy": 0.23977958109784633, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1435434, "num_agent_steps_sampled": 2870868, "num_steps_trained": 1435434, "num_agent_steps_trained": 2870868}, "done": false, "episodes_total": 1434, "training_iteration": 239, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-57-19", "timestamp": 1624967839, "time_this_iter_s": 25.319026470184326, "time_total_s": 6039.173693180084, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c77b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6039.173693180084, "timesteps_since_restore": 0, "iterations_since_restore": 239, "perf": {"cpu_util_percent": 30.812121212121212, "ram_util_percent": 67.37575757575758, "gpu_util_percent0": 0.386060606060606, "vram_util_percent0": 0.30667136481089974}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1740955.3098384363, "pol1": 1740955.3098384363}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1765902.9201385267, -1771610.6931069351, -1569041.3425316499, -1846458.8522706747, -1628399.7136599068, -1532784.3151837431, -1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177], "policy_pol1_reward": [1765902.9201385267, 1771610.6931069351, 1569041.3425316499, 1846458.8522706747, 1628399.7136599068, 1532784.3151837431, 1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2756377409136135, "mean_inference_ms": 3.81576507886221, "mean_action_processing_ms": 0.19066978493808623, "mean_env_wait_ms": 0.14442316782114037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1441440, "agent_timesteps_total": 2882880, "timers": {"sample_time_ms": 4481.953, "sample_throughput": 1340.041, "learn_time_ms": 20631.425, "learn_throughput": 291.109, "update_time_ms": 7.239}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4681536754324037e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 21362610611.744682, "policy_loss": -0.00038810189258545, "vf_loss": 21362610611.744682, "vf_explained_var": 1.204774804364206e-07, "kl": 0.0036839647268123448, "entropy": 2.6867723414238465, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 21976328235.574467, "policy_loss": -0.006118119991523154, "vf_loss": 21976328235.574467, "vf_explained_var": 1.3696386247374903e-07, "kl": 0.007101278385504129, "entropy": 0.19353810808760055, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1441440, "num_agent_steps_sampled": 2882880, "num_steps_trained": 1441440, "num_agent_steps_trained": 2882880}, "done": false, "episodes_total": 1440, "training_iteration": 240, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-57-44", "timestamp": 1624967864, "time_this_iter_s": 25.11081624031067, "time_total_s": 6064.284509420395, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c71e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6064.284509420395, "timesteps_since_restore": 0, "iterations_since_restore": 240, "perf": {"cpu_util_percent": 29.788235294117644, "ram_util_percent": 67.37352941176471, "gpu_util_percent0": 0.38029411764705884, "vram_util_percent0": 0.3067715458276334}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1742644.646461372, "pol1": 1742644.646461372}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1556369.2823705196, -1753586.9658946488, -1865788.235612704, -1701383.5468838087, -1551542.55293551, -1654700.8547754914, -1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607], "policy_pol1_reward": [1556369.2823705196, 1753586.9658946488, 1865788.235612704, 1701383.5468838087, 1551542.55293551, 1654700.8547754914, 1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27561905359028055, "mean_inference_ms": 3.8155692690528284, "mean_action_processing_ms": 0.19066009303447154, "mean_env_wait_ms": 0.1444168921728305, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1447446, "agent_timesteps_total": 2894892, "timers": {"sample_time_ms": 4500.787, "sample_throughput": 1334.433, "learn_time_ms": 20633.588, "learn_throughput": 291.079, "update_time_ms": 7.232}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.340768377162019e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 23979247136.68085, "policy_loss": -0.0027353574145347515, "vf_loss": 23979247136.68085, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.00802346980793679, "entropy": 2.642624175294917, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24638169262.29787, "policy_loss": -0.003034825099909559, "vf_loss": 24638169262.29787, "vf_explained_var": 8.370013659941833e-08, "kl": 0.00776400453747904, "entropy": 0.46894604411531005, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1447446, "num_agent_steps_sampled": 2894892, "num_steps_trained": 1447446, "num_agent_steps_trained": 2894892}, "done": false, "episodes_total": 1446, "training_iteration": 241, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-58-09", "timestamp": 1624967889, "time_this_iter_s": 25.22489333152771, "time_total_s": 6089.509402751923, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd7b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6089.509402751923, "timesteps_since_restore": 0, "iterations_since_restore": 241, "perf": {"cpu_util_percent": 30.76060606060606, "ram_util_percent": 67.3030303030303, "gpu_util_percent0": 0.37454545454545457, "vram_util_percent0": 0.3065998713117014}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1747438.7573443474, "pol1": 1747438.7573443474}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1651168.1003131128, -1888345.3730256488, -1636660.7409887703, -1616209.856384846, -1847969.4008287108, -1798578.810405705, -1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726], "policy_pol1_reward": [1651168.1003131128, 1888345.3730256488, 1636660.7409887703, 1616209.856384846, 1847969.4008287108, 1798578.810405705, 1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27560544481955634, "mean_inference_ms": 3.815375014755878, "mean_action_processing_ms": 0.1906504678077764, "mean_env_wait_ms": 0.14441071554513785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1453452, "agent_timesteps_total": 2906904, "timers": {"sample_time_ms": 4484.736, "sample_throughput": 1339.209, "learn_time_ms": 20624.684, "learn_throughput": 291.204, "update_time_ms": 4.983}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.340768377162019e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 25364394724.765957, "policy_loss": -0.0019607977109386567, "vf_loss": 25364394724.765957, "vf_explained_var": -3.804551784725163e-09, "kl": 0.010055062380876946, "entropy": 2.741607057287338, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26074938128.340427, "policy_loss": -0.00677949883677858, "vf_loss": 26074938128.340427, "vf_explained_var": 1.1920928955078125e-07, "kl": 0.0066233264639022505, "entropy": 0.6944174487540062, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1453452, "num_agent_steps_sampled": 2906904, "num_steps_trained": 1453452, "num_agent_steps_trained": 2906904}, "done": false, "episodes_total": 1452, "training_iteration": 242, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-58-34", "timestamp": 1624967914, "time_this_iter_s": 24.994612455368042, "time_total_s": 6114.504015207291, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6114.504015207291, "timesteps_since_restore": 0, "iterations_since_restore": 242, "perf": {"cpu_util_percent": 29.733333333333334, "ram_util_percent": 67.38484848484848, "gpu_util_percent0": 0.37909090909090903, "vram_util_percent0": 0.30666625813238557}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1747070.1507231472, "pol1": 1747070.1507231472}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1699691.6843003284, -1667009.9073505085, -1615610.584522504, -1735031.5696130688, -1753909.9159034768, -1765049.6570099555, -1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158], "policy_pol1_reward": [1699691.6843003284, 1667009.9073505085, 1615610.584522504, 1735031.5696130688, 1753909.9159034768, 1765049.6570099555, 1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27559268832655365, "mean_inference_ms": 3.815210359671029, "mean_action_processing_ms": 0.1906416677224616, "mean_env_wait_ms": 0.1444055949935147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1459458, "agent_timesteps_total": 2918916, "timers": {"sample_time_ms": 4501.184, "sample_throughput": 1334.316, "learn_time_ms": 20643.258, "learn_throughput": 290.942, "update_time_ms": 4.994}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.340768377162019e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 24507328773.446808, "policy_loss": -0.0004924281916402756, "vf_loss": 24507328773.446808, "vf_explained_var": 7.609103569450326e-09, "kl": 0.004374422053707407, "entropy": 2.727221204879436, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25203782242.042553, "policy_loss": -0.007227267594413555, "vf_loss": 25203782242.042553, "vf_explained_var": 9.384561394654156e-08, "kl": 0.00783044022527781, "entropy": 0.7480499921961034, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1459458, "num_agent_steps_sampled": 2918916, "num_steps_trained": 1459458, "num_agent_steps_trained": 2918916}, "done": false, "episodes_total": 1458, "training_iteration": 243, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-58-59", "timestamp": 1624967939, "time_this_iter_s": 25.271953344345093, "time_total_s": 6139.775968551636, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac0d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6139.775968551636, "timesteps_since_restore": 0, "iterations_since_restore": 243, "perf": {"cpu_util_percent": 30.742424242424242, "ram_util_percent": 67.26666666666667, "gpu_util_percent0": 0.37545454545454543, "vram_util_percent0": 0.3026421954632268}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1750191.083590989, "pol1": 1750191.083590989}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1838352.030185681, -1771897.8897795074, -1778401.4211064607, -1760184.6291833709, -1841924.9953149275, -1695144.7443022209, -1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982], "policy_pol1_reward": [1838352.030185681, 1771897.8897795074, 1778401.4211064607, 1760184.6291833709, 1841924.9953149275, 1695144.7443022209, 1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2755768021968202, "mean_inference_ms": 3.815029789631494, "mean_action_processing_ms": 0.1906322092836792, "mean_env_wait_ms": 0.1444002220894935, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1465464, "agent_timesteps_total": 2930928, "timers": {"sample_time_ms": 4496.448, "sample_throughput": 1335.721, "learn_time_ms": 20639.623, "learn_throughput": 290.994, "update_time_ms": 5.066}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.6703841885810093e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 25403119659.574467, "policy_loss": -0.002186438370931973, "vf_loss": 25403119659.574467, "vf_explained_var": 8.87728734966231e-09, "kl": 0.009142380138423214, "entropy": 2.691661647025575, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26124296192.0, "policy_loss": -0.006056120282316462, "vf_loss": 26124296192.0, "vf_explained_var": 1.0399108418823744e-07, "kl": 0.005779410652974819, "entropy": 0.9643665869185265, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1465464, "num_agent_steps_sampled": 2930928, "num_steps_trained": 1465464, "num_agent_steps_trained": 2930928}, "done": false, "episodes_total": 1464, "training_iteration": 244, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-59-24", "timestamp": 1624967964, "time_this_iter_s": 24.94507360458374, "time_total_s": 6164.7210421562195, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06277b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6164.7210421562195, "timesteps_since_restore": 0, "iterations_since_restore": 244, "perf": {"cpu_util_percent": 29.624242424242425, "ram_util_percent": 67.56060606060605, "gpu_util_percent0": 0.37696969696969695, "vram_util_percent0": 0.299598615068787}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1747003.0202037066, "pol1": 1747003.0202037066}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1734759.055843724, -1649484.5570186365, -1860267.182780928, -1507167.4855413744, -1678177.250573585, -1720175.4047933505, -1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404], "policy_pol1_reward": [1734759.055843724, 1649484.5570186365, 1860267.182780928, 1507167.4855413744, 1678177.250573585, 1720175.4047933505, 1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27556122645178055, "mean_inference_ms": 3.8148101330704782, "mean_action_processing_ms": 0.19062107873396578, "mean_env_wait_ms": 0.1443936974773765, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1471470, "agent_timesteps_total": 2942940, "timers": {"sample_time_ms": 4472.875, "sample_throughput": 1342.76, "learn_time_ms": 20608.868, "learn_throughput": 291.428, "update_time_ms": 5.217}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.6703841885810093e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 24302852052.425533, "policy_loss": -0.0003741958396548921, "vf_loss": 24302852052.425533, "vf_explained_var": 3.170459805801329e-08, "kl": 0.005130001323971342, "entropy": 2.7794225773912795, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24993402880.0, "policy_loss": -0.006138821172111846, "vf_loss": 24993402880.0, "vf_explained_var": 8.62365041598423e-08, "kl": 0.006492677432029171, "entropy": 1.0269009990895048, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1471470, "num_agent_steps_sampled": 2942940, "num_steps_trained": 1471470, "num_agent_steps_trained": 2942940}, "done": false, "episodes_total": 1470, "training_iteration": 245, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_14-59-49", "timestamp": 1624967989, "time_this_iter_s": 24.844462156295776, "time_total_s": 6189.565504312515, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdc80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e357b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6189.565504312515, "timesteps_since_restore": 0, "iterations_since_restore": 245, "perf": {"cpu_util_percent": 29.88181818181818, "ram_util_percent": 67.4757575757576, "gpu_util_percent0": 0.3790909090909091, "vram_util_percent0": 0.2997160686746127}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1752478.6855756328, "pol1": 1752478.6855756328}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1790982.0124232052, -1877319.5104469105, -1656512.6747059799, -1795805.6853585176, -1665214.841554463, -1582867.4562646956, -1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017], "policy_pol1_reward": [1790982.0124232052, 1877319.5104469105, 1656512.6747059799, 1795805.6853585176, 1665214.841554463, 1582867.4562646956, 1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2755488334814133, "mean_inference_ms": 3.8145863448537023, "mean_action_processing_ms": 0.19060983817961563, "mean_env_wait_ms": 0.14438712563972772, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1477476, "agent_timesteps_total": 2954952, "timers": {"sample_time_ms": 4491.464, "sample_throughput": 1337.203, "learn_time_ms": 20602.187, "learn_throughput": 291.522, "update_time_ms": 5.215}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.6703841885810093e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 26231955499.574467, "policy_loss": -0.0018296357283883906, "vf_loss": 26231955499.574467, "vf_explained_var": -4.8190990753482765e-08, "kl": 0.008304385874578928, "entropy": 2.7322543631208704, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26987768243.744682, "policy_loss": -0.00554204055360776, "vf_loss": 26987768243.744682, "vf_explained_var": 1.0779563552887339e-07, "kl": 0.005662254265886038, "entropy": 1.1397896523171283, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1477476, "num_agent_steps_sampled": 2954952, "num_steps_trained": 1477476, "num_agent_steps_trained": 2954952}, "done": false, "episodes_total": 1476, "training_iteration": 246, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-00-14", "timestamp": 1624968014, "time_this_iter_s": 25.280770778656006, "time_total_s": 6214.846275091171, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6214.846275091171, "timesteps_since_restore": 0, "iterations_since_restore": 246, "perf": {"cpu_util_percent": 31.25151515151515, "ram_util_percent": 67.24848484848485, "gpu_util_percent0": 0.38151515151515153, "vram_util_percent0": 0.2996037217473011}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1752323.3029317346, "pol1": 1752323.3029317346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1896576.2008539194, -1637051.6704883708, -1828429.68698678, -1865168.1186885308, -1690507.8221005057, -1760868.0471000802, -1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663], "policy_pol1_reward": [1896576.2008539194, 1637051.6704883708, 1828429.68698678, 1865168.1186885308, 1690507.8221005057, 1760868.0471000802, 1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2755420247192644, "mean_inference_ms": 3.8143755751208523, "mean_action_processing_ms": 0.19059942339160887, "mean_env_wait_ms": 0.1443806365984314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1483482, "agent_timesteps_total": 2966964, "timers": {"sample_time_ms": 4488.116, "sample_throughput": 1338.201, "learn_time_ms": 20604.149, "learn_throughput": 291.495, "update_time_ms": 5.21}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.6703841885810093e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 24381109836.255318, "policy_loss": -0.0026870424601625888, "vf_loss": 24381109836.255318, "vf_explained_var": 1.204774804364206e-07, "kl": 0.009634605172942293, "entropy": 2.648144103111105, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25067845980.595745, "policy_loss": -0.0063230758334727995, "vf_loss": 25067845980.595745, "vf_explained_var": 1.3315931823854044e-07, "kl": 0.007452568703113084, "entropy": 1.2819426490905437, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1483482, "num_agent_steps_sampled": 2966964, "num_steps_trained": 1483482, "num_agent_steps_trained": 2966964}, "done": false, "episodes_total": 1482, "training_iteration": 247, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-00-40", "timestamp": 1624968040, "time_this_iter_s": 25.092448234558105, "time_total_s": 6239.938723325729, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6239.938723325729, "timesteps_since_restore": 0, "iterations_since_restore": 247, "perf": {"cpu_util_percent": 29.92727272727273, "ram_util_percent": 67.44848484848485, "gpu_util_percent0": 0.3784848484848485, "vram_util_percent0": 0.2997211753531268}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1752746.435933175, "pol1": 1752746.435933175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1742140.559161349, -1822646.8727952258, -1754779.1537012924, -1829188.4291647864, -1855225.775445519, -1883014.1466529004, -1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395], "policy_pol1_reward": [1742140.559161349, 1822646.8727952258, 1754779.1537012924, 1829188.4291647864, 1855225.775445519, 1883014.1466529004, 1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27553824711325886, "mean_inference_ms": 3.814212363309941, "mean_action_processing_ms": 0.19059143198792888, "mean_env_wait_ms": 0.1443753292673504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1489488, "agent_timesteps_total": 2978976, "timers": {"sample_time_ms": 4512.41, "sample_throughput": 1330.996, "learn_time_ms": 20602.56, "learn_throughput": 291.517, "update_time_ms": 5.367}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.6703841885810093e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 26001672932.765957, "policy_loss": -0.0008096976919060058, "vf_loss": 26001672932.765957, "vf_explained_var": -3.804551695907321e-08, "kl": 0.00842070072255236, "entropy": 2.6347483878440046, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26722050048.0, "policy_loss": -0.004390476370586994, "vf_loss": 26722050048.0, "vf_explained_var": 1.1667292199035728e-07, "kl": 0.009569866037828492, "entropy": 1.3928523342660133, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1489488, "num_agent_steps_sampled": 2978976, "num_steps_trained": 1489488, "num_agent_steps_trained": 2978976}, "done": false, "episodes_total": 1488, "training_iteration": 248, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-01-05", "timestamp": 1624968065, "time_this_iter_s": 25.204611778259277, "time_total_s": 6265.143335103989, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cde18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd1e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6265.143335103989, "timesteps_since_restore": 0, "iterations_since_restore": 248, "perf": {"cpu_util_percent": 30.8030303030303, "ram_util_percent": 67.21212121212122, "gpu_util_percent0": 0.3824242424242424, "vram_util_percent0": 0.30121743215777597}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1749034.8088413707, "pol1": 1749034.8088413707}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1883479.0890998775, -1890460.8995638643, -1919688.553685173, -1881287.7920185653, -1808086.9420197855, -1787060.167332737, -1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756], "policy_pol1_reward": [1883479.0890998775, 1890460.8995638643, 1919688.553685173, 1881287.7920185653, 1808086.9420197855, 1787060.167332737, 1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2755364469297841, "mean_inference_ms": 3.814028894478641, "mean_action_processing_ms": 0.19058244818321282, "mean_env_wait_ms": 0.1443696739456392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1495494, "agent_timesteps_total": 2990988, "timers": {"sample_time_ms": 4498.841, "sample_throughput": 1335.011, "learn_time_ms": 20575.145, "learn_throughput": 291.906, "update_time_ms": 5.259}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.6703841885810093e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 25405397514.893616, "policy_loss": 0.001048664205727425, "vf_loss": 25405397514.893616, "vf_explained_var": 9.511379772675355e-08, "kl": 0.0024390888717421826, "entropy": 2.7086412044281656, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26155856482.042553, "policy_loss": -0.0058166266993639314, "vf_loss": 26155856482.042553, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.005577861182787951, "entropy": 1.3242234879351678, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1495494, "num_agent_steps_sampled": 2990988, "num_steps_trained": 1495494, "num_agent_steps_trained": 2990988}, "done": false, "episodes_total": 1494, "training_iteration": 249, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-01-30", "timestamp": 1624968090, "time_this_iter_s": 24.90907645225525, "time_total_s": 6290.052411556244, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac9d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6290.052411556244, "timesteps_since_restore": 0, "iterations_since_restore": 249, "perf": {"cpu_util_percent": 29.857575757575756, "ram_util_percent": 67.32424242424241, "gpu_util_percent0": 0.37909090909090915, "vram_util_percent0": 0.3029792362451614}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1739687.9827883926, "pol1": 1739687.9827883926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1763170.0424928216, -1712155.4425467309, -1825398.3987591683, -1679646.680018603, -1829663.5908060546, -1778526.2211615036, -1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955], "policy_pol1_reward": [1763170.0424928216, 1712155.4425467309, 1825398.3987591683, 1679646.680018603, 1829663.5908060546, 1778526.2211615036, 1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27553925594508993, "mean_inference_ms": 3.8138851229393738, "mean_action_processing_ms": 0.19057525863143382, "mean_env_wait_ms": 0.14436493504644754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1501500, "agent_timesteps_total": 3003000, "timers": {"sample_time_ms": 4509.486, "sample_throughput": 1331.859, "learn_time_ms": 20589.52, "learn_throughput": 291.702, "update_time_ms": 5.12}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8351920942905046e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 23689574661.446808, "policy_loss": -0.001717118189689961, "vf_loss": 23689574661.446808, "vf_explained_var": -1.065274517486614e-07, "kl": 0.009633190236351591, "entropy": 2.721407636683038, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24350305606.80851, "policy_loss": 0.0009668822935286988, "vf_loss": 24350305606.80851, "vf_explained_var": -1.1286837064972133e-07, "kl": 0.01187399974925087, "entropy": 1.4489793752102142, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1501500, "num_agent_steps_sampled": 3003000, "num_steps_trained": 1501500, "num_agent_steps_trained": 3003000}, "done": false, "episodes_total": 1500, "training_iteration": 250, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-01-55", "timestamp": 1624968115, "time_this_iter_s": 25.35800528526306, "time_total_s": 6315.410416841507, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6315.410416841507, "timesteps_since_restore": 0, "iterations_since_restore": 250, "perf": {"cpu_util_percent": 30.650000000000006, "ram_util_percent": 67.22352941176472, "gpu_util_percent0": 0.38088235294117645, "vram_util_percent0": 0.30304427129800354}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1958612.83603471, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1958612.83603471}, "policy_reward_mean": {"pol0": -1730665.677449765, "pol1": 1730665.677449765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1789192.1400186957, -1736608.6981031292, -1958612.83603471, -1900685.4611616821, -1874474.5604487804, -1772889.2814726315, -1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386], "policy_pol1_reward": [1789192.1400186957, 1736608.6981031292, 1958612.83603471, 1900685.4611616821, 1874474.5604487804, 1772889.2814726315, 1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27554118755951157, "mean_inference_ms": 3.8137080347977554, "mean_action_processing_ms": 0.19056748442570226, "mean_env_wait_ms": 0.1443596684458862, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1507506, "agent_timesteps_total": 3015012, "timers": {"sample_time_ms": 4486.05, "sample_throughput": 1338.817, "learn_time_ms": 20593.087, "learn_throughput": 291.651, "update_time_ms": 5.15}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8351920942905046e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 21346737870.97872, "policy_loss": -0.001174395626529734, "vf_loss": 21346737870.97872, "vf_explained_var": -1.242820246716292e-07, "kl": 0.009982443949643602, "entropy": 2.6847269027791123, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 21983719206.12766, "policy_loss": -0.0034600323502053604, "vf_loss": 21983719206.12766, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.007654565416197193, "entropy": 1.429018477176098, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1507506, "num_agent_steps_sampled": 3015012, "num_steps_trained": 1507506, "num_agent_steps_trained": 3015012}, "done": false, "episodes_total": 1506, "training_iteration": 251, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-02-20", "timestamp": 1624968140, "time_this_iter_s": 25.02739691734314, "time_total_s": 6340.43781375885, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6340.43781375885, "timesteps_since_restore": 0, "iterations_since_restore": 251, "perf": {"cpu_util_percent": 30.545454545454547, "ram_util_percent": 67.44242424242425, "gpu_util_percent0": 0.3812121212121212, "vram_util_percent0": 0.3029741295666472}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1908197.259667276, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1908197.259667276}, "policy_reward_mean": {"pol0": -1727341.7340596458, "pol1": 1727341.7340596458}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1652736.5738899538, -1829928.7530086993, -1632730.8474645028, -1653082.9891498722, -1876952.7072849695, -1794729.7732186615, -1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051], "policy_pol1_reward": [1652736.5738899538, 1829928.7530086993, 1632730.8474645028, 1653082.9891498722, 1876952.7072849695, 1794729.7732186615, 1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2755377727188854, "mean_inference_ms": 3.813525651624181, "mean_action_processing_ms": 0.19055930461334206, "mean_env_wait_ms": 0.1443546337505521, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1513512, "agent_timesteps_total": 3027024, "timers": {"sample_time_ms": 4506.457, "sample_throughput": 1332.754, "learn_time_ms": 20594.867, "learn_throughput": 291.626, "update_time_ms": 5.2}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8351920942905046e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 25903420307.06383, "policy_loss": -0.0021474727607787925, "vf_loss": 25903420307.06383, "vf_explained_var": -4.945917453369475e-08, "kl": 0.013803829300276776, "entropy": 2.6627523949805725, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26655530136.51064, "policy_loss": -0.006657795921126579, "vf_loss": 26655530136.51064, "vf_explained_var": -4.058188451949718e-08, "kl": 0.0069595929235219955, "entropy": 1.4882738336603691, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1513512, "num_agent_steps_sampled": 3027024, "num_steps_trained": 1513512, "num_agent_steps_trained": 3027024}, "done": false, "episodes_total": 1512, "training_iteration": 252, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-02-46", "timestamp": 1624968166, "time_this_iter_s": 25.216583490371704, "time_total_s": 6365.654397249222, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c78c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6365.654397249222, "timesteps_since_restore": 0, "iterations_since_restore": 252, "perf": {"cpu_util_percent": 30.4969696969697, "ram_util_percent": 67.23939393939395, "gpu_util_percent0": 0.376969696969697, "vram_util_percent0": 0.30305583642287376}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1734485.6166413054, "pol1": 1734485.6166413054}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1785731.5617117581, -1872064.693955087, -1858615.7645828524, -1822877.6137775716, -1825491.996559909, -1834422.1940831258, -1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851], "policy_pol1_reward": [1785731.5617117581, 1872064.693955087, 1858615.7645828524, 1822877.6137775716, 1825491.996559909, 1834422.1940831258, 1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27553020958696534, "mean_inference_ms": 3.8133245873364996, "mean_action_processing_ms": 0.19055023447995256, "mean_env_wait_ms": 0.14434860392508675, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1519518, "agent_timesteps_total": 3039036, "timers": {"sample_time_ms": 4494.024, "sample_throughput": 1336.441, "learn_time_ms": 20566.359, "learn_throughput": 292.03, "update_time_ms": 5.17}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8351920942905046e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 28518028527.659573, "policy_loss": 0.00022305789938632478, "vf_loss": 28518028527.659573, "vf_explained_var": -7.101829879729848e-08, "kl": 0.002957637501048281, "entropy": 2.6999325143530015, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 29370797252.085106, "policy_loss": -0.007534778221173489, "vf_loss": 29370797252.085106, "vf_explained_var": -3.170459805801329e-08, "kl": 0.006957999608935194, "entropy": 1.4384027998498146, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1519518, "num_agent_steps_sampled": 3039036, "num_steps_trained": 1519518, "num_agent_steps_trained": 3039036}, "done": false, "episodes_total": 1518, "training_iteration": 253, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-03-10", "timestamp": 1624968190, "time_this_iter_s": 24.862401008605957, "time_total_s": 6390.516798257828, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c79d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6390.516798257828, "timesteps_since_restore": 0, "iterations_since_restore": 253, "perf": {"cpu_util_percent": 28.72727272727273, "ram_util_percent": 67.54242424242425, "gpu_util_percent0": 0.38484848484848483, "vram_util_percent0": 0.3029741295666472}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1729899.5900629507, "pol1": 1729899.5900629507}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1433819.8853682447, -1908197.259667276, -1554658.753197972, -1711502.2610585794, -1653356.233428087, -1568910.967692545, -1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288], "policy_pol1_reward": [1433819.8853682447, 1908197.259667276, 1554658.753197972, 1711502.2610585794, 1653356.233428087, 1568910.967692545, 1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27552053006392274, "mean_inference_ms": 3.813116065679084, "mean_action_processing_ms": 0.19054083267615127, "mean_env_wait_ms": 0.14434211671227767, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1525524, "agent_timesteps_total": 3051048, "timers": {"sample_time_ms": 4492.775, "sample_throughput": 1336.813, "learn_time_ms": 20562.285, "learn_throughput": 292.088, "update_time_ms": 5.144}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.175960471452523e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 25472376396.255318, "policy_loss": -0.0022041572138984155, "vf_loss": 25472376396.255318, "vf_explained_var": 1.3823205335938837e-07, "kl": 0.007594327422532629, "entropy": 2.717293495827533, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26233854910.638298, "policy_loss": -0.007593626077187822, "vf_loss": 26233854910.638298, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.006608224305462964, "entropy": 1.4580882635522396, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1525524, "num_agent_steps_sampled": 3051048, "num_steps_trained": 1525524, "num_agent_steps_trained": 3051048}, "done": false, "episodes_total": 1524, "training_iteration": 254, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-03-35", "timestamp": 1624968215, "time_this_iter_s": 24.891483545303345, "time_total_s": 6415.408281803131, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06277b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6415.408281803131, "timesteps_since_restore": 0, "iterations_since_restore": 254, "perf": {"cpu_util_percent": 29.31875, "ram_util_percent": 67.69375, "gpu_util_percent0": 0.375625, "vram_util_percent0": 0.3030312605325244}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1732429.7013485702, "pol1": 1732429.7013485702}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1789543.3138738407, -1810546.6790198802, -1492951.3317547333, -1666580.2388275783, -1535466.8063406094, -1711113.7074052533, -1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576], "policy_pol1_reward": [1789543.3138738407, 1810546.6790198802, 1492951.3317547333, 1666580.2388275783, 1535466.8063406094, 1711113.7074052533, 1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27551117205660985, "mean_inference_ms": 3.8129058244442398, "mean_action_processing_ms": 0.19053129782291578, "mean_env_wait_ms": 0.1443356261563866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1531530, "agent_timesteps_total": 3063060, "timers": {"sample_time_ms": 4504.722, "sample_throughput": 1333.268, "learn_time_ms": 20570.027, "learn_throughput": 291.978, "update_time_ms": 5.166}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.175960471452523e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 23335314105.19149, "policy_loss": -0.0007392915877255988, "vf_loss": 23335314105.19149, "vf_explained_var": -3.550914939864924e-08, "kl": 0.006925671083971541, "entropy": 2.6792063966710518, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24037500710.12766, "policy_loss": -0.003867296501994133, "vf_loss": 24037500710.12766, "vf_explained_var": 0.0, "kl": 0.005381241019696314, "entropy": 1.3798641524416335, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1531530, "num_agent_steps_sampled": 3063060, "num_steps_trained": 1531530, "num_agent_steps_trained": 3063060}, "done": false, "episodes_total": 1530, "training_iteration": 255, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-04-00", "timestamp": 1624968240, "time_this_iter_s": 25.041738033294678, "time_total_s": 6440.450019836426, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05d4840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05d4730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6440.450019836426, "timesteps_since_restore": 0, "iterations_since_restore": 255, "perf": {"cpu_util_percent": 29.53529411764706, "ram_util_percent": 67.53235294117648, "gpu_util_percent0": 0.3729411764705883, "vram_util_percent0": 0.3029897499950435}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1328705.0181949001}, "policy_reward_max": {"pol0": -1328705.0181949001, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1738672.6782029902, "pol1": 1738672.6782029902}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1478152.666405472, -1328705.0181949001, -1847046.7955684445, -1731486.614281177, -1637465.2982039254, -1853547.1471993385, -1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674], "policy_pol1_reward": [1478152.666405472, 1328705.0181949001, 1847046.7955684445, 1731486.614281177, 1637465.2982039254, 1853547.1471993385, 1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.275499413444258, "mean_inference_ms": 3.812681620252318, "mean_action_processing_ms": 0.19052171622739117, "mean_env_wait_ms": 0.14432894395160256, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1537536, "agent_timesteps_total": 3075072, "timers": {"sample_time_ms": 4496.38, "sample_throughput": 1335.741, "learn_time_ms": 20587.476, "learn_throughput": 291.731, "update_time_ms": 5.198}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.175960471452523e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 25624250019.404255, "policy_loss": -0.0009898635400261016, "vf_loss": 25624250019.404255, "vf_explained_var": 8.62365041598423e-08, "kl": 0.007213571871769555, "entropy": 2.732058712776671, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26394711976.851063, "policy_loss": -0.006376050452285624, "vf_loss": 26394711976.851063, "vf_explained_var": 0.0, "kl": 0.00681201276428839, "entropy": 1.384965939724699, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1537536, "num_agent_steps_sampled": 3075072, "num_steps_trained": 1537536, "num_agent_steps_trained": 3075072}, "done": false, "episodes_total": 1536, "training_iteration": 256, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-04-26", "timestamp": 1624968266, "time_this_iter_s": 25.372008085250854, "time_total_s": 6465.822027921677, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6465.822027921677, "timesteps_since_restore": 0, "iterations_since_restore": 256, "perf": {"cpu_util_percent": 31.62121212121212, "ram_util_percent": 67.16969696969699, "gpu_util_percent0": 0.37303030303030305, "vram_util_percent0": 0.3029741295666472}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1745446.8467742044, "pol1": 1745446.8467742044}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1808063.0107848726, -1695367.9991515335, -1549451.1927053083, -1739236.8511400607, -1717079.0783718096, -1862807.348171526, -1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014], "policy_pol1_reward": [1808063.0107848726, 1695367.9991515335, 1549451.1927053083, 1739236.8511400607, 1717079.0783718096, 1862807.348171526, 1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754883014022616, "mean_inference_ms": 3.812489829710543, "mean_action_processing_ms": 0.19051254394226014, "mean_env_wait_ms": 0.14432251778729385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1543542, "agent_timesteps_total": 3087084, "timers": {"sample_time_ms": 4511.828, "sample_throughput": 1331.168, "learn_time_ms": 20578.389, "learn_throughput": 291.86, "update_time_ms": 5.168}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.175960471452523e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 25554402674.38298, "policy_loss": -0.00015161483687289217, "vf_loss": 25554402674.38298, "vf_explained_var": -1.6486390919112637e-08, "kl": 0.0025183001404350744, "entropy": 2.761716715832974, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26324782798.97872, "policy_loss": -0.004685204872425566, "vf_loss": 26324782798.97872, "vf_explained_var": -8.87728734966231e-09, "kl": 0.005795333871340498, "entropy": 1.5070237377856641, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1543542, "num_agent_steps_sampled": 3087084, "num_steps_trained": 1543542, "num_agent_steps_trained": 3087084}, "done": false, "episodes_total": 1542, "training_iteration": 257, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-04-51", "timestamp": 1624968291, "time_this_iter_s": 25.155235767364502, "time_total_s": 6490.977263689041, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6490.977263689041, "timesteps_since_restore": 0, "iterations_since_restore": 257, "perf": {"cpu_util_percent": 31.13030303030303, "ram_util_percent": 67.24848484848485, "gpu_util_percent0": 0.3790909090909091, "vram_util_percent0": 0.30305583642287376}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1744158.969085723, "pol1": 1744158.969085723}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1737237.367684478, -1857433.9954566841, -1738617.308213786, -1649607.4288718726, -1839581.5432177505, -1882795.0900395808, -1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369], "policy_pol1_reward": [1737237.367684478, 1857433.9954566841, 1738617.308213786, 1649607.4288718726, 1839581.5432177505, 1882795.0900395808, 1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754756008788722, "mean_inference_ms": 3.812275344713125, "mean_action_processing_ms": 0.19050255445128703, "mean_env_wait_ms": 0.14431581831967288, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1549548, "agent_timesteps_total": 3099096, "timers": {"sample_time_ms": 4489.809, "sample_throughput": 1337.696, "learn_time_ms": 20572.266, "learn_throughput": 291.946, "update_time_ms": 5.006}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5879802357262616e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 23873089230.97872, "policy_loss": -0.0036061560299168243, "vf_loss": 23873089230.97872, "vf_explained_var": -1.1033200308929736e-07, "kl": 0.00981529913050063, "entropy": 2.73302645886198, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24602851197.276596, "policy_loss": -0.006642122852041367, "vf_loss": 24602851197.276596, "vf_explained_var": 1.1794110577056927e-07, "kl": 0.005967128120283497, "entropy": 1.5182318053347, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1549548, "num_agent_steps_sampled": 3099096, "num_steps_trained": 1549548, "num_agent_steps_trained": 3099096}, "done": false, "episodes_total": 1548, "training_iteration": 258, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-05-16", "timestamp": 1624968316, "time_this_iter_s": 24.921816110610962, "time_total_s": 6515.899079799652, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cda60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6515.899079799652, "timesteps_since_restore": 0, "iterations_since_restore": 258, "perf": {"cpu_util_percent": 29.9, "ram_util_percent": 67.37878787878788, "gpu_util_percent0": 0.37727272727272726, "vram_util_percent0": 0.30296902288813304}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1742196.8461974526, "pol1": 1742196.8461974526}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1744557.577905505, -1651786.1727100136, -1578557.7950939513, -1704793.4408600158, -1545841.4684526422, -1774976.957548779, -1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301], "policy_pol1_reward": [1744557.577905505, 1651786.1727100136, 1578557.7950939513, 1704793.4408600158, 1545841.4684526422, 1774976.957548779, 1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27546501306812216, "mean_inference_ms": 3.8120980578866543, "mean_action_processing_ms": 0.19049431069944694, "mean_env_wait_ms": 0.14431010619822493, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1555554, "agent_timesteps_total": 3111108, "timers": {"sample_time_ms": 4509.186, "sample_throughput": 1331.948, "learn_time_ms": 20595.077, "learn_throughput": 291.623, "update_time_ms": 5.122}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5879802357262616e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 25429138976.68085, "policy_loss": -0.0028789001814228422, "vf_loss": 25429138976.68085, "vf_explained_var": 1.5725480295714078e-07, "kl": 0.008316144089590995, "entropy": 2.7208416106853077, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26203433090.723404, "policy_loss": -0.005349895381864081, "vf_loss": 26203433090.723404, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.005977933978701526, "entropy": 1.5281490899146872, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1555554, "num_agent_steps_sampled": 3111108, "num_steps_trained": 1555554, "num_agent_steps_trained": 3111108}, "done": false, "episodes_total": 1554, "training_iteration": 259, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-05-41", "timestamp": 1624968341, "time_this_iter_s": 25.33256506919861, "time_total_s": 6541.231644868851, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e352f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6541.231644868851, "timesteps_since_restore": 0, "iterations_since_restore": 259, "perf": {"cpu_util_percent": 31.451515151515153, "ram_util_percent": 67.14848484848486, "gpu_util_percent0": 0.37878787878787884, "vram_util_percent0": 0.3031017965295013}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1749761.8523485519, "pol1": 1749761.8523485519}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1799905.0785470528, -1754031.8450062124, -1852620.990886243, -1821020.2650430982, -1709718.6448269545, -1747843.3778046288, -1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854], "policy_pol1_reward": [1799905.0785470528, 1754031.8450062124, 1852620.990886243, 1821020.2650430982, 1709718.6448269545, 1747843.3778046288, 1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754572482623162, "mean_inference_ms": 3.811930382383482, "mean_action_processing_ms": 0.19048661578099121, "mean_env_wait_ms": 0.14430532187265277, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1561560, "agent_timesteps_total": 3123120, "timers": {"sample_time_ms": 4498.605, "sample_throughput": 1335.081, "learn_time_ms": 20618.059, "learn_throughput": 291.298, "update_time_ms": 5.073}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5879802357262616e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 26300966171.234043, "policy_loss": -0.001743707850456555, "vf_loss": 26300966171.234043, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.0076515634960316594, "entropy": 2.669244223452629, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 27098771978.893616, "policy_loss": -0.005360583378437986, "vf_loss": 27098771978.893616, "vf_explained_var": -1.2174565711120522e-07, "kl": 0.006046791372701843, "entropy": 1.5315181574922927, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1561560, "num_agent_steps_sampled": 3123120, "num_steps_trained": 1561560, "num_agent_steps_trained": 3123120}, "done": false, "episodes_total": 1560, "training_iteration": 260, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-06-07", "timestamp": 1624968367, "time_this_iter_s": 25.481243133544922, "time_total_s": 6566.712888002396, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6566.712888002396, "timesteps_since_restore": 0, "iterations_since_restore": 260, "perf": {"cpu_util_percent": 31.373529411764707, "ram_util_percent": 67.30294117647061, "gpu_util_percent0": 0.38000000000000006, "vram_util_percent0": 0.30663276432918973}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1749417.5414228095, "pol1": 1749417.5414228095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1709988.1552477367, -1654051.561040839, -1840901.3104862173, -1704596.3217375404, -1904694.6108386484, -1748013.7505709124, -1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606], "policy_pol1_reward": [1709988.1552477367, 1654051.561040839, 1840901.3104862173, 1704596.3217375404, 1904694.6108386484, 1748013.7505709124, 1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754507080009, "mean_inference_ms": 3.8117813632775968, "mean_action_processing_ms": 0.19047983239361957, "mean_env_wait_ms": 0.14430122404829923, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1567566, "agent_timesteps_total": 3135132, "timers": {"sample_time_ms": 4510.104, "sample_throughput": 1331.677, "learn_time_ms": 20604.252, "learn_throughput": 291.493, "update_time_ms": 5.107}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5879802357262616e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 25840174581.106384, "policy_loss": -0.002631772468064694, "vf_loss": 25840174581.106384, "vf_explained_var": -1.3442749491332506e-07, "kl": 0.009680374783087285, "entropy": 2.639642385726279, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26622295758.97872, "policy_loss": -0.007001537314437805, "vf_loss": 26622295758.97872, "vf_explained_var": -1.0145471662781347e-07, "kl": 0.007006560640528481, "entropy": 1.6087193311528956, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1567566, "num_agent_steps_sampled": 3135132, "num_steps_trained": 1567566, "num_agent_steps_trained": 3135132}, "done": false, "episodes_total": 1566, "training_iteration": 261, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-06-32", "timestamp": 1624968392, "time_this_iter_s": 25.004486322402954, "time_total_s": 6591.717374324799, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdc80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6591.717374324799, "timesteps_since_restore": 0, "iterations_since_restore": 261, "perf": {"cpu_util_percent": 30.081818181818182, "ram_util_percent": 67.39090909090909, "gpu_util_percent0": 0.3793939393939394, "vram_util_percent0": 0.3066968982034705}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1933355.070593029, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1933355.070593029}, "policy_reward_mean": {"pol0": -1747504.5964648274, "pol1": 1747504.5964648274}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1735908.8441722186, -1795255.4392752387, -1710412.9598472258, -1803311.869040017, -1797085.7347979594, -1646602.9630305795, -1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902], "policy_pol1_reward": [1735908.8441722186, 1795255.4392752387, 1710412.9598472258, 1803311.869040017, 1797085.7347979594, 1646602.9630305795, 1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.275448075928069, "mean_inference_ms": 3.8116496498535457, "mean_action_processing_ms": 0.1904745289021943, "mean_env_wait_ms": 0.14429809404458735, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1573572, "agent_timesteps_total": 3147144, "timers": {"sample_time_ms": 4508.366, "sample_throughput": 1332.19, "learn_time_ms": 20618.76, "learn_throughput": 291.288, "update_time_ms": 5.083}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5879802357262616e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 24547546264.51064, "policy_loss": -0.002518786216511371, "vf_loss": 24547546264.51064, "vf_explained_var": 1.3823205335938837e-07, "kl": 0.009298148782963448, "entropy": 2.615495666544488, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25303562675.744682, "policy_loss": -0.008205379815177714, "vf_loss": 25303562675.744682, "vf_explained_var": -9.638198150696553e-08, "kl": 0.007795206508896453, "entropy": 1.5850835049406011, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1573572, "num_agent_steps_sampled": 3147144, "num_steps_trained": 1573572, "num_agent_steps_trained": 3147144}, "done": false, "episodes_total": 1572, "training_iteration": 262, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-06-57", "timestamp": 1624968417, "time_this_iter_s": 25.344464540481567, "time_total_s": 6617.06183886528, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c71e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6617.06183886528, "timesteps_since_restore": 0, "iterations_since_restore": 262, "perf": {"cpu_util_percent": 31.46969696969697, "ram_util_percent": 67.13636363636363, "gpu_util_percent0": 0.37424242424242427, "vram_util_percent0": 0.3067071115604988}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1746358.7340623282, "pol1": 1746358.7340623282}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1615691.5940775394, -1722698.765873232, -1865275.3964707754, -1705809.4621138663, -1823746.9422514387, -1781699.2015146236, -1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575], "policy_pol1_reward": [1615691.5940775394, 1722698.765873232, 1865275.3964707754, 1705809.4621138663, 1823746.9422514387, 1781699.2015146236, 1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27544023429557357, "mean_inference_ms": 3.8115321392799393, "mean_action_processing_ms": 0.19046974203912018, "mean_env_wait_ms": 0.14429520667777473, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1579578, "agent_timesteps_total": 3159156, "timers": {"sample_time_ms": 4519.849, "sample_throughput": 1328.805, "learn_time_ms": 20647.697, "learn_throughput": 290.88, "update_time_ms": 5.137}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5879802357262616e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 24770761314.042553, "policy_loss": -0.00039745159843500625, "vf_loss": 24770761314.042553, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.004573014743150549, "entropy": 2.6081369633370257, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25529844060.595745, "policy_loss": -0.008016407192546003, "vf_loss": 25529844060.595745, "vf_explained_var": -1.3696386247374903e-07, "kl": 0.009106806766717358, "entropy": 1.5646475502785215, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1579578, "num_agent_steps_sampled": 3159156, "num_steps_trained": 1579578, "num_agent_steps_trained": 3159156}, "done": false, "episodes_total": 1578, "training_iteration": 263, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-07-23", "timestamp": 1624968443, "time_this_iter_s": 25.268974542617798, "time_total_s": 6642.330813407898, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac0d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6642.330813407898, "timesteps_since_restore": 0, "iterations_since_restore": 263, "perf": {"cpu_util_percent": 31.08235294117647, "ram_util_percent": 67.2529411764706, "gpu_util_percent0": 0.3779411764705882, "vram_util_percent0": 0.3066178948829279}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1744605.4076137496, "pol1": 1744605.4076137496}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1802032.5833375747, -1752638.4791464803, -1796836.1865209427, -1763961.4535911395, -1862503.1361643462, -1884288.2332043436, -1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578], "policy_pol1_reward": [1802032.5833375747, 1752638.4791464803, 1796836.1865209427, 1763961.4535911395, 1862503.1361643462, 1884288.2332043436, 1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27542996211567905, "mean_inference_ms": 3.811417304388339, "mean_action_processing_ms": 0.19046494581330783, "mean_env_wait_ms": 0.14429241563295, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1585584, "agent_timesteps_total": 3171168, "timers": {"sample_time_ms": 4532.842, "sample_throughput": 1324.996, "learn_time_ms": 20661.282, "learn_throughput": 290.689, "update_time_ms": 5.104}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2939901178631308e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 24254812421.446808, "policy_loss": 0.0044385848685782004, "vf_loss": 24254812421.446808, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.010635591597553897, "entropy": 2.5423346225251544, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25003327836.595745, "policy_loss": -0.005969308970614951, "vf_loss": 25003327836.595745, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.006066195993743678, "entropy": 1.6298979216433587, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1585584, "num_agent_steps_sampled": 3171168, "num_steps_trained": 1585584, "num_agent_steps_trained": 3171168}, "done": false, "episodes_total": 1584, "training_iteration": 264, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-07-48", "timestamp": 1624968468, "time_this_iter_s": 25.157898902893066, "time_total_s": 6667.488712310791, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6667.488712310791, "timesteps_since_restore": 0, "iterations_since_restore": 264, "perf": {"cpu_util_percent": 30.7030303030303, "ram_util_percent": 67.26060606060607, "gpu_util_percent0": 0.3706060606060606, "vram_util_percent0": 0.3067581783456404}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1735546.3780195203, "pol1": 1735546.3780195203}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1483592.440257974, -1736720.9191222803, -1827459.770517901, -1721267.7284737756, -1767924.7965549473, -1636704.725198708, -1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816], "policy_pol1_reward": [1483592.440257974, 1736720.9191222803, 1827459.770517901, 1721267.7284737756, 1767924.7965549473, 1636704.725198708, 1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754174321099418, "mean_inference_ms": 3.811285301212933, "mean_action_processing_ms": 0.19045909866664207, "mean_env_wait_ms": 0.14428894011161586, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1591590, "agent_timesteps_total": 3183180, "timers": {"sample_time_ms": 4534.796, "sample_throughput": 1324.425, "learn_time_ms": 20662.023, "learn_throughput": 290.678, "update_time_ms": 4.929}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2939901178631308e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 22472002058.893616, "policy_loss": 0.002273899022529417, "vf_loss": 22472002058.893616, "vf_explained_var": 7.609103569450326e-09, "kl": 0.02372761863343259, "entropy": 2.5631491021907076, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 23160256860.595745, "policy_loss": -0.004517281725210078, "vf_loss": 23160256860.595745, "vf_explained_var": -4.1850068299709164e-08, "kl": 0.005135089941719111, "entropy": 1.7659152289654345, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1591590, "num_agent_steps_sampled": 3183180, "num_steps_trained": 1591590, "num_agent_steps_trained": 3183180}, "done": false, "episodes_total": 1590, "training_iteration": 265, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-08-13", "timestamp": 1624968493, "time_this_iter_s": 25.066776990890503, "time_total_s": 6692.5554893016815, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdf28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6692.5554893016815, "timesteps_since_restore": 0, "iterations_since_restore": 265, "perf": {"cpu_util_percent": 30.21515151515152, "ram_util_percent": 67.46363636363637, "gpu_util_percent0": 0.3827272727272727, "vram_util_percent0": 0.30667647148941385}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1739361.3355853003, "pol1": 1739361.3355853003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1569784.322885947, -1756078.7676930646, -1714844.341205576, -1790043.884883955, -1439803.038978771, -1508973.1896667334, -1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558], "policy_pol1_reward": [1569784.322885947, 1756078.7676930646, 1714844.341205576, 1790043.884883955, 1439803.038978771, 1508973.1896667334, 1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754005161555069, "mean_inference_ms": 3.81116773352253, "mean_action_processing_ms": 0.19045404254425286, "mean_env_wait_ms": 0.1442855382589104, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1597596, "agent_timesteps_total": 3195192, "timers": {"sample_time_ms": 4542.176, "sample_throughput": 1322.274, "learn_time_ms": 20641.255, "learn_throughput": 290.971, "update_time_ms": 4.948}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4409851767946994e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 25263803588.085106, "policy_loss": -0.00020650399729926536, "vf_loss": 25263803588.085106, "vf_explained_var": -1.1413655442993331e-07, "kl": 0.010739931658385916, "entropy": 2.6964487978752625, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26047019705.19149, "policy_loss": -0.007076723976655209, "vf_loss": 26047019705.19149, "vf_explained_var": -4.058188451949718e-08, "kl": 0.0065331547322901, "entropy": 1.874629814574059, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1597596, "num_agent_steps_sampled": 3195192, "num_steps_trained": 1597596, "num_agent_steps_trained": 3195192}, "done": false, "episodes_total": 1596, "training_iteration": 266, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-08-38", "timestamp": 1624968518, "time_this_iter_s": 25.237850189208984, "time_total_s": 6717.7933394908905, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6717.7933394908905, "timesteps_since_restore": 0, "iterations_since_restore": 266, "perf": {"cpu_util_percent": 31.430303030303033, "ram_util_percent": 67.15454545454546, "gpu_util_percent0": 0.37363636363636366, "vram_util_percent0": 0.3067275382745555}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1743310.182011101, "pol1": 1743310.182011101}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1793648.6915562751, -1813695.5468878725, -1410982.1555682286, -1719227.2192642386, -1770336.4560561783, -1753424.7396724427, -1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983], "policy_pol1_reward": [1793648.6915562751, 1813695.5468878725, 1410982.1555682286, 1719227.2192642386, 1770336.4560561783, 1753424.7396724427, 1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27538375887873356, "mean_inference_ms": 3.81104612033467, "mean_action_processing_ms": 0.19044905854122834, "mean_env_wait_ms": 0.14428221459864582, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1603602, "agent_timesteps_total": 3207204, "timers": {"sample_time_ms": 4529.082, "sample_throughput": 1326.097, "learn_time_ms": 20882.92, "learn_throughput": 287.603, "update_time_ms": 4.982}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4409851767946994e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 23515728177.02128, "policy_loss": -0.0018625696526562913, "vf_loss": 23515728177.02128, "vf_explained_var": 1.0906381930908537e-07, "kl": 0.010205402237145191, "entropy": 2.7743758089998933, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24242851404.255318, "policy_loss": -0.005340054492525598, "vf_loss": 24242851404.255318, "vf_explained_var": -1.1160018686950934e-07, "kl": 0.009065570349388935, "entropy": 1.9519161391765514, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1603602, "num_agent_steps_sampled": 3207204, "num_steps_trained": 1603602, "num_agent_steps_trained": 3207204}, "done": false, "episodes_total": 1602, "training_iteration": 267, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-09-06", "timestamp": 1624968546, "time_this_iter_s": 27.442155122756958, "time_total_s": 6745.2354946136475, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7ae4194400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6745.2354946136475, "timesteps_since_restore": 0, "iterations_since_restore": 267, "perf": {"cpu_util_percent": 31.774999999999995, "ram_util_percent": 67.24722222222223, "gpu_util_percent0": 0.3758333333333333, "vram_util_percent0": 0.3066368947309291}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1741979.7893167583, "pol1": 1741979.7893167583}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1845803.2366000798, -1746049.090924386, -1896134.9139336166, -1688320.201041051, -1832528.8464924193, -1933355.070593029, -1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386], "policy_pol1_reward": [1845803.2366000798, 1746049.090924386, 1896134.9139336166, 1688320.201041051, 1832528.8464924193, 1933355.070593029, 1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2753658776604532, "mean_inference_ms": 3.8109475850900196, "mean_action_processing_ms": 0.19044456847732139, "mean_env_wait_ms": 0.14427852214983936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1609608, "agent_timesteps_total": 3219216, "timers": {"sample_time_ms": 4539.964, "sample_throughput": 1322.918, "learn_time_ms": 20906.09, "learn_throughput": 287.285, "update_time_ms": 4.998}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4409851767946994e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 23705818395.234043, "policy_loss": -0.0015887732597741676, "vf_loss": 23705818395.234043, "vf_explained_var": -7.862740147857039e-08, "kl": 0.011734921405924128, "entropy": 2.7598785136608366, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24463917971.06383, "policy_loss": -0.006110958596493335, "vf_loss": 24463917971.06383, "vf_explained_var": 4.1850068299709164e-08, "kl": 0.005503246124754561, "entropy": 1.9622860842562737, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1609608, "num_agent_steps_sampled": 3219216, "num_steps_trained": 1609608, "num_agent_steps_trained": 3219216}, "done": false, "episodes_total": 1608, "training_iteration": 268, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-09-31", "timestamp": 1624968571, "time_this_iter_s": 25.263060808181763, "time_total_s": 6770.498555421829, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e350d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6770.498555421829, "timesteps_since_restore": 0, "iterations_since_restore": 268, "perf": {"cpu_util_percent": 31.175757575757576, "ram_util_percent": 67.39999999999999, "gpu_util_percent0": 0.38636363636363635, "vram_util_percent0": 0.3066254047042723}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1734476.1000058406, "pol1": 1734476.1000058406}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1843503.042775451, -1773975.2297488302, -1931479.4660899907, -1839708.246482851, -1882204.656645331, -1812214.0326833331, -1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641], "policy_pol1_reward": [1843503.042775451, 1773975.2297488302, 1931479.4660899907, 1839708.246482851, 1882204.656645331, 1812214.0326833331, 1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27535075027892353, "mean_inference_ms": 3.8108563459752554, "mean_action_processing_ms": 0.19044076608688468, "mean_env_wait_ms": 0.14427535359505564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1615614, "agent_timesteps_total": 3231228, "timers": {"sample_time_ms": 4533.8, "sample_throughput": 1324.717, "learn_time_ms": 21941.532, "learn_throughput": 273.727, "update_time_ms": 5.238}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4409851767946994e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 23701064290.042553, "policy_loss": -0.0010421402118307478, "vf_loss": 23701064290.042553, "vf_explained_var": -1.3696386247374903e-07, "kl": 0.012861769666221547, "entropy": 2.6517471100421663, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24456783959.148937, "policy_loss": -0.004569128908692522, "vf_loss": 24456783959.148937, "vf_explained_var": -3.550914939864924e-08, "kl": 0.0037300979441150708, "entropy": 2.144043262968672, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1615614, "num_agent_steps_sampled": 3231228, "num_steps_trained": 1615614, "num_agent_steps_trained": 3231228}, "done": false, "episodes_total": 1614, "training_iteration": 269, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-10-07", "timestamp": 1624968607, "time_this_iter_s": 35.62935471534729, "time_total_s": 6806.1279101371765, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6806.1279101371765, "timesteps_since_restore": 0, "iterations_since_restore": 269, "perf": {"cpu_util_percent": 32.702173913043474, "ram_util_percent": 67.25652173913043, "gpu_util_percent0": 0.5554347826086956, "vram_util_percent0": 0.30902609867967934}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1731790.4390198276, "pol1": 1731790.4390198276}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1906716.7712556687, -1781829.1906955307, -1434308.980903667, -1723327.5346513288, -1677487.5647252721, -1784177.215505681, -1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363], "policy_pol1_reward": [1906716.7712556687, 1781829.1906955307, 1434308.980903667, 1723327.5346513288, 1677487.5647252721, 1784177.215505681, 1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2753661118689496, "mean_inference_ms": 3.8112762313634465, "mean_action_processing_ms": 0.19046090984821876, "mean_env_wait_ms": 0.14429005584899973, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1621620, "agent_timesteps_total": 3243240, "timers": {"sample_time_ms": 4777.608, "sample_throughput": 1257.114, "learn_time_ms": 23942.995, "learn_throughput": 250.846, "update_time_ms": 5.564}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4409851767946994e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 26703036328.851063, "policy_loss": 0.010710715197343776, "vf_loss": 26703036328.851063, "vf_explained_var": 7.609103569450326e-09, "kl": 0.04512429974497633, "entropy": 2.697990376898583, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 27562384057.19149, "policy_loss": -0.006428854738144164, "vf_loss": 27562384057.19149, "vf_explained_var": 2.916823049758932e-08, "kl": 0.007565015114526799, "entropy": 2.2238764661423702, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1621620, "num_agent_steps_sampled": 3243240, "num_steps_trained": 1621620, "num_agent_steps_trained": 3243240}, "done": false, "episodes_total": 1620, "training_iteration": 270, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-10-55", "timestamp": 1624968655, "time_this_iter_s": 47.94218564033508, "time_total_s": 6854.070095777512, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6854.070095777512, "timesteps_since_restore": 0, "iterations_since_restore": 270, "perf": {"cpu_util_percent": 34.77868852459017, "ram_util_percent": 67.3950819672131, "gpu_util_percent0": 0.720983606557377, "vram_util_percent0": 0.3119395315685658}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1350445.6404758336}, "policy_reward_max": {"pol0": -1350445.6404758336, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1729211.2191948805, "pol1": 1729211.2191948805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1828670.3090069164, -1350445.6404758336, -1771399.001890364, -1671276.757370576, -1839496.8274578964, -1653836.3746964233, -1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759], "policy_pol1_reward": [1828670.3090069164, 1350445.6404758336, 1771399.001890364, 1671276.757370576, 1839496.8274578964, 1653836.3746964233, 1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754068387384602, "mean_inference_ms": 3.8121763408196814, "mean_action_processing_ms": 0.1905028330063111, "mean_env_wait_ms": 0.1443207465515774, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1627626, "agent_timesteps_total": 3255252, "timers": {"sample_time_ms": 5022.785, "sample_throughput": 1195.751, "learn_time_ms": 25876.509, "learn_throughput": 232.102, "update_time_ms": 5.869}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.161477765192046e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 22771496742.12766, "policy_loss": 0.009548673881812299, "vf_loss": 22771496742.12766, "vf_explained_var": 1.5218207138900652e-08, "kl": 0.04319950549843463, "entropy": 2.966420833100664, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 23497207328.68085, "policy_loss": -0.008102157628758157, "vf_loss": 23497207328.68085, "vf_explained_var": 3.550914939864924e-08, "kl": 0.0076918787560722925, "entropy": 2.2341201609753547, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1627626, "num_agent_steps_sampled": 3255252, "num_steps_trained": 1627626, "num_agent_steps_trained": 3255252}, "done": false, "episodes_total": 1626, "training_iteration": 271, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-11-41", "timestamp": 1624968701, "time_this_iter_s": 46.796345233917236, "time_total_s": 6900.866441011429, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c78c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6900.866441011429, "timesteps_since_restore": 0, "iterations_since_restore": 271, "perf": {"cpu_util_percent": 34.22666666666667, "ram_util_percent": 67.23166666666667, "gpu_util_percent0": 0.7086666666666667, "vram_util_percent0": 0.31193966970003373}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1731139.863343957, "pol1": 1731139.863343957}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1842059.0627262702, -1628741.7774840854, -1788771.8311785392, -1877593.889120674, -1767471.506245425, -1559703.0550730512, -1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036], "policy_pol1_reward": [1842059.0627262702, 1628741.7774840854, 1788771.8311785392, 1877593.889120674, 1767471.506245425, 1559703.0550730512, 1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2754739826913829, "mean_inference_ms": 3.8134917467802216, "mean_action_processing_ms": 0.1905638903564285, "mean_env_wait_ms": 0.14436537569349125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1633632, "agent_timesteps_total": 3267264, "timers": {"sample_time_ms": 5225.666, "sample_throughput": 1149.327, "learn_time_ms": 27826.801, "learn_throughput": 215.835, "update_time_ms": 6.162}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.742216647788071e-08, "cur_lr": 5.000000000000002e-05, "total_loss": 24043525054.638298, "policy_loss": 0.021806632703606117, "vf_loss": 24043525054.638298, "vf_explained_var": -2.029094225974859e-08, "kl": 0.0782619093326812, "entropy": 2.5649745007778737, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 24810583279.659573, "policy_loss": -0.007781109356499733, "vf_loss": 24810583279.659573, "vf_explained_var": 2.4095495376741383e-08, "kl": 0.00938541987078621, "entropy": 2.0855765849985977, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1633632, "num_agent_steps_sampled": 3267264, "num_steps_trained": 1633632, "num_agent_steps_trained": 3267264}, "done": false, "episodes_total": 1632, "training_iteration": 272, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-12-28", "timestamp": 1624968748, "time_this_iter_s": 46.879987478256226, "time_total_s": 6947.746428489685, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd1e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdbf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6947.746428489685, "timesteps_since_restore": 0, "iterations_since_restore": 272, "perf": {"cpu_util_percent": 34.765, "ram_util_percent": 67.44, "gpu_util_percent0": 0.7031666666666666, "vram_util_percent0": 0.311883496236378}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1729963.4276449757, "pol1": 1729963.4276449757}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1799951.77833418, -1791439.4666886488, -1914433.158051977, -1720821.4325814014, -1543280.8421870074, -1886896.898057579, -1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822], "policy_pol1_reward": [1799951.77833418, 1791439.4666886488, 1914433.158051977, 1720821.4325814014, 1543280.8421870074, 1886896.898057579, 1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2755840863843138, "mean_inference_ms": 3.815170656127599, "mean_action_processing_ms": 0.19064132748104776, "mean_env_wait_ms": 0.1444223820488244, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1639638, "agent_timesteps_total": 3279276, "timers": {"sample_time_ms": 5434.359, "sample_throughput": 1105.19, "learn_time_ms": 29764.572, "learn_throughput": 201.784, "update_time_ms": 6.543}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1613324971682109e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 24205483291.234043, "policy_loss": 0.006962822433164779, "vf_loss": 24205483291.234043, "vf_explained_var": -1.356956857989644e-07, "kl": 0.03225974033170558, "entropy": 2.526668614529549, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 24980755652.085106, "policy_loss": -0.0058726683219379565, "vf_loss": 24980755652.085106, "vf_explained_var": 3.424096561843726e-08, "kl": 0.006412532557039819, "entropy": 2.1452556975344392, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1639638, "num_agent_steps_sampled": 3279276, "num_steps_trained": 1639638, "num_agent_steps_trained": 3279276}, "done": false, "episodes_total": 1638, "training_iteration": 273, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-13-15", "timestamp": 1624968795, "time_this_iter_s": 46.73707056045532, "time_total_s": 6994.48349905014, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05d42f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05d4268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6994.48349905014, "timesteps_since_restore": 0, "iterations_since_restore": 273, "perf": {"cpu_util_percent": 33.92166666666667, "ram_util_percent": 67.41833333333334, "gpu_util_percent0": 0.7081666666666668, "vram_util_percent0": 0.3119340523536682}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1727045.1197008658, "pol1": 1727045.1197008658}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1565967.6787051, -1798309.2084956896, -1582097.255567891, -1866665.82846369, -1545750.615697469, -1606362.9178116007, -1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708], "policy_pol1_reward": [1565967.6787051, 1798309.2084956896, 1582097.255567891, 1866665.82846369, 1545750.615697469, 1606362.9178116007, 1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27572033411631575, "mean_inference_ms": 3.8172391002132247, "mean_action_processing_ms": 0.19073763885878897, "mean_env_wait_ms": 0.14449329778972694, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1645644, "agent_timesteps_total": 3291288, "timers": {"sample_time_ms": 5652.278, "sample_throughput": 1062.58, "learn_time_ms": 31648.437, "learn_throughput": 189.772, "update_time_ms": 7.192}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7419987457523151e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 24294628809.531914, "policy_loss": 0.0010576038324135416, "vf_loss": 24294628809.531914, "vf_explained_var": 1.3315931823854044e-07, "kl": 0.04371375574710521, "entropy": 2.3869393125493477, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 25079552392.17021, "policy_loss": -0.007427236956960344, "vf_loss": 25079552392.17021, "vf_explained_var": 0.0, "kl": 0.009289020474286789, "entropy": 2.138094130982744, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1645644, "num_agent_steps_sampled": 3291288, "num_steps_trained": 1645644, "num_agent_steps_trained": 3291288}, "done": false, "episodes_total": 1644, "training_iteration": 274, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-14-01", "timestamp": 1624968841, "time_this_iter_s": 46.18430018424988, "time_total_s": 7040.66779923439, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05d4950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05d4840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7040.66779923439, "timesteps_since_restore": 0, "iterations_since_restore": 274, "perf": {"cpu_util_percent": 33.98833333333334, "ram_util_percent": 67.26833333333333, "gpu_util_percent0": 0.7121666666666667, "vram_util_percent0": 0.3119509043927649}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1733770.5373813503, "pol1": 1733770.5373813503}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1750128.0706421973, -1883541.3967472622, -1907686.323246284, -1815591.120512301, -1806830.3195188916, -1741649.2714536495, -1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764], "policy_pol1_reward": [1750128.0706421973, 1883541.3967472622, 1907686.323246284, 1815591.120512301, 1806830.3195188916, 1741649.2714536495, 1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27589212050008244, "mean_inference_ms": 3.8197342784947135, "mean_action_processing_ms": 0.19085360824337982, "mean_env_wait_ms": 0.14457846981634753, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1651650, "agent_timesteps_total": 3303300, "timers": {"sample_time_ms": 5880.607, "sample_throughput": 1021.323, "learn_time_ms": 33593.108, "learn_throughput": 178.787, "update_time_ms": 7.566}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.612998118628474e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 25751505593.19149, "policy_loss": 0.009380894990519006, "vf_loss": 25751505593.19149, "vf_explained_var": 1.0272290040802545e-07, "kl": 0.05702869800177026, "entropy": 2.3873922368313405, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26593426061.61702, "policy_loss": -0.007264294562504646, "vf_loss": 26593426061.61702, "vf_explained_var": -1.2681839578476684e-08, "kl": 0.008618944374091447, "entropy": 2.261116174941367, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1651650, "num_agent_steps_sampled": 3303300, "num_steps_trained": 1651650, "num_agent_steps_trained": 3303300}, "done": false, "episodes_total": 1650, "training_iteration": 275, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-14-48", "timestamp": 1624968888, "time_this_iter_s": 46.80360817909241, "time_total_s": 7087.471407413483, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c7730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7087.471407413483, "timesteps_since_restore": 0, "iterations_since_restore": 275, "perf": {"cpu_util_percent": 34.433898305084746, "ram_util_percent": 67.28305084745763, "gpu_util_percent0": 0.6983050847457627, "vram_util_percent0": 0.3119712315698675}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1731602.0162774252, "pol1": 1731602.0162774252}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1806378.6633052798, -1835012.334115386, -1763765.855689935, -1803377.5835976854, -1822318.4606674656, -1676354.1132079398, -1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733], "policy_pol1_reward": [1806378.6633052798, 1835012.334115386, 1763765.855689935, 1803377.5835976854, 1822318.4606674656, 1676354.1132079398, 1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27609849717355256, "mean_inference_ms": 3.8226250268557287, "mean_action_processing_ms": 0.19098746760695393, "mean_env_wait_ms": 0.14467719866010462, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1657656, "agent_timesteps_total": 3315312, "timers": {"sample_time_ms": 6107.034, "sample_throughput": 983.456, "learn_time_ms": 35491.22, "learn_throughput": 169.225, "update_time_ms": 7.828}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.919497177942712e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 26032010741.106384, "policy_loss": 0.01591594019865102, "vf_loss": 26032010741.106384, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.08548473249724571, "entropy": 2.4547383531611016, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26879513360.340427, "policy_loss": -0.010847045921106288, "vf_loss": 26879513360.340427, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.010146599976306266, "entropy": 2.2029345542826553, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1657656, "num_agent_steps_sampled": 3315312, "num_steps_trained": 1657656, "num_agent_steps_trained": 3315312}, "done": false, "episodes_total": 1656, "training_iteration": 276, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-15-35", "timestamp": 1624968935, "time_this_iter_s": 46.48913621902466, "time_total_s": 7133.960543632507, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7133.960543632507, "timesteps_since_restore": 0, "iterations_since_restore": 276, "perf": {"cpu_util_percent": 34.21666666666667, "ram_util_percent": 67.36, "gpu_util_percent0": 0.6991666666666666, "vram_util_percent0": 0.3119649477586787}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1729972.649341805, "pol1": 1729972.649341805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1914632.0774474032, -1628515.4211997231, -1764676.1765546869, -1844212.8604627606, -1741861.857513377, -1824286.6821906525, -1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283], "policy_pol1_reward": [1914632.0774474032, 1628515.4211997231, 1764676.1765546869, 1844212.8604627606, 1741861.857513377, 1824286.6821906525, 1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2763410907368015, "mean_inference_ms": 3.825917116825748, "mean_action_processing_ms": 0.19113911992900867, "mean_env_wait_ms": 0.14478840785280972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1663662, "agent_timesteps_total": 3327324, "timers": {"sample_time_ms": 6334.806, "sample_throughput": 948.095, "learn_time_ms": 37136.917, "learn_throughput": 161.726, "update_time_ms": 8.145}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.879245766914063e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 25428459955.744682, "policy_loss": 0.01274790430560391, "vf_loss": 25428459955.744682, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.08861490782905132, "entropy": 2.6659435667890183, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26265843276.255318, "policy_loss": -0.008324100140561449, "vf_loss": 26265843276.255318, "vf_explained_var": -3.804551784725163e-09, "kl": 0.010151919433252608, "entropy": 2.0371512656516217, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1663662, "num_agent_steps_sampled": 3327324, "num_steps_trained": 1663662, "num_agent_steps_trained": 3327324}, "done": false, "episodes_total": 1662, "training_iteration": 277, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-16-21", "timestamp": 1624968981, "time_this_iter_s": 46.18197011947632, "time_total_s": 7180.142513751984, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e35950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7180.142513751984, "timesteps_since_restore": 0, "iterations_since_restore": 277, "perf": {"cpu_util_percent": 34.164406779661014, "ram_util_percent": 67.27627118644068, "gpu_util_percent0": 0.7033898305084745, "vram_util_percent0": 0.3119712315698675}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1729011.0077676903, "pol1": 1729011.0077676903}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1429614.545595443, -1737029.8168462752, -1751522.318725817, -1886635.9932520902, -1881201.6092365126, -1702866.3275927887, -1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115], "policy_pol1_reward": [1429614.545595443, 1737029.8168462752, 1751522.318725817, 1886635.9932520902, 1881201.6092365126, 1702866.3275927887, 1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27660346303226446, "mean_inference_ms": 3.8296109358575676, "mean_action_processing_ms": 0.19130844609765937, "mean_env_wait_ms": 0.14491307335755277, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1669668, "agent_timesteps_total": 3339336, "timers": {"sample_time_ms": 6548.618, "sample_throughput": 917.14, "learn_time_ms": 38991.901, "learn_throughput": 154.032, "update_time_ms": 8.511}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.8188686503711e-07, "cur_lr": 5.000000000000002e-05, "total_loss": 25613808138.893616, "policy_loss": 0.024838810350666655, "vf_loss": 25613808138.893616, "vf_explained_var": -5.0727355649371475e-09, "kl": 0.06256831730616853, "entropy": 2.7437220938662263, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26429991304.17021, "policy_loss": -0.0041959828281022135, "vf_loss": 26429991304.17021, "vf_explained_var": -1.0145471129874295e-08, "kl": 0.0104683865297665, "entropy": 2.0613808530442257, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1669668, "num_agent_steps_sampled": 3339336, "num_steps_trained": 1669668, "num_agent_steps_trained": 3339336}, "done": false, "episodes_total": 1668, "training_iteration": 278, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-17-07", "timestamp": 1624969027, "time_this_iter_s": 45.958133935928345, "time_total_s": 7226.100647687912, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7226.100647687912, "timesteps_since_restore": 0, "iterations_since_restore": 278, "perf": {"cpu_util_percent": 34.30169491525424, "ram_util_percent": 67.27796610169491, "gpu_util_percent0": 0.7091525423728814, "vram_util_percent0": 0.31199979434799757}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1942203.5408312369, "pol1": 1361188.9225749113}, "policy_reward_max": {"pol0": -1361188.9225749113, "pol1": 1942203.5408312369}, "policy_reward_mean": {"pol0": -1733668.8708885184, "pol1": 1733668.8708885184}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1942203.5408312369, -1831279.974625339, -1361188.9225749113, -1655251.195052575, -1840842.7797407303, -1581536.3677237607, -1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625], "policy_pol1_reward": [1942203.5408312369, 1831279.974625339, 1361188.9225749113, 1655251.195052575, 1840842.7797407303, 1581536.3677237607, 1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27689219496195183, "mean_inference_ms": 3.83369959965004, "mean_action_processing_ms": 0.19149547160490674, "mean_env_wait_ms": 0.14505087825241625, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1675674, "agent_timesteps_total": 3351348, "timers": {"sample_time_ms": 6773.387, "sample_throughput": 886.706, "learn_time_ms": 39773.655, "learn_throughput": 151.004, "update_time_ms": 8.537}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3228302975556646e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 26772689549.61702, "policy_loss": 0.0236685902395464, "vf_loss": 26772689549.61702, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.07234459306965484, "entropy": 2.7568009559144366, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 27657919074.042553, "policy_loss": -0.007542337290942669, "vf_loss": 27657919074.042553, "vf_explained_var": -7.609103569450326e-09, "kl": 0.009370510258335383, "entropy": 2.075685115570718, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1675674, "num_agent_steps_sampled": 3351348, "num_steps_trained": 1675674, "num_agent_steps_trained": 3351348}, "done": false, "episodes_total": 1674, "training_iteration": 279, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-17-53", "timestamp": 1624969073, "time_this_iter_s": 45.6973876953125, "time_total_s": 7271.7980353832245, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7271.7980353832245, "timesteps_since_restore": 0, "iterations_since_restore": 279, "perf": {"cpu_util_percent": 34.03728813559322, "ram_util_percent": 67.33898305084746, "gpu_util_percent0": 0.6988135593220338, "vram_util_percent0": 0.31199979434799757}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1923218.0633536724, "pol1": 1454355.7608247597}, "policy_reward_max": {"pol0": -1454355.7608247597, "pol1": 1923218.0633536724}, "policy_reward_mean": {"pol0": -1737694.4294231022, "pol1": 1737694.4294231022}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1747180.1190330498, -1675169.6572721952, -1696556.1587706874, -1798303.6349031578, -1660609.792143713, -1500269.227498344, -1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414], "policy_pol1_reward": [1747180.1190330498, 1675169.6572721952, 1696556.1587706874, 1798303.6349031578, 1660609.792143713, 1500269.227498344, 1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2772238598115955, "mean_inference_ms": 3.8381656370651904, "mean_action_processing_ms": 0.19170028889463797, "mean_env_wait_ms": 0.14520160523394432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1681680, "agent_timesteps_total": 3363360, "timers": {"sample_time_ms": 6739.733, "sample_throughput": 891.133, "learn_time_ms": 39640.322, "learn_throughput": 151.512, "update_time_ms": 8.596}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9842454463334962e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 25655589691.914894, "policy_loss": 0.00638566550580745, "vf_loss": 25655589691.914894, "vf_explained_var": 1.2681839578476684e-08, "kl": 0.03713422260702925, "entropy": 2.71903462105609, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26496879899.234043, "policy_loss": -0.008189415955480108, "vf_loss": 26496879899.234043, "vf_explained_var": -6.340919789238342e-09, "kl": 0.011223921096546853, "entropy": 1.997598592271196, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1681680, "num_agent_steps_sampled": 3363360, "num_steps_trained": 1681680, "num_agent_steps_trained": 3363360}, "done": false, "episodes_total": 1680, "training_iteration": 280, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-18-39", "timestamp": 1624969119, "time_this_iter_s": 46.270716428756714, "time_total_s": 7318.068751811981, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdbf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7318.068751811981, "timesteps_since_restore": 0, "iterations_since_restore": 280, "perf": {"cpu_util_percent": 34.14067796610169, "ram_util_percent": 67.21016949152542, "gpu_util_percent0": 0.7011864406779662, "vram_util_percent0": 0.31199408179237137}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1923218.0633536724, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1923218.0633536724}, "policy_reward_mean": {"pol0": -1741889.5039604872, "pol1": 1741889.5039604872}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1690650.6566019086, -1910589.386813676, -1693208.926211231, -1501029.1232730816, -1755327.8129715584, -1801774.8852819786, -1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842], "policy_pol1_reward": [1690650.6566019086, 1910589.386813676, 1693208.926211231, 1501029.1232730816, 1755327.8129715584, 1801774.8852819786, 1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2775937067143712, "mean_inference_ms": 3.8429960616861263, "mean_action_processing_ms": 0.19192160105791728, "mean_env_wait_ms": 0.14536436776091666, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1687686, "agent_timesteps_total": 3375372, "timers": {"sample_time_ms": 6719.315, "sample_throughput": 893.841, "learn_time_ms": 39591.273, "learn_throughput": 151.7, "update_time_ms": 8.582}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9763681695002463e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 25395409026.723404, "policy_loss": -0.0021819400581273626, "vf_loss": 25395409026.723404, "vf_explained_var": 1.3315931823854044e-07, "kl": 0.02149582582902401, "entropy": 2.5499551651325634, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26246761711.659573, "policy_loss": -0.0058988891046573505, "vf_loss": 26246761711.659573, "vf_explained_var": 1.1160018686950934e-07, "kl": 0.008424777468230496, "entropy": 1.9257722205304084, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1687686, "num_agent_steps_sampled": 3375372, "num_steps_trained": 1687686, "num_agent_steps_trained": 3375372}, "done": false, "episodes_total": 1686, "training_iteration": 281, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-19-25", "timestamp": 1624969165, "time_this_iter_s": 46.10018706321716, "time_total_s": 7364.168938875198, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05c77b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05c7b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7364.168938875198, "timesteps_since_restore": 0, "iterations_since_restore": 281, "perf": {"cpu_util_percent": 33.81166666666666, "ram_util_percent": 67.19666666666666, "gpu_util_percent0": 0.7026666666666667, "vram_util_percent0": 0.3118722615436468}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1748454.0795075977, "pol1": 1748454.0795075977}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1760729.1601704874, -1782678.0299136173, -1766898.0236086678, -1687758.2247572558, -1474988.5669881648, -1710047.3594024866, -1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973], "policy_pol1_reward": [1760729.1601704874, 1782678.0299136173, 1766898.0236086678, 1687758.2247572558, 1474988.5669881648, 1710047.3594024866, 1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27798872778372546, "mean_inference_ms": 3.8482186501036573, "mean_action_processing_ms": 0.1921604877592387, "mean_env_wait_ms": 0.14554005884687757, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1693692, "agent_timesteps_total": 3387384, "timers": {"sample_time_ms": 6730.399, "sample_throughput": 892.369, "learn_time_ms": 39484.94, "learn_throughput": 152.109, "update_time_ms": 8.62}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.464552254250368e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 27545889334.468086, "policy_loss": 0.0005474866149907416, "vf_loss": 27545889334.468086, "vf_explained_var": 1.3823205335938837e-07, "kl": 0.030350297491284126, "entropy": 2.5319251456159226, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 28445816439.82979, "policy_loss": -0.0067582257250522046, "vf_loss": 28445816439.82979, "vf_explained_var": 1.2301384799684456e-07, "kl": 0.00804046272954091, "entropy": 2.1136064377236874, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1693692, "num_agent_steps_sampled": 3387384, "num_steps_trained": 1693692, "num_agent_steps_trained": 3387384}, "done": false, "episodes_total": 1692, "training_iteration": 282, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-20-11", "timestamp": 1624969211, "time_this_iter_s": 45.927491664886475, "time_total_s": 7410.096430540085, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e358c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7410.096430540085, "timesteps_since_restore": 0, "iterations_since_restore": 282, "perf": {"cpu_util_percent": 34.16271186440678, "ram_util_percent": 67.26779661016948, "gpu_util_percent0": 0.7116949152542373, "vram_util_percent0": 0.31191696229142035}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1746108.849513796, "pol1": 1746108.849513796}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1904031.141063848, -1640659.7505535025, -1827893.4840115132, -1616791.8858745983, -1803684.6193508385, -1789383.0628104252, -1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317], "policy_pol1_reward": [1904031.141063848, 1640659.7505535025, 1827893.4840115132, 1616791.8858745983, 1803684.6193508385, 1789383.0628104252, 1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27841812882877354, "mean_inference_ms": 3.8537693270981186, "mean_action_processing_ms": 0.1924143278062994, "mean_env_wait_ms": 0.14572712515457392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1699698, "agent_timesteps_total": 3399396, "timers": {"sample_time_ms": 6728.911, "sample_throughput": 892.566, "learn_time_ms": 39381.162, "learn_throughput": 152.509, "update_time_ms": 8.495}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.696828381375549e-06, "cur_lr": 5.000000000000002e-05, "total_loss": 22654322557.276596, "policy_loss": 0.02593797116362034, "vf_loss": 22654322557.276596, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.05922384988120262, "entropy": 2.8514033023347247, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 23423937601.361702, "policy_loss": -0.009777936172929215, "vf_loss": 23423937601.361702, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.008789036700383146, "entropy": 1.9638820962702974, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1699698, "num_agent_steps_sampled": 3399396, "num_steps_trained": 1699698, "num_agent_steps_trained": 3399396}, "done": false, "episodes_total": 1698, "training_iteration": 283, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-20-57", "timestamp": 1624969257, "time_this_iter_s": 45.68396520614624, "time_total_s": 7455.780395746231, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f06278c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7455.780395746231, "timesteps_since_restore": 0, "iterations_since_restore": 283, "perf": {"cpu_util_percent": 33.73275862068966, "ram_util_percent": 67.35689655172415, "gpu_util_percent0": 0.6979310344827587, "vram_util_percent0": 0.31193414920446766}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1745147.9959768236, "pol1": 1745147.9959768236}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1727352.022805709, -1481717.7882158635, -1835751.523371215, -1490386.5230168386, -1557516.9098809678, -1759618.377266237, -1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714], "policy_pol1_reward": [1727352.022805709, 1481717.7882158635, 1835751.523371215, 1490386.5230168386, 1557516.9098809678, 1759618.377266237, 1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2788689476536531, "mean_inference_ms": 3.8597316352146027, "mean_action_processing_ms": 0.19268769083337264, "mean_env_wait_ms": 0.14592813431904156, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1705704, "agent_timesteps_total": 3411408, "timers": {"sample_time_ms": 6740.36, "sample_throughput": 891.05, "learn_time_ms": 39384.834, "learn_throughput": 152.495, "update_time_ms": 8.243}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0045242572063328e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24964416446.638298, "policy_loss": 0.003925570108472032, "vf_loss": 24964416446.638298, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.04257471035135553, "entropy": 2.783909503449785, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 25801404677.446808, "policy_loss": -0.007579745447382014, "vf_loss": 25801404677.446808, "vf_explained_var": 0.0, "kl": 0.008709305193909306, "entropy": 2.1192515352939036, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1705704, "num_agent_steps_sampled": 3411408, "num_steps_trained": 1705704, "num_agent_steps_trained": 3411408}, "done": false, "episodes_total": 1704, "training_iteration": 284, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-21-43", "timestamp": 1624969303, "time_this_iter_s": 46.3329439163208, "time_total_s": 7502.113339662552, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eacea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7502.113339662552, "timesteps_since_restore": 0, "iterations_since_restore": 284, "perf": {"cpu_util_percent": 33.95333333333333, "ram_util_percent": 67.27666666666667, "gpu_util_percent0": 0.7061666666666666, "vram_util_percent0": 0.31196213908549614}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1752215.8877609328, "pol1": 1752215.8877609328}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1838475.251492585, -1758121.4829472187, -1454355.7608247597, -1823734.6460810641, -1853541.3984049894, -1797755.3467221577, -1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545], "policy_pol1_reward": [1838475.251492585, 1758121.4829472187, 1454355.7608247597, 1823734.6460810641, 1853541.3984049894, 1797755.3467221577, 1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27935464201672194, "mean_inference_ms": 3.8660598366677164, "mean_action_processing_ms": 0.19297792841625294, "mean_env_wait_ms": 0.14614154975081192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1711710, "agent_timesteps_total": 3423420, "timers": {"sample_time_ms": 6719.759, "sample_throughput": 893.782, "learn_time_ms": 39356.009, "learn_throughput": 152.607, "update_time_ms": 8.263}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5067863858094993e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 25239957198.97872, "policy_loss": 0.001240263078758057, "vf_loss": 25239957198.97872, "vf_explained_var": -3.550914939864924e-08, "kl": 0.04474529219751663, "entropy": 2.8289864570536514, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26091566624.68085, "policy_loss": -0.005515717544612732, "vf_loss": 26091566624.68085, "vf_explained_var": 0.0, "kl": 0.006570495803781012, "entropy": 2.09876079254962, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1711710, "num_agent_steps_sampled": 3423420, "num_steps_trained": 1711710, "num_agent_steps_trained": 3423420}, "done": false, "episodes_total": 1710, "training_iteration": 285, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-22-30", "timestamp": 1624969350, "time_this_iter_s": 46.309170722961426, "time_total_s": 7548.422510385513, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7548.422510385513, "timesteps_since_restore": 0, "iterations_since_restore": 285, "perf": {"cpu_util_percent": 34.53050847457627, "ram_util_percent": 67.46271186440677, "gpu_util_percent0": 0.7045762711864407, "vram_util_percent0": 0.3119455250695504}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1749841.1569542503, "pol1": 1749841.1569542503}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1820671.9629774813, -1614828.787267939, -1857420.1829397948, -1870300.8975121363, -1798995.512243669, -1587757.254431989, -1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738], "policy_pol1_reward": [1820671.9629774813, 1614828.787267939, 1857420.1829397948, 1870300.8975121363, 1798995.512243669, 1587757.254431989, 1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27985227681498714, "mean_inference_ms": 3.8726178312063246, "mean_action_processing_ms": 0.1932784525828604, "mean_env_wait_ms": 0.14636239703571663, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1717716, "agent_timesteps_total": 3435432, "timers": {"sample_time_ms": 6713.471, "sample_throughput": 894.619, "learn_time_ms": 39298.114, "learn_throughput": 152.832, "update_time_ms": 8.282}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.260179578714249e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24050400495.659573, "policy_loss": 0.002268894595351625, "vf_loss": 24050400495.659573, "vf_explained_var": -8.87728734966231e-09, "kl": 0.03581646425609893, "entropy": 2.546704576370564, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 24852274372.085106, "policy_loss": -0.00917574915876414, "vf_loss": 24852274372.085106, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.009942156232972729, "entropy": 2.0541568563339556, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1717716, "num_agent_steps_sampled": 3435432, "num_steps_trained": 1717716, "num_agent_steps_trained": 3435432}, "done": false, "episodes_total": 1716, "training_iteration": 286, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-23-16", "timestamp": 1624969396, "time_this_iter_s": 45.8472535610199, "time_total_s": 7594.269763946533, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cd1e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cdea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7594.269763946533, "timesteps_since_restore": 0, "iterations_since_restore": 286, "perf": {"cpu_util_percent": 34.291525423728814, "ram_util_percent": 67.36949152542373, "gpu_util_percent0": 0.7005084745762712, "vram_util_percent0": 0.31200265062581056}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1744867.7680194024, "pol1": 1744867.7680194024}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1651741.5031312623, -1740442.3402123747, -1627872.588278944, -1643116.0769441759, -1737976.5575734098, -1783457.5077832425, -1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453], "policy_pol1_reward": [1651741.5031312623, 1740442.3402123747, 1627872.588278944, 1643116.0769441759, 1737976.5575734098, 1783457.5077832425, 1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28034499713965, "mean_inference_ms": 3.879084260702359, "mean_action_processing_ms": 0.1935740858467711, "mean_env_wait_ms": 0.14658012256730854, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1723722, "agent_timesteps_total": 3447444, "timers": {"sample_time_ms": 6703.431, "sample_throughput": 895.959, "learn_time_ms": 39276.076, "learn_throughput": 152.918, "update_time_ms": 8.344}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.3902693680713736e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 22967079739.914894, "policy_loss": 0.005198891888907615, "vf_loss": 22967079739.914894, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.04216293316889316, "entropy": 2.42306371952625, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 23757893109.106384, "policy_loss": -0.008048655742660482, "vf_loss": 23757893109.106384, "vf_explained_var": 1.1794110577056927e-07, "kl": 0.008153720560701603, "entropy": 2.1532046084708356, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1723722, "num_agent_steps_sampled": 3447444, "num_steps_trained": 1723722, "num_agent_steps_trained": 3447444}, "done": false, "episodes_total": 1722, "training_iteration": 287, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-24-01", "timestamp": 1624969441, "time_this_iter_s": 45.862213373184204, "time_total_s": 7640.131977319717, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdd08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7640.131977319717, "timesteps_since_restore": 0, "iterations_since_restore": 287, "perf": {"cpu_util_percent": 34.288135593220346, "ram_util_percent": 67.27457627118643, "gpu_util_percent0": 0.7066101694915256, "vram_util_percent0": 0.3093834438712847}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1746662.5175817134, "pol1": 1746662.5175817134}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1827656.3875777638, -1560540.578603575, -1725422.2836789128, -1672936.0105888036, -1632818.9285464792, -1533922.5617707006, -1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453, -1629201.5168859079, -1643835.5458656189, -1715646.0937663568, -1812654.0173507358, -1723146.4655057727, -1839597.89078015], "policy_pol1_reward": [1827656.3875777638, 1560540.578603575, 1725422.2836789128, 1672936.0105888036, 1632818.9285464792, 1533922.5617707006, 1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453, 1629201.5168859079, 1643835.5458656189, 1715646.0937663568, 1812654.0173507358, 1723146.4655057727, 1839597.89078015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2808328830297367, "mean_inference_ms": 3.8854693843489327, "mean_action_processing_ms": 0.19386583399448015, "mean_env_wait_ms": 0.14679524743558392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1729728, "agent_timesteps_total": 3459456, "timers": {"sample_time_ms": 6699.221, "sample_throughput": 896.522, "learn_time_ms": 39241.403, "learn_throughput": 153.053, "update_time_ms": 8.319}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.085404052107062e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24122881873.70213, "policy_loss": 0.012076572415993568, "vf_loss": 24122881873.70213, "vf_explained_var": 7.101829879729848e-08, "kl": 0.049205890202775916, "entropy": 2.554284263164439, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 24941991500.255318, "policy_loss": -0.00772280198462466, "vf_loss": 24941991500.255318, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.006954933625665751, "entropy": 2.2500960623964352, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1729728, "num_agent_steps_sampled": 3459456, "num_steps_trained": 1729728, "num_agent_steps_trained": 3459456}, "done": false, "episodes_total": 1728, "training_iteration": 288, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-24-47", "timestamp": 1624969487, "time_this_iter_s": 45.56782150268555, "time_total_s": 7685.699798822403, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f05cdf28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7685.699798822403, "timesteps_since_restore": 0, "iterations_since_restore": 288, "perf": {"cpu_util_percent": 33.93220338983051, "ram_util_percent": 67.28983050847458, "gpu_util_percent0": 0.7015254237288134, "vram_util_percent0": 0.30500476998394765}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1750010.480534363, "pol1": 1750010.480534363}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1825724.487403504, -1797961.7919843877, -1719675.020702196, -1836594.7615226822, -1555742.6208435518, -1783225.8990201538, -1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453, -1629201.5168859079, -1643835.5458656189, -1715646.0937663568, -1812654.0173507358, -1723146.4655057727, -1839597.89078015, -1364972.5833388316, -1641596.7424844748, -1746974.4916876145, -1829475.6986553483, -1841973.0557421749, -1863100.4741227499], "policy_pol1_reward": [1825724.487403504, 1797961.7919843877, 1719675.020702196, 1836594.7615226822, 1555742.6208435518, 1783225.8990201538, 1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453, 1629201.5168859079, 1643835.5458656189, 1715646.0937663568, 1812654.0173507358, 1723146.4655057727, 1839597.89078015, 1364972.5833388316, 1641596.7424844748, 1746974.4916876145, 1829475.6986553483, 1841973.0557421749, 1863100.4741227499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28133044099537347, "mean_inference_ms": 3.891819037211436, "mean_action_processing_ms": 0.19415553640966898, "mean_env_wait_ms": 0.14700926427519614, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1735734, "agent_timesteps_total": 3471468, "timers": {"sample_time_ms": 6695.308, "sample_throughput": 897.046, "learn_time_ms": 39274.542, "learn_throughput": 152.923, "update_time_ms": 8.262}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.628106078160591e-05, "cur_lr": 5.000000000000002e-05, "total_loss": 24196889708.93617, "policy_loss": 0.01914446224319808, "vf_loss": 24196889708.93617, "vf_explained_var": -1.5598662628235616e-07, "kl": 0.07684016941075629, "entropy": 2.5478258031479855, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 25019930013.957447, "policy_loss": -0.009119144066217099, "vf_loss": 25019930013.957447, "vf_explained_var": -2.4095495376741383e-08, "kl": 0.009317544566348512, "entropy": 2.2380338425331927, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1735734, "num_agent_steps_sampled": 3471468, "num_steps_trained": 1735734, "num_agent_steps_trained": 3471468}, "done": false, "episodes_total": 1734, "training_iteration": 289, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-25-33", "timestamp": 1624969533, "time_this_iter_s": 45.98646688461304, "time_total_s": 7731.686265707016, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0e357b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0e35488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7731.686265707016, "timesteps_since_restore": 0, "iterations_since_restore": 289, "perf": {"cpu_util_percent": 34.11694915254237, "ram_util_percent": 67.30000000000001, "gpu_util_percent0": 0.7018644067796611, "vram_util_percent0": 0.3049505007055006}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1754480.711472755, "pol1": 1754480.711472755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1747950.8638809866, -1601830.8040900487, -1774833.6309629437, -1901408.9626920708, -1767546.8531842963, -1849729.0632007709, -1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453, -1629201.5168859079, -1643835.5458656189, -1715646.0937663568, -1812654.0173507358, -1723146.4655057727, -1839597.89078015, -1364972.5833388316, -1641596.7424844748, -1746974.4916876145, -1829475.6986553483, -1841973.0557421749, -1863100.4741227499, -1846764.1937978023, -1753941.8370171804, -1788465.3701638936, -1869992.946362851, -1801370.3587783875, -1905412.9691955894], "policy_pol1_reward": [1747950.8638809866, 1601830.8040900487, 1774833.6309629437, 1901408.9626920708, 1767546.8531842963, 1849729.0632007709, 1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453, 1629201.5168859079, 1643835.5458656189, 1715646.0937663568, 1812654.0173507358, 1723146.4655057727, 1839597.89078015, 1364972.5833388316, 1641596.7424844748, 1746974.4916876145, 1829475.6986553483, 1841973.0557421749, 1863100.4741227499, 1846764.1937978023, 1753941.8370171804, 1788465.3701638936, 1869992.946362851, 1801370.3587783875, 1905412.9691955894]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28182366281378396, "mean_inference_ms": 3.898087633568279, "mean_action_processing_ms": 0.19444146111846844, "mean_env_wait_ms": 0.14722026998903093, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1741740, "agent_timesteps_total": 3483480, "timers": {"sample_time_ms": 6684.427, "sample_throughput": 898.506, "learn_time_ms": 39264.937, "learn_throughput": 152.961, "update_time_ms": 8.32}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00011442159117240883, "cur_lr": 5.000000000000002e-05, "total_loss": 27227807177.531914, "policy_loss": 0.0249479611978886, "vf_loss": 27227807177.531914, "vf_explained_var": -8.496832037963031e-08, "kl": 0.11881734288119256, "entropy": 2.4550781554364143, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 28160458011.234043, "policy_loss": -0.009567482198806519, "vf_loss": 28160458011.234043, "vf_explained_var": -3.550914939864924e-08, "kl": 0.009611288521518099, "entropy": 2.135970602644251, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1741740, "num_agent_steps_sampled": 3483480, "num_steps_trained": 1741740, "num_agent_steps_trained": 3483480}, "done": false, "episodes_total": 1740, "training_iteration": 290, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-26-19", "timestamp": 1624969579, "time_this_iter_s": 46.06664824485779, "time_total_s": 7777.752913951874, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f06277b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7777.752913951874, "timesteps_since_restore": 0, "iterations_since_restore": 290, "perf": {"cpu_util_percent": 34.349152542372885, "ram_util_percent": 67.2949152542373, "gpu_util_percent0": 0.687457627118644, "vram_util_percent0": 0.3091178100346752}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1748481.7351894986, "pol1": 1748481.7351894986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1895606.2480228932, -1780537.4495605729, -1769245.1407645817, -1575030.5180567764, -1624077.63801439, -1724520.0229956864, -1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453, -1629201.5168859079, -1643835.5458656189, -1715646.0937663568, -1812654.0173507358, -1723146.4655057727, -1839597.89078015, -1364972.5833388316, -1641596.7424844748, -1746974.4916876145, -1829475.6986553483, -1841973.0557421749, -1863100.4741227499, -1846764.1937978023, -1753941.8370171804, -1788465.3701638936, -1869992.946362851, -1801370.3587783875, -1905412.9691955894, -1501137.6101616484, -1604617.7051297966, -1666913.409121419, -1856918.7071053414, -1748609.0815998733, -1665206.036567402], "policy_pol1_reward": [1895606.2480228932, 1780537.4495605729, 1769245.1407645817, 1575030.5180567764, 1624077.63801439, 1724520.0229956864, 1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453, 1629201.5168859079, 1643835.5458656189, 1715646.0937663568, 1812654.0173507358, 1723146.4655057727, 1839597.89078015, 1364972.5833388316, 1641596.7424844748, 1746974.4916876145, 1829475.6986553483, 1841973.0557421749, 1863100.4741227499, 1846764.1937978023, 1753941.8370171804, 1788465.3701638936, 1869992.946362851, 1801370.3587783875, 1905412.9691955894, 1501137.6101616484, 1604617.7051297966, 1666913.409121419, 1856918.7071053414, 1748609.0815998733, 1665206.036567402]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28231036774327567, "mean_inference_ms": 3.9042919524420063, "mean_action_processing_ms": 0.1947241320560847, "mean_env_wait_ms": 0.14742861405176963, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1747746, "agent_timesteps_total": 3495492, "timers": {"sample_time_ms": 6673.406, "sample_throughput": 899.99, "learn_time_ms": 39232.141, "learn_throughput": 153.089, "update_time_ms": 8.328}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001716323867586133, "cur_lr": 5.000000000000002e-05, "total_loss": 22749437167.659573, "policy_loss": 0.02642829191098188, "vf_loss": 22749437167.659573, "vf_explained_var": 3.550914939864924e-08, "kl": 0.12487453491763865, "entropy": 2.482887993467615, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 23522711639.148937, "policy_loss": -0.00846295833508385, "vf_loss": 23522711639.148937, "vf_explained_var": -4.945917453369475e-08, "kl": 0.009747556549437503, "entropy": 2.2867310808060015, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1747746, "num_agent_steps_sampled": 3495492, "num_steps_trained": 1747746, "num_agent_steps_trained": 3495492}, "done": false, "episodes_total": 1746, "training_iteration": 291, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-27-05", "timestamp": 1624969625, "time_this_iter_s": 45.688785791397095, "time_total_s": 7823.441699743271, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0627ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0627b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7823.441699743271, "timesteps_since_restore": 0, "iterations_since_restore": 291, "perf": {"cpu_util_percent": 33.60677966101695, "ram_util_percent": 67.31186440677965, "gpu_util_percent0": 0.7055932203389829, "vram_util_percent0": 0.31200265062581056}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1750650.30224524, "pol1": 1750650.30224524}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1877914.3256942118, -1783248.9188193004, -1897848.9712896477, -1780964.5149148733, -1755475.3831434213, -1899445.1481135858, -1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453, -1629201.5168859079, -1643835.5458656189, -1715646.0937663568, -1812654.0173507358, -1723146.4655057727, -1839597.89078015, -1364972.5833388316, -1641596.7424844748, -1746974.4916876145, -1829475.6986553483, -1841973.0557421749, -1863100.4741227499, -1846764.1937978023, -1753941.8370171804, -1788465.3701638936, -1869992.946362851, -1801370.3587783875, -1905412.9691955894, -1501137.6101616484, -1604617.7051297966, -1666913.409121419, -1856918.7071053414, -1748609.0815998733, -1665206.036567402, -1889391.142950477, -1412491.1311983885, -1808844.6596155867, -1879254.7545038075, -1719472.9875541308, -1876419.0471666364], "policy_pol1_reward": [1877914.3256942118, 1783248.9188193004, 1897848.9712896477, 1780964.5149148733, 1755475.3831434213, 1899445.1481135858, 1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453, 1629201.5168859079, 1643835.5458656189, 1715646.0937663568, 1812654.0173507358, 1723146.4655057727, 1839597.89078015, 1364972.5833388316, 1641596.7424844748, 1746974.4916876145, 1829475.6986553483, 1841973.0557421749, 1863100.4741227499, 1846764.1937978023, 1753941.8370171804, 1788465.3701638936, 1869992.946362851, 1801370.3587783875, 1905412.9691955894, 1501137.6101616484, 1604617.7051297966, 1666913.409121419, 1856918.7071053414, 1748609.0815998733, 1665206.036567402, 1889391.142950477, 1412491.1311983885, 1808844.6596155867, 1879254.7545038075, 1719472.9875541308, 1876419.0471666364]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28279610031612223, "mean_inference_ms": 3.9104265443907575, "mean_action_processing_ms": 0.19500461590744034, "mean_env_wait_ms": 0.14763434558852667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1753752, "agent_timesteps_total": 3507504, "timers": {"sample_time_ms": 6676.487, "sample_throughput": 899.575, "learn_time_ms": 39196.085, "learn_throughput": 153.23, "update_time_ms": 8.283}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00025744858013792, "cur_lr": 5.000000000000002e-05, "total_loss": 25572086500.765957, "policy_loss": 0.020161212976784148, "vf_loss": 25572086500.765957, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.0772304301883312, "entropy": 2.4565603327243886, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26450348685.61702, "policy_loss": -0.007693140391022601, "vf_loss": 26450348685.61702, "vf_explained_var": -1.2555021555726853e-07, "kl": 0.008420012068954553, "entropy": 2.444449850853453, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1753752, "num_agent_steps_sampled": 3507504, "num_steps_trained": 1753752, "num_agent_steps_trained": 3507504}, "done": false, "episodes_total": 1752, "training_iteration": 292, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-27-51", "timestamp": 1624969671, "time_this_iter_s": 45.598679542541504, "time_total_s": 7869.040379285812, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f7aedcc3730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f05cd488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7869.040379285812, "timesteps_since_restore": 0, "iterations_since_restore": 292, "perf": {"cpu_util_percent": 34.27413793103448, "ram_util_percent": 67.36379310344827, "gpu_util_percent0": 0.701551724137931, "vram_util_percent0": 0.3120009762560581}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1746579.1013439854, "pol1": 1746579.1013439854}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1566503.75475602, -1685930.9490473324, -1772913.1478386417, -1864001.9341226283, -1720401.7042177203, -1734107.7941686485, -1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453, -1629201.5168859079, -1643835.5458656189, -1715646.0937663568, -1812654.0173507358, -1723146.4655057727, -1839597.89078015, -1364972.5833388316, -1641596.7424844748, -1746974.4916876145, -1829475.6986553483, -1841973.0557421749, -1863100.4741227499, -1846764.1937978023, -1753941.8370171804, -1788465.3701638936, -1869992.946362851, -1801370.3587783875, -1905412.9691955894, -1501137.6101616484, -1604617.7051297966, -1666913.409121419, -1856918.7071053414, -1748609.0815998733, -1665206.036567402, -1889391.142950477, -1412491.1311983885, -1808844.6596155867, -1879254.7545038075, -1719472.9875541308, -1876419.0471666364, -1804800.5781749717, -1843664.6644446617, -1571748.0581827485, -1738629.2604097866, -1712846.042146255, -1916088.5684911632], "policy_pol1_reward": [1566503.75475602, 1685930.9490473324, 1772913.1478386417, 1864001.9341226283, 1720401.7042177203, 1734107.7941686485, 1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453, 1629201.5168859079, 1643835.5458656189, 1715646.0937663568, 1812654.0173507358, 1723146.4655057727, 1839597.89078015, 1364972.5833388316, 1641596.7424844748, 1746974.4916876145, 1829475.6986553483, 1841973.0557421749, 1863100.4741227499, 1846764.1937978023, 1753941.8370171804, 1788465.3701638936, 1869992.946362851, 1801370.3587783875, 1905412.9691955894, 1501137.6101616484, 1604617.7051297966, 1666913.409121419, 1856918.7071053414, 1748609.0815998733, 1665206.036567402, 1889391.142950477, 1412491.1311983885, 1808844.6596155867, 1879254.7545038075, 1719472.9875541308, 1876419.0471666364, 1804800.5781749717, 1843664.6644446617, 1571748.0581827485, 1738629.2604097866, 1712846.042146255, 1916088.5684911632]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2832658213642139, "mean_inference_ms": 3.9165385524349237, "mean_action_processing_ms": 0.19528431286282522, "mean_env_wait_ms": 0.14783916663369856, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1759758, "agent_timesteps_total": 3519516, "timers": {"sample_time_ms": 6692.715, "sample_throughput": 897.394, "learn_time_ms": 39207.779, "learn_throughput": 153.184, "update_time_ms": 8.328}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00038617287020687976, "cur_lr": 5.000000000000002e-05, "total_loss": 25507242855.48936, "policy_loss": 0.008886222351104655, "vf_loss": 25507242855.48936, "vf_explained_var": -1.3696386247374903e-07, "kl": 0.05693205826460047, "entropy": 2.232744125609702, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 26367536759.82979, "policy_loss": -0.004908073832221488, "vf_loss": 26367536759.82979, "vf_explained_var": -4.311825207992115e-08, "kl": 0.0070976306723945955, "entropy": 2.331049234309095, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1759758, "num_agent_steps_sampled": 3519516, "num_steps_trained": 1759758, "num_agent_steps_trained": 3519516}, "done": false, "episodes_total": 1758, "training_iteration": 293, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-28-37", "timestamp": 1624969717, "time_this_iter_s": 45.96287441253662, "time_total_s": 7915.003253698349, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7915.003253698349, "timesteps_since_restore": 0, "iterations_since_restore": 293, "perf": {"cpu_util_percent": 34.05084745762712, "ram_util_percent": 67.32881355932203, "gpu_util_percent0": 0.6989830508474577, "vram_util_percent0": 0.31198265668111935}, "trial_id": "01f89_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1934044.0910425973, "pol1": 1315380.2833825338}, "policy_reward_max": {"pol0": -1315380.2833825338, "pol1": 1934044.0910425973}, "policy_reward_mean": {"pol0": -1746245.6723492781, "pol1": 1746245.6723492781}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1765428.1787929118, -1856300.9848579857, -1699642.81448099, -1846139.4414389115, -1923218.0633536724, -1772634.5177987984, -1815249.3599590238, -1829408.8651320185, -1714993.5783387779, -1799152.5387494625, -1793721.2433319963, -1859008.9580172086, -1760058.440454158, -1462874.192539708, -1859683.0911143702, -1879512.708549414, -1808803.510099024, -1895472.7789912287, -1872940.9075810902, -1869737.1576673822, -1315380.2833825338, -1735261.40563842, -1744505.8506338305, -1907126.4108239338, -1776664.0764433444, -1897424.4205809387, -1749273.49633982, -1934044.0910425973, -1895584.5914617137, -1615438.6482029671, -1732786.8161242974, -1726876.6788959634, -1434255.5819462973, -1543634.048829317, -1694909.9749299304, -1690020.9695943324, -1782251.8684277718, -1904677.8062770395, -1713493.2295650097, -1701004.7411733714, -1587224.4958086833, -1809935.1740263847, -1790179.6714297575, -1856383.3875658996, -1746068.0934824608, -1769341.500654545, -1671559.6973354465, -1845950.9265506826, -1770171.2546306397, -1761125.7459783724, -1755842.2576716489, -1483860.9236377738, -1750175.7178208735, -1324261.74445904, -1781138.6033277663, -1758200.2816875747, -1916751.3591613693, -1522107.9974315453, -1629201.5168859079, -1643835.5458656189, -1715646.0937663568, -1812654.0173507358, -1723146.4655057727, -1839597.89078015, -1364972.5833388316, -1641596.7424844748, -1746974.4916876145, -1829475.6986553483, -1841973.0557421749, -1863100.4741227499, -1846764.1937978023, -1753941.8370171804, -1788465.3701638936, -1869992.946362851, -1801370.3587783875, -1905412.9691955894, -1501137.6101616484, -1604617.7051297966, -1666913.409121419, -1856918.7071053414, -1748609.0815998733, -1665206.036567402, -1889391.142950477, -1412491.1311983885, -1808844.6596155867, -1879254.7545038075, -1719472.9875541308, -1876419.0471666364, -1804800.5781749717, -1843664.6644446617, -1571748.0581827485, -1738629.2604097866, -1712846.042146255, -1916088.5684911632, -1757723.707045645, -1546103.3887640454, -1837531.6916171787, -1696802.0607156858, -1684487.8136385558, -1787867.7228991084], "policy_pol1_reward": [1765428.1787929118, 1856300.9848579857, 1699642.81448099, 1846139.4414389115, 1923218.0633536724, 1772634.5177987984, 1815249.3599590238, 1829408.8651320185, 1714993.5783387779, 1799152.5387494625, 1793721.2433319963, 1859008.9580172086, 1760058.440454158, 1462874.192539708, 1859683.0911143702, 1879512.708549414, 1808803.510099024, 1895472.7789912287, 1872940.9075810902, 1869737.1576673822, 1315380.2833825338, 1735261.40563842, 1744505.8506338305, 1907126.4108239338, 1776664.0764433444, 1897424.4205809387, 1749273.49633982, 1934044.0910425973, 1895584.5914617137, 1615438.6482029671, 1732786.8161242974, 1726876.6788959634, 1434255.5819462973, 1543634.048829317, 1694909.9749299304, 1690020.9695943324, 1782251.8684277718, 1904677.8062770395, 1713493.2295650097, 1701004.7411733714, 1587224.4958086833, 1809935.1740263847, 1790179.6714297575, 1856383.3875658996, 1746068.0934824608, 1769341.500654545, 1671559.6973354465, 1845950.9265506826, 1770171.2546306397, 1761125.7459783724, 1755842.2576716489, 1483860.9236377738, 1750175.7178208735, 1324261.74445904, 1781138.6033277663, 1758200.2816875747, 1916751.3591613693, 1522107.9974315453, 1629201.5168859079, 1643835.5458656189, 1715646.0937663568, 1812654.0173507358, 1723146.4655057727, 1839597.89078015, 1364972.5833388316, 1641596.7424844748, 1746974.4916876145, 1829475.6986553483, 1841973.0557421749, 1863100.4741227499, 1846764.1937978023, 1753941.8370171804, 1788465.3701638936, 1869992.946362851, 1801370.3587783875, 1905412.9691955894, 1501137.6101616484, 1604617.7051297966, 1666913.409121419, 1856918.7071053414, 1748609.0815998733, 1665206.036567402, 1889391.142950477, 1412491.1311983885, 1808844.6596155867, 1879254.7545038075, 1719472.9875541308, 1876419.0471666364, 1804800.5781749717, 1843664.6644446617, 1571748.0581827485, 1738629.2604097866, 1712846.042146255, 1916088.5684911632, 1757723.707045645, 1546103.3887640454, 1837531.6916171787, 1696802.0607156858, 1684487.8136385558, 1787867.7228991084]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.283728611189462, "mean_inference_ms": 3.9225876283355996, "mean_action_processing_ms": 0.1955608531185052, "mean_env_wait_ms": 0.148041644505876, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 1765764, "agent_timesteps_total": 3531528, "timers": {"sample_time_ms": 6668.877, "sample_throughput": 900.601, "learn_time_ms": 39186.338, "learn_throughput": 153.268, "update_time_ms": 8.274}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0005792593053103199, "cur_lr": 5.000000000000002e-05, "total_loss": 23978146358.468086, "policy_loss": -0.001852953608365769, "vf_loss": 23978146358.468086, "vf_explained_var": -5.0727358313906734e-08, "kl": 0.03162097403819256, "entropy": 2.3470952460106385, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18984374999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 24793464352.68085, "policy_loss": -0.009764182202993556, "vf_loss": 24793464352.68085, "vf_explained_var": -4.311825207992115e-08, "kl": 0.00986563420279863, "entropy": 2.327812504261098, "entropy_coeff": 0.0}}}, "num_steps_sampled": 1765764, "num_agent_steps_sampled": 3531528, "num_steps_trained": 1765764, "num_agent_steps_trained": 3531528}, "done": false, "episodes_total": 1764, "training_iteration": 294, "experiment_id": "4ed1e832e08f487aaacf365bf3eca9bf", "date": "2021-06-29_15-29-23", "timestamp": 1624969763, "time_this_iter_s": 45.879204750061035, "time_total_s": 7960.88245844841, "pid": 8072, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f79f0eac378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f79f0eac048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7960.88245844841, "timesteps_since_restore": 0, "iterations_since_restore": 294, "perf": {"cpu_util_percent": 34.045762711864406, "ram_util_percent": 67.35593220338983, "gpu_util_percent0": 0.7020338983050849, "vram_util_percent0": 0.3119626627364284}, "trial_id": "01f89_00000"}
