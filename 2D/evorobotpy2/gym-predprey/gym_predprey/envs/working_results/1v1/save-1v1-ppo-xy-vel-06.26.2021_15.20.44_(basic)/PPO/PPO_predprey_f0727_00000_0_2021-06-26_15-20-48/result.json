{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 10990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -10990.0}, "policy_reward_mean": {"pol0": 10990.0, "pol1": -10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761473459757609, "mean_inference_ms": 2.4482729511978705, "mean_action_processing_ms": 0.12439995497971268, "mean_env_wait_ms": 0.09548497366738486, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 6000, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 2977.022, "sample_throughput": 2015.437, "learn_time_ms": 15832.766, "learn_throughput": 378.961, "update_time_ms": 6.272}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 980101.5093085107, "policy_loss": -0.030695359896313636, "vf_loss": 980101.5412234042, "vf_explained_var": -1.0, "kl": 0.0035637113404400804, "entropy": 2.8180755807998334, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 980101.1489361703, "policy_loss": -0.018103046461622765, "vf_loss": 980101.1582446808, "vf_explained_var": -1.0, "kl": 0.0069709649468038945, "entropy": 2.8241550770211727, "entropy_coeff": 0.0}}}, "num_steps_sampled": 6000, "num_agent_steps_sampled": 12000, "num_steps_trained": 6000, "num_agent_steps_trained": 12000}, "done": false, "episodes_total": 6, "training_iteration": 1, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-21-16", "timestamp": 1624710076, "time_this_iter_s": 18.823264598846436, "time_total_s": 18.823264598846436, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd303b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd303c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.823264598846436, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 21.684, "ram_util_percent": 73.33200000000001, "gpu_util_percent0": 0.2208, "vram_util_percent0": 0.29008426019548367}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1000.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 10990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -10990.0}, "policy_reward_mean": {"pol0": 10990.0, "pol1": -10990.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1819054733181078, "mean_inference_ms": 2.5221318120085647, "mean_action_processing_ms": 0.1280495666157595, "mean_env_wait_ms": 0.0980934683088464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 12000, "agent_timesteps_total": 24000, "timers": {"sample_time_ms": 3143.542, "sample_throughput": 1908.675, "learn_time_ms": 16227.005, "learn_throughput": 369.754, "update_time_ms": 6.479}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 960521.7765957447, "policy_loss": -0.005019203561576123, "vf_loss": 960521.7859042553, "vf_explained_var": -1.0, "kl": 0.009297767475722953, "entropy": 2.6761735246536578, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 962971.4587765958, "policy_loss": -0.0022719521075487137, "vf_loss": 962971.4561170213, "vf_explained_var": -1.0, "kl": 0.007631606610610764, "entropy": 2.931899831650105, "entropy_coeff": 0.0}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 24000, "num_steps_trained": 12000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 12, "training_iteration": 2, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-21-36", "timestamp": 1624710096, "time_this_iter_s": 19.94487452507019, "time_total_s": 38.768139123916626, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84b801aea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f84b801ad90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 38.768139123916626, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 23.081481481481482, "ram_util_percent": 73.39629629629631, "gpu_util_percent0": 0.23074074074074075, "vram_util_percent0": 0.2903294261568613}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 928.8, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"pol0": 3090.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -3090.0}, "policy_reward_mean": {"pol0": 9978.0, "pol1": -9978.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18298601835142153, "mean_inference_ms": 2.5353819261042476, "mean_action_processing_ms": 0.12867583236279292, "mean_env_wait_ms": 0.09849655687279049, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 18576, "agent_timesteps_total": 37152, "timers": {"sample_time_ms": 3450.633, "sample_throughput": 1794.453, "learn_time_ms": 16861.353, "learn_throughput": 367.23, "update_time_ms": 6.262}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 857265.71875, "policy_loss": -0.0020068919357772055, "vf_loss": 857265.7103365385, "vf_explained_var": -8.252951033682621e-07, "kl": 0.02201979668237842, "entropy": 2.5166513048685513, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.19999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 860052.8377403846, "policy_loss": 0.0006576346663328317, "vf_loss": 860052.8257211539, "vf_explained_var": 7.51935544940352e-07, "kl": 0.012043654596289763, "entropy": 2.8040365393345175, "entropy_coeff": 0.0}}}, "num_steps_sampled": 18576, "num_agent_steps_sampled": 37152, "num_steps_trained": 18576, "num_agent_steps_trained": 37152}, "done": false, "episodes_total": 20, "training_iteration": 3, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-21-58", "timestamp": 1624710118, "time_this_iter_s": 22.208062171936035, "time_total_s": 60.97620129585266, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 60.97620129585266, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 21.43103448275862, "ram_util_percent": 73.37241379310343, "gpu_util_percent0": 0.2303448275862069, "vram_util_percent0": 0.2917204188603372}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 920.7777777777778, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1840.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1840.0}, "policy_reward_mean": {"pol0": 9901.481481481482, "pol1": -9901.481481481482}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18439487345581848, "mean_inference_ms": 2.553105195221508, "mean_action_processing_ms": 0.1294689250402952, "mean_env_wait_ms": 0.09913819897128963, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 24861, "agent_timesteps_total": 49722, "timers": {"sample_time_ms": 3537.246, "sample_throughput": 1757.087, "learn_time_ms": 17017.553, "learn_throughput": 365.226, "update_time_ms": 5.912}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.15000000000000002, "cur_lr": 5.000000000000001e-05, "total_loss": 896244.91875, "policy_loss": -0.004591325912624598, "vf_loss": 896244.91, "vf_explained_var": -0.020000247284770012, "kl": 0.08157300096005202, "entropy": 2.52469473361969, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.19999999999999996, "cur_lr": 5.000000000000001e-05, "total_loss": 900237.95625, "policy_loss": 8.94792377948761e-06, "vf_loss": 900237.94625, "vf_explained_var": -0.02000139281153679, "kl": 0.010325429951772094, "entropy": 2.762227816581726, "entropy_coeff": 0.0}}}, "num_steps_sampled": 24861, "num_agent_steps_sampled": 49722, "num_steps_trained": 24861, "num_agent_steps_trained": 49722}, "done": false, "episodes_total": 27, "training_iteration": 4, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-22-20", "timestamp": 1624710140, "time_this_iter_s": 21.29556941986084, "time_total_s": 82.2717707157135, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc218b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc218598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 82.2717707157135, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 22.035714285714285, "ram_util_percent": 73.0607142857143, "gpu_util_percent0": 0.2178571428571429, "vram_util_percent0": 0.29047498675911215}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 935.1818181818181, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1840.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1840.0}, "policy_reward_mean": {"pol0": 10099.39393939394, "pol1": -10099.39393939394}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1850636603283289, "mean_inference_ms": 2.560992200585224, "mean_action_processing_ms": 0.12985921661751368, "mean_env_wait_ms": 0.09943267867093436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 30861, "agent_timesteps_total": 61722, "timers": {"sample_time_ms": 3467.153, "sample_throughput": 1780.192, "learn_time_ms": 16737.399, "learn_throughput": 368.767, "update_time_ms": 5.778}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.22499999999999998, "cur_lr": 5.000000000000002e-05, "total_loss": 902415.4361702128, "policy_loss": 0.012741702707841042, "vf_loss": 902415.414893617, "vf_explained_var": -1.0, "kl": 0.05493546792484345, "entropy": 2.34169924005549, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 909345.8457446808, "policy_loss": -0.0033628908679523366, "vf_loss": 909345.840425532, "vf_explained_var": -1.0, "kl": 0.010345714523437176, "entropy": 2.557726337554607, "entropy_coeff": 0.0}}}, "num_steps_sampled": 30861, "num_agent_steps_sampled": 61722, "num_steps_trained": 30861, "num_agent_steps_trained": 61722}, "done": false, "episodes_total": 33, "training_iteration": 5, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-22-39", "timestamp": 1624710159, "time_this_iter_s": 18.815950632095337, "time_total_s": 101.08772134780884, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd296950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 101.08772134780884, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 21.356000000000005, "ram_util_percent": 72.852, "gpu_util_percent0": 0.20440000000000003, "vram_util_percent0": 0.29036063363667003}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 945.1538461538462, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1840.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1840.0}, "policy_reward_mean": {"pol0": 10236.410256410256, "pol1": -10236.410256410256}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18559595659914688, "mean_inference_ms": 2.5698507912786916, "mean_action_processing_ms": 0.13029055323696126, "mean_env_wait_ms": 0.09973920546828356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 36861, "agent_timesteps_total": 73722, "timers": {"sample_time_ms": 3450.929, "sample_throughput": 1780.245, "learn_time_ms": 16799.64, "learn_throughput": 365.692, "update_time_ms": 5.741}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 883199.9853723404, "policy_loss": 0.019412726362017876, "vf_loss": 883199.9428191489, "vf_explained_var": -1.0, "kl": 0.03719561079398115, "entropy": 2.422462468451642, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 887837.3231382979, "policy_loss": 0.010974619696114926, "vf_loss": 887837.3138297872, "vf_explained_var": -1.0, "kl": 0.02642404204828942, "entropy": 2.686290071365681, "entropy_coeff": 0.0}}}, "num_steps_sampled": 36861, "num_agent_steps_sampled": 73722, "num_steps_trained": 36861, "num_agent_steps_trained": 73722}, "done": false, "episodes_total": 39, "training_iteration": 6, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-22-59", "timestamp": 1624710179, "time_this_iter_s": 20.494024753570557, "time_total_s": 121.5817461013794, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 121.5817461013794, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 22.62592592592593, "ram_util_percent": 72.72222222222223, "gpu_util_percent0": 0.2751851851851852, "vram_util_percent0": 0.2909723002409217}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 952.4666666666667, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1840.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1840.0}, "policy_reward_mean": {"pol0": 10336.888888888889, "pol1": -10336.888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18614634851696138, "mean_inference_ms": 2.57869521088857, "mean_action_processing_ms": 0.13074246755492888, "mean_env_wait_ms": 0.10005479911902611, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 42861, "agent_timesteps_total": 85722, "timers": {"sample_time_ms": 3436.12, "sample_throughput": 1781.952, "learn_time_ms": 16904.888, "learn_throughput": 362.203, "update_time_ms": 5.675}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 864186.7313829787, "policy_loss": 0.019801622375528863, "vf_loss": 864186.6715425532, "vf_explained_var": "null", "kl": 0.06658514604923572, "entropy": 2.428536004208504, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 871785.5731382979, "policy_loss": -0.0013362101893475715, "vf_loss": 871785.5651595745, "vf_explained_var": -1.0, "kl": 0.007569036565403989, "entropy": 2.906720922348347, "entropy_coeff": 0.0}}}, "num_steps_sampled": 42861, "num_agent_steps_sampled": 85722, "num_steps_trained": 42861, "num_agent_steps_trained": 85722}, "done": false, "episodes_total": 45, "training_iteration": 7, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-23-20", "timestamp": 1624710200, "time_this_iter_s": 20.896334886550903, "time_total_s": 142.4780809879303, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc211a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc211488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 142.4780809879303, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 23.814814814814813, "ram_util_percent": 72.57407407407406, "gpu_util_percent0": 0.2992592592592593, "vram_util_percent0": 0.29041680710032575}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 958.0588235294117, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1840.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1840.0}, "policy_reward_mean": {"pol0": 10413.725490196079, "pol1": -10413.725490196079}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1866088460067833, "mean_inference_ms": 2.5865325813906397, "mean_action_processing_ms": 0.13114822715035584, "mean_env_wait_ms": 0.1003496940991976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 48861, "agent_timesteps_total": 97722, "timers": {"sample_time_ms": 3412.697, "sample_throughput": 1789.677, "learn_time_ms": 16865.694, "learn_throughput": 362.133, "update_time_ms": 5.817}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 845476.4853723404, "policy_loss": 0.012599587995321192, "vf_loss": 845476.4494680851, "vf_explained_var": -1.0, "kl": 0.032502483814320665, "entropy": 2.7024415300247515, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 850021.7127659575, "policy_loss": -0.003290933596485473, "vf_loss": 850021.7194148937, "vf_explained_var": -1.0, "kl": 0.008310547653347888, "entropy": 3.063846217825058, "entropy_coeff": 0.0}}}, "num_steps_sampled": 48861, "num_agent_steps_sampled": 97722, "num_steps_trained": 48861, "num_agent_steps_trained": 97722}, "done": false, "episodes_total": 51, "training_iteration": 8, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-23-40", "timestamp": 1624710220, "time_this_iter_s": 19.85396933555603, "time_total_s": 162.33205032348633, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20d158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20d048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 162.33205032348633, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 22.34444444444444, "ram_util_percent": 72.51481481481483, "gpu_util_percent0": 0.24777777777777776, "vram_util_percent0": 0.2906851914266811}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 934.3559322033898, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10062.372881355932, "pol1": -10062.372881355932}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18747867145736338, "mean_inference_ms": 2.5992338601443747, "mean_action_processing_ms": 0.13176711337342734, "mean_env_wait_ms": 0.10082450678742433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 55127, "agent_timesteps_total": 110254, "timers": {"sample_time_ms": 3527.303, "sample_throughput": 1736.517, "learn_time_ms": 17133.154, "learn_throughput": 357.507, "update_time_ms": 5.868}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390624999999999, "cur_lr": 5.000000000000001e-05, "total_loss": 730953.9107142857, "policy_loss": -0.003953099307813206, "vf_loss": 730953.8992346938, "vf_explained_var": -1.5813476750281552e-08, "kl": 0.018078667928977887, "entropy": 2.758589608328683, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5.000000000000001e-05, "total_loss": 735621.2831632653, "policy_loss": -0.0021127519501867344, "vf_loss": 735621.2844387755, "vf_explained_var": -1.0947792006277268e-08, "kl": 0.009738126370523657, "entropy": 3.0668268787617587, "entropy_coeff": 0.0}}}, "num_steps_sampled": 55127, "num_agent_steps_sampled": 110254, "num_steps_trained": 55127, "num_agent_steps_trained": 110254}, "done": false, "episodes_total": 59, "training_iteration": 9, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-24-04", "timestamp": 1624710244, "time_this_iter_s": 23.734676361083984, "time_total_s": 186.0667266845703, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20dd90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20dc80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 186.0667266845703, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 26.13225806451613, "ram_util_percent": 73.56129032258063, "gpu_util_percent0": 0.2403225806451613, "vram_util_percent0": 0.2982919642954217}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 914.7014925373135, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9778.805970149253, "pol1": -9778.805970149253}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1884139666969285, "mean_inference_ms": 2.614796933827419, "mean_action_processing_ms": 0.13252236509481466, "mean_env_wait_ms": 0.10133871647120926, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 61285, "agent_timesteps_total": 122570, "timers": {"sample_time_ms": 3604.952, "sample_throughput": 1700.022, "learn_time_ms": 17475.763, "learn_throughput": 350.686, "update_time_ms": 5.859}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390624999999999, "cur_lr": 5.000000000000001e-05, "total_loss": 710812.681122449, "policy_loss": -0.0050271287636489284, "vf_loss": 710812.6785714285, "vf_explained_var": 0.0043428516946733, "kl": 0.00740975481743107, "entropy": 2.7695825683827304, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5.000000000000001e-05, "total_loss": 713848.9885204082, "policy_loss": 0.0022735432056444032, "vf_loss": 713848.987244898, "vf_explained_var": -4.865685188093494e-09, "kl": 0.009559030777641706, "entropy": 3.136674623100125, "entropy_coeff": 0.0}}}, "num_steps_sampled": 61285, "num_agent_steps_sampled": 122570, "num_steps_trained": 61285, "num_agent_steps_trained": 122570}, "done": false, "episodes_total": 67, "training_iteration": 10, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-24-29", "timestamp": 1624710269, "time_this_iter_s": 24.876494646072388, "time_total_s": 210.9432213306427, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 210.9432213306427, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 26.418750000000003, "ram_util_percent": 73.06562500000001, "gpu_util_percent0": 0.303125, "vram_util_percent0": 0.29982410684192784}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 921.7123287671233, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9878.356164383562, "pol1": -9878.356164383562}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.188976675704439, "mean_inference_ms": 2.6240975844790473, "mean_action_processing_ms": 0.13297707939611736, "mean_env_wait_ms": 0.10164643709458976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 67285, "agent_timesteps_total": 134570, "timers": {"sample_time_ms": 3647.678, "sample_throughput": 1680.11, "learn_time_ms": 17579.911, "learn_throughput": 348.608, "update_time_ms": 5.848}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 791157.2593085107, "policy_loss": -0.001432616778827728, "vf_loss": 791157.2606382979, "vf_explained_var": -1.0, "kl": 0.002444641446655101, "entropy": 2.7702803205936513, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 795514.3736702128, "policy_loss": -0.003018344276921546, "vf_loss": 795514.3656914893, "vf_explained_var": "null", "kl": 0.013635645679971005, "entropy": 2.952795327977931, "entropy_coeff": 0.0}}}, "num_steps_sampled": 67285, "num_agent_steps_sampled": 134570, "num_steps_trained": 67285, "num_agent_steps_trained": 134570}, "done": false, "episodes_total": 73, "training_iteration": 11, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-24-49", "timestamp": 1624710289, "time_this_iter_s": 20.293687105178833, "time_total_s": 231.23690843582153, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84b801af28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f84b801ad90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 231.23690843582153, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 21.64074074074074, "ram_util_percent": 72.67037037037036, "gpu_util_percent0": 0.21444444444444444, "vram_util_percent0": 0.29738855808960296}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 921.675, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9856.75, "pol1": -9856.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1895018756178584, "mean_inference_ms": 2.633363634149293, "mean_action_processing_ms": 0.13340912294198648, "mean_env_wait_ms": 0.1019524683021921, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 73734, "agent_timesteps_total": 147468, "timers": {"sample_time_ms": 3760.812, "sample_throughput": 1641.507, "learn_time_ms": 17759.087, "learn_throughput": 347.619, "update_time_ms": 5.749}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5.000000000000001e-05, "total_loss": 727158.7401960784, "policy_loss": -0.006222266849933886, "vf_loss": 727158.743872549, "vf_explained_var": 1.3136395864421502e-06, "kl": 0.007159924792016254, "entropy": 2.880031006008971, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3000000000000001, "cur_lr": 5.000000000000001e-05, "total_loss": 731218.6421568628, "policy_loss": -0.00288394745439291, "vf_loss": 731218.6372549019, "vf_explained_var": -2.103693397259576e-08, "kl": 0.007851475082776126, "entropy": 2.8823057950711717, "entropy_coeff": 0.0}}}, "num_steps_sampled": 73734, "num_agent_steps_sampled": 147468, "num_steps_trained": 73734, "num_agent_steps_trained": 147468}, "done": false, "episodes_total": 80, "training_iteration": 12, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-25-12", "timestamp": 1624710312, "time_this_iter_s": 22.86790418624878, "time_total_s": 254.1048126220703, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 254.1048126220703, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 22.543333333333337, "ram_util_percent": 71.42, "gpu_util_percent0": 0.24333333333333335, "vram_util_percent0": 0.29453432198629365}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 927.1395348837209, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9935.813953488372, "pol1": -9935.813953488372}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1898777050211635, "mean_inference_ms": 2.6404530742930157, "mean_action_processing_ms": 0.13375980269224802, "mean_env_wait_ms": 0.10218724822750905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 79734, "agent_timesteps_total": 159468, "timers": {"sample_time_ms": 3689.432, "sample_throughput": 1657.653, "learn_time_ms": 17566.616, "learn_throughput": 348.149, "update_time_ms": 5.806}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 755591.284574468, "policy_loss": -0.00035231122548909897, "vf_loss": 755591.2593085107, "vf_explained_var": -1.0, "kl": 0.01734214856665819, "entropy": 2.8755034690207624, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 759975.5079787234, "policy_loss": -0.0005543289032388241, "vf_loss": 759975.4973404255, "vf_explained_var": "null", "kl": 0.01463621634831454, "entropy": 2.7262432828862617, "entropy_coeff": 0.0}}}, "num_steps_sampled": 79734, "num_agent_steps_sampled": 159468, "num_steps_trained": 79734, "num_agent_steps_trained": 159468}, "done": false, "episodes_total": 86, "training_iteration": 13, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-25-31", "timestamp": 1624710331, "time_this_iter_s": 19.569923400878906, "time_total_s": 273.6747360229492, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 273.6747360229492, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 23.657692307692308, "ram_util_percent": 70.52307692307691, "gpu_util_percent0": 0.21884615384615386, "vram_util_percent0": 0.2927393637707085}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 931.8913043478261, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10004.565217391304, "pol1": -10004.565217391304}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19017877436823985, "mean_inference_ms": 2.6464261277589314, "mean_action_processing_ms": 0.1340546795858444, "mean_env_wait_ms": 0.10238527613940138, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 85734, "agent_timesteps_total": 171468, "timers": {"sample_time_ms": 3632.03, "sample_throughput": 1676.005, "learn_time_ms": 17346.326, "learn_throughput": 350.927, "update_time_ms": 5.88}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 738002.6382978724, "policy_loss": 0.007828755898678557, "vf_loss": 738002.6236702128, "vf_explained_var": -1.0, "kl": 0.0249871811334123, "entropy": 2.8813506593095495, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 742642.0837765958, "policy_loss": -0.005120611373097338, "vf_loss": 742642.090425532, "vf_explained_var": "null", "kl": 0.007416413670920945, "entropy": 2.837674303257719, "entropy_coeff": 0.0}}}, "num_steps_sampled": 85734, "num_agent_steps_sampled": 171468, "num_steps_trained": 85734, "num_agent_steps_trained": 171468}, "done": false, "episodes_total": 92, "training_iteration": 14, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-25-50", "timestamp": 1624710350, "time_this_iter_s": 18.51965022087097, "time_total_s": 292.1943862438202, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20e048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20ec80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 292.1943862438202, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 21.71666666666667, "ram_util_percent": 70.50416666666666, "gpu_util_percent0": 0.21916666666666665, "vram_util_percent0": 0.2925303336703741}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 931.2929292929293, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9999.89898989899, "pol1": -9999.89898989899}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19039166727818366, "mean_inference_ms": 2.6512105546022435, "mean_action_processing_ms": 0.13427408335051816, "mean_env_wait_ms": 0.10251417198977754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 92198, "agent_timesteps_total": 184396, "timers": {"sample_time_ms": 3714.308, "sample_throughput": 1651.371, "learn_time_ms": 17422.673, "learn_throughput": 352.053, "update_time_ms": 5.886}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000002, "cur_lr": 5.000000000000001e-05, "total_loss": 699900.6299019608, "policy_loss": -0.0005538375756027652, "vf_loss": 699900.6323529412, "vf_explained_var": -4.674874176657795e-08, "kl": 0.012946357201857894, "entropy": 2.6694420646218693, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3000000000000001, "cur_lr": 5.000000000000001e-05, "total_loss": 704269.9816176471, "policy_loss": -0.00359715981518521, "vf_loss": 704269.9779411765, "vf_explained_var": 9.349748530951274e-09, "kl": 0.019511601065888125, "entropy": 2.7843283251220106, "entropy_coeff": 0.0}}}, "num_steps_sampled": 92198, "num_agent_steps_sampled": 184396, "num_steps_trained": 92198, "num_agent_steps_trained": 184396}, "done": false, "episodes_total": 99, "training_iteration": 15, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-26-10", "timestamp": 1624710370, "time_this_iter_s": 20.402511596679688, "time_total_s": 312.5968978404999, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc211598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc211510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 312.5968978404999, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 20.729629629629628, "ram_util_percent": 70.38148148148149, "gpu_util_percent0": 0.2111111111111111, "vram_util_percent0": 0.29221435793731043}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 931.98, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10009.8, "pol1": -10009.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19130464809909287, "mean_inference_ms": 2.6652760261165995, "mean_action_processing_ms": 0.13497064550407525, "mean_env_wait_ms": 0.10301489462006178, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 98198, "agent_timesteps_total": 196396, "timers": {"sample_time_ms": 3703.996, "sample_throughput": 1655.968, "learn_time_ms": 17263.639, "learn_throughput": 355.296, "update_time_ms": 5.863}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 703831.3005319149, "policy_loss": -0.0009093746899607334, "vf_loss": 703831.2965425532, "vf_explained_var": -1.0, "kl": 0.007656713283838744, "entropy": 2.7139300386956395, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 708334.5252659575, "policy_loss": 0.00020363391872416152, "vf_loss": 708334.5106382979, "vf_explained_var": "null", "kl": 0.030755876504043315, "entropy": 2.7153960288839136, "entropy_coeff": 0.0}}}, "num_steps_sampled": 98198, "num_agent_steps_sampled": 196396, "num_steps_trained": 98198, "num_agent_steps_trained": 196396}, "done": false, "episodes_total": 105, "training_iteration": 16, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-26-29", "timestamp": 1624710389, "time_this_iter_s": 18.800063848495483, "time_total_s": 331.39696168899536, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc211ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc211f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 331.39696168899536, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 21.712000000000003, "ram_util_percent": 70.332, "gpu_util_percent0": 0.2352, "vram_util_percent0": 0.2922345803842265}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 925.43, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9924.3, "pol1": -9924.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 535, 1000, 631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 4340.0, 10990.0, 5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -4340.0, -10990.0, -5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19173717780751687, "mean_inference_ms": 2.674641808348542, "mean_action_processing_ms": 0.1353938653096908, "mean_env_wait_ms": 0.10330638744667095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 104543, "agent_timesteps_total": 209086, "timers": {"sample_time_ms": 3755.521, "sample_throughput": 1642.435, "learn_time_ms": 17174.093, "learn_throughput": 359.157, "update_time_ms": 5.824}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000002, "cur_lr": 5.000000000000001e-05, "total_loss": 667795.21375, "policy_loss": -0.0025207466632127763, "vf_loss": 667795.22125, "vf_explained_var": 7.1525572131747595e-09, "kl": 0.005082028806209564, "entropy": 2.7844001770019533, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 675827.5475, "policy_loss": -0.0027409597754012795, "vf_loss": 675827.55, "vf_explained_var": -8.344650304081824e-09, "kl": 0.00816407786682248, "entropy": 3.0230803298950195, "entropy_coeff": 0.0}}}, "num_steps_sampled": 104543, "num_agent_steps_sampled": 209086, "num_steps_trained": 104543, "num_agent_steps_trained": 209086}, "done": false, "episodes_total": 112, "training_iteration": 17, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-26-50", "timestamp": 1624710410, "time_this_iter_s": 20.51757502555847, "time_total_s": 351.91453671455383, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20e9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20e048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 351.91453671455383, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 22.111111111111114, "ram_util_percent": 70.35555555555555, "gpu_util_percent0": 0.20962962962962967, "vram_util_percent0": 0.2911283376399656}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 930.08, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9990.8, "pol1": -9990.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [631, 410, 1000, 1000, 285, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [5300.0, 3090.0, 10990.0, 10990.0, 1840.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-5300.0, -3090.0, -10990.0, -10990.0, -1840.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19232077733467684, "mean_inference_ms": 2.6834790413404512, "mean_action_processing_ms": 0.1358605191788064, "mean_env_wait_ms": 0.10365340715435088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 110543, "agent_timesteps_total": 221086, "timers": {"sample_time_ms": 3746.275, "sample_throughput": 1646.489, "learn_time_ms": 17108.646, "learn_throughput": 360.531, "update_time_ms": 5.661}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 670317.522606383, "policy_loss": -0.017438316638482377, "vf_loss": 670317.5252659575, "vf_explained_var": "null", "kl": 0.012694807703349185, "entropy": 2.7602831201350435, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 675289.9361702128, "policy_loss": -0.002083621304878529, "vf_loss": 675289.9481382979, "vf_explained_var": "null", "kl": 0.007018432278740913, "entropy": 3.2143998348966556, "entropy_coeff": 0.0}}}, "num_steps_sampled": 110543, "num_agent_steps_sampled": 221086, "num_steps_trained": 110543, "num_agent_steps_trained": 221086}, "done": false, "episodes_total": 118, "training_iteration": 18, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-27-09", "timestamp": 1624710429, "time_this_iter_s": 19.105868339538574, "time_total_s": 371.0204050540924, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 371.0204050540924, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 20.831999999999997, "ram_util_percent": 70.46799999999999, "gpu_util_percent0": 0.2112, "vram_util_percent0": 0.2908122682844624}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 946.82, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10218.2, "pol1": -10218.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1926000168659904, "mean_inference_ms": 2.6897361604423224, "mean_action_processing_ms": 0.1361527571194117, "mean_env_wait_ms": 0.10382991039306604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 116543, "agent_timesteps_total": 233086, "timers": {"sample_time_ms": 3632.617, "sample_throughput": 1690.682, "learn_time_ms": 16748.943, "learn_throughput": 366.686, "update_time_ms": 5.564}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 653756.0239361703, "policy_loss": 0.01511338038092598, "vf_loss": 653756.0, "vf_explained_var": "null", "kl": 0.005836995536501103, "entropy": 2.6896380363626684, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 658257.097074468, "policy_loss": 0.00019720030274796992, "vf_loss": 658257.0811170213, "vf_explained_var": "null", "kl": 0.018035855065000817, "entropy": 3.0963125381063907, "entropy_coeff": 0.0}}}, "num_steps_sampled": 116543, "num_agent_steps_sampled": 233086, "num_steps_trained": 116543, "num_agent_steps_trained": 233086}, "done": false, "episodes_total": 124, "training_iteration": 19, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-27-28", "timestamp": 1624710448, "time_this_iter_s": 18.995826482772827, "time_total_s": 390.01623153686523, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20eb70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 390.01623153686523, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 21.375999999999998, "ram_util_percent": 70.608, "gpu_util_percent0": 0.2096, "vram_util_percent0": 0.290866194809572}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 935.66, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10046.6, "pol1": -10046.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1927662079018538, "mean_inference_ms": 2.6965688489921877, "mean_action_processing_ms": 0.13650724301703454, "mean_env_wait_ms": 0.10402936988728412, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 122427, "agent_timesteps_total": 244854, "timers": {"sample_time_ms": 3578.881, "sample_throughput": 1708.411, "learn_time_ms": 16159.06, "learn_throughput": 378.376, "update_time_ms": 5.485}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 581072.508152174, "policy_loss": -0.0012331068434793017, "vf_loss": 581072.5013586957, "vf_explained_var": -1.3475832361109497e-07, "kl": 0.006295940261739103, "entropy": 2.7343215631402056, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.45, "cur_lr": 5.0000000000000016e-05, "total_loss": 585056.4429347826, "policy_loss": -0.0008063663971488891, "vf_loss": 585056.4497282609, "vf_explained_var": -1.2957531714263837e-09, "kl": 0.010095699224621058, "entropy": 2.8911287007124526, "entropy_coeff": 0.0}}}, "num_steps_sampled": 122427, "num_agent_steps_sampled": 244854, "num_steps_trained": 122427, "num_agent_steps_trained": 244854}, "done": false, "episodes_total": 131, "training_iteration": 20, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-27-46", "timestamp": 1624710466, "time_this_iter_s": 18.43938398361206, "time_total_s": 408.4556155204773, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20e510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20e488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 408.4556155204773, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 20.427999999999997, "ram_util_percent": 70.524, "gpu_util_percent0": 0.21600000000000003, "vram_util_percent0": 0.290866194809572}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 935.66, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10046.6, "pol1": -10046.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19298692525586916, "mean_inference_ms": 2.7018229896730306, "mean_action_processing_ms": 0.1367622539605323, "mean_env_wait_ms": 0.1041984927049858, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 128427, "agent_timesteps_total": 256854, "timers": {"sample_time_ms": 3559.25, "sample_throughput": 1717.834, "learn_time_ms": 15976.773, "learn_throughput": 382.693, "update_time_ms": 5.389}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 621528.414893617, "policy_loss": -0.008700122581200396, "vf_loss": 621528.4135638297, "vf_explained_var": "null", "kl": 0.009096838216832343, "entropy": 2.612576043352168, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 627244.2553191489, "policy_loss": -0.0025487400076173723, "vf_loss": 627244.2526595745, "vf_explained_var": "null", "kl": 0.009152843309764533, "entropy": 2.9270028814356377, "entropy_coeff": 0.0}}}, "num_steps_sampled": 128427, "num_agent_steps_sampled": 256854, "num_steps_trained": 128427, "num_agent_steps_trained": 256854}, "done": false, "episodes_total": 137, "training_iteration": 21, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-28-05", "timestamp": 1624710485, "time_this_iter_s": 18.271835327148438, "time_total_s": 426.72745084762573, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20eea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20eae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 426.72745084762573, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 21.316666666666666, "ram_util_percent": 70.5125, "gpu_util_percent0": 0.21916666666666665, "vram_util_percent0": 0.29086619480957193}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 935.66, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10046.6, "pol1": -10046.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19314071610270045, "mean_inference_ms": 2.705489534098827, "mean_action_processing_ms": 0.13693863947056786, "mean_env_wait_ms": 0.10431341731948114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 134427, "agent_timesteps_total": 268854, "timers": {"sample_time_ms": 3435.444, "sample_throughput": 1766.671, "learn_time_ms": 15630.486, "learn_throughput": 388.299, "update_time_ms": 5.313}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 605592.477393617, "policy_loss": -0.07580214497098263, "vf_loss": 605592.5385638297, "vf_explained_var": "null", "kl": 0.008664989526918594, "entropy": 2.6260793411985355, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 610718.1688829787, "policy_loss": -0.007285772731151194, "vf_loss": 610718.1755319149, "vf_explained_var": "null", "kl": 0.006939506762601594, "entropy": 2.846181869506836, "entropy_coeff": 0.0}}}, "num_steps_sampled": 134427, "num_agent_steps_sampled": 268854, "num_steps_trained": 134427, "num_agent_steps_trained": 268854}, "done": false, "episodes_total": 143, "training_iteration": 22, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-28-23", "timestamp": 1624710503, "time_this_iter_s": 18.16598653793335, "time_total_s": 444.8934373855591, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 444.8934373855591, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 21.175, "ram_util_percent": 70.50833333333333, "gpu_util_percent0": 0.21916666666666665, "vram_util_percent0": 0.29086619480957193}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 930.72, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 9977.2, "pol1": -9977.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 435, 936, 200, 1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 3340.0, 8350.0, 990.0, 10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -3340.0, -8350.0, -990.0, -10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1932407703984917, "mean_inference_ms": 2.7091623175109225, "mean_action_processing_ms": 0.13710084025968206, "mean_env_wait_ms": 0.10441408868608028, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 140933, "agent_timesteps_total": 281866, "timers": {"sample_time_ms": 3516.471, "sample_throughput": 1740.353, "learn_time_ms": 15629.106, "learn_throughput": 391.571, "update_time_ms": 5.183}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000002, "cur_lr": 5.000000000000001e-05, "total_loss": 573713.7757352941, "policy_loss": -0.004542892835303849, "vf_loss": 573713.7720588235, "vf_explained_var": -5.843592720822244e-09, "kl": 0.011178479146431474, "entropy": 2.6075241472206865, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 578607.9926470588, "policy_loss": -0.0015767835372803257, "vf_loss": 578607.9865196078, "vf_explained_var": -5.843592720822244e-09, "kl": 0.007987880431042583, "entropy": 2.8647754239101038, "entropy_coeff": 0.0}}}, "num_steps_sampled": 140933, "num_agent_steps_sampled": 281866, "num_steps_trained": 140933, "num_agent_steps_trained": 281866}, "done": false, "episodes_total": 150, "training_iteration": 23, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-28-43", "timestamp": 1624710523, "time_this_iter_s": 20.365686655044556, "time_total_s": 465.25912404060364, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc22e510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc22e400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 465.25912404060364, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 20.65185185185185, "ram_util_percent": 70.59629629629627, "gpu_util_percent0": 0.21592592592592594, "vram_util_percent0": 0.2907538478822604}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 945.01, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1540.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1540.0}, "policy_reward_mean": {"pol0": 10180.1, "pol1": -10180.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 695, 1000, 446, 530, 286, 1000, 1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 5940.0, 10990.0, 3450.0, 4290.0, 1850.0, 10990.0, 10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -5940.0, -10990.0, -3450.0, -4290.0, -1850.0, -10990.0, -10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19315566775978715, "mean_inference_ms": 2.709637028162756, "mean_action_processing_ms": 0.13712039438056242, "mean_env_wait_ms": 0.10438795997777937, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 146933, "agent_timesteps_total": 293866, "timers": {"sample_time_ms": 3514.849, "sample_throughput": 1741.156, "learn_time_ms": 15587.145, "learn_throughput": 392.625, "update_time_ms": 5.128}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 574586.9813829787, "policy_loss": -0.10045496457593238, "vf_loss": 574587.0531914893, "vf_explained_var": "null", "kl": 0.008557932391921257, "entropy": 2.5490947733534144, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 579598.5625, "policy_loss": -0.0034647399480355547, "vf_loss": 579598.5558510638, "vf_explained_var": "null", "kl": 0.005526031664711364, "entropy": 2.889461649225113, "entropy_coeff": 0.0}}}, "num_steps_sampled": 146933, "num_agent_steps_sampled": 293866, "num_steps_trained": 146933, "num_agent_steps_trained": 293866}, "done": false, "episodes_total": 156, "training_iteration": 24, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-29-01", "timestamp": 1624710541, "time_this_iter_s": 18.083493947982788, "time_total_s": 483.3426179885864, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc22ef28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd296950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 483.3426179885864, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 20.729166666666664, "ram_util_percent": 70.61666666666666, "gpu_util_percent0": 0.22208333333333333, "vram_util_percent0": 0.29069767441860467}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 954.05, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10310.5, "pol1": -10310.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 896, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 7950.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -7950.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19289684919564037, "mean_inference_ms": 2.707934467452966, "mean_action_processing_ms": 0.13699747294493053, "mean_env_wait_ms": 0.10431168881605679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 152794, "agent_timesteps_total": 305588, "timers": {"sample_time_ms": 3429.64, "sample_throughput": 1766.833, "learn_time_ms": 15411.435, "learn_throughput": 393.189, "update_time_ms": 5.133}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 532079.711277174, "policy_loss": -0.0016592090099078157, "vf_loss": 532079.703125, "vf_explained_var": -1.2957531714263837e-09, "kl": 0.02070602288712626, "entropy": 2.49411504164986, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.45, "cur_lr": 5.0000000000000016e-05, "total_loss": 538153.1188858695, "policy_loss": -0.003517759447593404, "vf_loss": 538153.1338315217, "vf_explained_var": 1.2957531048130022e-08, "kl": 0.006907712637811252, "entropy": 2.861166135124538, "entropy_coeff": 0.0}}}, "num_steps_sampled": 152794, "num_agent_steps_sampled": 305588, "num_steps_trained": 152794, "num_agent_steps_trained": 305588}, "done": false, "episodes_total": 163, "training_iteration": 25, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-29-19", "timestamp": 1624710559, "time_this_iter_s": 17.793991565704346, "time_total_s": 501.13660955429077, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2107b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 501.13660955429077, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 20.847826086956523, "ram_util_percent": 70.69565217391305, "gpu_util_percent0": 0.21999999999999997, "vram_util_percent0": 0.29069767441860456}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 955.09, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10340.9, "pol1": -10340.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 515, 1000, 1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 4140.0, 10990.0, 10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -4140.0, -10990.0, -10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19260420651458238, "mean_inference_ms": 2.7054256474837417, "mean_action_processing_ms": 0.13688027278212786, "mean_env_wait_ms": 0.10422461432496187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 158794, "agent_timesteps_total": 317588, "timers": {"sample_time_ms": 3422.998, "sample_throughput": 1770.261, "learn_time_ms": 15364.406, "learn_throughput": 394.392, "update_time_ms": 5.284}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 544391.2553191489, "policy_loss": -0.014159449831919467, "vf_loss": 544391.2632978724, "vf_explained_var": "null", "kl": 0.01043341392056739, "entropy": 2.6469168967389045, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 549609.9986702128, "policy_loss": 0.005615126341581345, "vf_loss": 549609.9747340425, "vf_explained_var": "null", "kl": 0.032707955648607394, "entropy": 2.927393634268578, "entropy_coeff": 0.0}}}, "num_steps_sampled": 158794, "num_agent_steps_sampled": 317588, "num_steps_trained": 158794, "num_agent_steps_trained": 317588}, "done": false, "episodes_total": 169, "training_iteration": 26, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-29-37", "timestamp": 1624710577, "time_this_iter_s": 18.268561840057373, "time_total_s": 519.4051713943481, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc22e730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20e6a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 519.4051713943481, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 21.203999999999997, "ram_util_percent": 70.748, "gpu_util_percent0": 0.2232, "vram_util_percent0": 0.2906976744186046}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 957.09, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10360.9, "pol1": -10360.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 934, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000], "policy_pol0_reward": [10990.0, 8330.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0], "policy_pol1_reward": [-10990.0, -8330.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19234137609767543, "mean_inference_ms": 2.7031894838311428, "mean_action_processing_ms": 0.1368134711349544, "mean_env_wait_ms": 0.10414612153615105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 164509, "agent_timesteps_total": 329018, "timers": {"sample_time_ms": 3347.309, "sample_throughput": 1791.469, "learn_time_ms": 15137.303, "learn_throughput": 396.147, "update_time_ms": 5.309}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 513788.1826388889, "policy_loss": 0.0006008070376184252, "vf_loss": 513788.1659722222, "vf_explained_var": 1.0596381549987655e-08, "kl": 0.012704829685389996, "entropy": 2.6024642361534966, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5.0000000000000016e-05, "total_loss": 518443.70625, "policy_loss": -0.0002959950102700128, "vf_loss": 518443.70208333334, "vf_explained_var": 2.6490953874969136e-09, "kl": 0.008991628098818991, "entropy": 2.786457967758179, "entropy_coeff": 0.0}}}, "num_steps_sampled": 164509, "num_agent_steps_sampled": 329018, "num_steps_trained": 164509, "num_agent_steps_trained": 329018}, "done": false, "episodes_total": 175, "training_iteration": 27, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-29-55", "timestamp": 1624710595, "time_this_iter_s": 17.488112926483154, "time_total_s": 536.8932843208313, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84b801af28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2bad90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 536.8932843208313, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 21.35217391304348, "ram_util_percent": 70.81304347826085, "gpu_util_percent0": 0.22217391304347825, "vram_util_percent0": 0.29069767441860456}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 957.75, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10387.5, "pol1": -10387.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19207998354508057, "mean_inference_ms": 2.699943210344212, "mean_action_processing_ms": 0.1366545659361973, "mean_env_wait_ms": 0.10403748873009969, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 170509, "agent_timesteps_total": 341018, "timers": {"sample_time_ms": 3354.247, "sample_throughput": 1787.763, "learn_time_ms": 15046.251, "learn_throughput": 398.544, "update_time_ms": 5.346}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 515048.01196808513, "policy_loss": -0.0021772288737144877, "vf_loss": 515048.0039893617, "vf_explained_var": "null", "kl": 0.006215439594172417, "entropy": 2.5995999701479646, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 520874.017287234, "policy_loss": -0.0026815459924809477, "vf_loss": 520874.0166223404, "vf_explained_var": "null", "kl": 0.005088744130223356, "entropy": 2.874505712630901, "entropy_coeff": 0.0}}}, "num_steps_sampled": 170509, "num_agent_steps_sampled": 341018, "num_steps_trained": 170509, "num_agent_steps_trained": 341018}, "done": false, "episodes_total": 181, "training_iteration": 28, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-30-13", "timestamp": 1624710613, "time_this_iter_s": 18.26483178138733, "time_total_s": 555.1581161022186, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20e2f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20e268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 555.1581161022186, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 21.441666666666666, "ram_util_percent": 70.84583333333335, "gpu_util_percent0": 0.22208333333333333, "vram_util_percent0": 0.29069767441860467}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 957.75, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10387.5, "pol1": -10387.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1918253670471384, "mean_inference_ms": 2.696555821059452, "mean_action_processing_ms": 0.13648638238457073, "mean_env_wait_ms": 0.10392252373771674, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 176509, "agent_timesteps_total": 353018, "timers": {"sample_time_ms": 3340.571, "sample_throughput": 1795.082, "learn_time_ms": 14980.178, "learn_throughput": 400.302, "update_time_ms": 5.335}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.000000000000002e-05, "total_loss": 500520.7154255319, "policy_loss": -0.08707646145782572, "vf_loss": 500520.7965425532, "vf_explained_var": "null", "kl": 0.005489836813525316, "entropy": 2.584120400408481, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 506398.9833776596, "policy_loss": -0.0047665973134497375, "vf_loss": 506398.9840425532, "vf_explained_var": "null", "kl": 0.004753106382695284, "entropy": 2.7997378998614373, "entropy_coeff": 0.0}}}, "num_steps_sampled": 176509, "num_agent_steps_sampled": 353018, "num_steps_trained": 176509, "num_agent_steps_trained": 353018}, "done": false, "episodes_total": 187, "training_iteration": 29, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-30-32", "timestamp": 1624710632, "time_this_iter_s": 18.19930601119995, "time_total_s": 573.3574221134186, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc210158>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc210488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 573.3574221134186, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 20.69583333333333, "ram_util_percent": 70.9, "gpu_util_percent0": 0.2225, "vram_util_percent0": 0.29069767441860467}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 956.2, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10352.0, "pol1": -10352.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 464, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 3630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -3630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19159839190633957, "mean_inference_ms": 2.6934833521317887, "mean_action_processing_ms": 0.1363298883919113, "mean_env_wait_ms": 0.10381515591358337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 182354, "agent_timesteps_total": 364708, "timers": {"sample_time_ms": 3287.22, "sample_throughput": 1823.03, "learn_time_ms": 14997.594, "learn_throughput": 399.577, "update_time_ms": 5.384}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2814453124999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 472925.9137228261, "policy_loss": -0.00043780988325243413, "vf_loss": 472925.9076086957, "vf_explained_var": 1.2957531714263837e-09, "kl": 0.00395587928917097, "entropy": 2.5769629322964214, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5.0000000000000016e-05, "total_loss": 484143.03736413043, "policy_loss": -0.004005569984893436, "vf_loss": 484143.0394021739, "vf_explained_var": 3.6281086579492694e-08, "kl": 0.007353049814296158, "entropy": 2.8092328102692314, "entropy_coeff": 0.0}}}, "num_steps_sampled": 182354, "num_agent_steps_sampled": 364708, "num_steps_trained": 182354, "num_agent_steps_trained": 364708}, "done": false, "episodes_total": 193, "training_iteration": 30, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-30-50", "timestamp": 1624710650, "time_this_iter_s": 18.080219268798828, "time_total_s": 591.4376413822174, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20ebf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20ea60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 591.4376413822174, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 21.925, "ram_util_percent": 71.02083333333333, "gpu_util_percent0": 0.22041666666666668, "vram_util_percent0": 0.28946887990113473}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 961.56, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10425.6, "pol1": -10425.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1914335314804294, "mean_inference_ms": 2.6911838235513046, "mean_action_processing_ms": 0.13621172541231155, "mean_env_wait_ms": 0.10376709974882681, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 188354, "agent_timesteps_total": 376708, "timers": {"sample_time_ms": 3285.212, "sample_throughput": 1824.144, "learn_time_ms": 15048.598, "learn_throughput": 398.223, "update_time_ms": 5.377}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.000000000000002e-05, "total_loss": 472376.7779255319, "policy_loss": 0.004032961588273657, "vf_loss": 472376.77260638296, "vf_explained_var": "null", "kl": 0.003228313061705929, "entropy": 2.5034129112324814, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 477080.6003989362, "policy_loss": -0.003973974866118837, "vf_loss": 477080.59840425535, "vf_explained_var": "null", "kl": 0.008762548875777012, "entropy": 2.9199556594199323, "entropy_coeff": 0.0}}}, "num_steps_sampled": 188354, "num_agent_steps_sampled": 376708, "num_steps_trained": 188354, "num_agent_steps_trained": 376708}, "done": false, "episodes_total": 199, "training_iteration": 31, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-31-08", "timestamp": 1624710668, "time_this_iter_s": 18.761969804763794, "time_total_s": 610.1996111869812, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84b801af28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f84b801aea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 610.1996111869812, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 21.866666666666664, "ram_util_percent": 71.1375, "gpu_util_percent0": 0.21666666666666667, "vram_util_percent0": 0.2865338164251207}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 958.86, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10378.6, "pol1": -10378.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 345, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 2440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -2440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.191263086557645, "mean_inference_ms": 2.688774941546808, "mean_action_processing_ms": 0.13609133439835192, "mean_env_wait_ms": 0.10368431753202706, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 194084, "agent_timesteps_total": 388168, "timers": {"sample_time_ms": 3285.762, "sample_throughput": 1815.621, "learn_time_ms": 15135.826, "learn_throughput": 394.144, "update_time_ms": 5.384}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3203613281249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 446295.34791666665, "policy_loss": -0.0065241070050332285, "vf_loss": 446295.35, "vf_explained_var": -3.7087335869046e-08, "kl": 0.0069721365037063755, "entropy": 2.4902040163675943, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5.0000000000000016e-05, "total_loss": 450895.9, "policy_loss": -0.0050437791893879575, "vf_loss": 450895.89166666666, "vf_explained_var": 2.3841858265427618e-08, "kl": 0.016886188441680536, "entropy": 2.8938228130340575, "entropy_coeff": 0.0}}}, "num_steps_sampled": 194084, "num_agent_steps_sampled": 388168, "num_steps_trained": 194084, "num_agent_steps_trained": 388168}, "done": false, "episodes_total": 205, "training_iteration": 32, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-31-28", "timestamp": 1624710688, "time_this_iter_s": 19.06266713142395, "time_total_s": 629.2622783184052, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc20ef28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc20e950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 629.2622783184052, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 20.9, "ram_util_percent": 70.7923076923077, "gpu_util_percent0": 0.21230769230769228, "vram_util_percent0": 0.2867309636773742}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 965.41, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10464.1, "pol1": -10464.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19116599502450626, "mean_inference_ms": 2.686908714780442, "mean_action_processing_ms": 0.13601857406099405, "mean_env_wait_ms": 0.10363780220957308, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 200084, "agent_timesteps_total": 400168, "timers": {"sample_time_ms": 3186.171, "sample_throughput": 1856.492, "learn_time_ms": 15085.93, "learn_throughput": 392.094, "update_time_ms": 5.422}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3203613281249999, "cur_lr": 5.000000000000002e-05, "total_loss": 445064.2732712766, "policy_loss": -0.06998866095029294, "vf_loss": 445064.33178191487, "vf_explained_var": "null", "kl": 0.018751848924984323, "entropy": 2.3601010860280787, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375000000000001, "cur_lr": 5.000000000000002e-05, "total_loss": 452115.3603723404, "policy_loss": 0.0020234716382432493, "vf_loss": 452115.3503989362, "vf_explained_var": "null", "kl": 0.014868453640411509, "entropy": 2.742187738418579, "entropy_coeff": 0.0}}}, "num_steps_sampled": 200084, "num_agent_steps_sampled": 400168, "num_steps_trained": 200084, "num_agent_steps_trained": 400168}, "done": false, "episodes_total": 211, "training_iteration": 33, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-31-46", "timestamp": 1624710706, "time_this_iter_s": 18.891797304153442, "time_total_s": 648.1540756225586, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2132f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2131e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 648.1540756225586, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 20.424, "ram_util_percent": 70.15199999999999, "gpu_util_percent0": 0.218, "vram_util_percent0": 0.28667340748230535}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 961.31, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10403.1, "pol1": -10403.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 754, 255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6530.0, 1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6530.0, -1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19094436048386554, "mean_inference_ms": 2.6847025214063596, "mean_action_processing_ms": 0.13588070617856332, "mean_env_wait_ms": 0.10350908104625743, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 206674, "agent_timesteps_total": 413348, "timers": {"sample_time_ms": 3292.553, "sample_throughput": 1814.428, "learn_time_ms": 15330.975, "learn_throughput": 389.675, "update_time_ms": 5.457}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.32036132812499996, "cur_lr": 5.0000000000000016e-05, "total_loss": 422353.5204326923, "policy_loss": -0.001317215501330793, "vf_loss": 422353.52223557694, "vf_explained_var": -4.12647551684131e-08, "kl": 0.011741816925887879, "entropy": 2.202644889171307, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.33749999999999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 427310.5102163461, "policy_loss": 0.008180208665390428, "vf_loss": 427310.4921875, "vf_explained_var": -1.833989138333436e-08, "kl": 0.030247798619362023, "entropy": 2.7157777822934666, "entropy_coeff": 0.0}}}, "num_steps_sampled": 206674, "num_agent_steps_sampled": 413348, "num_steps_trained": 206674, "num_agent_steps_trained": 413348}, "done": false, "episodes_total": 218, "training_iteration": 34, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-32-08", "timestamp": 1624710728, "time_this_iter_s": 21.598710298538208, "time_total_s": 669.7527859210968, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc213f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2bac80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 669.7527859210968, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 22.075, "ram_util_percent": 70.17857142857143, "gpu_util_percent0": 0.19964285714285715, "vram_util_percent0": 0.28581058308055274}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 958.12, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10371.2, "pol1": -10371.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [255, 1000, 1000, 875, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000], "policy_pol0_reward": [1540.0, 10990.0, 10990.0, 7740.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-1540.0, -10990.0, -10990.0, -7740.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1908245641911508, "mean_inference_ms": 2.6826003386371577, "mean_action_processing_ms": 0.1357918590328216, "mean_env_wait_ms": 0.10343896228947445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 213109, "agent_timesteps_total": 426218, "timers": {"sample_time_ms": 3363.826, "sample_throughput": 1793.048, "learn_time_ms": 15492.806, "learn_throughput": 389.31, "update_time_ms": 5.456}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.320361328125, "cur_lr": 5.000000000000001e-05, "total_loss": 410202.8713235294, "policy_loss": -0.004754751920700073, "vf_loss": 410202.87071078434, "vf_explained_var": "null", "kl": 0.015858007722771635, "entropy": 2.314160431132597, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000002, "cur_lr": 5.000000000000001e-05, "total_loss": 414961.38296568627, "policy_loss": -0.007078534211306011, "vf_loss": 414961.38112745096, "vf_explained_var": -1.6362060151209334e-08, "kl": 0.014926749336368898, "entropy": 2.7792000630322624, "entropy_coeff": 0.0}}}, "num_steps_sampled": 213109, "num_agent_steps_sampled": 426218, "num_steps_trained": 213109, "num_agent_steps_trained": 426218}, "done": false, "episodes_total": 225, "training_iteration": 35, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-32-28", "timestamp": 1624710748, "time_this_iter_s": 20.12517547607422, "time_total_s": 689.877961397171, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc213268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 689.877961397171, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 20.41111111111111, "ram_util_percent": 70.36296296296297, "gpu_util_percent0": 0.21777777777777776, "vram_util_percent0": 0.2854860252905417}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 960.42, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10414.2, "pol1": -10414.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19070942519574566, "mean_inference_ms": 2.6802456633744582, "mean_action_processing_ms": 0.13565009103482997, "mean_env_wait_ms": 0.10338007324990826, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 219469, "agent_timesteps_total": 438938, "timers": {"sample_time_ms": 3413.445, "sample_throughput": 1777.53, "learn_time_ms": 15617.067, "learn_throughput": 388.517, "update_time_ms": 5.217}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.320361328125, "cur_lr": 5.000000000000001e-05, "total_loss": 398324.87625, "policy_loss": -0.005442581158131361, "vf_loss": 398324.870625, "vf_explained_var": 8.344650304081824e-09, "kl": 0.03246984738856554, "entropy": 2.124510169029236, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5.000000000000001e-05, "total_loss": 403091.8975, "policy_loss": -0.0005060386285185814, "vf_loss": 403091.89625, "vf_explained_var": 1.3113021779531664e-08, "kl": 0.009290821282193065, "entropy": 2.860825457572937, "entropy_coeff": 0.0}}}, "num_steps_sampled": 219469, "num_agent_steps_sampled": 438938, "num_steps_trained": 219469, "num_agent_steps_trained": 438938}, "done": false, "episodes_total": 232, "training_iteration": 36, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-32-48", "timestamp": 1624710768, "time_this_iter_s": 20.001173973083496, "time_total_s": 709.8791353702545, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 709.8791353702545, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 20.80384615384616, "ram_util_percent": 70.31923076923077, "gpu_util_percent0": 0.24000000000000002, "vram_util_percent0": 0.2855124316196106}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 957.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10363.6, "pol1": -10363.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19059949383056327, "mean_inference_ms": 2.6785979066951358, "mean_action_processing_ms": 0.13556322262702353, "mean_env_wait_ms": 0.10332557759674042, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 225163, "agent_timesteps_total": 450326, "timers": {"sample_time_ms": 3420.423, "sample_throughput": 1773.29, "learn_time_ms": 15665.335, "learn_throughput": 387.186, "update_time_ms": 5.215}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4805419921875001, "cur_lr": 5.0000000000000016e-05, "total_loss": 384300.1972222222, "policy_loss": -0.006526406274901496, "vf_loss": 384300.18680555554, "vf_explained_var": -2.3841858265427618e-08, "kl": 0.03519362024962902, "entropy": 2.2973755677541097, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 394377.3388888889, "policy_loss": -0.0016470916155311797, "vf_loss": 394377.34513888886, "vf_explained_var": -1.1920929132713809e-08, "kl": 0.007707491103145812, "entropy": 2.796031724082099, "entropy_coeff": 0.0}}}, "num_steps_sampled": 225163, "num_agent_steps_sampled": 450326, "num_steps_trained": 225163, "num_agent_steps_trained": 450326}, "done": false, "episodes_total": 238, "training_iteration": 37, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-33-06", "timestamp": 1624710786, "time_this_iter_s": 18.041922569274902, "time_total_s": 727.9210579395294, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 727.9210579395294, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 22.054166666666664, "ram_util_percent": 70.30833333333334, "gpu_util_percent0": 0.2166666666666667, "vram_util_percent0": 0.28549460734748905}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 957.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10363.6, "pol1": -10363.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 506, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 4050.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -4050.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19049438038392721, "mean_inference_ms": 2.6769804834694617, "mean_action_processing_ms": 0.1354762467834003, "mean_env_wait_ms": 0.10327122605944312, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 231163, "agent_timesteps_total": 462326, "timers": {"sample_time_ms": 3419.918, "sample_throughput": 1773.551, "learn_time_ms": 15660.337, "learn_throughput": 387.31, "update_time_ms": 5.19}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7208129882812501, "cur_lr": 5.000000000000002e-05, "total_loss": 380604.9368351064, "policy_loss": -0.1325948994527472, "vf_loss": 380605.0625, "vf_explained_var": "null", "kl": 0.011000725559573224, "entropy": 2.264254772916753, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 385763.14694148937, "policy_loss": -0.0050906823115779995, "vf_loss": 385763.14760638296, "vf_explained_var": "null", "kl": 0.0077141818313046975, "entropy": 2.8266106666402613, "entropy_coeff": 0.0}}}, "num_steps_sampled": 231163, "num_agent_steps_sampled": 462326, "num_steps_trained": 231163, "num_agent_steps_trained": 462326}, "done": false, "episodes_total": 244, "training_iteration": 38, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-33-25", "timestamp": 1624710805, "time_this_iter_s": 18.210290670394897, "time_total_s": 746.1313486099243, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 746.1313486099243, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 20.366666666666664, "ram_util_percent": 70.45416666666667, "gpu_util_percent0": 0.23416666666666666, "vram_util_percent0": 0.2855226940793169}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 957.95, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10369.5, "pol1": -10369.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19042130882322944, "mean_inference_ms": 2.6750359240860178, "mean_action_processing_ms": 0.13541235836003873, "mean_env_wait_ms": 0.1032323378348917, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 237728, "agent_timesteps_total": 475456, "timers": {"sample_time_ms": 3522.179, "sample_throughput": 1738.1, "learn_time_ms": 15862.318, "learn_throughput": 385.94, "update_time_ms": 5.214}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7208129882812503, "cur_lr": 5.0000000000000016e-05, "total_loss": 361825.02283653844, "policy_loss": -0.000953534313549216, "vf_loss": 361825.0132211539, "vf_explained_var": 2.4071105997336417e-08, "kl": 0.01096761984249147, "entropy": 2.137302050223717, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 366853.16826923075, "policy_loss": 0.0002615704702643248, "vf_loss": 366853.15985576925, "vf_explained_var": 9.16994569166718e-09, "kl": 0.019099533969822984, "entropy": 2.885591800396259, "entropy_coeff": 0.0}}}, "num_steps_sampled": 237728, "num_agent_steps_sampled": 475456, "num_steps_trained": 237728, "num_agent_steps_trained": 475456}, "done": false, "episodes_total": 251, "training_iteration": 39, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-33-46", "timestamp": 1624710826, "time_this_iter_s": 21.24457621574402, "time_total_s": 767.3759248256683, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc209620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2096a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 767.3759248256683, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 20.107142857142858, "ram_util_percent": 70.45714285714287, "gpu_util_percent0": 0.21107142857142858, "vram_util_percent0": 0.2855216909817516}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 957.95, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1000.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1000.0}, "policy_reward_mean": {"pol0": 10369.5, "pol1": -10369.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 201, 660, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 1000.0, 5590.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -1000.0, -5590.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1903351445478868, "mean_inference_ms": 2.673418220793386, "mean_action_processing_ms": 0.13532606563624977, "mean_env_wait_ms": 0.10317906250623944, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 243728, "agent_timesteps_total": 487456, "timers": {"sample_time_ms": 3514.683, "sample_throughput": 1746.217, "learn_time_ms": 15873.255, "learn_throughput": 386.65, "update_time_ms": 5.179}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7208129882812501, "cur_lr": 5.000000000000002e-05, "total_loss": 356141.46675531915, "policy_loss": 0.0012348680261601794, "vf_loss": 356141.44281914894, "vf_explained_var": "null", "kl": 0.027977163566553845, "entropy": 2.116183301235767, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 363505.2666223404, "policy_loss": 0.00015071902344835565, "vf_loss": 363505.2613031915, "vf_explained_var": "null", "kl": 0.007952359980566705, "entropy": 3.006766745384703, "entropy_coeff": 0.0}}}, "num_steps_sampled": 243728, "num_agent_steps_sampled": 487456, "num_steps_trained": 243728, "num_agent_steps_trained": 487456}, "done": false, "episodes_total": 257, "training_iteration": 40, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-34-04", "timestamp": 1624710844, "time_this_iter_s": 18.115469694137573, "time_total_s": 785.4913945198059, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc209ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc209048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 785.4913945198059, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 20.575000000000003, "ram_util_percent": 70.39583333333333, "gpu_util_percent0": 0.22375, "vram_util_percent0": 0.2855226940793169}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 962.53, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10435.3, "pol1": -10435.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1902894875884291, "mean_inference_ms": 2.67179142899143, "mean_action_processing_ms": 0.13525223925457597, "mean_env_wait_ms": 0.10313925282664417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 250047, "agent_timesteps_total": 500094, "timers": {"sample_time_ms": 3563.075, "sample_throughput": 1731.454, "learn_time_ms": 15925.976, "learn_throughput": 387.373, "update_time_ms": 5.178}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0812194824218748, "cur_lr": 5.000000000000001e-05, "total_loss": 340061.016875, "policy_loss": 7.564427331089973e-05, "vf_loss": 340060.993125, "vf_explained_var": 2.2649764730431343e-08, "kl": 0.022132854238152505, "entropy": 2.2742329597473145, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5.000000000000001e-05, "total_loss": 344992.57375, "policy_loss": -0.0014606758207082748, "vf_loss": 344992.57125, "vf_explained_var": -4.887580828949467e-08, "kl": 0.005301542179659009, "entropy": 2.946591114997864, "entropy_coeff": 0.0}}}, "num_steps_sampled": 250047, "num_agent_steps_sampled": 500094, "num_steps_trained": 250047, "num_agent_steps_trained": 500094}, "done": false, "episodes_total": 264, "training_iteration": 41, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-34-24", "timestamp": 1624710864, "time_this_iter_s": 19.77325940132141, "time_total_s": 805.2646539211273, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 805.2646539211273, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 22.065384615384616, "ram_util_percent": 70.4076923076923, "gpu_util_percent0": 0.21884615384615386, "vram_util_percent0": 0.28551891317310935}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 962.53, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10435.3, "pol1": -10435.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 715, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 6140.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -6140.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1902246358983572, "mean_inference_ms": 2.670407727830276, "mean_action_processing_ms": 0.13517758649811085, "mean_env_wait_ms": 0.10309219245797062, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 256047, "agent_timesteps_total": 512094, "timers": {"sample_time_ms": 3559.306, "sample_throughput": 1740.873, "learn_time_ms": 15841.7, "learn_throughput": 391.139, "update_time_ms": 5.204}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.621829223632813, "cur_lr": 5.000000000000002e-05, "total_loss": 332428.545212766, "policy_loss": 0.04944834224087127, "vf_loss": 332428.47739361704, "vf_explained_var": "null", "kl": 0.008592004342836903, "entropy": 2.2848883436081255, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 337028.6875, "policy_loss": -0.0024380544795000805, "vf_loss": 337028.6875, "vf_explained_var": "null", "kl": 0.007271746500454685, "entropy": 2.99953045743577, "entropy_coeff": 0.0}}}, "num_steps_sampled": 256047, "num_agent_steps_sampled": 512094, "num_steps_trained": 256047, "num_agent_steps_trained": 512094}, "done": false, "episodes_total": 270, "training_iteration": 42, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-34-42", "timestamp": 1624710882, "time_this_iter_s": 18.163167476654053, "time_total_s": 823.4278213977814, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc209510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc209158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 823.4278213977814, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 20.791666666666668, "ram_util_percent": 70.4875, "gpu_util_percent0": 0.22166666666666668, "vram_util_percent0": 0.2855226940793169}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 965.38, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10483.8, "pol1": -10483.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19014848838059792, "mean_inference_ms": 2.6689959840536206, "mean_action_processing_ms": 0.13510091150732534, "mean_env_wait_ms": 0.10304429039969032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 262047, "agent_timesteps_total": 524094, "timers": {"sample_time_ms": 3556.969, "sample_throughput": 1742.017, "learn_time_ms": 15678.832, "learn_throughput": 395.202, "update_time_ms": 5.117}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.621829223632813, "cur_lr": 5.000000000000002e-05, "total_loss": 320806.7227393617, "policy_loss": 0.006495985440275771, "vf_loss": 320806.701462766, "vf_explained_var": "null", "kl": 0.009960134939706706, "entropy": 2.2718816868802336, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 325735.97473404254, "policy_loss": -0.004948017613447093, "vf_loss": 325735.97739361704, "vf_explained_var": "null", "kl": 0.010464256787870793, "entropy": 2.9638348335915423, "entropy_coeff": 0.0}}}, "num_steps_sampled": 262047, "num_agent_steps_sampled": 524094, "num_steps_trained": 262047, "num_agent_steps_trained": 524094}, "done": false, "episodes_total": 276, "training_iteration": 43, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-34-59", "timestamp": 1624710899, "time_this_iter_s": 17.217518091201782, "time_total_s": 840.6453394889832, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 840.6453394889832, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 20.869565217391308, "ram_util_percent": 70.55217391304348, "gpu_util_percent0": 0.23260869565217393, "vram_util_percent0": 0.2855248311132604}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 965.38, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10483.8, "pol1": -10483.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19006389726441814, "mean_inference_ms": 2.667513155084897, "mean_action_processing_ms": 0.13502112356921636, "mean_env_wait_ms": 0.10299337130023252, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 268047, "agent_timesteps_total": 536094, "timers": {"sample_time_ms": 3436.631, "sample_throughput": 1785.848, "learn_time_ms": 15345.713, "learn_throughput": 399.936, "update_time_ms": 5.033}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.621829223632813, "cur_lr": 5.000000000000002e-05, "total_loss": 309382.47074468085, "policy_loss": -0.009196299009342143, "vf_loss": 309382.47340425535, "vf_explained_var": "null", "kl": 0.0054642581281826854, "entropy": 2.37420206881584, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 318087.54321808513, "policy_loss": -0.0034000213713722026, "vf_loss": 318087.5425531915, "vf_explained_var": "null", "kl": 0.010150458594348202, "entropy": 2.926956780413364, "entropy_coeff": 0.0}}}, "num_steps_sampled": 268047, "num_agent_steps_sampled": 536094, "num_steps_trained": 268047, "num_agent_steps_trained": 536094}, "done": false, "episodes_total": 282, "training_iteration": 44, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-35-16", "timestamp": 1624710916, "time_this_iter_s": 17.152015686035156, "time_total_s": 857.7973551750183, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84bbe20c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f84bf7e1268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 857.7973551750183, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 19.882608695652177, "ram_util_percent": 70.59565217391301, "gpu_util_percent0": 0.23695652173913048, "vram_util_percent0": 0.2855248311132604}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 964.99, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10459.9, "pol1": -10459.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 845, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 7440.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -7440.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18997163673466488, "mean_inference_ms": 2.6661094891407755, "mean_action_processing_ms": 0.1349474566414782, "mean_env_wait_ms": 0.10294616248857955, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 274008, "agent_timesteps_total": 548016, "timers": {"sample_time_ms": 3357.102, "sample_throughput": 1814.035, "learn_time_ms": 15116.022, "learn_throughput": 402.877, "update_time_ms": 4.957}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.621829223632813, "cur_lr": 5.000000000000002e-05, "total_loss": 295220.3902925532, "policy_loss": -0.0022349070282058512, "vf_loss": 295220.38696808513, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.004250094334178782, "entropy": 2.362072594622348, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 299623.2566489362, "policy_loss": -0.0021673723104152273, "vf_loss": 299623.25265957444, "vf_explained_var": 0.0, "kl": 0.017790982935656893, "entropy": 3.0105241105911578, "entropy_coeff": 0.0}}}, "num_steps_sampled": 274008, "num_agent_steps_sampled": 548016, "num_steps_trained": 274008, "num_agent_steps_trained": 548016}, "done": false, "episodes_total": 288, "training_iteration": 45, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-35-34", "timestamp": 1624710934, "time_this_iter_s": 17.031675338745117, "time_total_s": 874.8290305137634, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc232510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc232f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 874.8290305137634, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 21.647826086956524, "ram_util_percent": 70.69565217391305, "gpu_util_percent0": 0.24173913043478262, "vram_util_percent0": 0.28551750413974003}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 966.54, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10495.4, "pol1": -10495.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 730, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1898954304031684, "mean_inference_ms": 2.664783388879675, "mean_action_processing_ms": 0.1348825960916238, "mean_env_wait_ms": 0.10290333124965381, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 280008, "agent_timesteps_total": 560016, "timers": {"sample_time_ms": 3316.358, "sample_throughput": 1825.466, "learn_time_ms": 14901.108, "learn_throughput": 406.272, "update_time_ms": 4.978}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.000000000000002e-05, "total_loss": 287343.0691489362, "policy_loss": 0.014107546868159416, "vf_loss": 287343.0445478723, "vf_explained_var": "null", "kl": 0.006488819973186609, "entropy": 2.3165380701105645, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 291934.75265957444, "policy_loss": -0.000979462539420483, "vf_loss": 291934.74800531915, "vf_explained_var": "null", "kl": 0.010863524069018821, "entropy": 3.055423949627166, "entropy_coeff": 0.0}}}, "num_steps_sampled": 280008, "num_agent_steps_sampled": 560016, "num_steps_trained": 280008, "num_agent_steps_trained": 560016}, "done": false, "episodes_total": 294, "training_iteration": 46, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-35-51", "timestamp": 1624710951, "time_this_iter_s": 17.44447660446167, "time_total_s": 892.2735071182251, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2267b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 892.2735071182251, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 22.41304347826087, "ram_util_percent": 70.69565217391305, "gpu_util_percent0": 0.2669565217391303, "vram_util_percent0": 0.28600841136560134}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 965.13, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10481.3, "pol1": -10481.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18973957403778813, "mean_inference_ms": 2.6627081385844518, "mean_action_processing_ms": 0.1347408780927299, "mean_env_wait_ms": 0.10280595222534279, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 286597, "agent_timesteps_total": 573194, "timers": {"sample_time_ms": 3397.675, "sample_throughput": 1808.119, "learn_time_ms": 14964.418, "learn_throughput": 410.534, "update_time_ms": 4.923}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164063, "cur_lr": 5.0000000000000016e-05, "total_loss": 275247.0811298077, "policy_loss": 0.0007351982371451763, "vf_loss": 275247.0763221154, "vf_explained_var": -3.8972267191184073e-08, "kl": 0.0068308374969861824, "entropy": 2.2724731197723975, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 280481.84495192306, "policy_loss": -0.001921581570059061, "vf_loss": 280481.84435096156, "vf_explained_var": -2.1778619796464227e-08, "kl": 0.007981966428745251, "entropy": 2.9953128695487976, "entropy_coeff": 0.0}}}, "num_steps_sampled": 286597, "num_agent_steps_sampled": 573194, "num_steps_trained": 286597, "num_agent_steps_trained": 573194}, "done": false, "episodes_total": 301, "training_iteration": 47, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-36-11", "timestamp": 1624710971, "time_this_iter_s": 19.48608136177063, "time_total_s": 911.7595884799957, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 911.7595884799957, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 19.411538461538463, "ram_util_percent": 70.71923076923078, "gpu_util_percent0": 0.21461538461538465, "vram_util_percent0": 0.2865235539654144}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 963.13, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10441.3, "pol1": -10441.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18962773844484387, "mean_inference_ms": 2.660960931194067, "mean_action_processing_ms": 0.134654874014416, "mean_env_wait_ms": 0.1027462982219514, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 292397, "agent_timesteps_total": 584794, "timers": {"sample_time_ms": 3383.393, "sample_throughput": 1809.84, "learn_time_ms": 14829.627, "learn_throughput": 412.917, "update_time_ms": 4.837}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8109146118164064, "cur_lr": 5.0000000000000016e-05, "total_loss": 265132.44361413043, "policy_loss": -0.000953375483336656, "vf_loss": 265132.4300271739, "vf_explained_var": 1.2957531714263837e-09, "kl": 0.022476044807421124, "entropy": 2.2938791617103247, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 270031.70754076086, "policy_loss": -0.00781939846827932, "vf_loss": 270031.70482336957, "vf_explained_var": -1.2957531714263837e-09, "kl": 0.01414049902687902, "entropy": 3.1412166616191035, "entropy_coeff": 0.0}}}, "num_steps_sampled": 292397, "num_agent_steps_sampled": 584794, "num_steps_trained": 292397, "num_agent_steps_trained": 584794}, "done": false, "episodes_total": 307, "training_iteration": 48, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-36-27", "timestamp": 1624710987, "time_this_iter_s": 16.717923641204834, "time_total_s": 928.4775121212006, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 928.4775121212006, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 20.472727272727276, "ram_util_percent": 70.77727272727272, "gpu_util_percent0": 0.22045454545454543, "vram_util_percent0": 0.28648466464442196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 963.13, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10441.3, "pol1": -10441.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 590, 1000, 1000, 1000, 1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 4890.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -4890.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18950839277397016, "mean_inference_ms": 2.6589491081664054, "mean_action_processing_ms": 0.13455543636559308, "mean_env_wait_ms": 0.10267795197798907, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 298397, "agent_timesteps_total": 596794, "timers": {"sample_time_ms": 3271.0, "sample_throughput": 1854.754, "learn_time_ms": 14524.863, "learn_throughput": 417.691, "update_time_ms": 4.716}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2163719177246093, "cur_lr": 5.000000000000002e-05, "total_loss": 255898.6914893617, "policy_loss": -0.0051074546781626155, "vf_loss": 255898.67420212767, "vf_explained_var": "null", "kl": 0.018993011497436686, "entropy": 2.3315479298855397, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 261576.70113031915, "policy_loss": 0.002554599790179983, "vf_loss": 261576.6911569149, "vf_explained_var": "null", "kl": 0.01884041112312611, "entropy": 3.0943441695355354, "entropy_coeff": 0.0}}}, "num_steps_sampled": 298397, "num_agent_steps_sampled": 596794, "num_steps_trained": 298397, "num_agent_steps_trained": 596794}, "done": false, "episodes_total": 313, "training_iteration": 49, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-36-44", "timestamp": 1624711004, "time_this_iter_s": 17.06882405281067, "time_total_s": 945.5463361740112, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f84bf7e1268>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 945.5463361740112, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 19.97826086956522, "ram_util_percent": 70.8391304347826, "gpu_util_percent0": 0.2230434782608696, "vram_util_percent0": 0.28648466464442196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 967.23, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10502.3, "pol1": -10502.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 435, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 3340.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -3340.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18941946659127942, "mean_inference_ms": 2.65701891609997, "mean_action_processing_ms": 0.13450097996276145, "mean_env_wait_ms": 0.10264179158357223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 304397, "agent_timesteps_total": 608794, "timers": {"sample_time_ms": 3248.542, "sample_throughput": 1867.576, "learn_time_ms": 14423.829, "learn_throughput": 420.616, "update_time_ms": 4.636}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2163719177246093, "cur_lr": 5.000000000000002e-05, "total_loss": 245709.5904255319, "policy_loss": -0.07545582096072588, "vf_loss": 245709.66223404257, "vf_explained_var": "null", "kl": 0.0033234388349538155, "entropy": 2.249053173876823, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 250214.00432180852, "policy_loss": 0.0016184223498752776, "vf_loss": 250213.99933510637, "vf_explained_var": "null", "kl": 0.011545738264759804, "entropy": 2.9538775758540377, "entropy_coeff": 0.0}}}, "num_steps_sampled": 304397, "num_agent_steps_sampled": 608794, "num_steps_trained": 304397, "num_agent_steps_trained": 608794}, "done": false, "episodes_total": 319, "training_iteration": 50, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-37-01", "timestamp": 1624711021, "time_this_iter_s": 16.878767728805542, "time_total_s": 962.4251039028168, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc232ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc232510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 962.4251039028168, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 19.663636363636364, "ram_util_percent": 70.87727272727274, "gpu_util_percent0": 0.22318181818181818, "vram_util_percent0": 0.28648466464442196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 972.88, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10578.8, "pol1": -10578.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 360, 1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2590.0, 10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2590.0, -10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18926854194977444, "mean_inference_ms": 2.6554049590341053, "mean_action_processing_ms": 0.134399865018326, "mean_env_wait_ms": 0.10257952767238705, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 310397, "agent_timesteps_total": 620794, "timers": {"sample_time_ms": 3201.079, "sample_throughput": 1885.302, "learn_time_ms": 14206.507, "learn_throughput": 424.805, "update_time_ms": 4.566}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6081859588623046, "cur_lr": 5.000000000000002e-05, "total_loss": 235722.20977393616, "policy_loss": -0.12744329225747508, "vf_loss": 235722.3284574468, "vf_explained_var": "null", "kl": 0.014620130960928632, "entropy": 2.3088619455378105, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 240969.22074468085, "policy_loss": -0.0026876751650521096, "vf_loss": 240969.21642287233, "vf_explained_var": "null", "kl": 0.011825747352014197, "entropy": 2.8745931716675455, "entropy_coeff": 0.0}}}, "num_steps_sampled": 310397, "num_agent_steps_sampled": 620794, "num_steps_trained": 310397, "num_agent_steps_trained": 620794}, "done": false, "episodes_total": 325, "training_iteration": 51, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-37-18", "timestamp": 1624711038, "time_this_iter_s": 17.124294996261597, "time_total_s": 979.5493988990784, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc209d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc209e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 979.5493988990784, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 21.008695652173913, "ram_util_percent": 71.24347826086957, "gpu_util_percent0": 0.2234782608695653, "vram_util_percent0": 0.28652862648554384}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 979.28, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10662.8, "pol1": -10662.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 694, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 5930.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -5930.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18914253624889185, "mean_inference_ms": 2.653523747205044, "mean_action_processing_ms": 0.13430263967410558, "mean_env_wait_ms": 0.10251296778706365, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 316397, "agent_timesteps_total": 632794, "timers": {"sample_time_ms": 3180.945, "sample_throughput": 1897.235, "learn_time_ms": 14106.981, "learn_throughput": 427.802, "update_time_ms": 4.493}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6081859588623046, "cur_lr": 5.000000000000002e-05, "total_loss": 225956.54188829788, "policy_loss": 0.3219356562228913, "vf_loss": 225956.2071143617, "vf_explained_var": "null", "kl": 0.024093870668018116, "entropy": 2.320510803384984, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 230763.66522606384, "policy_loss": 0.0022492327509408302, "vf_loss": 230763.65458776595, "vf_explained_var": "null", "kl": 0.013605614133337711, "entropy": 2.784708702817876, "entropy_coeff": 0.0}}}, "num_steps_sampled": 316397, "num_agent_steps_sampled": 632794, "num_steps_trained": 316397, "num_agent_steps_trained": 632794}, "done": false, "episodes_total": 331, "training_iteration": 52, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-37-35", "timestamp": 1624711055, "time_this_iter_s": 16.966183185577393, "time_total_s": 996.5155820846558, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226ea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 996.5155820846558, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 20.504545454545454, "ram_util_percent": 71.17272727272729, "gpu_util_percent0": 0.22136363636363632, "vram_util_percent0": 0.2865306247510494}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 982.34, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10713.4, "pol1": -10713.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18900724768360752, "mean_inference_ms": 2.6515366601454025, "mean_action_processing_ms": 0.1341997426132178, "mean_env_wait_ms": 0.10244197989271604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 322397, "agent_timesteps_total": 644794, "timers": {"sample_time_ms": 3167.086, "sample_throughput": 1905.537, "learn_time_ms": 14126.107, "learn_throughput": 427.223, "update_time_ms": 4.464}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 216387.07313829788, "policy_loss": -0.12351394294107214, "vf_loss": 216387.19248670212, "vf_explained_var": "null", "kl": 0.00666594507291596, "entropy": 2.1674430877604385, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 221027.8008643617, "policy_loss": -0.004116948614729212, "vf_loss": 221027.79953457447, "vf_explained_var": "null", "kl": 0.008691266426776952, "entropy": 2.862620637771931, "entropy_coeff": 0.0}}}, "num_steps_sampled": 322397, "num_agent_steps_sampled": 644794, "num_steps_trained": 322397, "num_agent_steps_trained": 644794}, "done": false, "episodes_total": 337, "training_iteration": 53, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-37-53", "timestamp": 1624711073, "time_this_iter_s": 17.270240783691406, "time_total_s": 1013.7858228683472, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc232f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2bad90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1013.7858228683472, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 20.508695652173916, "ram_util_percent": 71.10434782608692, "gpu_util_percent0": 0.2217391304347826, "vram_util_percent0": 0.2866605120089096}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 982.34, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10713.4, "pol1": -10713.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 565, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 4640.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -4640.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18887352661281132, "mean_inference_ms": 2.6494536682798313, "mean_action_processing_ms": 0.13409230199323852, "mean_env_wait_ms": 0.10236604372861667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 328397, "agent_timesteps_total": 656794, "timers": {"sample_time_ms": 3161.633, "sample_throughput": 1908.823, "learn_time_ms": 14137.447, "learn_throughput": 426.88, "update_time_ms": 4.507}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 207024.94880319148, "policy_loss": -0.5804272458908406, "vf_loss": 207025.51263297873, "vf_explained_var": "null", "kl": 0.018107874636003312, "entropy": 2.182073451103048, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 211787.82945478722, "policy_loss": -0.00041558215037939395, "vf_loss": 211787.81815159574, "vf_explained_var": "null", "kl": 0.023296797846225983, "entropy": 2.8630607939781028, "entropy_coeff": 0.0}}}, "num_steps_sampled": 328397, "num_agent_steps_sampled": 656794, "num_steps_trained": 328397, "num_agent_steps_trained": 656794}, "done": false, "episodes_total": 343, "training_iteration": 54, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-38-10", "timestamp": 1624711090, "time_this_iter_s": 17.12281346321106, "time_total_s": 1030.9086363315582, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2232f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1030.9086363315582, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 19.9, "ram_util_percent": 71.17391304347827, "gpu_util_percent0": 0.22260869565217387, "vram_util_percent0": 0.2866531850353892}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 986.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10776.9, "pol1": -10776.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18871221455160436, "mean_inference_ms": 2.6477925267298774, "mean_action_processing_ms": 0.13396578420230487, "mean_env_wait_ms": 0.1022776084490159, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 334397, "agent_timesteps_total": 668794, "timers": {"sample_time_ms": 3176.846, "sample_throughput": 1900.91, "learn_time_ms": 14134.757, "learn_throughput": 427.238, "update_time_ms": 4.513}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 197866.5192819149, "policy_loss": 0.05165309292521882, "vf_loss": 197866.45611702127, "vf_explained_var": "null", "kl": 0.013412012223233568, "entropy": 2.163694828114611, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 202556.89228723405, "policy_loss": -0.004424306494679222, "vf_loss": 202556.88430851063, "vf_explained_var": "null", "kl": 0.015294774831768046, "entropy": 2.8726933864836997, "entropy_coeff": 0.0}}}, "num_steps_sampled": 334397, "num_agent_steps_sampled": 668794, "num_steps_trained": 334397, "num_agent_steps_trained": 668794}, "done": false, "episodes_total": 349, "training_iteration": 55, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-38-27", "timestamp": 1624711107, "time_this_iter_s": 17.15660834312439, "time_total_s": 1048.0652446746826, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2238c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc223f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1048.0652446746826, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 22.304347826086957, "ram_util_percent": 71.3695652173913, "gpu_util_percent0": 0.23304347826086966, "vram_util_percent0": 0.28670447385003145}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 986.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10776.9, "pol1": -10776.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18860082920429977, "mean_inference_ms": 2.6460055905100632, "mean_action_processing_ms": 0.1338736531435882, "mean_env_wait_ms": 0.10221391682268725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 340397, "agent_timesteps_total": 680794, "timers": {"sample_time_ms": 3156.226, "sample_throughput": 1913.329, "learn_time_ms": 14155.937, "learn_throughput": 426.598, "update_time_ms": 4.502}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 188923.67752659574, "policy_loss": -0.030572395395249762, "vf_loss": 188923.70113031915, "vf_explained_var": "null", "kl": 0.009063107159702068, "entropy": 2.1831689692558127, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 193460.02493351063, "policy_loss": -0.0005953130411340835, "vf_loss": 193460.0236037234, "vf_explained_var": "null", "kl": 0.006441728063324031, "entropy": 2.9038946172024342, "entropy_coeff": 0.0}}}, "num_steps_sampled": 340397, "num_agent_steps_sampled": 680794, "num_steps_trained": 340397, "num_agent_steps_trained": 680794}, "done": false, "episodes_total": 355, "training_iteration": 56, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-38-45", "timestamp": 1624711125, "time_this_iter_s": 17.450810432434082, "time_total_s": 1065.5160551071167, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc23b6a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc23bf28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1065.5160551071167, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 21.856521739130436, "ram_util_percent": 71.33478260869563, "gpu_util_percent0": 0.22739130434782606, "vram_util_percent0": 0.28670447385003145}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 986.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2180.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2180.0}, "policy_reward_mean": {"pol0": 10776.9, "pol1": -10776.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 319, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 2180.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -2180.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1884800410741751, "mean_inference_ms": 2.6440288592259504, "mean_action_processing_ms": 0.13377165802606844, "mean_env_wait_ms": 0.10214252099389051, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 346397, "agent_timesteps_total": 692794, "timers": {"sample_time_ms": 3059.001, "sample_throughput": 1954.887, "learn_time_ms": 14022.353, "learn_throughput": 426.462, "update_time_ms": 4.497}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 180192.625, "policy_loss": -0.32130601685097876, "vf_loss": 180192.93484042553, "vf_explained_var": "null", "kl": 0.013520914090282105, "entropy": 2.2863264946227377, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 184956.52593085106, "policy_loss": -0.0005396395089461448, "vf_loss": 184956.52160904257, "vf_explained_var": "null", "kl": 0.006849946483890427, "entropy": 2.853079374800337, "entropy_coeff": 0.0}}}, "num_steps_sampled": 346397, "num_agent_steps_sampled": 692794, "num_steps_trained": 346397, "num_agent_steps_trained": 692794}, "done": false, "episodes_total": 361, "training_iteration": 57, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-39-02", "timestamp": 1624711142, "time_this_iter_s": 17.17794442176819, "time_total_s": 1082.693999528885, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1082.693999528885, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 20.343478260869567, "ram_util_percent": 71.31304347826085, "gpu_util_percent0": 0.2186956521739131, "vram_util_percent0": 0.2866458580618689}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 993.5, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 4880.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -4880.0}, "policy_reward_mean": {"pol0": 10865.0, "pol1": -10865.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18836219632230888, "mean_inference_ms": 2.642123941715447, "mean_action_processing_ms": 0.13366998460522939, "mean_env_wait_ms": 0.10206574979333427, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 352397, "agent_timesteps_total": 704794, "timers": {"sample_time_ms": 3074.968, "sample_throughput": 1951.24, "learn_time_ms": 14062.323, "learn_throughput": 426.672, "update_time_ms": 4.644}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 171656.18184840426, "policy_loss": -0.4209684349120931, "vf_loss": 171656.59075797873, "vf_explained_var": "null", "kl": 0.011398080696767949, "entropy": 2.355943684882306, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 176297.82347074468, "policy_loss": -0.0021575924127976943, "vf_loss": 176297.8244680851, "vf_explained_var": "null", "kl": 0.004231597336524344, "entropy": 2.820346350365497, "entropy_coeff": 0.0}}}, "num_steps_sampled": 352397, "num_agent_steps_sampled": 704794, "num_steps_trained": 352397, "num_agent_steps_trained": 704794}, "done": false, "episodes_total": 367, "training_iteration": 58, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-39-19", "timestamp": 1624711159, "time_this_iter_s": 17.27848196029663, "time_total_s": 1099.9724814891815, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1099.9724814891815, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 20.517391304347832, "ram_util_percent": 71.42173913043482, "gpu_util_percent0": 0.22086956521739132, "vram_util_percent0": 0.28648466464442196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 993.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 4880.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -4880.0}, "policy_reward_mean": {"pol0": 10840.0, "pol1": -10840.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18822684044646212, "mean_inference_ms": 2.6401605492147304, "mean_action_processing_ms": 0.13356622766680928, "mean_env_wait_ms": 0.10199075415395897, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 358347, "agent_timesteps_total": 716694, "timers": {"sample_time_ms": 3070.139, "sample_throughput": 1952.681, "learn_time_ms": 14073.056, "learn_throughput": 425.991, "update_time_ms": 4.666}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9122789382934566, "cur_lr": 5.000000000000002e-05, "total_loss": 169751.50066489363, "policy_loss": -0.0015309421702268276, "vf_loss": 169751.4720744681, "vf_explained_var": -3.804551784725163e-09, "kl": 0.032278624145274465, "entropy": 2.352736807884054, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 174714.33909574468, "policy_loss": -0.008054947797605332, "vf_loss": 174714.34674202127, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.01031259280887056, "entropy": 2.7279578168341456, "entropy_coeff": 0.0}}}, "num_steps_sampled": 358347, "num_agent_steps_sampled": 716694, "num_steps_trained": 358347, "num_agent_steps_trained": 716694}, "done": false, "episodes_total": 373, "training_iteration": 59, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-39-36", "timestamp": 1624711176, "time_this_iter_s": 17.12773299217224, "time_total_s": 1117.1002144813538, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc209bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2091e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1117.1002144813538, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 19.691304347826087, "ram_util_percent": 71.44782608695655, "gpu_util_percent0": 0.22434782608695644, "vram_util_percent0": 0.28648466464442196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 993.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 4880.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -4880.0}, "policy_reward_mean": {"pol0": 10840.0, "pol1": -10840.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 961, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 8600.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -8600.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18808890916216775, "mean_inference_ms": 2.6381036620167073, "mean_action_processing_ms": 0.13345734913564736, "mean_env_wait_ms": 0.10191240807677142, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 364347, "agent_timesteps_total": 728694, "timers": {"sample_time_ms": 3071.417, "sample_throughput": 1951.868, "learn_time_ms": 14080.897, "learn_throughput": 425.754, "update_time_ms": 4.704}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.368418407440186, "cur_lr": 5.000000000000002e-05, "total_loss": 155350.1173537234, "policy_loss": -0.013312969713452015, "vf_loss": 155350.08444148937, "vf_explained_var": "null", "kl": 0.033537742067524724, "entropy": 2.3407237732664066, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 160946.28257978722, "policy_loss": -0.005102547698039958, "vf_loss": 160946.2849069149, "vf_explained_var": "null", "kl": 0.007392762575615594, "entropy": 2.69670099907733, "entropy_coeff": 0.0}}}, "num_steps_sampled": 364347, "num_agent_steps_sampled": 728694, "num_steps_trained": 364347, "num_agent_steps_trained": 728694}, "done": false, "episodes_total": 379, "training_iteration": 60, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-39-53", "timestamp": 1624711193, "time_this_iter_s": 16.970073223114014, "time_total_s": 1134.0702877044678, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc209d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2268c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1134.0702877044678, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 20.081818181818182, "ram_util_percent": 71.49545454545455, "gpu_util_percent0": 0.22500000000000006, "vram_util_percent0": 0.28648466464442196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 993.39, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 4880.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -4880.0}, "policy_reward_mean": {"pol0": 10863.9, "pol1": -10863.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1879471798303557, "mean_inference_ms": 2.635909756334306, "mean_action_processing_ms": 0.1333407150864475, "mean_env_wait_ms": 0.10182922157766412, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 370347, "agent_timesteps_total": 740694, "timers": {"sample_time_ms": 3041.28, "sample_throughput": 1971.21, "learn_time_ms": 14093.131, "learn_throughput": 425.385, "update_time_ms": 4.71}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.052627611160278, "cur_lr": 5.000000000000002e-05, "total_loss": 147441.14228723405, "policy_loss": -0.006163388847353611, "vf_loss": 147441.1323138298, "vf_explained_var": "null", "kl": 0.008026752937981423, "entropy": 2.4424774443849606, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 152169.16589095743, "policy_loss": -1.5368804018548195e-06, "vf_loss": 152169.15924202127, "vf_explained_var": "null", "kl": 0.012668972676421733, "entropy": 2.712313860020739, "entropy_coeff": 0.0}}}, "num_steps_sampled": 370347, "num_agent_steps_sampled": 740694, "num_steps_trained": 370347, "num_agent_steps_trained": 740694}, "done": false, "episodes_total": 385, "training_iteration": 61, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-40-10", "timestamp": 1624711210, "time_this_iter_s": 16.945132732391357, "time_total_s": 1151.0154204368591, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc23b950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc23b8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1151.0154204368591, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 19.81304347826087, "ram_util_percent": 71.60869565217388, "gpu_util_percent0": 0.22739130434782612, "vram_util_percent0": 0.28648466464442196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 991.25, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 4880.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -4880.0}, "policy_reward_mean": {"pol0": 10822.5, "pol1": -10822.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.187799686634415, "mean_inference_ms": 2.633677491683252, "mean_action_processing_ms": 0.13321988234739007, "mean_env_wait_ms": 0.10174385399246491, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 376133, "agent_timesteps_total": 752266, "timers": {"sample_time_ms": 3047.959, "sample_throughput": 1959.869, "learn_time_ms": 14068.312, "learn_throughput": 424.614, "update_time_ms": 4.738}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.052627611160278, "cur_lr": 5.0000000000000016e-05, "total_loss": 148389.20754076086, "policy_loss": 0.0028647112295679426, "vf_loss": 148389.17255434784, "vf_explained_var": 1.1661778209770546e-08, "kl": 0.018004138103645782, "entropy": 2.4837039864581563, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 154960.47690217392, "policy_loss": -0.0006459971646899762, "vf_loss": 154960.47520380435, "vf_explained_var": -1.2957531714263837e-09, "kl": 0.009952091713152502, "entropy": 2.962180661118549, "entropy_coeff": 0.0}}}, "num_steps_sampled": 376133, "num_agent_steps_sampled": 752266, "num_steps_trained": 376133, "num_agent_steps_trained": 752266}, "done": false, "episodes_total": 391, "training_iteration": 62, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-40-27", "timestamp": 1624711227, "time_this_iter_s": 16.784861087799072, "time_total_s": 1167.8002815246582, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc223510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1167.8002815246582, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 21.35909090909091, "ram_util_percent": 71.63636363636364, "gpu_util_percent0": 0.22272727272727275, "vram_util_percent0": 0.2865306247510494}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 989.89, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 4880.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -4880.0}, "policy_reward_mean": {"pol0": 10788.9, "pol1": -10788.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 589, 1000, 1000, 1000, 800, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 4880.0, 10990.0, 10990.0, 10990.0, 6990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -4880.0, -10990.0, -10990.0, -10990.0, -6990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18765251733711666, "mean_inference_ms": 2.631389950313874, "mean_action_processing_ms": 0.13309543294268764, "mean_env_wait_ms": 0.10165586851690936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 381997, "agent_timesteps_total": 763994, "timers": {"sample_time_ms": 3040.788, "sample_throughput": 1960.018, "learn_time_ms": 14018.076, "learn_throughput": 425.165, "update_time_ms": 4.754}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.052627611160278, "cur_lr": 5.0000000000000016e-05, "total_loss": 141803.5174932065, "policy_loss": -0.003210758628404659, "vf_loss": 141803.51171875, "vf_explained_var": -2.4619309257900568e-08, "kl": 0.004248348500012704, "entropy": 2.510948782381804, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 145688.88383152173, "policy_loss": -0.004564239684006442, "vf_loss": 145688.88383152173, "vf_explained_var": -3.6281086579492694e-08, "kl": 0.010241377410357412, "entropy": 3.0740859197533648, "entropy_coeff": 0.0}}}, "num_steps_sampled": 381997, "num_agent_steps_sampled": 763994, "num_steps_trained": 381997, "num_agent_steps_trained": 763994}, "done": false, "episodes_total": 397, "training_iteration": 63, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-40-44", "timestamp": 1624711244, "time_this_iter_s": 16.69589376449585, "time_total_s": 1184.496175289154, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84bbe20d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1184.496175289154, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 19.7, "ram_util_percent": 71.70000000000002, "gpu_util_percent0": 0.22590909090909086, "vram_util_percent0": 0.28653828476882065}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 996.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 6850.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -6850.0}, "policy_reward_mean": {"pol0": 10890.0, "pol1": -10890.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1875616858623654, "mean_inference_ms": 2.629174476673154, "mean_action_processing_ms": 0.1329744551456959, "mean_env_wait_ms": 0.10160370724753992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 387997, "agent_timesteps_total": 775994, "timers": {"sample_time_ms": 3049.892, "sample_throughput": 1954.168, "learn_time_ms": 14019.576, "learn_throughput": 425.12, "update_time_ms": 4.7}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.000000000000002e-05, "total_loss": 125178.56582446808, "policy_loss": -0.32394656063394345, "vf_loss": 125178.87583111702, "vf_explained_var": "null", "kl": 0.012964256959868239, "entropy": 2.539402865348978, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 129773.14893617021, "policy_loss": -0.004608535822084609, "vf_loss": 129773.15126329787, "vf_explained_var": "null", "kl": 0.00822781025372604, "entropy": 3.0414621271985642, "entropy_coeff": 0.0}}}, "num_steps_sampled": 387997, "num_agent_steps_sampled": 775994, "num_steps_trained": 387997, "num_agent_steps_trained": 775994}, "done": false, "episodes_total": 403, "training_iteration": 64, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-41-01", "timestamp": 1624711261, "time_this_iter_s": 17.226961135864258, "time_total_s": 1201.7231364250183, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2230d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2237b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1201.7231364250183, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 20.456521739130434, "ram_util_percent": 71.79130434782607, "gpu_util_percent0": 0.2230434782608696, "vram_util_percent0": 0.28424261074720486}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 992.45, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 5740.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -5740.0}, "policy_reward_mean": {"pol0": 10814.5, "pol1": -10814.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18741538949718756, "mean_inference_ms": 2.627183171195455, "mean_action_processing_ms": 0.1328588038815104, "mean_env_wait_ms": 0.10152249156134426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 393642, "agent_timesteps_total": 787284, "timers": {"sample_time_ms": 3015.425, "sample_throughput": 1964.732, "learn_time_ms": 13973.092, "learn_throughput": 423.993, "update_time_ms": 4.67}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.0000000000000016e-05, "total_loss": 139952.57447916668, "policy_loss": -0.004708782707651456, "vf_loss": 139952.56493055556, "vf_explained_var": 3.973643192267673e-09, "kl": 0.013453412511282497, "entropy": 2.598485814200507, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 143448.0831597222, "policy_loss": 0.0064882935749159916, "vf_loss": 143448.07100694443, "vf_explained_var": 3.973643192267673e-09, "kl": 0.016764712913168802, "entropy": 3.011826335059272, "entropy_coeff": 0.0}}}, "num_steps_sampled": 393642, "num_agent_steps_sampled": 787284, "num_steps_trained": 393642, "num_agent_steps_trained": 787284}, "done": false, "episodes_total": 409, "training_iteration": 65, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-41-17", "timestamp": 1624711277, "time_this_iter_s": 16.347795009613037, "time_total_s": 1218.0709314346313, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1218.0709314346313, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 19.400000000000002, "ram_util_percent": 71.81363636363635, "gpu_util_percent0": 0.22318181818181812, "vram_util_percent0": 0.28412537917087977}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 992.45, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 5740.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -5740.0}, "policy_reward_mean": {"pol0": 10814.5, "pol1": -10814.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18726662449896397, "mean_inference_ms": 2.625300611833828, "mean_action_processing_ms": 0.13274916760219274, "mean_env_wait_ms": 0.10144523009460082, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 399642, "agent_timesteps_total": 799284, "timers": {"sample_time_ms": 3001.685, "sample_throughput": 1973.724, "learn_time_ms": 13928.632, "learn_throughput": 425.347, "update_time_ms": 4.649}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.000000000000002e-05, "total_loss": 111315.07563164894, "policy_loss": 0.020226449566952725, "vf_loss": 111315.04853723405, "vf_explained_var": "null", "kl": 0.006662572456642668, "entropy": 2.5729992389678955, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 115319.89527925532, "policy_loss": -0.0025094910425708648, "vf_loss": 115319.89029255319, "vf_explained_var": "null", "kl": 0.018730129055837368, "entropy": 3.11548050921014, "entropy_coeff": 0.0}}}, "num_steps_sampled": 399642, "num_agent_steps_sampled": 799284, "num_steps_trained": 399642, "num_agent_steps_trained": 799284}, "done": false, "episodes_total": 415, "training_iteration": 66, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-41-34", "timestamp": 1624711294, "time_this_iter_s": 16.867924213409424, "time_total_s": 1234.9388556480408, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1234.9388556480408, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 20.277272727272727, "ram_util_percent": 71.81363636363635, "gpu_util_percent0": 0.22727272727272732, "vram_util_percent0": 0.28412537917087977}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 991.26, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 5740.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -5740.0}, "policy_reward_mean": {"pol0": 10782.6, "pol1": -10782.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18711994646061877, "mean_inference_ms": 2.6233706626742874, "mean_action_processing_ms": 0.13263917369508935, "mean_env_wait_ms": 0.101368305114588, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 405523, "agent_timesteps_total": 811046, "timers": {"sample_time_ms": 2983.729, "sample_throughput": 1981.614, "learn_time_ms": 13890.261, "learn_throughput": 425.665, "update_time_ms": 4.681}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.0000000000000016e-05, "total_loss": 116810.96773097826, "policy_loss": 0.0012060723105526488, "vf_loss": 116810.94667119565, "vf_explained_var": 1.2957531048130022e-08, "kl": 0.018893426081732563, "entropy": 2.5780960995218027, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 122014.25254755435, "policy_loss": -0.003994445944123942, "vf_loss": 122014.24762228261, "vf_explained_var": -4.2759854324003754e-08, "kl": 0.019254392701322617, "entropy": 3.1506868911826094, "entropy_coeff": 0.0}}}, "num_steps_sampled": 405523, "num_agent_steps_sampled": 811046, "num_steps_trained": 405523, "num_agent_steps_trained": 811046}, "done": false, "episodes_total": 421, "training_iteration": 67, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-41-51", "timestamp": 1624711311, "time_this_iter_s": 16.61576223373413, "time_total_s": 1251.554617881775, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2bae18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1251.554617881775, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 19.521739130434785, "ram_util_percent": 71.8695652173913, "gpu_util_percent0": 0.22826086956521743, "vram_util_percent0": 0.28412537917087977}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 988.71, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 5740.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -5740.0}, "policy_reward_mean": {"pol0": 10737.1, "pol1": -10737.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18697860903892977, "mean_inference_ms": 2.6214799823457247, "mean_action_processing_ms": 0.1325333502129041, "mean_env_wait_ms": 0.10129383051475116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 411268, "agent_timesteps_total": 822536, "timers": {"sample_time_ms": 2963.069, "sample_throughput": 1986.825, "learn_time_ms": 13861.466, "learn_throughput": 424.71, "update_time_ms": 4.535}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.0000000000000016e-05, "total_loss": 111487.49513888889, "policy_loss": -0.0030662815810905564, "vf_loss": 111487.490625, "vf_explained_var": -1.4570024298166118e-08, "kl": 0.007474551691363255, "entropy": 2.584569814470079, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 116885.96649305556, "policy_loss": -0.005166844899455706, "vf_loss": 116885.96909722222, "vf_explained_var": -7.947286384535346e-09, "kl": 0.011147943118380176, "entropy": 3.1077763981289332, "entropy_coeff": 0.0}}}, "num_steps_sampled": 411268, "num_agent_steps_sampled": 822536, "num_steps_trained": 411268, "num_agent_steps_trained": 822536}, "done": false, "episodes_total": 427, "training_iteration": 68, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-42-08", "timestamp": 1624711328, "time_this_iter_s": 16.78266453742981, "time_total_s": 1268.3372824192047, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd296950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2969d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1268.3372824192047, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 22.509090909090908, "ram_util_percent": 71.9590909090909, "gpu_util_percent0": 0.22272727272727275, "vram_util_percent0": 0.28416367925973596}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 968.36, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10473.6, "pol1": -10473.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18677710301096812, "mean_inference_ms": 2.6189772358312404, "mean_action_processing_ms": 0.13238300837421454, "mean_env_wait_ms": 0.10119196407515227, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 418233, "agent_timesteps_total": 836466, "timers": {"sample_time_ms": 3029.168, "sample_throughput": 1976.979, "learn_time_ms": 14141.507, "learn_throughput": 423.477, "update_time_ms": 4.537}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.000000000000002e-05, "total_loss": 128742.94048295454, "policy_loss": 0.001327038657936183, "vf_loss": 128742.92002840909, "vf_explained_var": 2.167441559564054e-09, "kl": 0.01847074930979447, "entropy": 2.601398901505904, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3796875, "cur_lr": 5.000000000000002e-05, "total_loss": 159835.26235795455, "policy_loss": -0.0021685001186349177, "vf_loss": 159835.25994318182, "vf_explained_var": 6.502324900736767e-09, "kl": 0.015069162964143536, "entropy": 3.1749662442640827, "entropy_coeff": 0.0}}}, "num_steps_sampled": 418233, "num_agent_steps_sampled": 836466, "num_steps_trained": 418233, "num_agent_steps_trained": 836466}, "done": false, "episodes_total": 436, "training_iteration": 69, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-42-28", "timestamp": 1624711348, "time_this_iter_s": 20.58956480026245, "time_total_s": 1288.9268472194672, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd303c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2266a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1288.9268472194672, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 21.02592592592593, "ram_util_percent": 71.88518518518518, "gpu_util_percent0": 0.2155555555555555, "vram_util_percent0": 0.2841253791708797}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 968.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10473.6, "pol1": -10473.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18665189094696938, "mean_inference_ms": 2.6172902561861675, "mean_action_processing_ms": 0.1322886592380001, "mean_env_wait_ms": 0.10112537455285624, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 424233, "agent_timesteps_total": 848466, "timers": {"sample_time_ms": 3038.738, "sample_throughput": 1970.752, "learn_time_ms": 14145.114, "learn_throughput": 423.369, "update_time_ms": 4.518}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.000000000000002e-05, "total_loss": 86126.17752659574, "policy_loss": 0.029843357490732313, "vf_loss": 86126.13996010639, "vf_explained_var": "null", "kl": 0.00792669103619583, "entropy": 2.583475706425119, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 90916.12632978724, "policy_loss": 3.3885121662566e-05, "vf_loss": 90916.11835106384, "vf_explained_var": "null", "kl": 0.018189242585225307, "entropy": 3.2286651185218322, "entropy_coeff": 0.0}}}, "num_steps_sampled": 424233, "num_agent_steps_sampled": 848466, "num_steps_trained": 424233, "num_agent_steps_trained": 848466}, "done": false, "episodes_total": 442, "training_iteration": 70, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-42-45", "timestamp": 1624711365, "time_this_iter_s": 17.102402210235596, "time_total_s": 1306.0292494297028, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1306.0292494297028, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 20.73913043478261, "ram_util_percent": 71.83913043478259, "gpu_util_percent0": 0.22347826086956515, "vram_util_percent0": 0.28412537917087977}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 968.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10473.6, "pol1": -10473.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18652084516384013, "mean_inference_ms": 2.6154837755831917, "mean_action_processing_ms": 0.1321885617139217, "mean_env_wait_ms": 0.10105433822177584, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 430233, "agent_timesteps_total": 860466, "timers": {"sample_time_ms": 3057.176, "sample_throughput": 1958.867, "learn_time_ms": 14147.238, "learn_throughput": 423.305, "update_time_ms": 4.522}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.000000000000002e-05, "total_loss": 80263.00964095745, "policy_loss": 0.06316872380990932, "vf_loss": 80262.9336768617, "vf_explained_var": "null", "kl": 0.012259875424206257, "entropy": 2.520922457918208, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 88419.47440159574, "policy_loss": 0.0023949924222332365, "vf_loss": 88419.46675531915, "vf_explained_var": "null", "kl": 0.013884550753108998, "entropy": 3.0464544752810863, "entropy_coeff": 0.0}}}, "num_steps_sampled": 430233, "num_agent_steps_sampled": 860466, "num_steps_trained": 430233, "num_agent_steps_trained": 860466}, "done": false, "episodes_total": 448, "training_iteration": 71, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-43-03", "timestamp": 1624711383, "time_this_iter_s": 17.151429414749146, "time_total_s": 1323.180678844452, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba2f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1323.180678844452, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 20.099999999999998, "ram_util_percent": 71.82173913043475, "gpu_util_percent0": 0.22217391304347825, "vram_util_percent0": 0.28412537917087977}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 968.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10473.6, "pol1": -10473.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1863907103076837, "mean_inference_ms": 2.613571821855309, "mean_action_processing_ms": 0.13208315760611453, "mean_env_wait_ms": 0.10097764546653057, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 436233, "agent_timesteps_total": 872466, "timers": {"sample_time_ms": 3054.629, "sample_throughput": 1967.506, "learn_time_ms": 14166.675, "learn_throughput": 424.235, "update_time_ms": 4.509}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.026313805580139, "cur_lr": 5.000000000000002e-05, "total_loss": 74604.14145611702, "policy_loss": -0.08797777140949001, "vf_loss": 74604.20944148937, "vf_explained_var": "null", "kl": 0.02078131205858068, "entropy": 2.4944161049863127, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 78141.12583111702, "policy_loss": -0.004637391564059764, "vf_loss": 78141.12566489361, "vf_explained_var": "null", "kl": 0.01277612086306227, "entropy": 2.9711994871180107, "entropy_coeff": 0.0}}}, "num_steps_sampled": 436233, "num_agent_steps_sampled": 872466, "num_steps_trained": 436233, "num_agent_steps_trained": 872466}, "done": false, "episodes_total": 454, "training_iteration": 72, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-43-20", "timestamp": 1624711400, "time_this_iter_s": 16.953595638275146, "time_total_s": 1340.134274482727, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc223488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1340.134274482727, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 20.28636363636364, "ram_util_percent": 71.86818181818181, "gpu_util_percent0": 0.22227272727272734, "vram_util_percent0": 0.28412537917087977}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 962.31, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10373.1, "pol1": -10373.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18622108179133787, "mean_inference_ms": 2.6116447993474314, "mean_action_processing_ms": 0.13199353755617133, "mean_env_wait_ms": 0.10087746372614947, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 442628, "agent_timesteps_total": 885256, "timers": {"sample_time_ms": 3113.939, "sample_throughput": 1947.084, "learn_time_ms": 14274.504, "learn_throughput": 424.75, "update_time_ms": 4.521}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5394707083702084, "cur_lr": 5.000000000000001e-05, "total_loss": 99170.54890625, "policy_loss": 0.0007422951608896255, "vf_loss": 99170.52546875, "vf_explained_var": 9.53674295089968e-09, "kl": 0.01499215729534626, "entropy": 2.4954126405715944, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 102184.8546875, "policy_loss": -0.002582611944526434, "vf_loss": 102184.85046875, "vf_explained_var": -1.7881394143159923e-08, "kl": 0.012292568776756526, "entropy": 2.9933595561981203, "entropy_coeff": 0.0}}}, "num_steps_sampled": 442628, "num_agent_steps_sampled": 885256, "num_steps_trained": 442628, "num_agent_steps_trained": 885256}, "done": false, "episodes_total": 461, "training_iteration": 73, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-43-38", "timestamp": 1624711418, "time_this_iter_s": 18.367992639541626, "time_total_s": 1358.5022671222687, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2269d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226598>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1358.5022671222687, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 19.291999999999998, "ram_util_percent": 71.98, "gpu_util_percent0": 0.22240000000000001, "vram_util_percent0": 0.28412537917087965}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 962.31, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10373.1, "pol1": -10373.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 950, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8490.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8490.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18608853025139052, "mean_inference_ms": 2.6097030831171315, "mean_action_processing_ms": 0.13188841344852886, "mean_env_wait_ms": 0.10080167977632508, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 448628, "agent_timesteps_total": 897256, "timers": {"sample_time_ms": 3096.781, "sample_throughput": 1957.872, "learn_time_ms": 14260.822, "learn_throughput": 425.158, "update_time_ms": 4.527}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5394707083702082, "cur_lr": 5.000000000000002e-05, "total_loss": 63993.024850398935, "policy_loss": 0.006729542376830223, "vf_loss": 63993.01080452128, "vf_explained_var": "null", "kl": 0.004545947051349472, "entropy": 2.432154782274936, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 67953.48553856384, "policy_loss": -0.0011752238298984284, "vf_loss": 67953.48105053192, "vf_explained_var": "null", "kl": 0.013944515245074922, "entropy": 3.081155371158681, "entropy_coeff": 0.0}}}, "num_steps_sampled": 448628, "num_agent_steps_sampled": 897256, "num_steps_trained": 448628, "num_agent_steps_trained": 897256}, "done": false, "episodes_total": 467, "training_iteration": 74, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-43-55", "timestamp": 1624711435, "time_this_iter_s": 16.919395685195923, "time_total_s": 1375.4216628074646, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc232598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc232c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1375.4216628074646, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 20.295454545454547, "ram_util_percent": 71.99545454545455, "gpu_util_percent0": 0.2222727272727273, "vram_util_percent0": 0.2841713392775072}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 960.61, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10356.1, "pol1": -10356.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1859652839415321, "mean_inference_ms": 2.6079139971040592, "mean_action_processing_ms": 0.13179143310493122, "mean_env_wait_ms": 0.10073215117893211, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 454408, "agent_timesteps_total": 908816, "timers": {"sample_time_ms": 3119.215, "sample_throughput": 1948.118, "learn_time_ms": 14293.29, "learn_throughput": 425.137, "update_time_ms": 4.547}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7697353541851042, "cur_lr": 5.0000000000000016e-05, "total_loss": 77436.95168138586, "policy_loss": 0.0012143736138291981, "vf_loss": 77436.94573709239, "vf_explained_var": 1.1661778209770546e-08, "kl": 0.0066645588401867, "entropy": 2.491635623185531, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 79521.71059782608, "policy_loss": -0.005495420576113722, "vf_loss": 79521.71187160326, "vf_explained_var": -1.684479045138687e-08, "kl": 0.011830900390834911, "entropy": 3.0974917567294575, "entropy_coeff": 0.0}}}, "num_steps_sampled": 454408, "num_agent_steps_sampled": 908816, "num_steps_trained": 454408, "num_agent_steps_trained": 908816}, "done": false, "episodes_total": 473, "training_iteration": 75, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-44-12", "timestamp": 1624711452, "time_this_iter_s": 16.8962082862854, "time_total_s": 1392.31787109375, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1392.31787109375, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 21.104347826086954, "ram_util_percent": 72.0869565217391, "gpu_util_percent0": 0.21913043478260866, "vram_util_percent0": 0.284176667985522}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 952.71, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10237.1, "pol1": -10237.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18580721050465399, "mean_inference_ms": 2.6058000840375914, "mean_action_processing_ms": 0.13168061193604413, "mean_env_wait_ms": 0.10061472985561679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 460618, "agent_timesteps_total": 921236, "timers": {"sample_time_ms": 3150.198, "sample_throughput": 1935.624, "learn_time_ms": 14348.925, "learn_throughput": 424.952, "update_time_ms": 4.564}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7697353541851043, "cur_lr": 5.000000000000001e-05, "total_loss": 89056.24840561225, "policy_loss": -0.004356620795264536, "vf_loss": 89056.2487244898, "vf_explained_var": -8.514949634275126e-09, "kl": 0.005590956487065675, "entropy": 2.508516720363072, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 91249.65768494898, "policy_loss": 0.002146953811907038, "vf_loss": 91249.65098852041, "vf_explained_var": 1.0947792006277268e-08, "kl": 0.009723138672356703, "entropy": 2.9878981405374954, "entropy_coeff": 0.0}}}, "num_steps_sampled": 460618, "num_agent_steps_sampled": 921236, "num_steps_trained": 460618, "num_agent_steps_trained": 921236}, "done": false, "episodes_total": 480, "training_iteration": 76, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-44-30", "timestamp": 1624711470, "time_this_iter_s": 17.73496437072754, "time_total_s": 1410.0528354644775, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226d90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1410.0528354644775, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 20.404347826086955, "ram_util_percent": 72.09999999999997, "gpu_util_percent0": 0.22173913043478255, "vram_util_percent0": 0.2841693410120017}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 952.71, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10237.1, "pol1": -10237.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 786, 1000, 1000, 864, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 6850.0, 10990.0, 10990.0, 7630.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -6850.0, -10990.0, -10990.0, -7630.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1856997619096252, "mean_inference_ms": 2.6042005012852503, "mean_action_processing_ms": 0.1315920318537912, "mean_env_wait_ms": 0.10055012224920576, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 466618, "agent_timesteps_total": 933236, "timers": {"sample_time_ms": 3176.604, "sample_throughput": 1923.281, "learn_time_ms": 14370.872, "learn_throughput": 425.131, "update_time_ms": 4.56}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7697353541851041, "cur_lr": 5.000000000000002e-05, "total_loss": 49640.39793882979, "policy_loss": -0.004201780093160082, "vf_loss": 49640.39694148936, "vf_explained_var": "null", "kl": 0.006340127913875782, "entropy": 2.4839955644404634, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 52567.13497340425, "policy_loss": -0.0011621943892950706, "vf_loss": 52567.131482712764, "vf_explained_var": "null", "kl": 0.01206664013815053, "entropy": 2.89642260429707, "entropy_coeff": 0.0}}}, "num_steps_sampled": 466618, "num_agent_steps_sampled": 933236, "num_steps_trained": 466618, "num_agent_steps_trained": 933236}, "done": false, "episodes_total": 486, "training_iteration": 77, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-44-47", "timestamp": 1624711487, "time_this_iter_s": 17.098464488983154, "time_total_s": 1427.1512999534607, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2230d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1427.1512999534607, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 19.934782608695656, "ram_util_percent": 72.16956521739128, "gpu_util_percent0": 0.22347826086956524, "vram_util_percent0": 0.284176667985522}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 956.21, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10312.1, "pol1": -10312.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18558126051165239, "mean_inference_ms": 2.6025089466083564, "mean_action_processing_ms": 0.13149918651032694, "mean_env_wait_ms": 0.10048271299701518, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 472618, "agent_timesteps_total": 945236, "timers": {"sample_time_ms": 3162.439, "sample_throughput": 1939.958, "learn_time_ms": 14403.022, "learn_throughput": 425.952, "update_time_ms": 4.587}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7697353541851041, "cur_lr": 5.000000000000002e-05, "total_loss": 45215.65890957447, "policy_loss": -0.010346681315531122, "vf_loss": 45215.66505984042, "vf_explained_var": "null", "kl": 0.00490240044297373, "entropy": 2.5066660972351724, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968749999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 49080.84616023936, "policy_loss": -0.006285614908692685, "vf_loss": 49080.84815492021, "vf_explained_var": "null", "kl": 0.009139636382856902, "entropy": 2.7467778439217425, "entropy_coeff": 0.0}}}, "num_steps_sampled": 472618, "num_agent_steps_sampled": 945236, "num_steps_trained": 472618, "num_agent_steps_trained": 945236}, "done": false, "episodes_total": 492, "training_iteration": 78, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-45-04", "timestamp": 1624711504, "time_this_iter_s": 16.963474988937378, "time_total_s": 1444.114774942398, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2bac80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1444.114774942398, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 19.604347826086954, "ram_util_percent": 72.19565217391305, "gpu_util_percent0": 0.22565217391304346, "vram_util_percent0": 0.284176667985522}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 951.76, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10247.6, "pol1": -10247.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 675, 1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5740.0, 10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5740.0, -10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18542008895692397, "mean_inference_ms": 2.600156217563044, "mean_action_processing_ms": 0.1313403602659933, "mean_env_wait_ms": 0.1004010229530364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 479173, "agent_timesteps_total": 958346, "timers": {"sample_time_ms": 3181.32, "sample_throughput": 1915.557, "learn_time_ms": 14263.391, "learn_throughput": 427.248, "update_time_ms": 4.608}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.38486767709255204, "cur_lr": 5.0000000000000016e-05, "total_loss": 59201.672400841344, "policy_loss": -0.004493134490285928, "vf_loss": 59201.672926682695, "vf_explained_var": -9.16994569166718e-09, "kl": 0.008850870591301758, "entropy": 2.4792146453490624, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5.0000000000000016e-05, "total_loss": 62013.283128004805, "policy_loss": 0.0037308021161991814, "vf_loss": 62013.268254206734, "vf_explained_var": 0.0, "kl": 0.02759242419583293, "entropy": 2.786421720798199, "entropy_coeff": 0.0}}}, "num_steps_sampled": 479173, "num_agent_steps_sampled": 958346, "num_steps_trained": 479173, "num_agent_steps_trained": 958346}, "done": false, "episodes_total": 499, "training_iteration": 79, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-45-23", "timestamp": 1624711523, "time_this_iter_s": 19.38107419013977, "time_total_s": 1463.4958491325378, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223510>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc223730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1463.4958491325378, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 19.896, "ram_util_percent": 72.192, "gpu_util_percent0": 0.21080000000000004, "vram_util_percent0": 0.28412537917087965}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 955.01, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10300.1, "pol1": -10300.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 970, 1000, 1000, 1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 8690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -8690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18531200442339466, "mean_inference_ms": 2.598379765036772, "mean_action_processing_ms": 0.13125129741234667, "mean_env_wait_ms": 0.10033651630337893, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 485173, "agent_timesteps_total": 970346, "timers": {"sample_time_ms": 3167.713, "sample_throughput": 1923.785, "learn_time_ms": 14274.287, "learn_throughput": 426.921, "update_time_ms": 4.62}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.38486767709255204, "cur_lr": 5.000000000000002e-05, "total_loss": 37047.79296875, "policy_loss": 0.03427308968248519, "vf_loss": 37047.75166223404, "vf_explained_var": "null", "kl": 0.016797480668793333, "entropy": 2.4550421237945557, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 40023.442736037236, "policy_loss": -0.0005442717290939169, "vf_loss": 40023.43567154255, "vf_explained_var": "null", "kl": 0.012672433471109005, "entropy": 2.9677836134078657, "entropy_coeff": 0.0}}}, "num_steps_sampled": 485173, "num_agent_steps_sampled": 970346, "num_steps_trained": 485173, "num_agent_steps_trained": 970346}, "done": false, "episodes_total": 505, "training_iteration": 80, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-45-40", "timestamp": 1624711540, "time_this_iter_s": 17.075275897979736, "time_total_s": 1480.5711250305176, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2238c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc223d90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1480.5711250305176, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 19.852173913043476, "ram_util_percent": 72.20869565217393, "gpu_util_percent0": 0.23130434782608705, "vram_util_percent0": 0.28412537917087977}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 955.31, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10323.1, "pol1": -10323.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 881, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 7800.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -7800.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18521021391702544, "mean_inference_ms": 2.5966892735247686, "mean_action_processing_ms": 0.13116680397399252, "mean_env_wait_ms": 0.10027520925248329, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 491173, "agent_timesteps_total": 982346, "timers": {"sample_time_ms": 3155.396, "sample_throughput": 1931.295, "learn_time_ms": 14272.097, "learn_throughput": 426.987, "update_time_ms": 4.615}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.38486767709255204, "cur_lr": 5.000000000000002e-05, "total_loss": 33236.775930851065, "policy_loss": 0.0025154937534256185, "vf_loss": 33236.76653922872, "vf_explained_var": "null", "kl": 0.017692507561692532, "entropy": 2.4207982458966844, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 35889.890625, "policy_loss": -0.0025144240402794897, "vf_loss": 35889.88971077128, "vf_explained_var": "null", "kl": 0.006280978854270058, "entropy": 2.9593185414659215, "entropy_coeff": 0.0}}}, "num_steps_sampled": 491173, "num_agent_steps_sampled": 982346, "num_steps_trained": 491173, "num_agent_steps_trained": 982346}, "done": false, "episodes_total": 511, "training_iteration": 81, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-45-57", "timestamp": 1624711557, "time_this_iter_s": 17.00649118423462, "time_total_s": 1497.5776162147522, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2262f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2268c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1497.5776162147522, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 19.499999999999996, "ram_util_percent": 72.29565217391303, "gpu_util_percent0": 0.2269565217391305, "vram_util_percent0": 0.28375170352134343}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 949.91, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10229.1, "pol1": -10229.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18511627342035616, "mean_inference_ms": 2.5951670854498508, "mean_action_processing_ms": 0.1310911889610369, "mean_env_wait_ms": 0.10021937693200986, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 496514, "agent_timesteps_total": 993028, "timers": {"sample_time_ms": 3155.47, "sample_throughput": 1910.365, "learn_time_ms": 14141.207, "learn_throughput": 426.279, "update_time_ms": 4.599}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3848676770925522, "cur_lr": 5.000000000000001e-05, "total_loss": 103439.41238839286, "policy_loss": -0.00726020500241291, "vf_loss": 103439.41536458333, "vf_explained_var": -5.676632941487014e-09, "kl": 0.00951049126507271, "entropy": 2.423385495231265, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5.000000000000001e-05, "total_loss": 104614.03915550595, "policy_loss": -0.0013580452650785446, "vf_loss": 104614.03534226191, "vf_explained_var": -4.257474817137563e-09, "kl": 0.009692591792416005, "entropy": 2.9451637097767422, "entropy_coeff": 0.0}}}, "num_steps_sampled": 496514, "num_agent_steps_sampled": 993028, "num_steps_trained": 496514, "num_agent_steps_trained": 993028}, "done": false, "episodes_total": 517, "training_iteration": 82, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-46-13", "timestamp": 1624711573, "time_this_iter_s": 15.662362813949585, "time_total_s": 1513.2399790287018, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84b801aea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f84b801ad90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1513.2399790287018, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 21.642857142857142, "ram_util_percent": 72.40000000000002, "gpu_util_percent0": 0.22047619047619044, "vram_util_percent0": 0.28365191712006677}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 949.91, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10229.1, "pol1": -10229.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 745, 1000, 1000, 385, 1000, 1000, 1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 6440.0, 10990.0, 10990.0, 2840.0, 10990.0, 10990.0, 10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -6440.0, -10990.0, -10990.0, -2840.0, -10990.0, -10990.0, -10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1850177278967548, "mean_inference_ms": 2.593655628694535, "mean_action_processing_ms": 0.1310157454702093, "mean_env_wait_ms": 0.10016358687186803, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 502514, "agent_timesteps_total": 1005028, "timers": {"sample_time_ms": 3092.798, "sample_throughput": 1936.305, "learn_time_ms": 14119.514, "learn_throughput": 424.136, "update_time_ms": 4.588}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.38486767709255204, "cur_lr": 5.000000000000002e-05, "total_loss": 26291.288189827126, "policy_loss": -0.016830255812469948, "vf_loss": 26291.296293218085, "vf_explained_var": "null", "kl": 0.022417547101987168, "entropy": 2.5223728748078043, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 28935.19261136968, "policy_loss": -0.0037493931248467017, "vf_loss": 28935.19173869681, "vf_explained_var": "null", "kl": 0.00846911068173482, "entropy": 3.018120709885942, "entropy_coeff": 0.0}}}, "num_steps_sampled": 502514, "num_agent_steps_sampled": 1005028, "num_steps_trained": 502514, "num_agent_steps_trained": 1005028}, "done": false, "episodes_total": 523, "training_iteration": 83, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-46-30", "timestamp": 1624711590, "time_this_iter_s": 17.524412393569946, "time_total_s": 1530.7643914222717, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc2406a8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc240510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1530.7643914222717, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 22.94782608695652, "ram_util_percent": 72.36086956521739, "gpu_util_percent0": 0.2195652173913044, "vram_util_percent0": 0.28367110681262}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 951.86, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 1690.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -1690.0}, "policy_reward_mean": {"pol0": 10268.6, "pol1": -10268.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 310, 1000, 270, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 2090.0, 10990.0, 1690.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -2090.0, -10990.0, -1690.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184902078989968, "mean_inference_ms": 2.591846826641829, "mean_action_processing_ms": 0.13092594272041522, "mean_env_wait_ms": 0.10009703493015673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 508839, "agent_timesteps_total": 1017678, "timers": {"sample_time_ms": 3142.388, "sample_throughput": 1916.091, "learn_time_ms": 14208.282, "learn_throughput": 423.774, "update_time_ms": 4.599}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5773015156388284, "cur_lr": 5.000000000000001e-05, "total_loss": 45480.5961328125, "policy_loss": -0.0024442313984036445, "vf_loss": 45480.59140625, "vf_explained_var": 3.5762788286319847e-08, "kl": 0.011576440315693617, "entropy": 2.7115142011642455, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5.000000000000001e-05, "total_loss": 47606.66265625, "policy_loss": -0.003242560066282749, "vf_loss": 47606.6618359375, "vf_explained_var": -2.2649764730431343e-08, "kl": 0.007632231395691633, "entropy": 3.0360541677474977, "entropy_coeff": 0.0}}}, "num_steps_sampled": 508839, "num_agent_steps_sampled": 1017678, "num_steps_trained": 508839, "num_agent_steps_trained": 1017678}, "done": false, "episodes_total": 530, "training_iteration": 84, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-46-49", "timestamp": 1624711609, "time_this_iter_s": 18.302844524383545, "time_total_s": 1549.0672359466553, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226ae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1549.0672359466553, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 19.566666666666666, "ram_util_percent": 72.45416666666667, "gpu_util_percent0": 0.22458333333333336, "vram_util_percent0": 0.2836619480957196}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 966.06, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10450.6, "pol1": -10450.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1848405248986306, "mean_inference_ms": 2.5908281093520085, "mean_action_processing_ms": 0.1308941584038422, "mean_env_wait_ms": 0.10007977379495366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 514839, "agent_timesteps_total": 1029678, "timers": {"sample_time_ms": 3133.181, "sample_throughput": 1928.742, "learn_time_ms": 14238.434, "learn_throughput": 424.422, "update_time_ms": 4.609}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5773015156388286, "cur_lr": 5.000000000000002e-05, "total_loss": 20156.518907912236, "policy_loss": 0.06527639616360055, "vf_loss": 20156.445187832447, "vf_explained_var": "null", "kl": 0.014096929473762817, "entropy": 2.74922178146687, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 22446.71488530585, "policy_loss": 0.001477269653944259, "vf_loss": 22446.702418550532, "vf_explained_var": "null", "kl": 0.018941314395596372, "entropy": 3.0662921388098536, "entropy_coeff": 0.0}}}, "num_steps_sampled": 514839, "num_agent_steps_sampled": 1029678, "num_steps_trained": 514839, "num_agent_steps_trained": 1029678}, "done": false, "episodes_total": 536, "training_iteration": 85, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-47-06", "timestamp": 1624711626, "time_this_iter_s": 17.106303930282593, "time_total_s": 1566.1735398769379, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2232f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1566.1735398769379, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 20.291304347826088, "ram_util_percent": 72.54782608695652, "gpu_util_percent0": 0.23043478260869568, "vram_util_percent0": 0.2837004147067012}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 963.06, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10400.6, "pol1": -10400.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1847481526381788, "mean_inference_ms": 2.5893370919395142, "mean_action_processing_ms": 0.13081826938037583, "mean_env_wait_ms": 0.10002434876402147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 520539, "agent_timesteps_total": 1041078, "timers": {"sample_time_ms": 3092.54, "sample_throughput": 1937.598, "learn_time_ms": 14125.58, "learn_throughput": 424.202, "update_time_ms": 4.632}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5773015156388285, "cur_lr": 5.0000000000000016e-05, "total_loss": 44119.47556423611, "policy_loss": 0.0019373932439419959, "vf_loss": 44119.46236979167, "vf_explained_var": 3.973643192267673e-09, "kl": 0.019210902725656828, "entropy": 2.6679483731587728, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 44911.166579861114, "policy_loss": -0.0014436934557225968, "vf_loss": 44911.16085069445, "vf_explained_var": -2.6490953430879927e-08, "kl": 0.013057908519274658, "entropy": 3.0747380680508085, "entropy_coeff": 0.0}}}, "num_steps_sampled": 520539, "num_agent_steps_sampled": 1041078, "num_steps_trained": 520539, "num_agent_steps_trained": 1041078}, "done": false, "episodes_total": 542, "training_iteration": 86, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-47-22", "timestamp": 1624711642, "time_this_iter_s": 16.20041012763977, "time_total_s": 1582.3739500045776, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2239d8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1582.3739500045776, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 19.9047619047619, "ram_util_percent": 72.75238095238097, "gpu_util_percent0": 0.23428571428571437, "vram_util_percent0": 0.283788338388945}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 963.06, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10400.6, "pol1": -10400.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18465721849330735, "mean_inference_ms": 2.587849952794886, "mean_action_processing_ms": 0.1307421936004662, "mean_env_wait_ms": 0.09996912130683373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 526539, "agent_timesteps_total": 1053078, "timers": {"sample_time_ms": 3081.248, "sample_throughput": 1944.699, "learn_time_ms": 14157.513, "learn_throughput": 423.245, "update_time_ms": 4.604}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5773015156388286, "cur_lr": 5.000000000000002e-05, "total_loss": 14839.337454288563, "policy_loss": 0.09354590087574213, "vf_loss": 14839.233439993352, "vf_explained_var": "null", "kl": 0.017664080049763334, "entropy": 2.4872362715132694, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 16802.470287566488, "policy_loss": -0.0033038858760227547, "vf_loss": 16802.462641289894, "vf_explained_var": "null", "kl": 0.018609855324029922, "entropy": 2.934374743319572, "entropy_coeff": 0.0}}}, "num_steps_sampled": 526539, "num_agent_steps_sampled": 1053078, "num_steps_trained": 526539, "num_agent_steps_trained": 1053078}, "done": false, "episodes_total": 548, "training_iteration": 87, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-47-39", "timestamp": 1624711659, "time_this_iter_s": 17.304187297821045, "time_total_s": 1599.6781373023987, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223d08>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2236a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1599.6781373023987, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 20.160869565217396, "ram_util_percent": 72.69130434782608, "gpu_util_percent0": 0.23217391304347826, "vram_util_percent0": 0.28378833838894496}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 956.8, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10318.0, "pol1": -10318.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [565, 830, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000], "policy_pol0_reward": [4640.0, 7290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-4640.0, -7290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1845400201347098, "mean_inference_ms": 2.5856459711403255, "mean_action_processing_ms": 0.13063818386724613, "mean_env_wait_ms": 0.09988872374385512, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 532913, "agent_timesteps_total": 1065826, "timers": {"sample_time_ms": 3143.415, "sample_throughput": 1918.137, "learn_time_ms": 14247.147, "learn_throughput": 423.208, "update_time_ms": 4.602}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5773015156388284, "cur_lr": 5.000000000000001e-05, "total_loss": 37260.380390625, "policy_loss": 0.004222597647458315, "vf_loss": 37260.35978515625, "vf_explained_var": 3.099441414633475e-08, "kl": 0.027324414700269698, "entropy": 2.4845468330383302, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5.000000000000001e-05, "total_loss": 38712.68107421875, "policy_loss": -0.0009063531830906868, "vf_loss": 38712.665546875, "vf_explained_var": -1.7881394143159923e-08, "kl": 0.029894506223499775, "entropy": 2.8958673906326293, "entropy_coeff": 0.0}}}, "num_steps_sampled": 532913, "num_agent_steps_sampled": 1065826, "num_steps_trained": 532913, "num_agent_steps_trained": 1065826}, "done": false, "episodes_total": 555, "training_iteration": 88, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-47-58", "timestamp": 1624711678, "time_this_iter_s": 18.481579780578613, "time_total_s": 1618.1597170829773, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc232620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc232f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1618.1597170829773, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 19.476, "ram_util_percent": 72.72000000000001, "gpu_util_percent0": 0.21280000000000002, "vram_util_percent0": 0.2838355240984159}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 960.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10376.9, "pol1": -10376.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18442506560204264, "mean_inference_ms": 2.584368703393597, "mean_action_processing_ms": 0.13053001009509513, "mean_env_wait_ms": 0.09984958698214516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 538697, "agent_timesteps_total": 1077394, "timers": {"sample_time_ms": 3043.649, "sample_throughput": 1955.679, "learn_time_ms": 14073.815, "learn_throughput": 422.941, "update_time_ms": 4.614}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8659522734582424, "cur_lr": 5.0000000000000016e-05, "total_loss": 39107.710067085594, "policy_loss": 0.004705710377058257, "vf_loss": 39107.694696841034, "vf_explained_var": -1.4253284774667918e-08, "kl": 0.01168690698788218, "entropy": 2.5484458985535996, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 39005.64852241848, "policy_loss": 0.007561980281025171, "vf_loss": 39005.62599779212, "vf_explained_var": -6.478765524065011e-09, "kl": 0.01667946629712115, "entropy": 2.9503262457640274, "entropy_coeff": 0.0}}}, "num_steps_sampled": 538697, "num_agent_steps_sampled": 1077394, "num_steps_trained": 538697, "num_agent_steps_trained": 1077394}, "done": false, "episodes_total": 561, "training_iteration": 89, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-48-15", "timestamp": 1624711695, "time_this_iter_s": 16.651355743408203, "time_total_s": 1634.8110728263855, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc240400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc240730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1634.8110728263855, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 19.43636363636364, "ram_util_percent": 72.75, "gpu_util_percent0": 0.2254545454545455, "vram_util_percent0": 0.2836810981401477}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 960.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10376.9, "pol1": -10376.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 780, 1000, 1000, 1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 6790.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -6790.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843402255467241, "mean_inference_ms": 2.5831795135018663, "mean_action_processing_ms": 0.13046842926480762, "mean_env_wait_ms": 0.09980541800286845, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 544697, "agent_timesteps_total": 1089394, "timers": {"sample_time_ms": 3085.061, "sample_throughput": 1929.427, "learn_time_ms": 14110.949, "learn_throughput": 421.828, "update_time_ms": 4.683}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8659522734582423, "cur_lr": 5.000000000000002e-05, "total_loss": 8402.153278756648, "policy_loss": -0.03773376850926496, "vf_loss": 8402.182596409575, "vf_explained_var": "null", "kl": 0.009913135280317448, "entropy": 2.514231047731765, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 10660.609582779256, "policy_loss": 0.00017534511441245993, "vf_loss": 10660.597926363032, "vf_explained_var": "null", "kl": 0.013461644860341194, "entropy": 2.95883986290465, "entropy_coeff": 0.0}}}, "num_steps_sampled": 544697, "num_agent_steps_sampled": 1089394, "num_steps_trained": 544697, "num_agent_steps_trained": 1089394}, "done": false, "episodes_total": 567, "training_iteration": 90, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-48-33", "timestamp": 1624711713, "time_this_iter_s": 17.86185121536255, "time_total_s": 1652.672924041748, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba730>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2bab70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1652.672924041748, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 23.1875, "ram_util_percent": 72.88333333333334, "gpu_util_percent0": 0.24333333333333332, "vram_util_percent0": 0.2861335804965734}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 955.29, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10302.9, "pol1": -10302.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 586, 624, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 4850.0, 5230.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -4850.0, -5230.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18426978348747614, "mean_inference_ms": 2.5814076518951987, "mean_action_processing_ms": 0.13039717324522834, "mean_env_wait_ms": 0.09974527566854892, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 550937, "agent_timesteps_total": 1101874, "timers": {"sample_time_ms": 3161.97, "sample_throughput": 1890.088, "learn_time_ms": 14432.668, "learn_throughput": 414.088, "update_time_ms": 4.738}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8659522734582425, "cur_lr": 5.000000000000001e-05, "total_loss": 60784.89953364158, "policy_loss": -0.0037627055176666807, "vf_loss": 60784.8925382653, "vf_explained_var": -1.4597056008369691e-08, "kl": 0.010768370607829824, "entropy": 2.5043753847783927, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000001, "cur_lr": 5.000000000000001e-05, "total_loss": 61071.57633131377, "policy_loss": -0.00013691205911490383, "vf_loss": 61071.56768176021, "vf_explained_var": -8.514949634275126e-09, "kl": 0.009541441192280273, "entropy": 2.8803895784884084, "entropy_coeff": 0.0}}}, "num_steps_sampled": 550937, "num_agent_steps_sampled": 1101874, "num_steps_trained": 550937, "num_agent_steps_trained": 1101874}, "done": false, "episodes_total": 574, "training_iteration": 91, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-48-54", "timestamp": 1624711734, "time_this_iter_s": 20.99527931213379, "time_total_s": 1673.6682033538818, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc240048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc240e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1673.6682033538818, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 24.35357142857143, "ram_util_percent": 73.13928571428572, "gpu_util_percent0": 0.2517857142857143, "vram_util_percent0": 0.2920518561317348}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 963.19, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10421.9, "pol1": -10421.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18422381140973074, "mean_inference_ms": 2.5804531954085554, "mean_action_processing_ms": 0.1303447316098479, "mean_env_wait_ms": 0.09974421365876951, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 556937, "agent_timesteps_total": 1113874, "timers": {"sample_time_ms": 3176.393, "sample_throughput": 1902.252, "learn_time_ms": 14722.195, "learn_throughput": 410.421, "update_time_ms": 4.744}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8659522734582423, "cur_lr": 5.000000000000002e-05, "total_loss": 5149.527125581782, "policy_loss": 0.0068536856548583255, "vf_loss": 5149.513671875, "vf_explained_var": "null", "kl": 0.0076625334851919335, "entropy": 2.511946201324463, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 6379.913314494681, "policy_loss": -0.00017788086799865074, "vf_loss": 6379.906374667553, "vf_explained_var": "null", "kl": 0.008297916075729944, "entropy": 2.7880793074344066, "entropy_coeff": 0.0}}}, "num_steps_sampled": 556937, "num_agent_steps_sampled": 1113874, "num_steps_trained": 556937, "num_agent_steps_trained": 1113874}, "done": false, "episodes_total": 580, "training_iteration": 92, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-49-12", "timestamp": 1624711752, "time_this_iter_s": 18.6858651638031, "time_total_s": 1692.354068517685, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1692.354068517685, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 22.8125, "ram_util_percent": 73.24583333333334, "gpu_util_percent0": 0.21833333333333335, "vram_util_percent0": 0.2873764183799573}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 963.19, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10421.9, "pol1": -10421.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417423763637564, "mean_inference_ms": 2.5796695150281668, "mean_action_processing_ms": 0.130305781295627, "mean_env_wait_ms": 0.09971491293820652, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 562937, "agent_timesteps_total": 1125874, "timers": {"sample_time_ms": 3232.876, "sample_throughput": 1869.017, "learn_time_ms": 14791.619, "learn_throughput": 408.495, "update_time_ms": 4.741}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8659522734582423, "cur_lr": 5.000000000000002e-05, "total_loss": 3794.5873815658247, "policy_loss": 0.07221962448130263, "vf_loss": 3794.494073096742, "vf_explained_var": "null", "kl": 0.02440171795798109, "entropy": 2.452282799051163, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 4879.373244265293, "policy_loss": -1.5196568788366114e-05, "vf_loss": 4879.36418508976, "vf_explained_var": "null", "kl": 0.010590802263864812, "entropy": 2.7957011638803686, "entropy_coeff": 0.0}}}, "num_steps_sampled": 562937, "num_agent_steps_sampled": 1125874, "num_steps_trained": 562937, "num_agent_steps_trained": 1125874}, "done": false, "episodes_total": 586, "training_iteration": 93, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-49-31", "timestamp": 1624711771, "time_this_iter_s": 18.78339457511902, "time_total_s": 1711.137463092804, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2ba598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd296950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1711.137463092804, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 23.791999999999998, "ram_util_percent": 73.444, "gpu_util_percent0": 0.2576, "vram_util_percent0": 0.2866666666666667}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 963.19, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 2240.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -2240.0}, "policy_reward_mean": {"pol0": 10421.9, "pol1": -10421.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 555, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 4540.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -4540.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18412980152062194, "mean_inference_ms": 2.57905560690785, "mean_action_processing_ms": 0.1302754452023013, "mean_env_wait_ms": 0.0996911612655169, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 568937, "agent_timesteps_total": 1137874, "timers": {"sample_time_ms": 3213.29, "sample_throughput": 1870.295, "learn_time_ms": 14798.107, "learn_throughput": 406.12, "update_time_ms": 4.754}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.298928410187364, "cur_lr": 5.000000000000002e-05, "total_loss": 2647.353811710439, "policy_loss": -0.002551892415640202, "vf_loss": 2647.327667885638, "vf_explained_var": "null", "kl": 0.022097253854921523, "entropy": 2.5647587522547295, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000004, "cur_lr": 5.000000000000002e-05, "total_loss": 3681.1644728640294, "policy_loss": 0.0003887732374541303, "vf_loss": 3681.1531229222073, "vf_explained_var": "null", "kl": 0.012808841375752967, "entropy": 2.9046397259894836, "entropy_coeff": 0.0}}}, "num_steps_sampled": 568937, "num_agent_steps_sampled": 1137874, "num_steps_trained": 568937, "num_agent_steps_trained": 1137874}, "done": false, "episodes_total": 592, "training_iteration": 94, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-49-49", "timestamp": 1624711789, "time_this_iter_s": 18.171504735946655, "time_total_s": 1729.3089678287506, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc223598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2230d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1729.3089678287506, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 22.270833333333332, "ram_util_percent": 73.52083333333333, "gpu_util_percent0": 0.21916666666666665, "vram_util_percent0": 0.2858035613975958}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 959.64, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10386.4, "pol1": -10386.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 200, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18407304943007408, "mean_inference_ms": 2.5789334212918607, "mean_action_processing_ms": 0.13026600245835515, "mean_env_wait_ms": 0.09965044944321776, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 575137, "agent_timesteps_total": 1150274, "timers": {"sample_time_ms": 3250.495, "sample_throughput": 1855.04, "learn_time_ms": 14903.423, "learn_throughput": 404.592, "update_time_ms": 4.749}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9483926152810456, "cur_lr": 5.000000000000001e-05, "total_loss": 30963.585329639667, "policy_loss": -0.004896271441664014, "vf_loss": 30963.568708147322, "vf_explained_var": 1.7029899268550253e-08, "kl": 0.011301539002024397, "entropy": 2.5606831433821697, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.8542968750000001, "cur_lr": 5.000000000000001e-05, "total_loss": 31370.971918845662, "policy_loss": -0.0030505796134167786, "vf_loss": 31370.9721480389, "vf_explained_var": 1.7029899268550253e-08, "kl": 0.004483528401968735, "entropy": 2.966907481757962, "entropy_coeff": 0.0}}}, "num_steps_sampled": 575137, "num_agent_steps_sampled": 1150274, "num_steps_trained": 575137, "num_agent_steps_trained": 1150274}, "done": false, "episodes_total": 599, "training_iteration": 95, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-50-08", "timestamp": 1624711808, "time_this_iter_s": 18.531417846679688, "time_total_s": 1747.8403856754303, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc226620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1747.8403856754303, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 20.56, "ram_util_percent": 73.268, "gpu_util_percent0": 0.2364, "vram_util_percent0": 0.2851836872261544}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 959.64, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10386.4, "pol1": -10386.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 200, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1840476488138914, "mean_inference_ms": 2.5785677750978864, "mean_action_processing_ms": 0.13024951712209693, "mean_env_wait_ms": 0.09963638325309168, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 581137, "agent_timesteps_total": 1162274, "timers": {"sample_time_ms": 3268.243, "sample_throughput": 1854.146, "learn_time_ms": 15003.265, "learn_throughput": 403.899, "update_time_ms": 4.74}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9483926152810462, "cur_lr": 5.000000000000002e-05, "total_loss": 980.0137004446476, "policy_loss": -0.004741805744297961, "vf_loss": 979.9592583838929, "vf_explained_var": "null", "kl": 0.030369249271585585, "entropy": 2.602316978129935, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 1611.0966173537233, "policy_loss": -0.0032675891639070307, "vf_loss": 1611.0975030127993, "vf_explained_var": "null", "kl": 0.005593404451266248, "entropy": 2.8013314236985876, "entropy_coeff": 0.0}}}, "num_steps_sampled": 581137, "num_agent_steps_sampled": 1162274, "num_steps_trained": 581137, "num_agent_steps_trained": 1162274}, "done": false, "episodes_total": 605, "training_iteration": 96, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-50-25", "timestamp": 1624711825, "time_this_iter_s": 17.375595092773438, "time_total_s": 1765.2159807682037, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc232b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2322f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1765.2159807682037, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 20.94347826086957, "ram_util_percent": 73.2695652173913, "gpu_util_percent0": 0.23434782608695648, "vram_util_percent0": 0.2851804633578055}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 959.64, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10386.4, "pol1": -10386.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 791, 1000, 710, 840, 1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 200, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 6900.0, 10990.0, 6090.0, 7390.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -6900.0, -10990.0, -6090.0, -7390.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1840272774313653, "mean_inference_ms": 2.578282502647365, "mean_action_processing_ms": 0.13023717017321043, "mean_env_wait_ms": 0.09962566551228395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 587137, "agent_timesteps_total": 1174274, "timers": {"sample_time_ms": 3272.409, "sample_throughput": 1851.786, "learn_time_ms": 15052.092, "learn_throughput": 402.589, "update_time_ms": 4.848}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9225889229215674, "cur_lr": 5.000000000000002e-05, "total_loss": 448.36209560962436, "policy_loss": 0.0007371919507041891, "vf_loss": 448.3501664831283, "vf_explained_var": "null", "kl": 0.003830866219396604, "entropy": 2.612023855777497, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.4271484375000002, "cur_lr": 5.000000000000002e-05, "total_loss": 1053.672573657746, "policy_loss": 0.0004031343306315706, "vf_loss": 1053.663540454621, "vf_explained_var": "null", "kl": 0.020226090472746403, "entropy": 2.621507705526149, "entropy_coeff": 0.0}}}, "num_steps_sampled": 587137, "num_agent_steps_sampled": 1174274, "num_steps_trained": 587137, "num_agent_steps_trained": 1174274}, "done": false, "episodes_total": 611, "training_iteration": 97, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-50-43", "timestamp": 1624711843, "time_this_iter_s": 17.84005308151245, "time_total_s": 1783.0560338497162, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cc240840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc240b70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1783.0560338497162, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 20.854166666666668, "ram_util_percent": 73.30416666666666, "gpu_util_percent0": 0.24416666666666667, "vram_util_percent0": 0.28517863161442536}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 966.23, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10512.3, "pol1": -10512.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 200, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18401450680594003, "mean_inference_ms": 2.578213439276006, "mean_action_processing_ms": 0.1302307603547553, "mean_env_wait_ms": 0.09961943205626493, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 593137, "agent_timesteps_total": 1186274, "timers": {"sample_time_ms": 3280.138, "sample_throughput": 1836.02, "learn_time_ms": 15040.978, "learn_throughput": 400.399, "update_time_ms": 4.905}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4612944614607837, "cur_lr": 5.000000000000002e-05, "total_loss": 122.38680770549368, "policy_loss": -0.01336609274941556, "vf_loss": 122.39741694673579, "vf_explained_var": "null", "kl": 0.0018886842893713967, "entropy": 2.664637956213444, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.000000000000002e-05, "total_loss": 451.33640500332444, "policy_loss": -0.001303668312252836, "vf_loss": 451.33213124376664, "vf_explained_var": "null", "kl": 0.008711164767675578, "entropy": 2.7795196340439166, "entropy_coeff": 0.0}}}, "num_steps_sampled": 593137, "num_agent_steps_sampled": 1186274, "num_steps_trained": 593137, "num_agent_steps_trained": 1186274}, "done": false, "episodes_total": 617, "training_iteration": 98, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-51-02", "timestamp": 1624711862, "time_this_iter_s": 18.449070692062378, "time_total_s": 1801.5051045417786, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd2bac80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cd2ba2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1801.5051045417786, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 24.004166666666666, "ram_util_percent": 73.39583333333333, "gpu_util_percent0": 0.2304166666666667, "vram_util_percent0": 0.28618975396022917}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 964.33, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10473.3, "pol1": -10473.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [325, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 200, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 810, 1000, 1000], "policy_pol0_reward": [2240.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7090.0, 10990.0, 10990.0], "policy_pol1_reward": [-2240.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7090.0, -10990.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1840165172842921, "mean_inference_ms": 2.578340740895044, "mean_action_processing_ms": 0.13023375256040695, "mean_env_wait_ms": 0.09961943457886066, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 598947, "agent_timesteps_total": 1197894, "timers": {"sample_time_ms": 3310.66, "sample_throughput": 1819.879, "learn_time_ms": 15175.241, "learn_throughput": 397.028, "update_time_ms": 4.868}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7306472307303918, "cur_lr": 5.0000000000000016e-05, "total_loss": 33163.5846371858, "policy_loss": -0.006950331710117019, "vf_loss": 33163.58896272079, "vf_explained_var": 1.684479045138687e-08, "kl": 0.0036688638932031135, "entropy": 2.642879175103229, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6407226562499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 33259.68339206861, "policy_loss": -0.0003299951634329298, "vf_loss": 33259.669762652855, "vf_explained_var": 2.5915063428527674e-09, "kl": 0.023236073958485023, "entropy": 2.775107979774475, "entropy_coeff": 0.0}}}, "num_steps_sampled": 598947, "num_agent_steps_sampled": 1197894, "num_steps_trained": 598947, "num_agent_steps_trained": 1197894}, "done": false, "episodes_total": 623, "training_iteration": 99, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-51-20", "timestamp": 1624711880, "time_this_iter_s": 18.298715114593506, "time_total_s": 1819.803819656372, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f83cd303b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc2322f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1819.803819656372, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 23.8125, "ram_util_percent": 73.37916666666668, "gpu_util_percent0": 0.23708333333333334, "vram_util_percent0": 0.28619677564318613}, "trial_id": "f0727_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 959.05, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"pol0": 990.0, "pol1": -10990.0}, "policy_reward_max": {"pol0": 10990.0, "pol1": -990.0}, "policy_reward_mean": {"pol0": 10400.5, "pol1": -10400.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 700, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 374, 1000, 1000, 1000, 1000, 1000, 784, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 910, 1000, 1000, 330, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 200, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 810, 1000, 1000, 1000, 1000, 286, 1000, 1000, 1000, 511, 1000], "policy_pol0_reward": [10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 5990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 2730.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 6830.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 8090.0, 10990.0, 10990.0, 2290.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 10990.0, 7090.0, 10990.0, 10990.0, 10990.0, 10990.0, 1850.0, 10990.0, 10990.0, 10990.0, 4100.0, 10990.0], "policy_pol1_reward": [-10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -5990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -2730.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -6830.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -8090.0, -10990.0, -10990.0, -2290.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -10990.0, -7090.0, -10990.0, -10990.0, -10990.0, -10990.0, -1850.0, -10990.0, -10990.0, -10990.0, -4100.0, -10990.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18406255808979552, "mean_inference_ms": 2.578038776220205, "mean_action_processing_ms": 0.13024586716067718, "mean_env_wait_ms": 0.09961534463513326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 605744, "agent_timesteps_total": 1211488, "timers": {"sample_time_ms": 3404.128, "sample_throughput": 1793.323, "learn_time_ms": 15509.864, "learn_throughput": 393.601, "update_time_ms": 4.81}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.365323615365196, "cur_lr": 5.0000000000000016e-05, "total_loss": 55553.220091643154, "policy_loss": -0.00688347310103752, "vf_loss": 55553.22460485388, "vf_explained_var": 1.9868215517249155e-08, "kl": 0.007591048272809497, "entropy": 2.749285172533106, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.9610839843750001, "cur_lr": 5.0000000000000016e-05, "total_loss": 56866.9736328125, "policy_loss": -0.005213316236795099, "vf_loss": 56866.97256582755, "vf_explained_var": -2.6490953430879927e-08, "kl": 0.0066214868091736675, "entropy": 2.773061898019579, "entropy_coeff": 0.0}}}, "num_steps_sampled": 605744, "num_agent_steps_sampled": 1211488, "num_steps_trained": 605744, "num_agent_steps_trained": 1211488}, "done": true, "episodes_total": 631, "training_iteration": 100, "experiment_id": "11ab79ecec0f4265b5118db8ef222ec0", "date": "2021-06-26_15-51-42", "timestamp": 1624711902, "time_this_iter_s": 22.14240264892578, "time_total_s": 1841.9462223052979, "pid": 1002, "hostname": "hany606", "node_ip": "10.91.73.206", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7f84bf7e1268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7f83cc226d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1841.9462223052979, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 20.663333333333338, "ram_util_percent": 73.4066666666667, "gpu_util_percent0": 0.26, "vram_util_percent0": 0.28652398606898105}, "trial_id": "f0727_00000"}
