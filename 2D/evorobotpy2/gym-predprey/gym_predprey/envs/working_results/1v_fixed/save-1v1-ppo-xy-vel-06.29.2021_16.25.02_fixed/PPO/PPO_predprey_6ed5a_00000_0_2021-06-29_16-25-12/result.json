{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1847565.56274634, "pol1": 1698357.4777091006}, "policy_reward_max": {"pol0": -1698357.4777091006, "pol1": 1847565.56274634}, "policy_reward_mean": {"pol0": -1791620.3893097967, "pol1": 1791620.3893097967}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22982139232074586, "mean_inference_ms": 3.0276893141740806, "mean_action_processing_ms": 0.15198783880856856, "mean_env_wait_ms": 0.12171431057308801, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 6006, "agent_timesteps_total": 12012, "timers": {"sample_time_ms": 3618.091, "sample_throughput": 1659.991, "learn_time_ms": 18129.014, "learn_throughput": 331.292, "update_time_ms": 8.267}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27070603961.19149, "policy_loss": -0.0049788200078492465, "vf_loss": 27070603961.19149, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.007251122282778329, "entropy": 2.81477312331504, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27067926658.723404, "policy_loss": -0.0062252410905475316, "vf_loss": 27067926658.723404, "vf_explained_var": -1.775457469932462e-08, "kl": 0.006385920073916303, "entropy": 2.8213599032544074, "entropy_coeff": 0.0}}}, "num_steps_sampled": 6006, "num_agent_steps_sampled": 12012, "num_steps_trained": 6006, "num_agent_steps_trained": 12012}, "done": false, "episodes_total": 6, "training_iteration": 1, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-26-03", "timestamp": 1624973163, "time_this_iter_s": 21.76400589942932, "time_total_s": 21.76400589942932, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47af28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.76400589942932, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 19.362068965517246, "ram_util_percent": 43.67241379310346, "gpu_util_percent0": 0.2220689655172414, "vram_util_percent0": 0.22475390211870808}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1847565.56274634, "pol1": 1606748.3731939094}, "policy_reward_max": {"pol0": -1606748.3731939094, "pol1": 1847565.56274634}, "policy_reward_mean": {"pol0": -1757262.3701914977, "pol1": 1757262.3701914977}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.225811649738576, "mean_inference_ms": 3.021129036882043, "mean_action_processing_ms": 0.15150781657813614, "mean_env_wait_ms": 0.12158938821372896, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 12012, "agent_timesteps_total": 24024, "timers": {"sample_time_ms": 3639.97, "sample_throughput": 1650.014, "learn_time_ms": 18169.303, "learn_throughput": 330.558, "update_time_ms": 8.003}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25056382714.553192, "policy_loss": -0.001597723071562483, "vf_loss": 25056382714.553192, "vf_explained_var": -4.058188451949718e-08, "kl": 0.00907929069263504, "entropy": 2.746122416029585, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25058849203.744682, "policy_loss": -0.003118711048142707, "vf_loss": 25058849203.744682, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.0058140945918065436, "entropy": 2.837030415839337, "entropy_coeff": 0.0}}}, "num_steps_sampled": 12012, "num_agent_steps_sampled": 24024, "num_steps_trained": 12012, "num_agent_steps_trained": 24024}, "done": false, "episodes_total": 12, "training_iteration": 2, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-26-25", "timestamp": 1624973185, "time_this_iter_s": 21.88895297050476, "time_total_s": 43.65295886993408, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4b0ea0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f4b0c80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 43.65295886993408, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 19.875862068965514, "ram_util_percent": 43.79655172413794, "gpu_util_percent0": 0.2406896551724138, "vram_util_percent0": 0.22535825110700458}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1885717.6072209042, "pol1": 1430686.8455345873}, "policy_reward_max": {"pol0": -1430686.8455345873, "pol1": 1885717.6072209042}, "policy_reward_mean": {"pol0": -1726687.3732492873, "pol1": 1726687.3732492873}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22358490324378272, "mean_inference_ms": 3.013389614606567, "mean_action_processing_ms": 0.15112216149227534, "mean_env_wait_ms": 0.1214678154587424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 18018, "agent_timesteps_total": 36036, "timers": {"sample_time_ms": 3609.205, "sample_throughput": 1664.078, "learn_time_ms": 18020.57, "learn_throughput": 333.286, "update_time_ms": 7.877}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 23710516202.212765, "policy_loss": 0.004442085591243937, "vf_loss": 23710516202.212765, "vf_explained_var": 1.0018653284760148e-07, "kl": 0.019424933781649206, "entropy": 2.7404021810978016, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 23715269740.93617, "policy_loss": -0.004584801878700865, "vf_loss": 23715269740.93617, "vf_explained_var": -1.1413655798264699e-08, "kl": 0.006040982753434714, "entropy": 2.939583697217576, "entropy_coeff": 0.0}}}, "num_steps_sampled": 18018, "num_agent_steps_sampled": 36036, "num_steps_trained": 18018, "num_agent_steps_trained": 36036}, "done": false, "episodes_total": 18, "training_iteration": 3, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-26-46", "timestamp": 1624973206, "time_this_iter_s": 21.287472009658813, "time_total_s": 64.9404308795929, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47a0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e4606a8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 64.9404308795929, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 19.15357142857143, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.2446428571428572, "vram_util_percent0": 0.22533583706485624}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1885717.6072209042, "pol1": 1430686.8455345873}, "policy_reward_max": {"pol0": -1430686.8455345873, "pol1": 1885717.6072209042}, "policy_reward_mean": {"pol0": -1730825.1555089548, "pol1": 1730825.1555089548}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22215915223320404, "mean_inference_ms": 3.0084870869292595, "mean_action_processing_ms": 0.15084506452641525, "mean_env_wait_ms": 0.12137731995567887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 24024, "agent_timesteps_total": 48048, "timers": {"sample_time_ms": 3615.27, "sample_throughput": 1661.287, "learn_time_ms": 17909.798, "learn_throughput": 335.347, "update_time_ms": 7.526}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25654627611.234043, "policy_loss": 0.0018322517540543637, "vf_loss": 25654627611.234043, "vf_explained_var": 2.5363679156953367e-08, "kl": 0.01623648000841445, "entropy": 2.796865148747221, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 25663012733.276596, "policy_loss": 0.0003007456581009195, "vf_loss": 25663012733.276596, "vf_explained_var": 2.1559126039960574e-08, "kl": 0.002694775442037969, "entropy": 2.8669440340488515, "entropy_coeff": 0.0}}}, "num_steps_sampled": 24024, "num_agent_steps_sampled": 48048, "num_steps_trained": 24024, "num_agent_steps_trained": 48048}, "done": false, "episodes_total": 24, "training_iteration": 4, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-27-07", "timestamp": 1624973227, "time_this_iter_s": 21.226484298706055, "time_total_s": 86.16691517829895, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44e400>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44e378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 86.16691517829895, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 19.025, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23428571428571424, "vram_util_percent0": 0.22533583706485624}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1885717.6072209042, "pol1": 1430686.8455345873}, "policy_reward_max": {"pol0": -1430686.8455345873, "pol1": 1885717.6072209042}, "policy_reward_mean": {"pol0": -1736406.548860524, "pol1": 1736406.548860524}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22139041736672785, "mean_inference_ms": 3.009796938061685, "mean_action_processing_ms": 0.15089999769145082, "mean_env_wait_ms": 0.12147054304952193, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 30030, "agent_timesteps_total": 60060, "timers": {"sample_time_ms": 3640.71, "sample_throughput": 1649.678, "learn_time_ms": 17819.153, "learn_throughput": 337.053, "update_time_ms": 7.344}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1999999999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26102729706.212765, "policy_loss": -0.0013083061203360558, "vf_loss": 26102729706.212765, "vf_explained_var": 1.3442749491332506e-07, "kl": 0.02090142588032053, "entropy": 2.858449768512807, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 26109729726.638298, "policy_loss": -0.004031188171753224, "vf_loss": 26109729726.638298, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.008269866789750595, "entropy": 2.776655009452333, "entropy_coeff": 0.0}}}, "num_steps_sampled": 30030, "num_agent_steps_sampled": 60060, "num_steps_trained": 30030, "num_agent_steps_trained": 60060}, "done": false, "episodes_total": 30, "training_iteration": 5, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-27-29", "timestamp": 1624973249, "time_this_iter_s": 21.214407920837402, "time_total_s": 107.38132309913635, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4840d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44eae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 107.38132309913635, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 19.53928571428571, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23535714285714285, "vram_util_percent0": 0.2253538928210313}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1885717.6072209042, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1885717.6072209042}, "policy_reward_mean": {"pol0": -1725315.5942109255, "pol1": 1725315.5942109255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22087159249044055, "mean_inference_ms": 3.012458193718066, "mean_action_processing_ms": 0.15102772121779595, "mean_env_wait_ms": 0.12159728553624616, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 36036, "agent_timesteps_total": 72072, "timers": {"sample_time_ms": 3657.519, "sample_throughput": 1642.097, "learn_time_ms": 17901.638, "learn_throughput": 335.5, "update_time_ms": 7.27}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000016, "cur_lr": 5.000000000000002e-05, "total_loss": 23656435101.957447, "policy_loss": 0.003971144477737711, "vf_loss": 23656435101.957447, "vf_explained_var": -1.1794110577056927e-07, "kl": 0.020206563214355325, "entropy": 2.8130212134503303, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.09999999999999995, "cur_lr": 5.000000000000002e-05, "total_loss": 23665488961.361702, "policy_loss": -0.00265859990836458, "vf_loss": 23665488961.361702, "vf_explained_var": -6.340919789238342e-09, "kl": 0.004369968543463248, "entropy": 2.6736452122952077, "entropy_coeff": 0.0}}}, "num_steps_sampled": 36036, "num_agent_steps_sampled": 72072, "num_steps_trained": 36036, "num_agent_steps_trained": 72072}, "done": false, "episodes_total": 36, "training_iteration": 6, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-27-51", "timestamp": 1624973271, "time_this_iter_s": 22.071057081222534, "time_total_s": 129.4523801803589, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4841e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 129.4523801803589, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 19.396551724137936, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23034482758620692, "vram_util_percent0": 0.22533500691514705}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1885717.6072209042, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1885717.6072209042}, "policy_reward_mean": {"pol0": -1725567.7114582267, "pol1": 1725567.7114582267}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22047723200594896, "mean_inference_ms": 3.014348544922135, "mean_action_processing_ms": 0.1511190663602458, "mean_env_wait_ms": 0.12168793995815747, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 42042, "agent_timesteps_total": 84084, "timers": {"sample_time_ms": 3654.073, "sample_throughput": 1643.645, "learn_time_ms": 17850.26, "learn_throughput": 336.466, "update_time_ms": 7.185}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25259960842.893616, "policy_loss": -0.0013589001399405458, "vf_loss": 25259960842.893616, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.010630279264234483, "entropy": 2.708726999607492, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25273060112.340427, "policy_loss": -0.002832101697617389, "vf_loss": 25273060112.340427, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.00747948011105999, "entropy": 2.6913398833985025, "entropy_coeff": 0.0}}}, "num_steps_sampled": 42042, "num_agent_steps_sampled": 84084, "num_steps_trained": 42042, "num_agent_steps_trained": 84084}, "done": false, "episodes_total": 42, "training_iteration": 7, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-28-12", "timestamp": 1624973292, "time_this_iter_s": 21.19052767753601, "time_total_s": 150.6429078578949, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44c488>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44c400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 150.6429078578949, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 19.514285714285712, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.2389285714285714, "vram_util_percent0": 0.22533583706485624}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1725567.1947614562, "pol1": 1725567.1947614562}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22015892308761353, "mean_inference_ms": 3.016102713231105, "mean_action_processing_ms": 0.15120280798433053, "mean_env_wait_ms": 0.12177150935973395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 48048, "agent_timesteps_total": 96096, "timers": {"sample_time_ms": 3660.555, "sample_throughput": 1640.735, "learn_time_ms": 17821.833, "learn_throughput": 337.002, "update_time_ms": 7.117}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25308496743.48936, "policy_loss": -0.0005111782910658958, "vf_loss": 25308496743.48936, "vf_explained_var": 9.384561394654156e-08, "kl": 0.010920443948596082, "entropy": 2.786043420751044, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25322813788.595745, "policy_loss": -0.0033951421525884183, "vf_loss": 25322813788.595745, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.009520148363043653, "entropy": 2.5714347666882453, "entropy_coeff": 0.0}}}, "num_steps_sampled": 48048, "num_agent_steps_sampled": 96096, "num_steps_trained": 48048, "num_agent_steps_trained": 96096}, "done": false, "episodes_total": 48, "training_iteration": 8, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-28-33", "timestamp": 1624973313, "time_this_iter_s": 21.34494161605835, "time_total_s": 171.98784947395325, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44c9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44cf28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 171.98784947395325, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 19.275000000000002, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23678571428571424, "vram_util_percent0": 0.225359911406423}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1722314.3950702678, "pol1": 1722314.3950702678}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21988781312315459, "mean_inference_ms": 3.0173838313494667, "mean_action_processing_ms": 0.15127629479079438, "mean_env_wait_ms": 0.12183824188473114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 54054, "agent_timesteps_total": 108108, "timers": {"sample_time_ms": 3663.598, "sample_throughput": 1639.372, "learn_time_ms": 17792.239, "learn_throughput": 337.563, "update_time_ms": 7.082}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24250618204.595745, "policy_loss": -0.0005126002026682204, "vf_loss": 24250618204.595745, "vf_explained_var": 1.1413655798264699e-08, "kl": 0.010355421203248043, "entropy": 2.7784786528729377, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24264739948.93617, "policy_loss": -0.004453037409706318, "vf_loss": 24264739948.93617, "vf_explained_var": 1.154047382101453e-07, "kl": 0.008131301089962746, "entropy": 2.73717178182399, "entropy_coeff": 0.0}}}, "num_steps_sampled": 54054, "num_agent_steps_sampled": 108108, "num_steps_trained": 54054, "num_agent_steps_trained": 108108}, "done": false, "episodes_total": 54, "training_iteration": 9, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-28-55", "timestamp": 1624973335, "time_this_iter_s": 21.25911545753479, "time_total_s": 193.24696493148804, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44eae8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44e620>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 193.24696493148804, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 19.2, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.24214285714285713, "vram_util_percent0": 0.22533583706485624}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1727129.53823785, "pol1": 1727129.53823785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21966078466715153, "mean_inference_ms": 3.0193931983909708, "mean_action_processing_ms": 0.1513305547966513, "mean_env_wait_ms": 0.12189155987991539, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 60060, "agent_timesteps_total": 120120, "timers": {"sample_time_ms": 3674.965, "sample_throughput": 1634.301, "learn_time_ms": 17784.528, "learn_throughput": 337.709, "update_time_ms": 7.055}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26727530583.148937, "policy_loss": 0.00040354226973462613, "vf_loss": 26727530583.148937, "vf_explained_var": 2.663186293716535e-08, "kl": 0.009555549796749937, "entropy": 2.7121683181600367, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26742392570.553192, "policy_loss": -0.004849087922496998, "vf_loss": 26742392570.553192, "vf_explained_var": 2.916823049758932e-08, "kl": 0.007868666568414328, "entropy": 2.862369714899266, "entropy_coeff": 0.0}}}, "num_steps_sampled": 60060, "num_agent_steps_sampled": 120120, "num_steps_trained": 60060, "num_agent_steps_trained": 120120}, "done": false, "episodes_total": 60, "training_iteration": 10, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-29-16", "timestamp": 1624973356, "time_this_iter_s": 21.508535861968994, "time_total_s": 214.75550079345703, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484ae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 214.75550079345703, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 19.85714285714286, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.24000000000000002, "vram_util_percent0": 0.22545620877269007}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1719628.496255871, "pol1": 1719628.496255871}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2195950011968971, "mean_inference_ms": 3.023179069848687, "mean_action_processing_ms": 0.1514922706753695, "mean_env_wait_ms": 0.12203307605415971, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 66066, "agent_timesteps_total": 132132, "timers": {"sample_time_ms": 3703.746, "sample_throughput": 1621.602, "learn_time_ms": 17744.762, "learn_throughput": 338.466, "update_time_ms": 6.88}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 22820026542.29787, "policy_loss": -0.003332545762842006, "vf_loss": 22820026542.29787, "vf_explained_var": 3.550914939864924e-08, "kl": 0.010449898666999441, "entropy": 2.6868307133938405, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 22832235106.042553, "policy_loss": -0.003802661566024131, "vf_loss": 22832235106.042553, "vf_explained_var": 1.4203659759459697e-07, "kl": 0.011331215916954457, "entropy": 2.812789648137194, "entropy_coeff": 0.0}}}, "num_steps_sampled": 66066, "num_agent_steps_sampled": 132132, "num_steps_trained": 66066, "num_agent_steps_trained": 132132}, "done": false, "episodes_total": 66, "training_iteration": 11, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-29-38", "timestamp": 1624973378, "time_this_iter_s": 21.653161764144897, "time_total_s": 236.40866255760193, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47aa60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f47a950>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 236.40866255760193, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 20.231034482758623, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.2255172413793103, "vram_util_percent0": 0.23001871157444528}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1719113.1606658278, "pol1": 1719113.1606658278}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2195501088729923, "mean_inference_ms": 3.0261161266606686, "mean_action_processing_ms": 0.1516257970494966, "mean_env_wait_ms": 0.12214589944622938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 72072, "agent_timesteps_total": 144144, "timers": {"sample_time_ms": 3704.769, "sample_throughput": 1621.154, "learn_time_ms": 17646.153, "learn_throughput": 340.357, "update_time_ms": 6.745}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24831050730.212765, "policy_loss": -0.00025117167450012043, "vf_loss": 24831050730.212765, "vf_explained_var": -2.2827311596529398e-08, "kl": 0.016288258769410723, "entropy": 2.7900282930820546, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24844755161.87234, "policy_loss": -0.005166271800531986, "vf_loss": 24844755161.87234, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.011122414049633007, "entropy": 2.8622771222540675, "entropy_coeff": 0.0}}}, "num_steps_sampled": 72072, "num_agent_steps_sampled": 144144, "num_steps_trained": 72072, "num_agent_steps_trained": 144144}, "done": false, "episodes_total": 72, "training_iteration": 12, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-29-59", "timestamp": 1624973399, "time_this_iter_s": 20.91097331047058, "time_total_s": 257.3196358680725, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484d08>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 257.3196358680725, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 19.62222222222222, "ram_util_percent": 43.900000000000006, "gpu_util_percent0": 0.23148148148148148, "vram_util_percent0": 0.23039234043615572}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1720722.9298618617, "pol1": 1720722.9298618617}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21951779318428108, "mean_inference_ms": 3.028531966192143, "mean_action_processing_ms": 0.15173840576695763, "mean_env_wait_ms": 0.1222408494759842, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 78078, "agent_timesteps_total": 156156, "timers": {"sample_time_ms": 3721.652, "sample_throughput": 1613.799, "learn_time_ms": 17649.606, "learn_throughput": 340.291, "update_time_ms": 6.64}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25573346325.787235, "policy_loss": 0.002091823522239289, "vf_loss": 25573346325.787235, "vf_explained_var": 3.424096561843726e-08, "kl": 0.008552308560923693, "entropy": 2.8001998333220786, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25594975863.82979, "policy_loss": -0.005422952446214696, "vf_loss": 25594975863.82979, "vf_explained_var": 1.0145471129874295e-08, "kl": 0.009061946315651244, "entropy": 2.840565432893469, "entropy_coeff": 0.0}}}, "num_steps_sampled": 78078, "num_agent_steps_sampled": 156156, "num_steps_trained": 78078, "num_agent_steps_trained": 156156}, "done": false, "episodes_total": 78, "training_iteration": 13, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-30-20", "timestamp": 1624973420, "time_this_iter_s": 21.490286111831665, "time_total_s": 278.8099219799042, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4848c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 278.8099219799042, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 18.92068965517241, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23413793103448272, "vram_util_percent0": 0.2304138628360238}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1720328.9911707554, "pol1": 1720328.9911707554}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21948096265857717, "mean_inference_ms": 3.0303779616860287, "mean_action_processing_ms": 0.15182691192150652, "mean_env_wait_ms": 0.12231541341025318, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 84084, "agent_timesteps_total": 168168, "timers": {"sample_time_ms": 3731.894, "sample_throughput": 1609.371, "learn_time_ms": 17655.614, "learn_throughput": 340.175, "update_time_ms": 6.642}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24904310696.851063, "policy_loss": 0.0019064480240674729, "vf_loss": 24904310696.851063, "vf_explained_var": -2.916823049758932e-08, "kl": 0.013223735318380468, "entropy": 2.879075679373234, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24926732026.553192, "policy_loss": -0.005530897666640738, "vf_loss": 24926732026.553192, "vf_explained_var": 1.5345025872193219e-07, "kl": 0.010336820848603198, "entropy": 2.6359849280499397, "entropy_coeff": 0.0}}}, "num_steps_sampled": 84084, "num_agent_steps_sampled": 168168, "num_steps_trained": 84084, "num_agent_steps_trained": 168168}, "done": false, "episodes_total": 84, "training_iteration": 14, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-30-42", "timestamp": 1624973442, "time_this_iter_s": 21.38996171951294, "time_total_s": 300.1998836994171, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44cb70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44c8c8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 300.1998836994171, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 19.23928571428571, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23535714285714285, "vram_util_percent0": 0.23039144879387546}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1724017.453569906, "pol1": 1724017.453569906}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21944312627493748, "mean_inference_ms": 3.0319862758846763, "mean_action_processing_ms": 0.15190269680375773, "mean_env_wait_ms": 0.12238071562357432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 90090, "agent_timesteps_total": 180180, "timers": {"sample_time_ms": 3728.466, "sample_throughput": 1610.85, "learn_time_ms": 17694.502, "learn_throughput": 339.427, "update_time_ms": 6.648}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26475232277.787235, "policy_loss": -0.002476958577778745, "vf_loss": 26475232277.787235, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.006478310523039483, "entropy": 2.8016737775599703, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26501347633.02128, "policy_loss": -0.005280364611919256, "vf_loss": 26501347633.02128, "vf_explained_var": -1.2681839578476684e-08, "kl": 0.008580967575866492, "entropy": 2.6063666698780468, "entropy_coeff": 0.0}}}, "num_steps_sampled": 90090, "num_agent_steps_sampled": 180180, "num_steps_trained": 90090, "num_agent_steps_trained": 180180}, "done": false, "episodes_total": 90, "training_iteration": 15, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-31-03", "timestamp": 1624973463, "time_this_iter_s": 21.570223093032837, "time_total_s": 321.77010679244995, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e3e6e18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e3e60d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 321.77010679244995, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 19.574999999999996, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.22, "vram_util_percent0": 0.23039144879387546}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1724914.2120831432, "pol1": 1724914.2120831432}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1847565.56274634, -1698357.4777091006, -1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553], "policy_pol1_reward": [1847565.56274634, 1698357.4777091006, 1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21941736835641837, "mean_inference_ms": 3.0334205558031173, "mean_action_processing_ms": 0.15196993710556514, "mean_env_wait_ms": 0.12243835701495077, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 96096, "agent_timesteps_total": 192192, "timers": {"sample_time_ms": 3725.213, "sample_throughput": 1612.257, "learn_time_ms": 17604.582, "learn_throughput": 341.161, "update_time_ms": 6.728}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25578096857.87234, "policy_loss": -0.003697014057097283, "vf_loss": 25578096857.87234, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.008342999588460364, "entropy": 2.8634691542767463, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25600652135.48936, "policy_loss": -0.005077886315894888, "vf_loss": 25600652135.48936, "vf_explained_var": -1.3950023358688668e-08, "kl": 0.006741970638803979, "entropy": 2.786098769370546, "entropy_coeff": 0.0}}}, "num_steps_sampled": 96096, "num_agent_steps_sampled": 192192, "num_steps_trained": 96096, "num_agent_steps_trained": 192192}, "done": false, "episodes_total": 96, "training_iteration": 16, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-31-25", "timestamp": 1624973485, "time_this_iter_s": 21.141571760177612, "time_total_s": 342.91167855262756, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44cbf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44c488>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 342.91167855262756, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 19.421428571428574, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23249999999999998, "vram_util_percent0": 0.2304155231354422}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1724119.614648765, "pol1": 1724119.614648765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1730729.0665513526, -1802016.0371114311, -1825791.5586127476, -1845262.6331278079, -1833045.4961932567, -1606748.3731939094, -1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082], "policy_pol1_reward": [1730729.0665513526, 1802016.0371114311, 1825791.5586127476, 1845262.6331278079, 1833045.4961932567, 1606748.3731939094, 1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21909209562344653, "mean_inference_ms": 3.035848943443406, "mean_action_processing_ms": 0.15210235823711246, "mean_env_wait_ms": 0.12253472570527205, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 102102, "agent_timesteps_total": 204204, "timers": {"sample_time_ms": 3731.194, "sample_throughput": 1609.672, "learn_time_ms": 17601.984, "learn_throughput": 341.212, "update_time_ms": 6.752}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25101617457.02128, "policy_loss": -0.0019836495531366225, "vf_loss": 25101617457.02128, "vf_explained_var": 1.1794110577056927e-07, "kl": 0.012497086553497518, "entropy": 2.8627465633635825, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25122641484.255318, "policy_loss": -0.005375850351249918, "vf_loss": 25122641484.255318, "vf_explained_var": 5.0727355649371475e-09, "kl": 0.010233918363426594, "entropy": 2.7272531326780927, "entropy_coeff": 0.0}}}, "num_steps_sampled": 102102, "num_agent_steps_sampled": 204204, "num_steps_trained": 102102, "num_agent_steps_trained": 204204}, "done": false, "episodes_total": 102, "training_iteration": 17, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-31-46", "timestamp": 1624973506, "time_this_iter_s": 21.225130558013916, "time_total_s": 364.1368091106415, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44c8c8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44cd90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 364.1368091106415, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 19.27857142857143, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.2278571428571428, "vram_util_percent0": 0.23039144879387546}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1724016.2454869053, "pol1": 1724016.2454869053}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1774776.391842725, -1798081.473298621, -1648733.7421836196, -1676040.6297270623, -1591508.0955822289, -1853522.0995153463, -1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145], "policy_pol1_reward": [1774776.391842725, 1798081.473298621, 1648733.7421836196, 1676040.6297270623, 1591508.0955822289, 1853522.0995153463, 1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21871016991233247, "mean_inference_ms": 3.037743650519113, "mean_action_processing_ms": 0.15217828474658388, "mean_env_wait_ms": 0.12263364656340958, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 108108, "agent_timesteps_total": 216216, "timers": {"sample_time_ms": 3724.8, "sample_throughput": 1612.435, "learn_time_ms": 17670.624, "learn_throughput": 339.886, "update_time_ms": 6.748}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26383650075.234043, "policy_loss": 0.00219568281256138, "vf_loss": 26383650075.234043, "vf_explained_var": 1.1667292199035728e-07, "kl": 0.014664683253207106, "entropy": 2.7558936717662403, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26408777597.276596, "policy_loss": -0.0051154529953256565, "vf_loss": 26408777597.276596, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.008133220981727255, "entropy": 2.6968427160952952, "entropy_coeff": 0.0}}}, "num_steps_sampled": 108108, "num_agent_steps_sampled": 216216, "num_steps_trained": 108108, "num_agent_steps_trained": 216216}, "done": false, "episodes_total": 108, "training_iteration": 18, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-32-08", "timestamp": 1624973528, "time_this_iter_s": 21.96757411956787, "time_total_s": 386.10438323020935, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4847b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 386.10438323020935, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 19.155172413793107, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.2231034482758621, "vram_util_percent0": 0.23039061864416627}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1723927.0238356327, "pol1": 1723927.0238356327}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1609976.0397478554, -1885717.6072209042, -1430686.8455345873, -1621813.5885882785, -1720386.3432032194, -1776559.82068919, -1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016], "policy_pol1_reward": [1609976.0397478554, 1885717.6072209042, 1430686.8455345873, 1621813.5885882785, 1720386.3432032194, 1776559.82068919, 1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21866373642147294, "mean_inference_ms": 3.039756054843522, "mean_action_processing_ms": 0.15228367032507686, "mean_env_wait_ms": 0.12272634007317074, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 114114, "agent_timesteps_total": 228228, "timers": {"sample_time_ms": 3727.166, "sample_throughput": 1611.412, "learn_time_ms": 17676.08, "learn_throughput": 339.781, "update_time_ms": 6.806}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 24972444955.234043, "policy_loss": -0.000340056744344691, "vf_loss": 24972444955.234043, "vf_explained_var": -3.0436414277801305e-08, "kl": 0.007593477808652406, "entropy": 2.7816012666580523, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24998353811.06383, "policy_loss": -0.0029460740018081156, "vf_loss": 24998353811.06383, "vf_explained_var": -1.4203659759459697e-07, "kl": 0.008573556011740832, "entropy": 2.8841150314249893, "entropy_coeff": 0.0}}}, "num_steps_sampled": 114114, "num_agent_steps_sampled": 228228, "num_steps_trained": 114114, "num_agent_steps_trained": 228228}, "done": false, "episodes_total": 114, "training_iteration": 19, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-32-29", "timestamp": 1624973549, "time_this_iter_s": 21.33943748474121, "time_total_s": 407.44382071495056, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47ad90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f47ab70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 407.44382071495056, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 19.11785714285714, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.2353571428571428, "vram_util_percent0": 0.23040950455005052}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1728231.2357511662, "pol1": 1728231.2357511662}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1765752.4945870661, -1881508.7147268592, -1818864.2344398575, -1496359.406081547, -1760439.5726560734, -1691629.3972748925, -1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788], "policy_pol1_reward": [1765752.4945870661, 1881508.7147268592, 1818864.2344398575, 1496359.406081547, 1760439.5726560734, 1691629.3972748925, 1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21874252514929146, "mean_inference_ms": 3.0424624859919045, "mean_action_processing_ms": 0.15241709272051987, "mean_env_wait_ms": 0.12283329454803679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 120120, "agent_timesteps_total": 240240, "timers": {"sample_time_ms": 3717.083, "sample_throughput": 1615.783, "learn_time_ms": 17650.754, "learn_throughput": 340.269, "update_time_ms": 6.83}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25761037943.82979, "policy_loss": 0.0016027249871416295, "vf_loss": 25761037943.82979, "vf_explained_var": -1.065274517486614e-07, "kl": 0.01051497923091371, "entropy": 2.723272161280855, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25786223986.38298, "policy_loss": -0.0020642466446820725, "vf_loss": 25786223986.38298, "vf_explained_var": 9.89183490673895e-08, "kl": 0.007000701264181035, "entropy": 3.1088108306235456, "entropy_coeff": 0.0}}}, "num_steps_sampled": 120120, "num_agent_steps_sampled": 240240, "num_steps_trained": 120120, "num_agent_steps_trained": 240240}, "done": false, "episodes_total": 120, "training_iteration": 20, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-32-50", "timestamp": 1624973570, "time_this_iter_s": 21.15516185760498, "time_total_s": 428.59898257255554, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484bf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f4847b8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 428.59898257255554, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 19.414285714285718, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.22964285714285712, "vram_util_percent0": 0.23039144879387546}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1731020.2842713438, "pol1": 1731020.2842713438}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1768421.6438046137, -1752047.6150250784, -1744082.544630679, -1835771.9602094726, -1662473.176659806, -1732622.7439316888, -1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702], "policy_pol1_reward": [1768421.6438046137, 1752047.6150250784, 1744082.544630679, 1835771.9602094726, 1662473.176659806, 1732622.7439316888, 1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21882468816715075, "mean_inference_ms": 3.045500462577232, "mean_action_processing_ms": 0.1525720570928927, "mean_env_wait_ms": 0.12294932987340729, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 126126, "agent_timesteps_total": 252252, "timers": {"sample_time_ms": 3685.213, "sample_throughput": 1629.756, "learn_time_ms": 17625.725, "learn_throughput": 340.752, "update_time_ms": 6.876}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26748106011.234043, "policy_loss": 0.0007527043294914543, "vf_loss": 26748106011.234043, "vf_explained_var": -3.677733317886123e-08, "kl": 0.013745024007685642, "entropy": 2.7937629121415157, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26777966069.106384, "policy_loss": -0.004075829553952876, "vf_loss": 26777966069.106384, "vf_explained_var": 1.2681838912342869e-09, "kl": 0.007711079407562601, "entropy": 2.9925169538944325, "entropy_coeff": 0.0}}}, "num_steps_sampled": 126126, "num_agent_steps_sampled": 252252, "num_steps_trained": 126126, "num_agent_steps_trained": 252252}, "done": false, "episodes_total": 126, "training_iteration": 21, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-33-11", "timestamp": 1624973591, "time_this_iter_s": 21.084338665008545, "time_total_s": 449.6833212375641, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4b0c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e3e6bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 449.6833212375641, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 19.074999999999996, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23071428571428568, "vram_util_percent0": 0.2303854302084838}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1344333.2170190183}, "policy_reward_max": {"pol0": -1344333.2170190183, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1730560.910713313, "pol1": 1730560.910713313}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1750918.4105751768, -1870918.6968658292, -1657898.6807260853, -1344333.2170190183, -1722938.229381026, -1640954.5002809702, -1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008], "policy_pol1_reward": [1750918.4105751768, 1870918.6968658292, 1657898.6807260853, 1344333.2170190183, 1722938.229381026, 1640954.5002809702, 1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21888462697833877, "mean_inference_ms": 3.046833795179637, "mean_action_processing_ms": 0.15264692184026946, "mean_env_wait_ms": 0.12300734384312338, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 132132, "agent_timesteps_total": 264264, "timers": {"sample_time_ms": 3686.721, "sample_throughput": 1629.09, "learn_time_ms": 17689.601, "learn_throughput": 339.522, "update_time_ms": 6.921}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25529226653.957447, "policy_loss": -0.0006418979944700891, "vf_loss": 25529226653.957447, "vf_explained_var": -3.2972781838225274e-08, "kl": 0.014569468023453621, "entropy": 2.7792955865251256, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25554925742.29787, "policy_loss": -0.004659651857899859, "vf_loss": 25554925742.29787, "vf_explained_var": 1.0145471662781347e-07, "kl": 0.009551435907153374, "entropy": 3.1339979932663287, "entropy_coeff": 0.0}}}, "num_steps_sampled": 132132, "num_agent_steps_sampled": 264264, "num_steps_trained": 132132, "num_agent_steps_trained": 264264}, "done": false, "episodes_total": 132, "training_iteration": 22, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-33-33", "timestamp": 1624973613, "time_this_iter_s": 21.565864324569702, "time_total_s": 471.2491855621338, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e3fa620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e3fa048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 471.2491855621338, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 19.471428571428568, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23178571428571432, "vram_util_percent0": 0.23040950455005052}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1924760.5733854347, "pol1": 1377561.0333750807}, "policy_reward_max": {"pol0": -1377561.0333750807, "pol1": 1924760.5733854347}, "policy_reward_mean": {"pol0": -1735229.4423715505, "pol1": 1735229.4423715505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1832568.5994188387, -1557178.6295347079, -1756122.6964625018, -1852719.8345741641, -1593657.6626996382, -1924760.5733854347, -1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996], "policy_pol1_reward": [1832568.5994188387, 1557178.6295347079, 1756122.6964625018, 1852719.8345741641, 1593657.6626996382, 1924760.5733854347, 1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21895291107150047, "mean_inference_ms": 3.047998659110935, "mean_action_processing_ms": 0.15270551057708662, "mean_env_wait_ms": 0.12305757449847551, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 138138, "agent_timesteps_total": 276276, "timers": {"sample_time_ms": 3692.117, "sample_throughput": 1626.709, "learn_time_ms": 17690.068, "learn_throughput": 339.513, "update_time_ms": 6.936}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 25713008029.957447, "policy_loss": -0.002148399089879178, "vf_loss": 25713008029.957447, "vf_explained_var": 1.3442749491332506e-07, "kl": 0.012155496416256783, "entropy": 2.721134525664309, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25737126890.212765, "policy_loss": -0.0037923426902357568, "vf_loss": 25737126846.638298, "vf_explained_var": 1.610593614032041e-07, "kl": 0.009145578983774844, "entropy": 3.1086410664497537, "entropy_coeff": 0.0}}}, "num_steps_sampled": 138138, "num_agent_steps_sampled": 276276, "num_steps_trained": 138138, "num_agent_steps_trained": 276276}, "done": false, "episodes_total": 138, "training_iteration": 23, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-33-55", "timestamp": 1624973635, "time_this_iter_s": 21.54989004135132, "time_total_s": 492.7990756034851, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e3fab70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e3faf28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 492.7990756034851, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 19.746428571428574, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.23214285714285715, "vram_util_percent0": 0.23039144879387546}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1920946.592120296, "pol1": 1325481.5317233107}, "policy_reward_max": {"pol0": -1325481.5317233107, "pol1": 1920946.592120296}, "policy_reward_mean": {"pol0": -1736382.6545807477, "pol1": 1736382.6545807477}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1723354.4338212686, -1704992.8124142436, -1731172.264068786, -1675443.720915001, -1760667.3471828601, -1735103.4784528269, -1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767], "policy_pol1_reward": [1723354.4338212686, 1704992.8124142436, 1731172.264068786, 1675443.720915001, 1760667.3471828601, 1735103.4784528269, 1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2190204532870413, "mean_inference_ms": 3.0491145187741573, "mean_action_processing_ms": 0.1527635430527574, "mean_env_wait_ms": 0.123105576218938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 144144, "agent_timesteps_total": 288288, "timers": {"sample_time_ms": 3691.736, "sample_throughput": 1626.877, "learn_time_ms": 17680.799, "learn_throughput": 339.691, "update_time_ms": 6.923}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 26829416099.404255, "policy_loss": -0.0021296113511507816, "vf_loss": 26829416099.404255, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.009512525804816409, "entropy": 2.685632517997255, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26866602463.31915, "policy_loss": -0.002900192197015945, "vf_loss": 26866602463.31915, "vf_explained_var": 1.1667292199035728e-07, "kl": 0.011132032531214522, "entropy": 3.1096264707281236, "entropy_coeff": 0.0}}}, "num_steps_sampled": 144144, "num_agent_steps_sampled": 288288, "num_steps_trained": 144144, "num_agent_steps_trained": 288288}, "done": false, "episodes_total": 144, "training_iteration": 24, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-34-16", "timestamp": 1624973656, "time_this_iter_s": 21.294251203536987, "time_total_s": 514.0933268070221, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484598>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f4842f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 514.0933268070221, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 19.285714285714285, "ram_util_percent": 43.90000000000001, "gpu_util_percent0": 0.2282142857142857, "vram_util_percent0": 0.23039144879387546}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926308.5385843017, "pol1": 1325481.5317233107}, "policy_reward_max": {"pol0": -1325481.5317233107, "pol1": 1926308.5385843017}, "policy_reward_mean": {"pol0": -1741450.0567275726, "pol1": 1741450.0567275726}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1915133.0590731713, -1625562.9528222813, -1566424.2674183617, -1574860.8802950615, -1804685.1771979984, -1885372.9358972972, -1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875], "policy_pol1_reward": [1915133.0590731713, 1625562.9528222813, 1566424.2674183617, 1574860.8802950615, 1804685.1771979984, 1885372.9358972972, 1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21909947633483687, "mean_inference_ms": 3.049899997372664, "mean_action_processing_ms": 0.152805593722391, "mean_env_wait_ms": 0.12314199594592727, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 150150, "agent_timesteps_total": 300300, "timers": {"sample_time_ms": 3690.063, "sample_throughput": 1627.614, "learn_time_ms": 17652.829, "learn_throughput": 340.229, "update_time_ms": 6.995}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.44999999999999996, "cur_lr": 5.000000000000002e-05, "total_loss": 27521825944.51064, "policy_loss": -0.0009059328585863113, "vf_loss": 27521825944.51064, "vf_explained_var": -7.989558525878238e-08, "kl": 0.02401647574089943, "entropy": 2.7839110049795597, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 27551323593.531914, "policy_loss": -0.0050919770877412025, "vf_loss": 27551323593.531914, "vf_explained_var": -1.2681839223205316e-07, "kl": 0.011086865387698437, "entropy": 2.79243166903232, "entropy_coeff": 0.0}}}, "num_steps_sampled": 150150, "num_agent_steps_sampled": 300300, "num_steps_trained": 150150, "num_agent_steps_trained": 300300}, "done": false, "episodes_total": 150, "training_iteration": 25, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-34-37", "timestamp": 1624973677, "time_this_iter_s": 21.27467632293701, "time_total_s": 535.3680031299591, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47a9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f47ae18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 535.3680031299591, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 19.267857142857142, "ram_util_percent": 43.989285714285714, "gpu_util_percent0": 0.22392857142857142, "vram_util_percent0": 0.2282006837113005}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1926308.5385843017, "pol1": 1325481.5317233107}, "policy_reward_max": {"pol0": -1325481.5317233107, "pol1": 1926308.5385843017}, "policy_reward_mean": {"pol0": -1746618.3133836598, "pol1": 1746618.3133836598}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1668087.4676311407, -1920946.592120296, -1669040.3774712898, -1674662.4101585196, -1757179.2260228994, -1737985.743975326, -1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411], "policy_pol1_reward": [1668087.4676311407, 1920946.592120296, 1669040.3774712898, 1674662.4101585196, 1757179.2260228994, 1737985.743975326, 1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21920933825829214, "mean_inference_ms": 3.0506132442833196, "mean_action_processing_ms": 0.15284958433131016, "mean_env_wait_ms": 0.1231803543543272, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 156156, "agent_timesteps_total": 312312, "timers": {"sample_time_ms": 3681.524, "sample_throughput": 1631.39, "learn_time_ms": 17662.284, "learn_throughput": 340.047, "update_time_ms": 6.943}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 27661618720.68085, "policy_loss": -0.002130463144722137, "vf_loss": 27661618720.68085, "vf_explained_var": -6.340919789238342e-09, "kl": 0.009503671364422808, "entropy": 2.869843396734684, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 27697354621.276596, "policy_loss": -0.006673131093501728, "vf_loss": 27697354621.276596, "vf_explained_var": 2.2827311596529398e-08, "kl": 0.014768031762635454, "entropy": 2.78252138990037, "entropy_coeff": 0.0}}}, "num_steps_sampled": 156156, "num_agent_steps_sampled": 312312, "num_steps_trained": 156156, "num_agent_steps_trained": 312312}, "done": false, "episodes_total": 156, "training_iteration": 26, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-34-59", "timestamp": 1624973699, "time_this_iter_s": 21.151212453842163, "time_total_s": 556.5192155838013, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44e950>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44e378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 556.5192155838013, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 19.414285714285715, "ram_util_percent": 44.0, "gpu_util_percent0": 0.22999999999999998, "vram_util_percent0": 0.22791781019789112}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1325481.5317233107}, "policy_reward_max": {"pol0": -1325481.5317233107, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1748463.9887777762, "pol1": 1748463.9887777762}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1537367.421909746, -1557204.2890479034, -1377561.0333750807, -1900410.7442855122, -1554444.9369018546, -1747316.4083389272, -1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117], "policy_pol1_reward": [1537367.421909746, 1557204.2890479034, 1377561.0333750807, 1900410.7442855122, 1554444.9369018546, 1747316.4083389272, 1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2192745026230937, "mean_inference_ms": 3.0504378011432234, "mean_action_processing_ms": 0.15286834985104356, "mean_env_wait_ms": 0.12319531494898504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 162162, "agent_timesteps_total": 324324, "timers": {"sample_time_ms": 3665.538, "sample_throughput": 1638.504, "learn_time_ms": 17781.71, "learn_throughput": 337.763, "update_time_ms": 6.926}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 26403630581.106384, "policy_loss": 0.00254546878661247, "vf_loss": 26403630581.106384, "vf_explained_var": 8.87728734966231e-09, "kl": 0.015497490882556489, "entropy": 2.798961974204855, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26436752797.957447, "policy_loss": -0.003625225672062407, "vf_loss": 26436752797.957447, "vf_explained_var": 7.609103391814642e-08, "kl": 0.007852592683852987, "entropy": 3.0304808971729686, "entropy_coeff": 0.0}}}, "num_steps_sampled": 162162, "num_agent_steps_sampled": 324324, "num_steps_trained": 162162, "num_agent_steps_trained": 324324}, "done": false, "episodes_total": 162, "training_iteration": 27, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-35-21", "timestamp": 1624973721, "time_this_iter_s": 22.26041007041931, "time_total_s": 578.7796256542206, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 578.7796256542206, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 19.593333333333327, "ram_util_percent": 44.0, "gpu_util_percent0": 0.22133333333333333, "vram_util_percent0": 0.22795753286147627}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1752336.7663615108, "pol1": 1752336.7663615108}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1639017.4186739, -1712735.6610681529, -1729953.2400161007, -1897199.1500531915, -1827987.2559829615, -1402216.1721125322, -1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406], "policy_pol1_reward": [1639017.4186739, 1712735.6610681529, 1729953.2400161007, 1897199.1500531915, 1827987.2559829615, 1402216.1721125322, 1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2192891816387754, "mean_inference_ms": 3.0493030269123444, "mean_action_processing_ms": 0.15283535100649612, "mean_env_wait_ms": 0.12316650031559667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 168168, "agent_timesteps_total": 336336, "timers": {"sample_time_ms": 3664.739, "sample_throughput": 1638.862, "learn_time_ms": 17697.775, "learn_throughput": 339.365, "update_time_ms": 6.971}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 23845999376.340427, "policy_loss": -0.0007805015812528894, "vf_loss": 23845999376.340427, "vf_explained_var": -1.775457469932462e-08, "kl": 0.007352730903298931, "entropy": 2.820884537189565, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 23878800057.19149, "policy_loss": -0.00514049112717522, "vf_loss": 23878800057.19149, "vf_explained_var": 0.0, "kl": 0.00923285430217994, "entropy": 2.7343965844905123, "entropy_coeff": 0.0}}}, "num_steps_sampled": 168168, "num_agent_steps_sampled": 336336, "num_steps_trained": 168168, "num_agent_steps_trained": 336336}, "done": false, "episodes_total": 168, "training_iteration": 28, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-35-42", "timestamp": 1624973742, "time_this_iter_s": 21.121077060699463, "time_total_s": 599.90070271492, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4b0c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f4b0bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 599.90070271492, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 19.496296296296297, "ram_util_percent": 44.0, "gpu_util_percent0": 0.2348148148148148, "vram_util_percent0": 0.22792694953126366}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1759757.1632903307, "pol1": 1759757.1632903307}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1785420.6464698007, -1732481.605277255, -1777060.959481369, -1915074.3219616725, -1692600.0163430988, -1512024.4656181843, -1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338], "policy_pol1_reward": [1785420.6464698007, 1732481.605277255, 1777060.959481369, 1915074.3219616725, 1692600.0163430988, 1512024.4656181843, 1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21927464303476646, "mean_inference_ms": 3.0482543931865926, "mean_action_processing_ms": 0.15279912453327169, "mean_env_wait_ms": 0.12313923017779657, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 174174, "agent_timesteps_total": 348348, "timers": {"sample_time_ms": 3651.229, "sample_throughput": 1644.926, "learn_time_ms": 17688.327, "learn_throughput": 339.546, "update_time_ms": 6.881}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 27988422089.531914, "policy_loss": -0.0033947270799507484, "vf_loss": 27988422089.531914, "vf_explained_var": 4.311825207992115e-08, "kl": 0.007816719049786, "entropy": 2.721202515541239, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 28037073201.02128, "policy_loss": -0.006635410235600269, "vf_loss": 28037073201.02128, "vf_explained_var": -7.609103569450326e-09, "kl": 0.013301069095255212, "entropy": 2.5341580675003375, "entropy_coeff": 0.0}}}, "num_steps_sampled": 174174, "num_agent_steps_sampled": 348348, "num_steps_trained": 174174, "num_agent_steps_trained": 348348}, "done": false, "episodes_total": 174, "training_iteration": 29, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-36-03", "timestamp": 1624973763, "time_this_iter_s": 21.109162092208862, "time_total_s": 621.0098648071289, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44ed90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44e378>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 621.0098648071289, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 19.11785714285715, "ram_util_percent": 44.0, "gpu_util_percent0": 0.2310714285714286, "vram_util_percent0": 0.2279238287832828}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1760792.736342013, "pol1": 1760792.736342013}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1844932.077733974, -1769793.5779740985, -1795210.6371650198, -1676685.9542838987, -1749672.5643427449, -1780132.1243330147, -1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144], "policy_pol1_reward": [1844932.077733974, 1769793.5779740985, 1795210.6371650198, 1676685.9542838987, 1749672.5643427449, 1780132.1243330147, 1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21928439452129914, "mean_inference_ms": 3.047410723070838, "mean_action_processing_ms": 0.15276956964149566, "mean_env_wait_ms": 0.12311725600596135, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 180180, "agent_timesteps_total": 360360, "timers": {"sample_time_ms": 3655.473, "sample_throughput": 1643.016, "learn_time_ms": 17694.383, "learn_throughput": 339.43, "update_time_ms": 6.841}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 5.000000000000002e-05, "total_loss": 25824854974.638298, "policy_loss": 0.01612817656565854, "vf_loss": 25824854974.638298, "vf_explained_var": 1.1794110577056927e-07, "kl": 0.028326865602680978, "entropy": 2.7481479847684818, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25865532524.93617, "policy_loss": -0.004779035483110458, "vf_loss": 25865532524.93617, "vf_explained_var": -1.0399108418823744e-07, "kl": 0.008190218814985549, "entropy": 2.767182806704907, "entropy_coeff": 0.0}}}, "num_steps_sampled": 180180, "num_agent_steps_sampled": 360360, "num_steps_trained": 180180, "num_agent_steps_trained": 360360}, "done": false, "episodes_total": 180, "training_iteration": 30, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-36-24", "timestamp": 1624973784, "time_this_iter_s": 21.258053302764893, "time_total_s": 642.2679181098938, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44e048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44e2f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 642.2679181098938, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 19.689285714285717, "ram_util_percent": 44.0, "gpu_util_percent0": 0.22642857142857142, "vram_util_percent0": 0.22795392171024126}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1759861.4724702996, "pol1": 1759861.4724702996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1790100.4969579817, -1832098.393607479, -1733905.464203438, -1768026.5195033858, -1662168.185123683, -1704915.1258360636, -1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875], "policy_pol1_reward": [1790100.4969579817, 1832098.393607479, 1733905.464203438, 1768026.5195033858, 1662168.185123683, 1704915.1258360636, 1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21929538696301612, "mean_inference_ms": 3.0465223449842425, "mean_action_processing_ms": 0.15273804925560167, "mean_env_wait_ms": 0.1230951573538435, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 186186, "agent_timesteps_total": 372372, "timers": {"sample_time_ms": 3657.119, "sample_throughput": 1642.276, "learn_time_ms": 17704.888, "learn_throughput": 339.228, "update_time_ms": 6.855}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 25899908422.80851, "policy_loss": -0.0010274346085621955, "vf_loss": 25899908422.80851, "vf_explained_var": -9.257743016632958e-08, "kl": 0.006983877248824277, "entropy": 2.76441275819819, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25939135335.48936, "policy_loss": -0.006312283191909181, "vf_loss": 25939135335.48936, "vf_explained_var": -6.340919789238342e-09, "kl": 0.010357670327450367, "entropy": 2.7789727322598723, "entropy_coeff": 0.0}}}, "num_steps_sampled": 186186, "num_agent_steps_sampled": 372372, "num_steps_trained": 186186, "num_agent_steps_trained": 372372}, "done": false, "episodes_total": 186, "training_iteration": 31, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-36-46", "timestamp": 1624973806, "time_this_iter_s": 21.20578670501709, "time_total_s": 663.4737048149109, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47abf8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f47aea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 663.4737048149109, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 19.22142857142857, "ram_util_percent": 44.0, "gpu_util_percent0": 0.23035714285714284, "vram_util_percent0": 0.22792984736867453}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1759113.159396642, "pol1": 1759113.159396642}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1680879.5422715165, -1749540.2597463927, -1829362.0991677027, -1803328.3265448553, -1794890.8389775797, -1690980.9645262465, -1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919], "policy_pol1_reward": [1680879.5422715165, 1749540.2597463927, 1829362.0991677027, 1803328.3265448553, 1794890.8389775797, 1690980.9645262465, 1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21931337547265373, "mean_inference_ms": 3.0456728594657063, "mean_action_processing_ms": 0.15270642737234222, "mean_env_wait_ms": 0.12307259518148869, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 192192, "agent_timesteps_total": 384384, "timers": {"sample_time_ms": 3674.415, "sample_throughput": 1634.546, "learn_time_ms": 17678.607, "learn_throughput": 339.733, "update_time_ms": 6.879}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0125000000000006, "cur_lr": 5.000000000000002e-05, "total_loss": 25261298143.31915, "policy_loss": -0.0018334582613959434, "vf_loss": 25261298143.31915, "vf_explained_var": 1.2681839223205316e-07, "kl": 0.0037667939459231307, "entropy": 2.765975891275609, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25295843676.595745, "policy_loss": -0.004472454573879851, "vf_loss": 25295843676.595745, "vf_explained_var": 7.989558525878238e-08, "kl": 0.009528846579029205, "entropy": 2.7236672563755766, "entropy_coeff": 0.0}}}, "num_steps_sampled": 192192, "num_agent_steps_sampled": 384384, "num_steps_trained": 192192, "num_agent_steps_trained": 384384}, "done": false, "episodes_total": 192, "training_iteration": 32, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-37-07", "timestamp": 1624973827, "time_this_iter_s": 21.476699352264404, "time_total_s": 684.9504041671753, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484378>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484e18>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 684.9504041671753, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 19.082142857142856, "ram_util_percent": 44.0, "gpu_util_percent0": 0.2292857142857143, "vram_util_percent0": 0.2279238287832828}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1760111.6956503799, "pol1": 1760111.6956503799}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1782016.746451641, -1675060.9416138486, -1707654.3922728866, -1715516.2615080082, -1746123.0798160094, -1761665.7567122274, -1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904], "policy_pol1_reward": [1782016.746451641, 1675060.9416138486, 1707654.3922728866, 1715516.2615080082, 1746123.0798160094, 1761665.7567122274, 1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2193034867354097, "mean_inference_ms": 3.0449690751214904, "mean_action_processing_ms": 0.1526825229866598, "mean_env_wait_ms": 0.12305573720979707, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 198198, "agent_timesteps_total": 396396, "timers": {"sample_time_ms": 3675.417, "sample_throughput": 1634.1, "learn_time_ms": 17656.071, "learn_throughput": 340.166, "update_time_ms": 6.904}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26486754412.93617, "policy_loss": -0.0002560472472551021, "vf_loss": 26486754412.93617, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.011364470533234007, "entropy": 2.762408307258119, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26529046179.404255, "policy_loss": -0.005141170497270341, "vf_loss": 26529046179.404255, "vf_explained_var": -2.5363679156953367e-08, "kl": 0.008929022488758919, "entropy": 2.573993652424914, "entropy_coeff": 0.0}}}, "num_steps_sampled": 198198, "num_agent_steps_sampled": 396396, "num_steps_trained": 198198, "num_agent_steps_trained": 396396}, "done": false, "episodes_total": 198, "training_iteration": 33, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-37-29", "timestamp": 1624973849, "time_this_iter_s": 21.335131645202637, "time_total_s": 706.2855358123779, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 706.2855358123779, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 19.553571428571434, "ram_util_percent": 44.0, "gpu_util_percent0": 0.2278571428571428, "vram_util_percent0": 0.22795392171024126}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1759169.3238732978, "pol1": 1759169.3238732978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1726085.8881863481, -1689346.9600851724, -1867622.2660782328, -1842412.2977265145, -1818020.5832586153, -1669536.7663143608, -1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818], "policy_pol1_reward": [1726085.8881863481, 1689346.9600851724, 1867622.2660782328, 1842412.2977265145, 1818020.5832586153, 1669536.7663143608, 1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21929420083387638, "mean_inference_ms": 3.0444917322057363, "mean_action_processing_ms": 0.1526683007098434, "mean_env_wait_ms": 0.12304594517729207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 204204, "agent_timesteps_total": 408408, "timers": {"sample_time_ms": 3685.532, "sample_throughput": 1629.616, "learn_time_ms": 17665.652, "learn_throughput": 339.982, "update_time_ms": 6.963}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24861008830.638298, "policy_loss": 0.002103911851473311, "vf_loss": 24861008830.638298, "vf_explained_var": -1.5091389116150822e-07, "kl": 0.01896962436272743, "entropy": 2.6876433200024543, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24900743037.276596, "policy_loss": -0.005651902843345987, "vf_loss": 24900743037.276596, "vf_explained_var": -1.2681839578476684e-08, "kl": 0.00868950380963531, "entropy": 2.505680784266046, "entropy_coeff": 0.0}}}, "num_steps_sampled": 204204, "num_agent_steps_sampled": 408408, "num_steps_trained": 204204, "num_agent_steps_trained": 408408}, "done": false, "episodes_total": 204, "training_iteration": 34, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-37-50", "timestamp": 1624973870, "time_this_iter_s": 21.49068307876587, "time_total_s": 727.7762188911438, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4b0c80>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44ebf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 727.7762188911438, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 19.22413793103448, "ram_util_percent": 44.0, "gpu_util_percent0": 0.23137931034482756, "vram_util_percent0": 0.22792673430726504}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1932548.7678041155, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1932548.7678041155}, "policy_reward_mean": {"pol0": -1751339.5156819238, "pol1": 1751339.5156819238}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1642275.3712394792, -1803128.071524716, -1811385.8503103293, -1589393.6243749016, -1840805.853530789, -1796654.8841223859, -1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983], "policy_pol1_reward": [1642275.3712394792, 1803128.071524716, 1811385.8503103293, 1589393.6243749016, 1840805.853530789, 1796654.8841223859, 1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21927810645217452, "mean_inference_ms": 3.0440065800186678, "mean_action_processing_ms": 0.1526502764846712, "mean_env_wait_ms": 0.1230355236177816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 210210, "agent_timesteps_total": 420420, "timers": {"sample_time_ms": 3675.917, "sample_throughput": 1633.878, "learn_time_ms": 17634.505, "learn_throughput": 340.582, "update_time_ms": 6.943}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 22579221090.042553, "policy_loss": 0.0060171090224955944, "vf_loss": 22579221090.042553, "vf_explained_var": 1.5598662628235616e-07, "kl": 0.010954858477603881, "entropy": 2.7290027547389903, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 22613452712.851063, "policy_loss": -0.006311102314515316, "vf_loss": 22613452712.851063, "vf_explained_var": 0.0, "kl": 0.010662332117716049, "entropy": 2.65387721264616, "entropy_coeff": 0.0}}}, "num_steps_sampled": 210210, "num_agent_steps_sampled": 420420, "num_steps_trained": 210210, "num_agent_steps_trained": 420420}, "done": false, "episodes_total": 210, "training_iteration": 35, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-38-11", "timestamp": 1624973891, "time_this_iter_s": 20.866676807403564, "time_total_s": 748.6428956985474, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44eb70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44eae8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 748.6428956985474, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 19.755555555555556, "ram_util_percent": 44.0, "gpu_util_percent0": 0.23111111111111104, "vram_util_percent0": 0.22792694953126366}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1752851.002663006, "pol1": 1752851.002663006}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1673150.9984849095, -1669031.7801357468, -1743623.415228851, -1752294.5050346788, -1825190.5317065069, -1901849.4371678573, -1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282], "policy_pol1_reward": [1673150.9984849095, 1669031.7801357468, 1743623.415228851, 1752294.5050346788, 1825190.5317065069, 1901849.4371678573, 1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2192749831963096, "mean_inference_ms": 3.043509975639976, "mean_action_processing_ms": 0.15263059142894117, "mean_env_wait_ms": 0.12302387216751809, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 216216, "agent_timesteps_total": 432432, "timers": {"sample_time_ms": 3683.232, "sample_throughput": 1630.633, "learn_time_ms": 17641.909, "learn_throughput": 340.439, "update_time_ms": 6.883}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26379765977.87234, "policy_loss": -0.00154930147084784, "vf_loss": 26379765977.87234, "vf_explained_var": 1.9022758479536606e-08, "kl": 0.006627311305876108, "entropy": 2.686763433699912, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26427825260.93617, "policy_loss": -0.003120342071386094, "vf_loss": 26427825260.93617, "vf_explained_var": 2.5363677824685738e-09, "kl": 0.008431107192201184, "entropy": 2.8498657459908343, "entropy_coeff": 0.0}}}, "num_steps_sampled": 216216, "num_agent_steps_sampled": 432432, "num_steps_trained": 216216, "num_agent_steps_trained": 432432}, "done": false, "episodes_total": 216, "training_iteration": 36, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-38-32", "timestamp": 1624973912, "time_this_iter_s": 21.296512365341187, "time_total_s": 769.9394080638885, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e443620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e443048>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 769.9394080638885, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 19.507142857142856, "ram_util_percent": 44.0, "gpu_util_percent0": 0.23357142857142854, "vram_util_percent0": 0.22795392171024126}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1748948.479469576, "pol1": 1748948.479469576}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1755296.0394302495, -1672815.554837298, -1831223.990106472, -1707083.118535702, -1814669.2294882375, -1765080.4155494978, -1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495], "policy_pol1_reward": [1755296.0394302495, 1672815.554837298, 1831223.990106472, 1707083.118535702, 1814669.2294882375, 1765080.4155494978, 1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21928972789113998, "mean_inference_ms": 3.043226203570841, "mean_action_processing_ms": 0.1526193272867311, "mean_env_wait_ms": 0.12301805119992058, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 222222, "agent_timesteps_total": 444444, "timers": {"sample_time_ms": 3714.078, "sample_throughput": 1617.09, "learn_time_ms": 17647.897, "learn_throughput": 340.324, "update_time_ms": 7.076}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24009379927.148937, "policy_loss": -0.004870355961487648, "vf_loss": 24009379927.148937, "vf_explained_var": 1.5852299384278012e-07, "kl": 0.009649752322188083, "entropy": 2.7398897992803697, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24047588722.38298, "policy_loss": -0.004137318026512227, "vf_loss": 24047588722.38298, "vf_explained_var": 3.804551784725163e-09, "kl": 0.009873863616760107, "entropy": 3.115356977949751, "entropy_coeff": 0.0}}}, "num_steps_sampled": 222222, "num_agent_steps_sampled": 444444, "num_steps_trained": 222222, "num_agent_steps_trained": 444444}, "done": false, "episodes_total": 222, "training_iteration": 37, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-38-55", "timestamp": 1624973935, "time_this_iter_s": 22.631213188171387, "time_total_s": 792.5706212520599, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e443b70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e443f28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 792.5706212520599, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 19.220000000000002, "ram_util_percent": 44.013333333333335, "gpu_util_percent0": 0.219, "vram_util_percent0": 0.22792382878328285}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1752994.0646852432, "pol1": 1752994.0646852432}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1659363.3373747305, -1859428.4301007777, -1687542.5504208896, -1663398.3655241008, -1484981.5523532107, -1869366.609109038, -1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074], "policy_pol1_reward": [1659363.3373747305, 1859428.4301007777, 1687542.5504208896, 1663398.3655241008, 1484981.5523532107, 1869366.609109038, 1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2193819487937307, "mean_inference_ms": 3.0443534344824186, "mean_action_processing_ms": 0.15267447810251406, "mean_env_wait_ms": 0.12306317468446626, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 228228, "agent_timesteps_total": 456456, "timers": {"sample_time_ms": 3811.117, "sample_throughput": 1575.916, "learn_time_ms": 18675.066, "learn_throughput": 321.605, "update_time_ms": 7.044}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 28049243201.361702, "policy_loss": 0.007573695694829555, "vf_loss": 28049243201.361702, "vf_explained_var": 9.638198150696553e-08, "kl": 0.023275019799141174, "entropy": 2.73353984000835, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 28100588696.51064, "policy_loss": -0.005031524543115434, "vf_loss": 28100588696.51064, "vf_explained_var": 1.3950023358688668e-08, "kl": 0.011763891641129839, "entropy": 3.016690299866047, "entropy_coeff": 0.0}}}, "num_steps_sampled": 228228, "num_agent_steps_sampled": 456456, "num_steps_trained": 228228, "num_agent_steps_trained": 456456}, "done": false, "episodes_total": 228, "training_iteration": 38, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-39-27", "timestamp": 1624973967, "time_this_iter_s": 32.362443923950195, "time_total_s": 824.9330651760101, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44eb70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44eea0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 824.9330651760101, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 30.70714285714286, "ram_util_percent": 48.81666666666667, "gpu_util_percent0": 0.34261904761904766, "vram_util_percent0": 0.23651836872261547}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1757391.8439832216, "pol1": 1757391.8439832216}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1855189.6032430076, -1717174.1759522238, -1747088.8087955727, -1781014.1512187996, -1779767.0749542715, -1920755.048889221, -1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903], "policy_pol1_reward": [1855189.6032430076, 1717174.1759522238, 1747088.8087955727, 1781014.1512187996, 1779767.0749542715, 1920755.048889221, 1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21950434971826088, "mean_inference_ms": 3.046119324753315, "mean_action_processing_ms": 0.1527643788754086, "mean_env_wait_ms": 0.12312858349692947, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 234234, "agent_timesteps_total": 468468, "timers": {"sample_time_ms": 3862.752, "sample_throughput": 1554.85, "learn_time_ms": 18760.113, "learn_throughput": 320.147, "update_time_ms": 7.051}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 26703641273.19149, "policy_loss": -0.003364484836446478, "vf_loss": 26703641273.19149, "vf_explained_var": -1.2681838912342869e-09, "kl": 0.00799924660315539, "entropy": 2.6653019925381276, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26760203808.68085, "policy_loss": -0.005675312488320026, "vf_loss": 26760203808.68085, "vf_explained_var": 2.7900046717377336e-08, "kl": 0.01095497560627917, "entropy": 3.0931602082353957, "entropy_coeff": 0.0}}}, "num_steps_sampled": 234234, "num_agent_steps_sampled": 468468, "num_steps_trained": 234234, "num_agent_steps_trained": 468468}, "done": false, "episodes_total": 234, "training_iteration": 39, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-39-50", "timestamp": 1624973990, "time_this_iter_s": 22.475034713745117, "time_total_s": 847.4080998897552, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47ab70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f47ad90>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 847.4080998897552, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 23.506896551724136, "ram_util_percent": 52.47931034482759, "gpu_util_percent0": 0.24896551724137936, "vram_util_percent0": 0.23658519577420595}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1758130.963606535, "pol1": 1758130.963606535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1876528.5162856532, -1844051.4461307398, -1325481.5317233107, -1885745.5990117767, -1755750.2623626345, -1823664.0509607797, -1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022], "policy_pol1_reward": [1876528.5162856532, 1844051.4461307398, 1325481.5317233107, 1885745.5990117767, 1755750.2623626345, 1823664.0509607797, 1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2196764392285914, "mean_inference_ms": 3.0483824725295756, "mean_action_processing_ms": 0.1528812016343953, "mean_env_wait_ms": 0.12321238698603564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 240240, "agent_timesteps_total": 480480, "timers": {"sample_time_ms": 3919.403, "sample_throughput": 1532.376, "learn_time_ms": 18800.653, "learn_throughput": 319.457, "update_time_ms": 6.898}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 27737694120.851063, "policy_loss": 0.0011296712575440712, "vf_loss": 27737694120.851063, "vf_explained_var": 1.6486390919112637e-08, "kl": 0.016593943865216794, "entropy": 2.7471420967832523, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 27797788105.531914, "policy_loss": -0.003047981160752317, "vf_loss": 27797788105.531914, "vf_explained_var": -1.1667292199035728e-07, "kl": 0.011542251492117314, "entropy": 3.0440133277406085, "entropy_coeff": 0.0}}}, "num_steps_sampled": 240240, "num_agent_steps_sampled": 480480, "num_steps_trained": 240240, "num_agent_steps_trained": 480480}, "done": false, "episodes_total": 240, "training_iteration": 40, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-40-12", "timestamp": 1624974012, "time_this_iter_s": 22.22600817680359, "time_total_s": 869.6341080665588, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f484620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484158>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 869.6341080665588, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 23.93793103448276, "ram_util_percent": 52.05862068965518, "gpu_util_percent0": 0.23448275862068968, "vram_util_percent0": 0.23630626547191516}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1752970.69385952, "pol1": 1752970.69385952}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1926308.5385843017, -1695043.6101582483, -1773117.1291564992, -1863590.6803150875, -1734570.2935635676, -1814394.4931513069, -1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404], "policy_pol1_reward": [1926308.5385843017, 1695043.6101582483, 1773117.1291564992, 1863590.6803150875, 1734570.2935635676, 1814394.4931513069, 1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21982626465606145, "mean_inference_ms": 3.050565975796559, "mean_action_processing_ms": 0.15299465597909742, "mean_env_wait_ms": 0.12328835519053248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 246246, "agent_timesteps_total": 492492, "timers": {"sample_time_ms": 3918.638, "sample_throughput": 1532.675, "learn_time_ms": 18930.886, "learn_throughput": 317.259, "update_time_ms": 6.758}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.7593749999999999, "cur_lr": 5.000000000000002e-05, "total_loss": 23288483404.255318, "policy_loss": 0.0038212899990538334, "vf_loss": 23288483404.255318, "vf_explained_var": -1.5218207138900652e-08, "kl": 0.023259353209683236, "entropy": 2.757980980771653, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 23331435106.042553, "policy_loss": -0.00476567389720932, "vf_loss": 23331435106.042553, "vf_explained_var": 1.1413655798264699e-08, "kl": 0.012464678767038153, "entropy": 2.990234471381979, "entropy_coeff": 0.0}}}, "num_steps_sampled": 246246, "num_agent_steps_sampled": 492492, "num_steps_trained": 246246, "num_agent_steps_trained": 492492}, "done": false, "episodes_total": 246, "training_iteration": 41, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-40-35", "timestamp": 1624974035, "time_this_iter_s": 22.499842405319214, "time_total_s": 892.133950471878, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e44ed90>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44e510>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 892.133950471878, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 25.42666666666667, "ram_util_percent": 53.51666666666667, "gpu_util_percent0": 0.24200000000000002, "vram_util_percent0": 0.23842826648691157}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1746976.6882999432, "pol1": 1746976.6882999432}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1786366.1605789533, -1819055.4763230926, -1900909.2509365084, -1833569.263759411, -1708192.2383590105, -1652597.7872947124, -1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301], "policy_pol1_reward": [1786366.1605789533, 1819055.4763230926, 1900909.2509365084, 1833569.263759411, 1708192.2383590105, 1652597.7872947124, 1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2199874509202175, "mean_inference_ms": 3.052879993798326, "mean_action_processing_ms": 0.15311617291591714, "mean_env_wait_ms": 0.12336645409789884, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 252252, "agent_timesteps_total": 504504, "timers": {"sample_time_ms": 3912.819, "sample_throughput": 1534.955, "learn_time_ms": 19663.444, "learn_throughput": 305.44, "update_time_ms": 6.58}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24635941256.17021, "policy_loss": 0.0013467687122682309, "vf_loss": 24635941256.17021, "vf_explained_var": -2.7900046717377336e-08, "kl": 0.01667779995168143, "entropy": 2.7608239701453674, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24681763382.468086, "policy_loss": -0.005013031176628268, "vf_loss": 24681763382.468086, "vf_explained_var": -5.580009343475467e-08, "kl": 0.012397113612833176, "entropy": 3.145170937193201, "entropy_coeff": 0.0}}}, "num_steps_sampled": 252252, "num_agent_steps_sampled": 504504, "num_steps_trained": 252252, "num_agent_steps_trained": 504504}, "done": false, "episodes_total": 252, "training_iteration": 42, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-41-04", "timestamp": 1624974064, "time_this_iter_s": 28.74068832397461, "time_total_s": 920.8746387958527, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f47ae18>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e44ef28>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 920.8746387958527, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 34.98157894736842, "ram_util_percent": 58.392105263157895, "gpu_util_percent0": 0.4102631578947369, "vram_util_percent0": 0.2833803416529189}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1745250.8023075492, "pol1": 1745250.8023075492}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1753701.65772042, -1743263.1419531743, -1932548.7678041155, -1822165.7636597117, -1549338.028598047, -1890999.1819588027, -1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186], "policy_pol1_reward": [1753701.65772042, 1743263.1419531743, 1932548.7678041155, 1822165.7636597117, 1549338.028598047, 1890999.1819588027, 1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202290215106199, "mean_inference_ms": 3.056669376331066, "mean_action_processing_ms": 0.1533118230015773, "mean_env_wait_ms": 0.1234934840682942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 258258, "agent_timesteps_total": 516516, "timers": {"sample_time_ms": 4018.583, "sample_throughput": 1494.557, "learn_time_ms": 22656.858, "learn_throughput": 265.085, "update_time_ms": 6.497}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 25879152465.70213, "policy_loss": 0.003075193574136876, "vf_loss": 25879152465.70213, "vf_explained_var": 3.804551784725163e-09, "kl": 0.018452220834157568, "entropy": 2.8506634032472653, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 25929385853.276596, "policy_loss": -0.005373030821693704, "vf_loss": 25929385853.276596, "vf_explained_var": -1.204774804364206e-07, "kl": 0.012837334773800474, "entropy": 3.1546805818030177, "entropy_coeff": 0.0}}}, "num_steps_sampled": 258258, "num_agent_steps_sampled": 516516, "num_steps_trained": 258258, "num_agent_steps_trained": 516516}, "done": false, "episodes_total": 258, "training_iteration": 43, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-41-56", "timestamp": 1624974116, "time_this_iter_s": 52.324281215667725, "time_total_s": 973.1989200115204, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e443620>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e443a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 973.1989200115204, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 41.35294117647058, "ram_util_percent": 61.69705882352942, "gpu_util_percent0": 0.8447058823529412, "vram_util_percent0": 0.3195072265508833}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1313962.452914874}, "policy_reward_max": {"pol0": -1313962.452914874, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1744401.4375096539, "pol1": 1744401.4375096539}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1693030.8200446183, -1313962.452914874, -1912027.1711726808, -1702224.9375434406, -1889549.981121038, -1766658.503805176, -1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186, -1747073.944364254, -1639777.4786949689, -1706829.3034688458, -1906531.0452840542, -1849440.0441057198, -1757428.2459868947], "policy_pol1_reward": [1693030.8200446183, 1313962.452914874, 1912027.1711726808, 1702224.9375434406, 1889549.981121038, 1766658.503805176, 1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186, 1747073.944364254, 1639777.4786949689, 1706829.3034688458, 1906531.0452840542, 1849440.0441057198, 1757428.2459868947]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2205076249155195, "mean_inference_ms": 3.0610197512246593, "mean_action_processing_ms": 0.15353614142340669, "mean_env_wait_ms": 0.12363609675736678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 264264, "agent_timesteps_total": 528528, "timers": {"sample_time_ms": 4048.58, "sample_throughput": 1483.483, "learn_time_ms": 23175.003, "learn_throughput": 259.159, "update_time_ms": 6.364}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26309741328.340427, "policy_loss": 0.0061820345197586305, "vf_loss": 26309741328.340427, "vf_explained_var": 1.0018653284760148e-07, "kl": 0.01830110916907483, "entropy": 2.8301769723283483, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26362644872.17021, "policy_loss": -0.004455252411834737, "vf_loss": 26362644872.17021, "vf_explained_var": -1.6486390919112637e-08, "kl": 0.016519919275603395, "entropy": 2.881570633421553, "entropy_coeff": 0.0}}}, "num_steps_sampled": 264264, "num_agent_steps_sampled": 528528, "num_steps_trained": 264264, "num_agent_steps_trained": 528528}, "done": false, "episodes_total": 264, "training_iteration": 44, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-42-23", "timestamp": 1624974143, "time_this_iter_s": 26.969217777252197, "time_total_s": 1000.1681377887726, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29f4841e0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29f484a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1000.1681377887726, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 31.399999999999995, "ram_util_percent": 62.580555555555556, "gpu_util_percent0": 0.39, "vram_util_percent0": 0.3203806688387072}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1319896.9675137196}, "policy_reward_max": {"pol0": -1319896.9675137196, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1739892.3747667063, "pol1": 1739892.3747667063}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1793108.6207823157, -1858820.8830882171, -1880098.8275832154, -1762911.7744088338, -1739286.4671400199, -1806473.824973672, -1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186, -1747073.944364254, -1639777.4786949689, -1706829.3034688458, -1906531.0452840542, -1849440.0441057198, -1757428.2459868947, -1757610.3068762796, -1430358.7590642031, -1630109.896551072, -1652432.7585349383, -1723507.2411395542, -1632528.6301410072], "policy_pol1_reward": [1793108.6207823157, 1858820.8830882171, 1880098.8275832154, 1762911.7744088338, 1739286.4671400199, 1806473.824973672, 1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186, 1747073.944364254, 1639777.4786949689, 1706829.3034688458, 1906531.0452840542, 1849440.0441057198, 1757428.2459868947, 1757610.3068762796, 1430358.7590642031, 1630109.896551072, 1652432.7585349383, 1723507.2411395542, 1632528.6301410072]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2208041139374086, "mean_inference_ms": 3.0656743789306096, "mean_action_processing_ms": 0.15377646525086933, "mean_env_wait_ms": 0.1237867989255164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 270270, "agent_timesteps_total": 540540, "timers": {"sample_time_ms": 4084.405, "sample_throughput": 1470.471, "learn_time_ms": 23697.598, "learn_throughput": 253.443, "update_time_ms": 6.202}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 22519376133.446808, "policy_loss": 0.001498282252949603, "vf_loss": 22519376133.446808, "vf_explained_var": 1.5471843539671681e-07, "kl": 0.008019223036442666, "entropy": 2.8735281761656415, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 22559863132.595745, "policy_loss": -0.004075004639936254, "vf_loss": 22559863132.595745, "vf_explained_var": 2.663186293716535e-08, "kl": 0.016399280346454458, "entropy": 2.5585699182875614, "entropy_coeff": 0.0}}}, "num_steps_sampled": 270270, "num_agent_steps_sampled": 540540, "num_steps_trained": 270270, "num_agent_steps_trained": 540540}, "done": false, "episodes_total": 270, "training_iteration": 45, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-42-50", "timestamp": 1624974170, "time_this_iter_s": 26.44831681251526, "time_total_s": 1026.6164546012878, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e4437b8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e443840>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1026.6164546012878, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 30.602857142857147, "ram_util_percent": 62.47714285714285, "gpu_util_percent0": 0.36714285714285716, "vram_util_percent0": 0.3202994848090905}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1319896.9675137196}, "policy_reward_max": {"pol0": -1319896.9675137196, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1737304.0649623342, "pol1": 1737304.0649623342}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1809253.0326104271, -1607017.1153230346, -1850368.4639569786, -1705820.4163155144, -1816637.8754496393, -1610373.9358205067, -1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186, -1747073.944364254, -1639777.4786949689, -1706829.3034688458, -1906531.0452840542, -1849440.0441057198, -1757428.2459868947, -1757610.3068762796, -1430358.7590642031, -1630109.896551072, -1652432.7585349383, -1723507.2411395542, -1632528.6301410072, -1836302.5564759746, -1627906.5477692087, -1846374.016394402, -1684592.5042700756, -1884884.6490028051, -1701809.1436266352], "policy_pol1_reward": [1809253.0326104271, 1607017.1153230346, 1850368.4639569786, 1705820.4163155144, 1816637.8754496393, 1610373.9358205067, 1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186, 1747073.944364254, 1639777.4786949689, 1706829.3034688458, 1906531.0452840542, 1849440.0441057198, 1757428.2459868947, 1757610.3068762796, 1430358.7590642031, 1630109.896551072, 1652432.7585349383, 1723507.2411395542, 1632528.6301410072, 1836302.5564759746, 1627906.5477692087, 1846374.016394402, 1684592.5042700756, 1884884.6490028051, 1701809.1436266352]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2211342566774089, "mean_inference_ms": 3.0711329684540596, "mean_action_processing_ms": 0.15405560559102452, "mean_env_wait_ms": 0.1239608959927417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 276276, "agent_timesteps_total": 552552, "timers": {"sample_time_ms": 4149.358, "sample_throughput": 1447.453, "learn_time_ms": 24205.204, "learn_throughput": 248.128, "update_time_ms": 6.29}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26214822672.340427, "policy_loss": -0.00020071230036147096, "vf_loss": 26214822672.340427, "vf_explained_var": 1.4964570027586888e-07, "kl": 0.006279204664950041, "entropy": 2.804173692743829, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26271651142.80851, "policy_loss": -0.0013110128013377495, "vf_loss": 26271651142.80851, "vf_explained_var": 4.1850068299709164e-08, "kl": 0.008926826182435801, "entropy": 2.422923656220132, "entropy_coeff": 0.0}}}, "num_steps_sampled": 276276, "num_agent_steps_sampled": 552552, "num_steps_trained": 276276, "num_agent_steps_trained": 552552}, "done": false, "episodes_total": 276, "training_iteration": 46, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-43-17", "timestamp": 1624974197, "time_this_iter_s": 27.023160934448242, "time_total_s": 1053.639615535736, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e443f28>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e443bf8>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1053.639615535736, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 31.991428571428568, "ram_util_percent": 62.51142857142856, "gpu_util_percent0": 0.4065714285714286, "vram_util_percent0": 0.30711637536713365}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1319896.9675137196}, "policy_reward_max": {"pol0": -1319896.9675137196, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1736646.2121836962, "pol1": 1736646.2121836962}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1903592.3125123403, -1764757.842151, -1768778.221843504, -1659160.3608843875, -1624865.5487211663, -1723276.3330687333, -1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186, -1747073.944364254, -1639777.4786949689, -1706829.3034688458, -1906531.0452840542, -1849440.0441057198, -1757428.2459868947, -1757610.3068762796, -1430358.7590642031, -1630109.896551072, -1652432.7585349383, -1723507.2411395542, -1632528.6301410072, -1836302.5564759746, -1627906.5477692087, -1846374.016394402, -1684592.5042700756, -1884884.6490028051, -1701809.1436266352, -1726005.0161018653, -1787085.828795328, -1718277.2658209845, -1546241.2084106058, -1775467.534171352, -1780608.7083121776], "policy_pol1_reward": [1903592.3125123403, 1764757.842151, 1768778.221843504, 1659160.3608843875, 1624865.5487211663, 1723276.3330687333, 1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186, 1747073.944364254, 1639777.4786949689, 1706829.3034688458, 1906531.0452840542, 1849440.0441057198, 1757428.2459868947, 1757610.3068762796, 1430358.7590642031, 1630109.896551072, 1652432.7585349383, 1723507.2411395542, 1632528.6301410072, 1836302.5564759746, 1627906.5477692087, 1846374.016394402, 1684592.5042700756, 1884884.6490028051, 1701809.1436266352, 1726005.0161018653, 1787085.828795328, 1718277.2658209845, 1546241.2084106058, 1775467.534171352, 1780608.7083121776]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22145064202951897, "mean_inference_ms": 3.0765855535381763, "mean_action_processing_ms": 0.15433756343572302, "mean_env_wait_ms": 0.12413510989591427, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 282282, "agent_timesteps_total": 564564, "timers": {"sample_time_ms": 4160.219, "sample_throughput": 1443.674, "learn_time_ms": 24576.292, "learn_throughput": 244.382, "update_time_ms": 5.961}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 24779545491.06383, "policy_loss": 0.000348123107501801, "vf_loss": 24779545491.06383, "vf_explained_var": 8.877287172026627e-08, "kl": 0.008594895088847013, "entropy": 2.7321044789983873, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 24824615478.468086, "policy_loss": -0.0031107527184042524, "vf_loss": 24824615478.468086, "vf_explained_var": 6.97501150170865e-08, "kl": 0.008110521004555072, "entropy": 2.336687113376374, "entropy_coeff": 0.0}}}, "num_steps_sampled": 282282, "num_agent_steps_sampled": 564564, "num_steps_trained": 282282, "num_agent_steps_trained": 564564}, "done": false, "episodes_total": 282, "training_iteration": 47, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-43-43", "timestamp": 1624974223, "time_this_iter_s": 26.446516752243042, "time_total_s": 1080.0861322879791, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e3fb9d8>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e3fb400>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1080.0861322879791, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 32.36, "ram_util_percent": 62.67142857142857, "gpu_util_percent0": 0.3277142857142857, "vram_util_percent0": 0.28127497712937544}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1319896.9675137196}, "policy_reward_max": {"pol0": -1319896.9675137196, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1739460.4629814206, "pol1": 1739460.4629814206}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1725070.54353111, -1857751.748419718, -1704284.0523666106, -1781134.651758919, -1785911.3628526593, -1807796.7260149496, -1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186, -1747073.944364254, -1639777.4786949689, -1706829.3034688458, -1906531.0452840542, -1849440.0441057198, -1757428.2459868947, -1757610.3068762796, -1430358.7590642031, -1630109.896551072, -1652432.7585349383, -1723507.2411395542, -1632528.6301410072, -1836302.5564759746, -1627906.5477692087, -1846374.016394402, -1684592.5042700756, -1884884.6490028051, -1701809.1436266352, -1726005.0161018653, -1787085.828795328, -1718277.2658209845, -1546241.2084106058, -1775467.534171352, -1780608.7083121776, -1890326.0394053909, -1888364.1018286294, -1766993.2794768326, -1683307.604441011, -1669895.5689851863, -1826969.1048164887], "policy_pol1_reward": [1725070.54353111, 1857751.748419718, 1704284.0523666106, 1781134.651758919, 1785911.3628526593, 1807796.7260149496, 1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186, 1747073.944364254, 1639777.4786949689, 1706829.3034688458, 1906531.0452840542, 1849440.0441057198, 1757428.2459868947, 1757610.3068762796, 1430358.7590642031, 1630109.896551072, 1652432.7585349383, 1723507.2411395542, 1632528.6301410072, 1836302.5564759746, 1627906.5477692087, 1846374.016394402, 1684592.5042700756, 1884884.6490028051, 1701809.1436266352, 1726005.0161018653, 1787085.828795328, 1718277.2658209845, 1546241.2084106058, 1775467.534171352, 1780608.7083121776, 1890326.0394053909, 1888364.1018286294, 1766993.2794768326, 1683307.604441011, 1669895.5689851863, 1826969.1048164887]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2217949331209849, "mean_inference_ms": 3.0825482162374835, "mean_action_processing_ms": 0.15464477384059605, "mean_env_wait_ms": 0.12432029930735446, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 288288, "agent_timesteps_total": 576576, "timers": {"sample_time_ms": 4112.813, "sample_throughput": 1460.315, "learn_time_ms": 23907.88, "learn_throughput": 251.214, "update_time_ms": 5.875}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26867794530.042553, "policy_loss": -0.003190777217473914, "vf_loss": 26867794530.042553, "vf_explained_var": -1.6232753807798872e-07, "kl": 0.010834422636222332, "entropy": 2.7059940784535508, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26928110918.80851, "policy_loss": -0.0021463373398527188, "vf_loss": 26928110918.80851, "vf_explained_var": -2.5363677824685738e-09, "kl": 0.010605845957043324, "entropy": 2.0149394299121615, "entropy_coeff": 0.0}}}, "num_steps_sampled": 288288, "num_agent_steps_sampled": 576576, "num_steps_trained": 288288, "num_agent_steps_trained": 576576}, "done": false, "episodes_total": 288, "training_iteration": 48, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-44-09", "timestamp": 1624974249, "time_this_iter_s": 25.20184063911438, "time_total_s": 1105.2879729270935, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e3fb268>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e3fb1e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1105.2879729270935, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 30.484848484848488, "ram_util_percent": 63.91212121212121, "gpu_util_percent0": 0.3136363636363636, "vram_util_percent0": 0.28875713658322355}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1319896.9675137196}, "policy_reward_max": {"pol0": -1319896.9675137196, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1738723.8314104977, "pol1": 1738723.8314104977}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1636208.3348472286, -1791067.6355313475, -1844292.7013950434, -1783558.895966904, -1690401.4873453903, -1854985.734173724, -1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186, -1747073.944364254, -1639777.4786949689, -1706829.3034688458, -1906531.0452840542, -1849440.0441057198, -1757428.2459868947, -1757610.3068762796, -1430358.7590642031, -1630109.896551072, -1652432.7585349383, -1723507.2411395542, -1632528.6301410072, -1836302.5564759746, -1627906.5477692087, -1846374.016394402, -1684592.5042700756, -1884884.6490028051, -1701809.1436266352, -1726005.0161018653, -1787085.828795328, -1718277.2658209845, -1546241.2084106058, -1775467.534171352, -1780608.7083121776, -1890326.0394053909, -1888364.1018286294, -1766993.2794768326, -1683307.604441011, -1669895.5689851863, -1826969.1048164887, -1924722.6168472716, -1903360.857002695, -1441966.1709164984, -1810170.1743647794, -1751783.3614665926, -1756282.747253863], "policy_pol1_reward": [1636208.3348472286, 1791067.6355313475, 1844292.7013950434, 1783558.895966904, 1690401.4873453903, 1854985.734173724, 1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186, 1747073.944364254, 1639777.4786949689, 1706829.3034688458, 1906531.0452840542, 1849440.0441057198, 1757428.2459868947, 1757610.3068762796, 1430358.7590642031, 1630109.896551072, 1652432.7585349383, 1723507.2411395542, 1632528.6301410072, 1836302.5564759746, 1627906.5477692087, 1846374.016394402, 1684592.5042700756, 1884884.6490028051, 1701809.1436266352, 1726005.0161018653, 1787085.828795328, 1718277.2658209845, 1546241.2084106058, 1775467.534171352, 1780608.7083121776, 1890326.0394053909, 1888364.1018286294, 1766993.2794768326, 1683307.604441011, 1669895.5689851863, 1826969.1048164887, 1924722.6168472716, 1903360.857002695, 1441966.1709164984, 1810170.1743647794, 1751783.3614665926, 1756282.747253863]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2221482802715338, "mean_inference_ms": 3.0888077617361693, "mean_action_processing_ms": 0.15497006926277906, "mean_env_wait_ms": 0.12451422707638173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 294294, "agent_timesteps_total": 588588, "timers": {"sample_time_ms": 4107.991, "sample_throughput": 1462.029, "learn_time_ms": 23927.34, "learn_throughput": 251.01, "update_time_ms": 5.811}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1390625000000003, "cur_lr": 5.000000000000002e-05, "total_loss": 26469643547.234043, "policy_loss": -0.001147125708930036, "vf_loss": 26469643547.234043, "vf_explained_var": -3.804551784725163e-09, "kl": 0.0031811556422171442, "entropy": 2.692203851456338, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 26536035872.68085, "policy_loss": -0.0035041990551225683, "vf_loss": 26536035872.68085, "vf_explained_var": 3.804551784725163e-09, "kl": 0.01059550403597507, "entropy": 1.9887551677987931, "entropy_coeff": 0.0}}}, "num_steps_sampled": 294294, "num_agent_steps_sampled": 588588, "num_steps_trained": 294294, "num_agent_steps_trained": 588588}, "done": false, "episodes_total": 294, "training_iteration": 49, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-44-31", "timestamp": 1624974271, "time_this_iter_s": 22.622098922729492, "time_total_s": 1127.910071849823, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e3fb840>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e3fb730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1127.910071849823, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 28.69, "ram_util_percent": 64.31000000000002, "gpu_util_percent0": 0.27466666666666667, "vram_util_percent0": 0.28874283788338395}, "trial_id": "6ed5a_00000"}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 1001.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"pol0": -1947809.931517951, "pol1": 1319896.9675137196}, "policy_reward_max": {"pol0": -1319896.9675137196, "pol1": 1947809.931517951}, "policy_reward_mean": {"pol0": -1732825.3013950111, "pol1": 1732825.3013950111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "policy_pol0_reward": [-1612897.237088195, -1565161.7568216417, -1786300.3884743003, -1784053.3967631818, -1681810.3318682762, -1648643.4354375259, -1838489.417795678, -1319896.9675137196, -1711190.8788866282, -1630012.9110099983, -1723449.8836482316, -1947809.931517951, -1866106.0867889307, -1794540.0266248598, -1661687.835737811, -1641198.5888930282, -1707147.9005690739, -1704891.6391061721, -1492038.116606197, -1781543.3139392904, -1715221.4984502115, -1774045.8797445495, -1828139.6694689253, -1879376.2637624464, -1821766.192128552, -1784609.2967747075, -1690282.5361523984, -1946552.9112272074, -1729908.0749471914, -1742530.7575183485, -1835587.3747448365, -1895640.5446060942, -1714535.243855631, -1745656.7790084903, -1798512.156963975, -1609852.8648966828, -1919825.0173508066, -1888609.982067263, -1853720.3930440883, -1804380.4110616022, -1873651.6953397493, -1757728.5748005167, -1676783.9917037333, -1489031.5805332228, -1679002.4251865577, -1518996.1642096404, -1753825.711774449, -1887178.574147601, -1665905.5588050496, -1580675.6656624163, -1465980.5623302704, -1854058.1162515301, -1657311.8515925168, -1794811.2709337953, -1760270.253999665, -1674187.3983066056, -1788481.029815863, -1853039.7733638186, -1747073.944364254, -1639777.4786949689, -1706829.3034688458, -1906531.0452840542, -1849440.0441057198, -1757428.2459868947, -1757610.3068762796, -1430358.7590642031, -1630109.896551072, -1652432.7585349383, -1723507.2411395542, -1632528.6301410072, -1836302.5564759746, -1627906.5477692087, -1846374.016394402, -1684592.5042700756, -1884884.6490028051, -1701809.1436266352, -1726005.0161018653, -1787085.828795328, -1718277.2658209845, -1546241.2084106058, -1775467.534171352, -1780608.7083121776, -1890326.0394053909, -1888364.1018286294, -1766993.2794768326, -1683307.604441011, -1669895.5689851863, -1826969.1048164887, -1924722.6168472716, -1903360.857002695, -1441966.1709164984, -1810170.1743647794, -1751783.3614665926, -1756282.747253863, -1725226.859419856, -1590434.2908184095, -1730913.3544833995, -1605509.7710888973, -1855997.095561399, -1502580.4163390321], "policy_pol1_reward": [1612897.237088195, 1565161.7568216417, 1786300.3884743003, 1784053.3967631818, 1681810.3318682762, 1648643.4354375259, 1838489.417795678, 1319896.9675137196, 1711190.8788866282, 1630012.9110099983, 1723449.8836482316, 1947809.931517951, 1866106.0867889307, 1794540.0266248598, 1661687.835737811, 1641198.5888930282, 1707147.9005690739, 1704891.6391061721, 1492038.116606197, 1781543.3139392904, 1715221.4984502115, 1774045.8797445495, 1828139.6694689253, 1879376.2637624464, 1821766.192128552, 1784609.2967747075, 1690282.5361523984, 1946552.9112272074, 1729908.0749471914, 1742530.7575183485, 1835587.3747448365, 1895640.5446060942, 1714535.243855631, 1745656.7790084903, 1798512.156963975, 1609852.8648966828, 1919825.0173508066, 1888609.982067263, 1853720.3930440883, 1804380.4110616022, 1873651.6953397493, 1757728.5748005167, 1676783.9917037333, 1489031.5805332228, 1679002.4251865577, 1518996.1642096404, 1753825.711774449, 1887178.574147601, 1665905.5588050496, 1580675.6656624163, 1465980.5623302704, 1854058.1162515301, 1657311.8515925168, 1794811.2709337953, 1760270.253999665, 1674187.3983066056, 1788481.029815863, 1853039.7733638186, 1747073.944364254, 1639777.4786949689, 1706829.3034688458, 1906531.0452840542, 1849440.0441057198, 1757428.2459868947, 1757610.3068762796, 1430358.7590642031, 1630109.896551072, 1652432.7585349383, 1723507.2411395542, 1632528.6301410072, 1836302.5564759746, 1627906.5477692087, 1846374.016394402, 1684592.5042700756, 1884884.6490028051, 1701809.1436266352, 1726005.0161018653, 1787085.828795328, 1718277.2658209845, 1546241.2084106058, 1775467.534171352, 1780608.7083121776, 1890326.0394053909, 1888364.1018286294, 1766993.2794768326, 1683307.604441011, 1669895.5689851863, 1826969.1048164887, 1924722.6168472716, 1903360.857002695, 1441966.1709164984, 1810170.1743647794, 1751783.3614665926, 1756282.747253863, 1725226.859419856, 1590434.2908184095, 1730913.3544833995, 1605509.7710888973, 1855997.095561399, 1502580.4163390321]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2225265664879235, "mean_inference_ms": 3.095338505925618, "mean_action_processing_ms": 0.15531018434724655, "mean_env_wait_ms": 0.12471547672105984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 6, "timesteps_total": 300300, "agent_timesteps_total": 600600, "timers": {"sample_time_ms": 4099.258, "sample_throughput": 1465.143, "learn_time_ms": 24253.936, "learn_throughput": 247.63, "update_time_ms": 5.902}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5695312500000002, "cur_lr": 5.000000000000002e-05, "total_loss": 23265352638.638298, "policy_loss": -0.0011787239382875726, "vf_loss": 23265352638.638298, "vf_explained_var": 1.0272290040802545e-07, "kl": 0.01795494562371614, "entropy": 2.6890094635334423, "entropy_coeff": 0.0}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.049999999999999975, "cur_lr": 5.000000000000002e-05, "total_loss": 23314887178.893616, "policy_loss": -0.004781592795823483, "vf_loss": 23314887178.893616, "vf_explained_var": -1.0272290040802545e-07, "kl": 0.012699522058221889, "entropy": 2.2073247686345527, "entropy_coeff": 0.0}}}, "num_steps_sampled": 300300, "num_agent_steps_sampled": 600600, "num_steps_trained": 300300, "num_agent_steps_trained": 600600}, "done": false, "episodes_total": 300, "training_iteration": 50, "experiment_id": "65d3188580c6456a98d2b01088581ce7", "date": "2021-06-29_16-44-57", "timestamp": 1624974297, "time_this_iter_s": 25.406440496444702, "time_total_s": 1153.3165123462677, "pid": 3816, "hostname": "hany606", "node_ip": "192.168.0.106", "config": {"num_workers": 6, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 666, "batch_mode": "complete_episodes", "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "predprey", "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 0}], "pol1": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Dict(opponent_action:Box(-1.0, 1.0, (2,), float32), opponent_obs:Box(0.0, 3000.0, (2,), float32), own_obs:Box(0.0, 3000.0, (2,), float32))", "Box(-1.0, 1.0, (2,), float32)", {"agent_id": 1}]}, "policy_mapping_fn": "<function <lambda> at 0x7fe29e443048>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x7fe29e443730>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1153.3165123462677, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 31.685294117647064, "ram_util_percent": 65.32352941176471, "gpu_util_percent0": 0.31794117647058817, "vram_util_percent0": 0.29311643767719425}, "trial_id": "6ed5a_00000"}
