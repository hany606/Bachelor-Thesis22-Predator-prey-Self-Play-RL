{
  "experiment": {
    "experiment_id": "1",
    "experiment_name": "-debug-v5",
    "experiment_log_prefix": "test-",
    "wandb_enable": true,
    "wandb_project": "Behavioral-Learning-Thesis",
    "wandb_group": "self-play",
    "wandb_entity": null,
    "wandb_notes": "Debugging why the graphs are not appearing",
    "env": "SelfPlay1v1-Pred_Prey-v0",
    "log_env_dir_name": "Evorobotpy2",
    "num_workers": 1,
    "num_rounds": 5,
    "population_size": 1,
    "parallel_alternate_training": true,
    "seed_value": 3,
    "framework": "stable_baselines3",
    "hierarchy": "2D:evorobotpy2:predprey:1v1",
    "agents_order": {
      "0": "pred",
      "1": "prey"
    }
  },
  "shared": {
    "sample_after_rollout": false,
    "sample_after_reset": true,
    "opponent_selection": "reverse-cyclic",
    "delta_latest": 2,
    "eval_matrix_method": "length",
    "randomly_reseed_sampling": false,
    "best_agent_search_radius": 5
  },
  "testing": {
    "pred": {
      "path": "/home/hany606/University/Thesis/Drones-PEG-Bachelor-Thesis-2022/2D/experiments/selfplay-results/save-SelfPlay1v1-Pred_Prey-v0-10.31.2021_21.48.46/pred",
      "gens": 0,
      "mode": "round",
      "freq": 1
    },
    "prey": {
      "path": "/home/hany606/University/Thesis/Drones-PEG-Bachelor-Thesis-2022/2D/experiments/selfplay-results/save-SelfPlay1v1-Pred_Prey-v0-10.31.2021_21.48.46/prey",
      "gens": 0,
      "mode": "round",
      "freq": 1
    }
  },
  "agent0": {
    "id": 0,
    "name": "pred",
    "env_class": "SelfPlayPredEnv",
    "opponent_name": "prey",
    "obs": "full",
    "act": "vel",
    "aggregate_eval_matrix": false,
    "num_heatmap_eval_episodes": 2,
    "heatmap_log_freq": 3,
    "eval_matrix_testing_freq": 3,
    "eval_matrix_method": "length",
    "final_save_freq": 3,
    "best_agent_search_radius": 5,
    "num_eval_episodes": 2,
    "num_timesteps": 2000.0,
    "eval_freq": 0,
    "save_freq": 0,
    "eval_metric": "lastreward",
    "eval_opponent_selection": "random",
    "rl_algorithm": "PPO",
    "policy": "MlpPolicy",
    "clip_range": 0.2,
    "ent_coef": 0.0,
    "batch_size": 64,
    "gamma": 0.99,
    "lr": 0.0003,
    "n_epochs": 10,
    "n_steps": 2048,
    "opponent_selection": "reverse-cyclic",
    "training_agent_selection": "latest",
    "delta_latest": 2,
    "num_sampled_opponent_per_round": 10,
    "sample_after_rollout": false,
    "sample_after_reset": true,
    "randomly_reseed_sampling": false
  },
  "agent1": {
    "id": 1,
    "name": "prey",
    "env_class": "SelfPlayPreyEnv",
    "opponent_name": "pred",
    "obs": "full",
    "act": "vel",
    "aggregate_eval_matrix": false,
    "num_heatmap_eval_episodes": 2,
    "heatmap_log_freq": 3,
    "eval_matrix_testing_freq": 3,
    "eval_matrix_method": "length",
    "final_save_freq": 3,
    "best_agent_search_radius": 5,
    "num_eval_episodes": 2,
    "num_timesteps": 2000.0,
    "eval_freq": 0,
    "save_freq": 0,
    "eval_metric": "lastreward",
    "eval_opponent_selection": "random",
    "rl_algorithm": "PPO",
    "policy": "MlpPolicy",
    "clip_range": 0.2,
    "ent_coef": 0.0,
    "batch_size": 64,
    "gamma": 0.99,
    "lr": 0.0003,
    "n_epochs": 10,
    "n_steps": 2048,
    "opponent_selection": "reverse-cyclic",
    "training_agent_selection": "latest",
    "delta_latest": 2,
    "num_sampled_opponent_per_round": 10,
    "sample_after_rollout": false,
    "sample_after_reset": true,
    "randomly_reseed_sampling": false
  }
}